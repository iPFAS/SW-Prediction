{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "current_dir = os.getcwd()  \n",
    "project_root = os.path.dirname(current_dir)  \n",
    "sys.path.insert(0, project_root) \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.data.data_preprocessor import DataPreprocessor\n",
    "from src.config.config import Config\n",
    "data_preprocessor = DataPreprocessor()\n",
    "\n",
    "def detect_and_remove_anomalies(df, target_col, country_col='Country Name', year_col='Year', \n",
    "                               z_threshold=2.0, ratio_threshold=2.0, \n",
    "                               min_years=3, return_anomalies=False):\n",
    "    \"\"\"\n",
    "    检测并移除目标列中的异常值 - 改进版\n",
    "    \n",
    "    参数:\n",
    "    - df: 数据框\n",
    "    - target_col: 目标列名（工业废物量）\n",
    "    - country_col: 国家列名\n",
    "    - year_col: 年份列名\n",
    "    - z_threshold: Z-score阈值，超过此值视为异常\n",
    "    - ratio_threshold: 比值阈值，与相邻年份比值超过此值视为异常\n",
    "    - min_years: 最少需要的年份数据量，少于此值的国家不进行异常检测\n",
    "    - return_anomalies: 是否返回异常值信息\n",
    "    \n",
    "    返回:\n",
    "    - 清洗后的数据框，如果return_anomalies=True，则同时返回异常值信息\n",
    "    \"\"\"\n",
    "    # 复制数据框，避免修改原始数据\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 存储所有异常记录\n",
    "    all_anomalies = pd.DataFrame()\n",
    "    \n",
    "    # 按国家分组处理\n",
    "    for country, country_data in df_clean.groupby(country_col):\n",
    "        # 如果数据量太少，跳过异常检测\n",
    "        if len(country_data) < min_years:\n",
    "            continue\n",
    "            \n",
    "        # 按年份排序\n",
    "        country_data = country_data.sort_values(year_col)\n",
    "        \n",
    "        # 方法1: 基于Z-score的异常检测\n",
    "        z_scores = np.abs((country_data[target_col] - country_data[target_col].mean()) / country_data[target_col].std())\n",
    "        z_anomalies = country_data[z_scores > z_threshold].index\n",
    "        \n",
    "        # 方法2: 基于相邻年份比值的异常检测\n",
    "        country_data_sorted = country_data.sort_values(year_col)\n",
    "        \n",
    "        # 计算与前一年的比值\n",
    "        prev_ratios = country_data_sorted[target_col] / country_data_sorted[target_col].shift(1)\n",
    "        # 计算与后一年的比值\n",
    "        next_ratios = country_data_sorted[target_col] / country_data_sorted[target_col].shift(-1)\n",
    "        \n",
    "        # 找出异常记录\n",
    "        ratio_anomalies = country_data_sorted[\n",
    "            ((prev_ratios > ratio_threshold) | (prev_ratios < 1/ratio_threshold)) & \n",
    "            ((next_ratios > ratio_threshold) | (next_ratios < 1/ratio_threshold))\n",
    "        ].index\n",
    "        \n",
    "        # 方法3: 考虑年份间隔的异常检测\n",
    "        # 计算年份间隔\n",
    "        year_gaps = country_data_sorted[year_col].diff()\n",
    "        # 调整比值阈值，根据年份间隔\n",
    "        adjusted_ratios = prev_ratios / year_gaps\n",
    "        gap_anomalies = country_data_sorted[\n",
    "            (adjusted_ratios > ratio_threshold) & (year_gaps > 1)\n",
    "        ].index\n",
    "        \n",
    "        # 方法4: 基于IQR的异常检测 (新增)\n",
    "        Q1 = country_data[target_col].quantile(0.25)\n",
    "        Q3 = country_data[target_col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        iqr_lower_bound = Q1 - 1.5 * IQR\n",
    "        iqr_upper_bound = Q3 + 1.5 * IQR\n",
    "        iqr_anomalies = country_data[\n",
    "            (country_data[target_col] < iqr_lower_bound) | \n",
    "            (country_data[target_col] > iqr_upper_bound)\n",
    "        ].index\n",
    "        \n",
    "        # 方法5: 基于移动平均的异常检测 (新增)\n",
    "        if len(country_data) >= 5:  # 至少需要5个数据点\n",
    "            # 计算移动平均和标准差\n",
    "            rolling_mean = country_data[target_col].rolling(window=3, min_periods=1).mean()\n",
    "            rolling_std = country_data[target_col].rolling(window=3, min_periods=1).std().fillna(country_data[target_col].std())\n",
    "            \n",
    "            # 检测时间序列异常值\n",
    "            lower_bound = rolling_mean - 2 * rolling_std\n",
    "            upper_bound = rolling_mean + 2 * rolling_std\n",
    "            \n",
    "            # 创建异常值掩码\n",
    "            rolling_anomalies = country_data[\n",
    "                (country_data[target_col] < lower_bound) | \n",
    "                (country_data[target_col] > upper_bound)\n",
    "            ].index\n",
    "        else:\n",
    "            rolling_anomalies = pd.Index([])\n",
    "        \n",
    "        # 方法6: 基于增长率的异常检测 (新增)\n",
    "        # 计算年增长率\n",
    "        growth_rates = country_data[target_col].pct_change() * 100\n",
    "        # 异常增长率阈值 (例如超过50%或下降超过30%)\n",
    "        growth_anomalies = country_data[\n",
    "            (growth_rates > 50) | (growth_rates < -30)\n",
    "        ].index\n",
    "        \n",
    "        # 综合多种方法，确定最终的异常值\n",
    "        # 使用投票机制：至少被两种方法判定为异常的记录\n",
    "        anomaly_counts = {}\n",
    "        for idx in set(z_anomalies) | set(ratio_anomalies) | set(gap_anomalies) | set(iqr_anomalies) | set(rolling_anomalies) | set(growth_anomalies):\n",
    "            anomaly_counts[idx] = 0\n",
    "            if idx in z_anomalies: anomaly_counts[idx] += 1\n",
    "            if idx in ratio_anomalies: anomaly_counts[idx] += 1\n",
    "            if idx in gap_anomalies: anomaly_counts[idx] += 1\n",
    "            if idx in iqr_anomalies: anomaly_counts[idx] += 1\n",
    "            if idx in rolling_anomalies: anomaly_counts[idx] += 1\n",
    "            if idx in growth_anomalies: anomaly_counts[idx] += 1\n",
    "        \n",
    "        # 至少被两种方法判定为异常\n",
    "        anomaly_indices = [idx for idx, count in anomaly_counts.items() if count >= 2]\n",
    "        \n",
    "        if anomaly_indices and return_anomalies:\n",
    "            # 收集异常记录信息\n",
    "            anomalies = country_data.loc[anomaly_indices].copy()\n",
    "            anomalies['z_score'] = z_scores.loc[anomaly_indices]\n",
    "            anomalies['prev_ratio'] = prev_ratios.loc[anomaly_indices]\n",
    "            anomalies['next_ratio'] = next_ratios.loc[anomaly_indices]\n",
    "            anomalies['year_gap'] = year_gaps.loc[anomaly_indices]\n",
    "            # 添加新的异常检测指标\n",
    "            anomalies['iqr_lower'] = iqr_lower_bound\n",
    "            anomalies['iqr_upper'] = iqr_upper_bound\n",
    "            if len(country_data) >= 5:\n",
    "                anomalies['rolling_lower'] = lower_bound.loc[anomaly_indices]\n",
    "                anomalies['rolling_upper'] = upper_bound.loc[anomaly_indices]\n",
    "            anomalies['growth_rate'] = growth_rates.loc[anomaly_indices]\n",
    "            anomalies['anomaly_methods'] = [anomaly_counts[idx] for idx in anomaly_indices]\n",
    "            all_anomalies = pd.concat([all_anomalies, anomalies])\n",
    "        \n",
    "        # 从清洗数据中移除异常值\n",
    "        df_clean = df_clean.drop(anomaly_indices)\n",
    "    \n",
    "    if return_anomalies:\n",
    "        return df_clean, all_anomalies\n",
    "    else:\n",
    "        return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"加载1990-2022数据\"\"\"\n",
    "historical_df = pd.read_excel(\n",
    "    Config.FEATURE_CONFIG['historical_data_path'],\n",
    "    sheet_name=Config.FEATURE_CONFIG['historical_sheet'],\n",
    "    usecols=Config.FEATURE_CONFIG['usecols'] \n",
    ")\n",
    "\n",
    "historical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"执行完整处理流程\"\"\"\n",
    "# 第一阶段：处理历史数据\n",
    "all_countries_df = data_preprocessor.process_historical_data(historical_df)\n",
    "features_path = Path(Config.PATH_CONFIG['features_dir']) / 'global_features.csv'\n",
    "all_countries_df.to_csv(features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二阶段：处理MSW数据\n",
    "\"\"\"加载包含MSW的目标数据\"\"\"\n",
    "msw_df = pd.read_excel(\n",
    "    Config.FEATURE_CONFIG['historical_msw_data_path'],\n",
    "    sheet_name=Config.FEATURE_CONFIG['historical_msw_sheet'],\n",
    "    usecols=Config.FEATURE_CONFIG['usecols'] + [Config.DATA_CONFIG['target_column']]\n",
    ")\n",
    "\n",
    "# 先检测异常值但不移除，查看异常值情况\n",
    "target_col = Config.DATA_CONFIG['target_column']\n",
    "_, anomalies = detect_and_remove_anomalies(msw_df, target_col, return_anomalies=True)\n",
    "print(f\"检测到 {len(anomalies)} 条异常记录:\")\n",
    "print(f\"检测到 {len(anomalies)} 条异常记录:\")\n",
    "if len(anomalies) > 0:\n",
    "    display(anomalies.sort_values(['Country Name', 'Year']))\n",
    "else:\n",
    "    print(\"没有检测到异常记录\")\n",
    "\n",
    "# 分析每个国家数据的分布情况\n",
    "print(\"\\n===== 各国数据分布情况分析 =====\")\n",
    "for country, country_data in msw_df.groupby('Country Name'):\n",
    "    if len(country_data) < 3:  # 跳过数据量太少的国家\n",
    "        continue\n",
    "        \n",
    "    country_data = country_data.sort_values('Year')\n",
    "    \n",
    "    # 计算Z-score\n",
    "    z_scores = np.abs((country_data[target_col] - country_data[target_col].mean()) / country_data[target_col].std())\n",
    "    \n",
    "    # 计算年度增长比例\n",
    "    growth_ratios = country_data[target_col].pct_change()\n",
    "    \n",
    "    print(f\"\\n国家: {country}, 数据点数: {len(country_data)}\")\n",
    "    print(f\"平均值: {country_data[target_col].mean():.2f}, 标准差: {country_data[target_col].std():.2f}\")\n",
    "    print(f\"最大Z-score: {z_scores.max():.2f}\")\n",
    "    print(f\"最大年度增长率: {growth_ratios.max():.2%}\")\n",
    "    print(f\"最小年度增长率: {growth_ratios.min():.2%}\")\n",
    "    \n",
    "    # 显示可能的异常点\n",
    "    potential_anomalies = country_data[(z_scores > 2.0) | (growth_ratios > 0.5) | (growth_ratios < -0.3)]\n",
    "    if len(potential_anomalies) > 0:\n",
    "        print(\"潜在异常点:\")\n",
    "        display(potential_anomalies[['Year', target_col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = detect_and_remove_anomalies(msw_df, target_col)\n",
    "print(f\"原始数据: {len(msw_df)} 行, 清洗后: {len(df_clean)} 行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, predict_df = data_preprocessor.merge_features(df_clean)\n",
    "print(f\"用于训练的数据: {len(train_df)} 行, 预测的历史数据: {len(predict_df)} 行, 总共: {len(train_df)+len(predict_df)}行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最终数据集\n",
    "train_df.to_csv(\n",
    "    Path(Config.PATH_CONFIG['features_dir']) / 'training_data.csv', \n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "predict_df.to_csv(\n",
    "    Path(Config.PATH_CONFIG['features_dir']) / 'prediction_data.csv', \n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "历史数据最后一年: 2022\n",
      "过滤前未来数据形状: (66755, 9)\n",
      "过滤掉年份 <= 2022 后，未来数据形状: (65910, 9)\n",
      "加载特征工程参数从: e:\\code\\jupyter\\固废产生\\SW-Prediction\\iw\\src\\features\\featurefile\\feature_params.pkl\n",
      "特征工程参数已从 e:\\code\\jupyter\\固废产生\\SW-Prediction\\iw\\src\\features\\featurefile\\feature_params.pkl 加载\n",
      "合并历史数据和未来数据...\n",
      "合并后数据形状: (71341, 9)\n",
      "按国家和年份排序...\n",
      "应用特征工程转换...\n",
      "开始 Transform 过程...\n",
      "应用对数变换...\n",
      "...已生成: GDP PPP 2017_log\n",
      "...已生成: GDP PPP/capita 2017_log\n",
      "...已生成: Population_log\n",
      "创建非线性特征...\n",
      "...已生成: gdp_pc_log_squared\n",
      "创建时间特征...\n",
      "...已生成: year_relative (基准年: 1990)\n",
      "计算增长率...\n",
      "...已生成: GDP PPP 2017_log_growth_1y\n",
      "...已生成: Population_log_growth_1y\n",
      "处理城市化率...\n",
      "...已生成: urban_pop_perc\n",
      "创建交互特征...\n",
      "...已生成: gdp_log_x_pop_log\n",
      "...已生成: gdp_pc_log_x_urban\n",
      "...已生成: gdp_pc_log2_x_urban\n",
      "创建时间相关的交互特征...\n",
      "...已生成: year_relative_x_gdp_pc_log\n",
      "...已生成: year_relative_x_Population_log\n",
      "...已生成: year_relative_x_urban_pop_perc\n",
      "处理缺失值和无穷值...\n",
      "...正在使用中位数填充NaN值...\n",
      "...填充完成，共处理了 0 个 NaN 值。\n",
      "裁剪极端数值...\n",
      "Transform 过程完成。\n",
      "特征转换后数据形状: (71341, 23)\n",
      "筛选未来数据...\n",
      "筛选出的未来数据形状: (65910, 23)\n",
      "按场景拆分并保存未来特征文件...\n",
      "  处理场景: SSP1\n",
      "    已保存场景 'SSP1' 的处理后特征 (13182 行) 至: e:\\code\\jupyter\\固废产生\\SW-Prediction\\iw\\src\\features\\featurefile\\future_features_SSP1.csv\n",
      "  处理场景: SSP2\n",
      "    已保存场景 'SSP2' 的处理后特征 (13182 行) 至: e:\\code\\jupyter\\固废产生\\SW-Prediction\\iw\\src\\features\\featurefile\\future_features_SSP2.csv\n",
      "  处理场景: SSP3\n",
      "    已保存场景 'SSP3' 的处理后特征 (13182 行) 至: e:\\code\\jupyter\\固废产生\\SW-Prediction\\iw\\src\\features\\featurefile\\future_features_SSP3.csv\n",
      "  处理场景: SSP4\n",
      "    已保存场景 'SSP4' 的处理后特征 (13182 行) 至: e:\\code\\jupyter\\固废产生\\SW-Prediction\\iw\\src\\features\\featurefile\\future_features_SSP4.csv\n",
      "  处理场景: SSP5\n",
      "    已保存场景 'SSP5' 的处理后特征 (13182 行) 至: e:\\code\\jupyter\\固废产生\\SW-Prediction\\iw\\src\\features\\featurefile\\future_features_SSP5.csv\n",
      "\n",
      "未来数据特征生成完成。\n",
      "未来数据特征生成完成。各场景文件路径:\n",
      "{'SSP1': WindowsPath('e:/code/jupyter/固废产生/SW-Prediction/iw/src/features/featurefile/future_features_SSP1.csv'), 'SSP2': WindowsPath('e:/code/jupyter/固废产生/SW-Prediction/iw/src/features/featurefile/future_features_SSP2.csv'), 'SSP3': WindowsPath('e:/code/jupyter/固废产生/SW-Prediction/iw/src/features/featurefile/future_features_SSP3.csv'), 'SSP4': WindowsPath('e:/code/jupyter/固废产生/SW-Prediction/iw/src/features/featurefile/future_features_SSP4.csv'), 'SSP5': WindowsPath('e:/code/jupyter/固废产生/SW-Prediction/iw/src/features/featurefile/future_features_SSP5.csv')}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"加载2022-2050数据\"\"\"\n",
    "future_df = pd.read_excel(\n",
    "    Config.FEATURE_CONFIG['future_data_path'],\n",
    "    sheet_name=Config.FEATURE_CONFIG['future_sheet'],\n",
    "    usecols=Config.FEATURE_CONFIG['usecols']+['Scenario']\n",
    ")\n",
    "\n",
    "\"\"\"加载1990-2022数据\"\"\"\n",
    "historical_df = pd.read_excel(\n",
    "    Config.FEATURE_CONFIG['historical_data_path'],\n",
    "    sheet_name=Config.FEATURE_CONFIG['historical_sheet'],\n",
    "    usecols=Config.FEATURE_CONFIG['usecols']\n",
    ")\n",
    "\n",
    "# !! 新增：在调用处理函数前，预先移除未来数据中与历史数据重叠的年份 !!\n",
    "last_historical_year = historical_df['Year'].max()\n",
    "print(f\"历史数据最后一年: {last_historical_year}\")\n",
    "print(f\"过滤前未来数据形状: {future_df.shape}\")\n",
    "\n",
    "future_df_filtered = future_df[future_df['Year'] > last_historical_year].copy()\n",
    "print(f\"过滤掉年份 <= {last_historical_year} 后，未来数据形状: {future_df_filtered.shape}\")\n",
    "\n",
    "# 检查过滤后是否还有数据\n",
    "if future_df_filtered.empty:\n",
    "    print(\"错误：过滤重叠年份后，没有有效的未来数据。请检查数据范围。\")\n",
    "    # 可以选择退出或抛出异常\n",
    "    # sys.exit(1) \n",
    "else:\n",
    "    # 使用过滤后的 future_df 调用处理函数\n",
    "    processed_data_paths = data_preprocessor.process_future_data(historical_df, future_df_filtered)\n",
    "    print(\"未来数据特征生成完成。各场景文件路径:\")\n",
    "    print(processed_data_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret3.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
