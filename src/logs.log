2025-03-19 19:23:36,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:36,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:36,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:36,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:36,471:INFO:Initializing load_model()
2025-03-19 19:23:36,471:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:23:37,027:INFO:Initializing predict_model()
2025-03-19 19:23:37,027:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212AAE0FF10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000212AAFF5B80>)
2025-03-19 19:23:37,027:INFO:Checking exceptions
2025-03-19 19:23:37,027:INFO:Preloading libraries
2025-03-19 19:23:37,028:INFO:Set up data.
2025-03-19 19:23:37,034:INFO:Set up index.
2025-03-19 19:23:54,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:54,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:54,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:54,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:23:54,723:INFO:Initializing load_model()
2025-03-19 19:23:54,723:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:23:55,309:INFO:Initializing predict_model()
2025-03-19 19:23:55,309:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000012ABC48E700>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000012ABC6A5B80>)
2025-03-19 19:23:55,309:INFO:Checking exceptions
2025-03-19 19:23:55,309:INFO:Preloading libraries
2025-03-19 19:23:55,309:INFO:Set up data.
2025-03-19 19:23:55,317:INFO:Set up index.
2025-03-19 19:23:55,431:INFO:Initializing load_model()
2025-03-19 19:23:55,431:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:23:55,461:INFO:Initializing predict_model()
2025-03-19 19:23:55,461:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000012ABD3E8FA0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000012ABC6A5AF0>)
2025-03-19 19:23:55,461:INFO:Checking exceptions
2025-03-19 19:23:55,461:INFO:Preloading libraries
2025-03-19 19:23:55,461:INFO:Set up data.
2025-03-19 19:23:55,467:INFO:Set up index.
2025-03-19 19:23:58,564:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:25:09,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:25:09,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:25:09,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:25:09,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:25:10,100:INFO:Initializing load_model()
2025-03-19 19:25:10,101:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:25:10,696:INFO:Initializing predict_model()
2025-03-19 19:25:10,696:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B524838D60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B5091D4B80>)
2025-03-19 19:25:10,697:INFO:Checking exceptions
2025-03-19 19:25:10,697:INFO:Preloading libraries
2025-03-19 19:25:10,697:INFO:Set up data.
2025-03-19 19:25:10,702:INFO:Set up index.
2025-03-19 19:25:10,804:INFO:Initializing load_model()
2025-03-19 19:25:10,804:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:25:10,835:INFO:Initializing predict_model()
2025-03-19 19:25:10,835:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B524838D60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B5091D49D0>)
2025-03-19 19:25:10,836:INFO:Checking exceptions
2025-03-19 19:25:10,836:INFO:Preloading libraries
2025-03-19 19:25:10,836:INFO:Set up data.
2025-03-19 19:25:10,842:INFO:Set up index.
2025-03-19 19:25:14,265:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:26:19,837:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:29:32,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:29:32,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:29:32,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:29:32,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:29:32,776:INFO:Initializing load_model()
2025-03-19 19:29:32,776:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:29:33,387:INFO:Initializing predict_model()
2025-03-19 19:29:33,387:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029790ECE820>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000297910D4B80>)
2025-03-19 19:29:33,387:INFO:Checking exceptions
2025-03-19 19:29:33,387:INFO:Preloading libraries
2025-03-19 19:29:33,388:INFO:Set up data.
2025-03-19 19:29:33,395:INFO:Set up index.
2025-03-19 19:29:33,490:INFO:Initializing load_model()
2025-03-19 19:29:33,490:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:29:33,531:INFO:Initializing predict_model()
2025-03-19 19:29:33,531:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297AC768E20>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000297910D4AF0>)
2025-03-19 19:29:33,531:INFO:Checking exceptions
2025-03-19 19:29:33,531:INFO:Preloading libraries
2025-03-19 19:29:33,531:INFO:Set up data.
2025-03-19 19:29:33,540:INFO:Set up index.
2025-03-19 19:29:36,993:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:30:42,114:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:31:08,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:08,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:08,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:08,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:08,594:INFO:Initializing load_model()
2025-03-19 19:31:08,594:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:31:09,194:INFO:Initializing predict_model()
2025-03-19 19:31:09,194:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001993D61BD90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001993D674B80>)
2025-03-19 19:31:09,194:INFO:Checking exceptions
2025-03-19 19:31:09,194:INFO:Preloading libraries
2025-03-19 19:31:09,194:INFO:Set up data.
2025-03-19 19:31:09,201:INFO:Set up index.
2025-03-19 19:31:09,300:INFO:Initializing load_model()
2025-03-19 19:31:09,300:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:31:09,330:INFO:Initializing predict_model()
2025-03-19 19:31:09,330:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019957BAEFA0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001993D674AF0>)
2025-03-19 19:31:09,330:INFO:Checking exceptions
2025-03-19 19:31:09,330:INFO:Preloading libraries
2025-03-19 19:31:09,330:INFO:Set up data.
2025-03-19 19:31:09,337:INFO:Set up index.
2025-03-19 19:31:12,772:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:31:52,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:52,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:52,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:52,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:31:52,203:INFO:Initializing load_model()
2025-03-19 19:31:52,203:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:31:52,860:INFO:Initializing predict_model()
2025-03-19 19:31:52,860:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001718A1EE160>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001718A3D5AF0>)
2025-03-19 19:31:52,860:INFO:Checking exceptions
2025-03-19 19:31:52,860:INFO:Preloading libraries
2025-03-19 19:31:52,861:INFO:Set up data.
2025-03-19 19:31:52,868:INFO:Set up index.
2025-03-19 19:31:52,968:INFO:Initializing load_model()
2025-03-19 19:31:52,968:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:31:53,009:INFO:Initializing predict_model()
2025-03-19 19:31:53,010:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001718A427100>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001718A3D5A60>)
2025-03-19 19:31:53,010:INFO:Checking exceptions
2025-03-19 19:31:53,010:INFO:Preloading libraries
2025-03-19 19:31:53,010:INFO:Set up data.
2025-03-19 19:31:53,019:INFO:Set up index.
2025-03-19 19:31:56,502:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:31:58,778:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:111: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:35:47,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:35:47,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:35:47,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:35:47,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 19:35:47,949:INFO:Initializing load_model()
2025-03-19 19:35:47,949:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:35:48,526:INFO:Initializing predict_model()
2025-03-19 19:35:48,526:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002337EE2FF70>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002337F052AF0>)
2025-03-19 19:35:48,526:INFO:Checking exceptions
2025-03-19 19:35:48,526:INFO:Preloading libraries
2025-03-19 19:35:48,526:INFO:Set up data.
2025-03-19 19:35:48,532:INFO:Set up index.
2025-03-19 19:35:48,624:INFO:Initializing load_model()
2025-03-19 19:35:48,624:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 19:35:48,661:INFO:Initializing predict_model()
2025-03-19 19:35:48,661:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002337EE2FF70>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_std_5y',
                                             'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_trend_interaction',
                                             'gdp_trend_log_interaction',
                                             'log_gdp_per_capita',
                                             'gdp_per_capi...
                                                                    random_state=888)),
                                             ('Gradient Boosting Regressor',
                                              GradientBoostingRegressor(learning_rate=0.10207159291326559,
                                                                        max_depth=6,
                                                                        max_features=0.6843072946535471,
                                                                        min_impurity_decrease=7.766049343150833e-06,
                                                                        min_samples_split=7,
                                                                        n_estimators=154,
                                                                        random_state=888,
                                                                        subsample=0.5419873891136111)),
                                             ('Decision Tree Regressor',
                                              DecisionTreeRegressor(random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002337F052A60>)
2025-03-19 19:35:48,661:INFO:Checking exceptions
2025-03-19 19:35:48,661:INFO:Preloading libraries
2025-03-19 19:35:48,661:INFO:Set up data.
2025-03-19 19:35:48,669:INFO:Set up index.
2025-03-19 19:35:52,166:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:118: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 19:35:54,338:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:118: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 21:07:13,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:07:13,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:07:13,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:07:13,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:07:13,560:INFO:Initializing load_model()
2025-03-19 21:07:13,560:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_191610, platform=None, authentication=None, verbose=True)
2025-03-19 21:08:04,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:08:04,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:08:04,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:08:04,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:08:05,058:INFO:Initializing load_model()
2025-03-19 21:08:05,058:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250319_195717, platform=None, authentication=None, verbose=True)
2025-03-19 21:08:05,578:INFO:Initializing predict_model()
2025-03-19 21:08:05,579:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CB81F94070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_15y_ma',
                                             'gdp_std_5y', 'gdp_std_10y',
                                             'gdp_std_15y', 'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_volatility_5y',
                                             'gdp_volatility_10y',
                                             'gdp...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.10765632912615021,
                                           max_depth=6,
                                           max_features=0.9299620530924891,
                                           min_impurity_decrease=0.0687590885246824,
                                           min_samples_leaf=2,
                                           min_samples_split=3,
                                           n_estimators=158, random_state=888,
                                           subsample=0.23433482263448735))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CBE854E700>)
2025-03-19 21:08:05,579:INFO:Checking exceptions
2025-03-19 21:08:05,579:INFO:Preloading libraries
2025-03-19 21:08:05,579:INFO:Set up data.
2025-03-19 21:08:05,584:INFO:Set up index.
2025-03-19 21:08:05,640:INFO:Initializing load_model()
2025-03-19 21:08:05,640:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250319_195717, platform=None, authentication=None, verbose=True)
2025-03-19 21:08:05,650:INFO:Initializing predict_model()
2025-03-19 21:08:05,650:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CBE75AE880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_15y_ma',
                                             'gdp_std_5y', 'gdp_std_10y',
                                             'gdp_std_15y', 'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_volatility_5y',
                                             'gdp_volatility_10y',
                                             'gdp...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.10765632912615021,
                                           max_depth=6,
                                           max_features=0.9299620530924891,
                                           min_impurity_decrease=0.0687590885246824,
                                           min_samples_leaf=2,
                                           min_samples_split=3,
                                           n_estimators=158, random_state=888,
                                           subsample=0.23433482263448735))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CBE7AF3040>)
2025-03-19 21:08:05,650:INFO:Checking exceptions
2025-03-19 21:08:05,650:INFO:Preloading libraries
2025-03-19 21:08:05,650:INFO:Set up data.
2025-03-19 21:08:05,655:INFO:Set up index.
2025-03-19 21:08:09,088:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:118: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 21:08:11,203:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:118: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 21:28:17,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:17,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:17,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:17,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:17,489:INFO:Initializing load_model()
2025-03-19 21:28:17,489:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_212155, platform=None, authentication=None, verbose=True)
2025-03-19 21:28:18,183:INFO:Initializing predict_model()
2025-03-19 21:28:18,183:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021D88E4ACD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_15y_ma',
                                             'gdp_std_5y', 'gdp_std_10y',
                                             'gdp_std_15y', 'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_volatility_5y',
                                             'gdp_volatility_10y',
                                             'gdp...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07427738302912393,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=5,
                                                           max_leaves=None,
                                                           min_child_weight=1,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=123,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021DED536AF0>)
2025-03-19 21:28:18,183:INFO:Checking exceptions
2025-03-19 21:28:18,183:INFO:Preloading libraries
2025-03-19 21:28:18,183:INFO:Set up data.
2025-03-19 21:28:18,239:INFO:Set up index.
2025-03-19 21:28:47,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:47,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:47,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:47,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 21:28:47,877:INFO:Initializing load_model()
2025-03-19 21:28:47,877:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_212155, platform=None, authentication=None, verbose=True)
2025-03-19 21:28:48,731:INFO:Initializing predict_model()
2025-03-19 21:28:48,731:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C5A87FBFA0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_15y_ma',
                                             'gdp_std_5y', 'gdp_std_10y',
                                             'gdp_std_15y', 'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_volatility_5y',
                                             'gdp_volatility_10y',
                                             'gdp...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07427738302912393,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=5,
                                                           max_leaves=None,
                                                           min_child_weight=1,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=123,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C58E0E78B0>)
2025-03-19 21:28:48,731:INFO:Checking exceptions
2025-03-19 21:28:48,731:INFO:Preloading libraries
2025-03-19 21:28:48,732:INFO:Set up data.
2025-03-19 21:28:48,739:INFO:Set up index.
2025-03-19 21:28:48,855:INFO:Initializing load_model()
2025-03-19 21:28:48,855:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250319_212155, platform=None, authentication=None, verbose=True)
2025-03-19 21:28:48,950:INFO:Initializing predict_model()
2025-03-19 21:28:48,950:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C5A87FBFA0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_15y_ma',
                                             'gdp_std_5y', 'gdp_std_10y',
                                             'gdp_std_15y', 'gdp_cagr',
                                             'gdp_cumulative_growth',
                                             'gdp_volatility_5y',
                                             'gdp_volatility_10y',
                                             'gdp...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07427738302912393,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=5,
                                                           max_leaves=None,
                                                           min_child_weight=1,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=123,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C58E113040>)
2025-03-19 21:28:48,950:INFO:Checking exceptions
2025-03-19 21:28:48,950:INFO:Preloading libraries
2025-03-19 21:28:48,951:INFO:Set up data.
2025-03-19 21:28:48,958:INFO:Set up index.
2025-03-19 21:28:52,480:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:118: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-19 21:28:54,609:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:118: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 17:07:57,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:07:57,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:07:57,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:07:57,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:08:20,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:08:20,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:08:20,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:08:20,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:15:51,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:15:51,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:15:51,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:15:51,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:20:52,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:20:52,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:20:52,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:20:52,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:33,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:33,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:33,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:33,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:59,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:59,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:59,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:25:59,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:29:56,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:29:56,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:29:56,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:29:56,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:34:46,026:INFO:PyCaret RegressionExperiment
2025-03-20 17:34:46,027:INFO:Logging name: reg-default-name
2025-03-20 17:34:46,027:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 17:34:46,027:INFO:version 3.2.0
2025-03-20 17:34:46,027:INFO:Initializing setup()
2025-03-20 17:34:46,027:INFO:self.USI: d979
2025-03-20 17:34:46,027:INFO:self._variable_keys: {'X_test', 'transform_target_param', 'gpu_n_jobs_param', 'logging_param', 'data', 'y', 'seed', 'fold_generator', 'USI', 'y_train', 'y_test', 'idx', 'pipeline', 'X_train', 'n_jobs_param', 'target_param', 'fold_shuffle_param', 'memory', 'exp_name_log', 'fold_groups_param', '_available_plots', 'log_plots_param', 'html_param', '_ml_usecase', 'gpu_param', 'exp_id', 'X'}
2025-03-20 17:34:46,027:INFO:Checking environment
2025-03-20 17:34:46,027:INFO:python_version: 3.8.20
2025-03-20 17:34:46,027:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 17:34:46,027:INFO:machine: AMD64
2025-03-20 17:34:46,027:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 17:34:46,040:INFO:Memory: svmem(total=68447973376, available=40465154048, percent=40.9, used=27982819328, free=40465154048)
2025-03-20 17:34:46,040:INFO:Physical Core: 24
2025-03-20 17:34:46,040:INFO:Logical Core: 32
2025-03-20 17:34:46,040:INFO:Checking libraries
2025-03-20 17:34:46,040:INFO:System:
2025-03-20 17:34:46,040:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 17:34:46,040:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 17:34:46,040:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 17:34:46,040:INFO:PyCaret required dependencies:
2025-03-20 17:34:46,586:INFO:                 pip: 24.2
2025-03-20 17:34:46,586:INFO:          setuptools: 75.1.0
2025-03-20 17:34:46,586:INFO:             pycaret: 3.2.0
2025-03-20 17:34:46,586:INFO:             IPython: 8.12.3
2025-03-20 17:34:46,586:INFO:          ipywidgets: 8.1.5
2025-03-20 17:34:46,586:INFO:                tqdm: 4.67.1
2025-03-20 17:34:46,586:INFO:               numpy: 1.24.4
2025-03-20 17:34:46,586:INFO:              pandas: 1.5.3
2025-03-20 17:34:46,586:INFO:              jinja2: 3.1.4
2025-03-20 17:34:46,586:INFO:               scipy: 1.10.1
2025-03-20 17:34:46,586:INFO:              joblib: 1.3.2
2025-03-20 17:34:46,586:INFO:             sklearn: 1.2.2
2025-03-20 17:34:46,587:INFO:                pyod: 2.0.2
2025-03-20 17:34:46,587:INFO:            imblearn: 0.12.4
2025-03-20 17:34:46,587:INFO:   category_encoders: 2.6.4
2025-03-20 17:34:46,587:INFO:            lightgbm: 4.5.0
2025-03-20 17:34:46,587:INFO:               numba: 0.58.1
2025-03-20 17:34:46,587:INFO:            requests: 2.32.3
2025-03-20 17:34:46,587:INFO:          matplotlib: 3.6.0
2025-03-20 17:34:46,587:INFO:          scikitplot: 0.3.7
2025-03-20 17:34:46,587:INFO:         yellowbrick: 1.5
2025-03-20 17:34:46,587:INFO:              plotly: 5.24.1
2025-03-20 17:34:46,587:INFO:    plotly-resampler: Not installed
2025-03-20 17:34:46,587:INFO:             kaleido: 0.2.1
2025-03-20 17:34:46,587:INFO:           schemdraw: 0.15
2025-03-20 17:34:46,587:INFO:         statsmodels: 0.14.1
2025-03-20 17:34:46,587:INFO:              sktime: 0.21.1
2025-03-20 17:34:46,587:INFO:               tbats: 1.1.3
2025-03-20 17:34:46,587:INFO:            pmdarima: 2.0.4
2025-03-20 17:34:46,587:INFO:              psutil: 6.1.0
2025-03-20 17:34:46,587:INFO:          markupsafe: 2.1.5
2025-03-20 17:34:46,587:INFO:             pickle5: Not installed
2025-03-20 17:34:46,587:INFO:         cloudpickle: 2.2.1
2025-03-20 17:34:46,587:INFO:         deprecation: 2.1.0
2025-03-20 17:34:46,587:INFO:              xxhash: 3.5.0
2025-03-20 17:34:46,587:INFO:           wurlitzer: Not installed
2025-03-20 17:34:46,587:INFO:PyCaret optional dependencies:
2025-03-20 17:34:47,904:INFO:                shap: 0.44.1
2025-03-20 17:34:47,904:INFO:           interpret: 0.6.6
2025-03-20 17:34:47,904:INFO:                umap: 0.5.7
2025-03-20 17:34:47,904:INFO:     ydata_profiling: 4.6.0
2025-03-20 17:34:47,904:INFO:  explainerdashboard: 0.4.7
2025-03-20 17:34:47,904:INFO:             autoviz: Not installed
2025-03-20 17:34:47,904:INFO:           fairlearn: 0.7.0
2025-03-20 17:34:47,904:INFO:          deepchecks: Not installed
2025-03-20 17:34:47,904:INFO:             xgboost: 2.1.3
2025-03-20 17:34:47,904:INFO:            catboost: 1.2.7
2025-03-20 17:34:47,904:INFO:              kmodes: 0.12.2
2025-03-20 17:34:47,904:INFO:             mlxtend: 0.23.1
2025-03-20 17:34:47,905:INFO:       statsforecast: 1.5.0
2025-03-20 17:34:47,905:INFO:        tune_sklearn: 0.5.0
2025-03-20 17:34:47,905:INFO:                 ray: 2.10.0
2025-03-20 17:34:47,905:INFO:            hyperopt: 0.2.7
2025-03-20 17:34:47,905:INFO:              optuna: 4.1.0
2025-03-20 17:34:47,905:INFO:               skopt: 0.10.2
2025-03-20 17:34:47,905:INFO:              mlflow: 1.30.1
2025-03-20 17:34:47,905:INFO:              gradio: 3.50.2
2025-03-20 17:34:47,905:INFO:             fastapi: 0.115.5
2025-03-20 17:34:47,905:INFO:             uvicorn: 0.32.1
2025-03-20 17:34:47,905:INFO:              m2cgen: 0.10.0
2025-03-20 17:34:47,905:INFO:           evidently: 0.2.8
2025-03-20 17:34:47,905:INFO:               fugue: 0.8.6
2025-03-20 17:34:47,905:INFO:           streamlit: Not installed
2025-03-20 17:34:47,905:INFO:             prophet: Not installed
2025-03-20 17:34:47,905:INFO:None
2025-03-20 17:34:47,905:INFO:Set up data.
2025-03-20 17:35:10,620:INFO:PyCaret RegressionExperiment
2025-03-20 17:35:10,621:INFO:Logging name: reg-default-name
2025-03-20 17:35:10,621:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 17:35:10,621:INFO:version 3.2.0
2025-03-20 17:35:10,621:INFO:Initializing setup()
2025-03-20 17:35:10,621:INFO:self.USI: dd34
2025-03-20 17:35:10,621:INFO:self._variable_keys: {'X_test', 'transform_target_param', 'gpu_n_jobs_param', 'logging_param', 'data', 'y', 'seed', 'fold_generator', 'USI', 'y_train', 'y_test', 'idx', 'pipeline', 'X_train', 'n_jobs_param', 'target_param', 'fold_shuffle_param', 'memory', 'exp_name_log', 'fold_groups_param', '_available_plots', 'log_plots_param', 'html_param', '_ml_usecase', 'gpu_param', 'exp_id', 'X'}
2025-03-20 17:35:10,621:INFO:Checking environment
2025-03-20 17:35:10,621:INFO:python_version: 3.8.20
2025-03-20 17:35:10,621:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 17:35:10,621:INFO:machine: AMD64
2025-03-20 17:35:10,621:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 17:35:10,634:INFO:Memory: svmem(total=68447973376, available=40526524416, percent=40.8, used=27921448960, free=40526524416)
2025-03-20 17:35:10,634:INFO:Physical Core: 24
2025-03-20 17:35:10,634:INFO:Logical Core: 32
2025-03-20 17:35:10,634:INFO:Checking libraries
2025-03-20 17:35:10,634:INFO:System:
2025-03-20 17:35:10,634:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 17:35:10,634:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 17:35:10,634:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 17:35:10,634:INFO:PyCaret required dependencies:
2025-03-20 17:35:10,634:INFO:                 pip: 24.2
2025-03-20 17:35:10,634:INFO:          setuptools: 75.1.0
2025-03-20 17:35:10,634:INFO:             pycaret: 3.2.0
2025-03-20 17:35:10,635:INFO:             IPython: 8.12.3
2025-03-20 17:35:10,635:INFO:          ipywidgets: 8.1.5
2025-03-20 17:35:10,635:INFO:                tqdm: 4.67.1
2025-03-20 17:35:10,635:INFO:               numpy: 1.24.4
2025-03-20 17:35:10,635:INFO:              pandas: 1.5.3
2025-03-20 17:35:10,635:INFO:              jinja2: 3.1.4
2025-03-20 17:35:10,635:INFO:               scipy: 1.10.1
2025-03-20 17:35:10,635:INFO:              joblib: 1.3.2
2025-03-20 17:35:10,635:INFO:             sklearn: 1.2.2
2025-03-20 17:35:10,635:INFO:                pyod: 2.0.2
2025-03-20 17:35:10,635:INFO:            imblearn: 0.12.4
2025-03-20 17:35:10,635:INFO:   category_encoders: 2.6.4
2025-03-20 17:35:10,635:INFO:            lightgbm: 4.5.0
2025-03-20 17:35:10,635:INFO:               numba: 0.58.1
2025-03-20 17:35:10,635:INFO:            requests: 2.32.3
2025-03-20 17:35:10,635:INFO:          matplotlib: 3.6.0
2025-03-20 17:35:10,635:INFO:          scikitplot: 0.3.7
2025-03-20 17:35:10,635:INFO:         yellowbrick: 1.5
2025-03-20 17:35:10,635:INFO:              plotly: 5.24.1
2025-03-20 17:35:10,635:INFO:    plotly-resampler: Not installed
2025-03-20 17:35:10,635:INFO:             kaleido: 0.2.1
2025-03-20 17:35:10,635:INFO:           schemdraw: 0.15
2025-03-20 17:35:10,635:INFO:         statsmodels: 0.14.1
2025-03-20 17:35:10,635:INFO:              sktime: 0.21.1
2025-03-20 17:35:10,635:INFO:               tbats: 1.1.3
2025-03-20 17:35:10,635:INFO:            pmdarima: 2.0.4
2025-03-20 17:35:10,635:INFO:              psutil: 6.1.0
2025-03-20 17:35:10,635:INFO:          markupsafe: 2.1.5
2025-03-20 17:35:10,635:INFO:             pickle5: Not installed
2025-03-20 17:35:10,636:INFO:         cloudpickle: 2.2.1
2025-03-20 17:35:10,636:INFO:         deprecation: 2.1.0
2025-03-20 17:35:10,636:INFO:              xxhash: 3.5.0
2025-03-20 17:35:10,636:INFO:           wurlitzer: Not installed
2025-03-20 17:35:10,636:INFO:PyCaret optional dependencies:
2025-03-20 17:35:10,636:INFO:                shap: 0.44.1
2025-03-20 17:35:10,636:INFO:           interpret: 0.6.6
2025-03-20 17:35:10,636:INFO:                umap: 0.5.7
2025-03-20 17:35:10,636:INFO:     ydata_profiling: 4.6.0
2025-03-20 17:35:10,636:INFO:  explainerdashboard: 0.4.7
2025-03-20 17:35:10,636:INFO:             autoviz: Not installed
2025-03-20 17:35:10,636:INFO:           fairlearn: 0.7.0
2025-03-20 17:35:10,636:INFO:          deepchecks: Not installed
2025-03-20 17:35:10,636:INFO:             xgboost: 2.1.3
2025-03-20 17:35:10,636:INFO:            catboost: 1.2.7
2025-03-20 17:35:10,636:INFO:              kmodes: 0.12.2
2025-03-20 17:35:10,636:INFO:             mlxtend: 0.23.1
2025-03-20 17:35:10,636:INFO:       statsforecast: 1.5.0
2025-03-20 17:35:10,636:INFO:        tune_sklearn: 0.5.0
2025-03-20 17:35:10,636:INFO:                 ray: 2.10.0
2025-03-20 17:35:10,636:INFO:            hyperopt: 0.2.7
2025-03-20 17:35:10,636:INFO:              optuna: 4.1.0
2025-03-20 17:35:10,636:INFO:               skopt: 0.10.2
2025-03-20 17:35:10,636:INFO:              mlflow: 1.30.1
2025-03-20 17:35:10,636:INFO:              gradio: 3.50.2
2025-03-20 17:35:10,636:INFO:             fastapi: 0.115.5
2025-03-20 17:35:10,636:INFO:             uvicorn: 0.32.1
2025-03-20 17:35:10,637:INFO:              m2cgen: 0.10.0
2025-03-20 17:35:10,637:INFO:           evidently: 0.2.8
2025-03-20 17:35:10,637:INFO:               fugue: 0.8.6
2025-03-20 17:35:10,637:INFO:           streamlit: Not installed
2025-03-20 17:35:10,637:INFO:             prophet: Not installed
2025-03-20 17:35:10,637:INFO:None
2025-03-20 17:35:10,637:INFO:Set up data.
2025-03-20 17:35:10,641:INFO:Set up folding strategy.
2025-03-20 17:35:10,641:INFO:Set up train/test split.
2025-03-20 17:35:10,641:INFO:Set up data.
2025-03-20 17:35:10,645:INFO:Set up index.
2025-03-20 17:35:10,645:INFO:Assigning column types.
2025-03-20 17:35:10,647:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 17:35:10,647:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,649:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,695:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:10,696:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:10,709:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,711:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,757:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:10,758:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:10,758:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 17:35:10,760:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,762:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,807:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:10,808:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:10,811:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,813:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,857:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:10,858:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:10,858:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 17:35:10,862:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,906:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:10,907:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:10,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:10,953:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:10,954:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:10,955:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 17:35:10,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:11,000:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:11,000:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:11,001:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:11,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:11,046:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:35:11,046:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:11,047:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:11,048:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 17:35:11,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:11,093:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:11,094:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:11,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:35:11,141:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:11,142:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:11,142:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 17:35:11,188:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:11,189:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:11,237:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:35:11,238:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:35:11,239:INFO:Preparing preprocessing pipeline...
2025-03-20 17:35:11,239:INFO:Set up simple imputation.
2025-03-20 17:35:11,240:INFO:Set up encoding of categorical features.
2025-03-20 17:35:11,240:INFO:Set up feature normalization.
2025-03-20 17:35:11,241:INFO:Set up column name cleaning.
2025-03-20 17:36:11,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:36:11,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:36:11,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:36:11,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:36:13,979:INFO:PyCaret RegressionExperiment
2025-03-20 17:36:13,980:INFO:Logging name: reg-default-name
2025-03-20 17:36:13,980:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 17:36:13,980:INFO:version 3.2.0
2025-03-20 17:36:13,980:INFO:Initializing setup()
2025-03-20 17:36:13,980:INFO:self.USI: c776
2025-03-20 17:36:13,980:INFO:self._variable_keys: {'fold_shuffle_param', 'y', 'gpu_n_jobs_param', 'exp_id', 'logging_param', 'data', 'idx', '_ml_usecase', 'fold_generator', 'transform_target_param', 'log_plots_param', 'y_test', 'exp_name_log', 'X_test', '_available_plots', 'X', 'pipeline', 'memory', 'seed', 'X_train', 'y_train', 'USI', 'target_param', 'fold_groups_param', 'gpu_param', 'html_param', 'n_jobs_param'}
2025-03-20 17:36:13,980:INFO:Checking environment
2025-03-20 17:36:13,980:INFO:python_version: 3.8.20
2025-03-20 17:36:13,980:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 17:36:13,980:INFO:machine: AMD64
2025-03-20 17:36:13,980:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 17:36:13,993:INFO:Memory: svmem(total=68447973376, available=40479064064, percent=40.9, used=27968909312, free=40479064064)
2025-03-20 17:36:13,993:INFO:Physical Core: 24
2025-03-20 17:36:13,993:INFO:Logical Core: 32
2025-03-20 17:36:13,993:INFO:Checking libraries
2025-03-20 17:36:13,993:INFO:System:
2025-03-20 17:36:13,993:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 17:36:13,993:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 17:36:13,993:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 17:36:13,993:INFO:PyCaret required dependencies:
2025-03-20 17:36:14,480:INFO:                 pip: 24.2
2025-03-20 17:36:14,480:INFO:          setuptools: 75.1.0
2025-03-20 17:36:14,480:INFO:             pycaret: 3.2.0
2025-03-20 17:36:14,480:INFO:             IPython: 8.12.3
2025-03-20 17:36:14,480:INFO:          ipywidgets: 8.1.5
2025-03-20 17:36:14,480:INFO:                tqdm: 4.67.1
2025-03-20 17:36:14,480:INFO:               numpy: 1.24.4
2025-03-20 17:36:14,480:INFO:              pandas: 1.5.3
2025-03-20 17:36:14,480:INFO:              jinja2: 3.1.4
2025-03-20 17:36:14,480:INFO:               scipy: 1.10.1
2025-03-20 17:36:14,480:INFO:              joblib: 1.3.2
2025-03-20 17:36:14,480:INFO:             sklearn: 1.2.2
2025-03-20 17:36:14,480:INFO:                pyod: 2.0.2
2025-03-20 17:36:14,480:INFO:            imblearn: 0.12.4
2025-03-20 17:36:14,480:INFO:   category_encoders: 2.6.4
2025-03-20 17:36:14,480:INFO:            lightgbm: 4.5.0
2025-03-20 17:36:14,480:INFO:               numba: 0.58.1
2025-03-20 17:36:14,480:INFO:            requests: 2.32.3
2025-03-20 17:36:14,480:INFO:          matplotlib: 3.6.0
2025-03-20 17:36:14,480:INFO:          scikitplot: 0.3.7
2025-03-20 17:36:14,480:INFO:         yellowbrick: 1.5
2025-03-20 17:36:14,480:INFO:              plotly: 5.24.1
2025-03-20 17:36:14,480:INFO:    plotly-resampler: Not installed
2025-03-20 17:36:14,480:INFO:             kaleido: 0.2.1
2025-03-20 17:36:14,480:INFO:           schemdraw: 0.15
2025-03-20 17:36:14,480:INFO:         statsmodels: 0.14.1
2025-03-20 17:36:14,480:INFO:              sktime: 0.21.1
2025-03-20 17:36:14,480:INFO:               tbats: 1.1.3
2025-03-20 17:36:14,480:INFO:            pmdarima: 2.0.4
2025-03-20 17:36:14,480:INFO:              psutil: 6.1.0
2025-03-20 17:36:14,480:INFO:          markupsafe: 2.1.5
2025-03-20 17:36:14,480:INFO:             pickle5: Not installed
2025-03-20 17:36:14,480:INFO:         cloudpickle: 2.2.1
2025-03-20 17:36:14,480:INFO:         deprecation: 2.1.0
2025-03-20 17:36:14,480:INFO:              xxhash: 3.5.0
2025-03-20 17:36:14,480:INFO:           wurlitzer: Not installed
2025-03-20 17:36:14,480:INFO:PyCaret optional dependencies:
2025-03-20 17:36:15,757:INFO:                shap: 0.44.1
2025-03-20 17:36:15,757:INFO:           interpret: 0.6.6
2025-03-20 17:36:15,757:INFO:                umap: 0.5.7
2025-03-20 17:36:15,757:INFO:     ydata_profiling: 4.6.0
2025-03-20 17:36:15,757:INFO:  explainerdashboard: 0.4.7
2025-03-20 17:36:15,757:INFO:             autoviz: Not installed
2025-03-20 17:36:15,757:INFO:           fairlearn: 0.7.0
2025-03-20 17:36:15,757:INFO:          deepchecks: Not installed
2025-03-20 17:36:15,757:INFO:             xgboost: 2.1.3
2025-03-20 17:36:15,757:INFO:            catboost: 1.2.7
2025-03-20 17:36:15,757:INFO:              kmodes: 0.12.2
2025-03-20 17:36:15,757:INFO:             mlxtend: 0.23.1
2025-03-20 17:36:15,757:INFO:       statsforecast: 1.5.0
2025-03-20 17:36:15,757:INFO:        tune_sklearn: 0.5.0
2025-03-20 17:36:15,757:INFO:                 ray: 2.10.0
2025-03-20 17:36:15,757:INFO:            hyperopt: 0.2.7
2025-03-20 17:36:15,757:INFO:              optuna: 4.1.0
2025-03-20 17:36:15,757:INFO:               skopt: 0.10.2
2025-03-20 17:36:15,757:INFO:              mlflow: 1.30.1
2025-03-20 17:36:15,757:INFO:              gradio: 3.50.2
2025-03-20 17:36:15,757:INFO:             fastapi: 0.115.5
2025-03-20 17:36:15,757:INFO:             uvicorn: 0.32.1
2025-03-20 17:36:15,757:INFO:              m2cgen: 0.10.0
2025-03-20 17:36:15,757:INFO:           evidently: 0.2.8
2025-03-20 17:36:15,757:INFO:               fugue: 0.8.6
2025-03-20 17:36:15,757:INFO:           streamlit: Not installed
2025-03-20 17:36:15,757:INFO:             prophet: Not installed
2025-03-20 17:36:15,757:INFO:None
2025-03-20 17:36:15,757:INFO:Set up data.
2025-03-20 17:36:15,762:INFO:Set up folding strategy.
2025-03-20 17:36:15,762:INFO:Set up train/test split.
2025-03-20 17:36:15,762:INFO:Set up data.
2025-03-20 17:36:15,767:INFO:Set up index.
2025-03-20 17:36:15,767:INFO:Assigning column types.
2025-03-20 17:36:15,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 17:36:15,769:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,771:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,772:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,816:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:15,817:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:15,827:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,829:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,875:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:15,876:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:15,876:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 17:36:15,878:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,880:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,923:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:15,924:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:15,926:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,928:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,952:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:15,971:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:15,972:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:15,972:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 17:36:15,976:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,020:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,021:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,025:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,068:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,069:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,069:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 17:36:16,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,116:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,117:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,164:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,165:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,167:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 17:36:16,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,213:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,214:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,243:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:36:16,261:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,263:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,263:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 17:36:16,311:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,312:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,360:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:36:16,361:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:36:16,362:INFO:Preparing preprocessing pipeline...
2025-03-20 17:36:16,362:INFO:Set up simple imputation.
2025-03-20 17:36:16,363:INFO:Set up encoding of categorical features.
2025-03-20 17:36:16,364:INFO:Set up feature normalization.
2025-03-20 17:36:16,364:INFO:Set up column name cleaning.
2025-03-20 17:37:56,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:37:56,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:37:56,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:37:56,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:38:02,752:INFO:PyCaret RegressionExperiment
2025-03-20 17:38:02,752:INFO:Logging name: reg-default-name
2025-03-20 17:38:02,752:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 17:38:02,752:INFO:version 3.2.0
2025-03-20 17:38:02,752:INFO:Initializing setup()
2025-03-20 17:38:02,752:INFO:self.USI: c9cd
2025-03-20 17:38:02,752:INFO:self._variable_keys: {'y_test', 'gpu_param', 'logging_param', '_available_plots', 'X_test', 'y', 'memory', 'USI', 'transform_target_param', 'data', 'fold_shuffle_param', '_ml_usecase', 'X_train', 'target_param', 'exp_name_log', 'log_plots_param', 'seed', 'pipeline', 'idx', 'fold_generator', 'y_train', 'gpu_n_jobs_param', 'X', 'html_param', 'exp_id', 'fold_groups_param', 'n_jobs_param'}
2025-03-20 17:38:02,752:INFO:Checking environment
2025-03-20 17:38:02,752:INFO:python_version: 3.8.20
2025-03-20 17:38:02,752:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 17:38:02,752:INFO:machine: AMD64
2025-03-20 17:38:02,752:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 17:38:02,759:INFO:Memory: svmem(total=68447973376, available=40590450688, percent=40.7, used=27857522688, free=40590450688)
2025-03-20 17:38:02,759:INFO:Physical Core: 24
2025-03-20 17:38:02,759:INFO:Logical Core: 32
2025-03-20 17:38:02,759:INFO:Checking libraries
2025-03-20 17:38:02,759:INFO:System:
2025-03-20 17:38:02,759:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 17:38:02,759:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 17:38:02,759:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 17:38:02,759:INFO:PyCaret required dependencies:
2025-03-20 17:38:03,262:INFO:                 pip: 24.2
2025-03-20 17:38:03,262:INFO:          setuptools: 75.1.0
2025-03-20 17:38:03,262:INFO:             pycaret: 3.2.0
2025-03-20 17:38:03,262:INFO:             IPython: 8.12.3
2025-03-20 17:38:03,262:INFO:          ipywidgets: 8.1.5
2025-03-20 17:38:03,262:INFO:                tqdm: 4.67.1
2025-03-20 17:38:03,263:INFO:               numpy: 1.24.4
2025-03-20 17:38:03,263:INFO:              pandas: 1.5.3
2025-03-20 17:38:03,263:INFO:              jinja2: 3.1.4
2025-03-20 17:38:03,263:INFO:               scipy: 1.10.1
2025-03-20 17:38:03,263:INFO:              joblib: 1.3.2
2025-03-20 17:38:03,263:INFO:             sklearn: 1.2.2
2025-03-20 17:38:03,263:INFO:                pyod: 2.0.2
2025-03-20 17:38:03,263:INFO:            imblearn: 0.12.4
2025-03-20 17:38:03,263:INFO:   category_encoders: 2.6.4
2025-03-20 17:38:03,263:INFO:            lightgbm: 4.5.0
2025-03-20 17:38:03,263:INFO:               numba: 0.58.1
2025-03-20 17:38:03,263:INFO:            requests: 2.32.3
2025-03-20 17:38:03,263:INFO:          matplotlib: 3.6.0
2025-03-20 17:38:03,263:INFO:          scikitplot: 0.3.7
2025-03-20 17:38:03,263:INFO:         yellowbrick: 1.5
2025-03-20 17:38:03,263:INFO:              plotly: 5.24.1
2025-03-20 17:38:03,263:INFO:    plotly-resampler: Not installed
2025-03-20 17:38:03,263:INFO:             kaleido: 0.2.1
2025-03-20 17:38:03,263:INFO:           schemdraw: 0.15
2025-03-20 17:38:03,263:INFO:         statsmodels: 0.14.1
2025-03-20 17:38:03,263:INFO:              sktime: 0.21.1
2025-03-20 17:38:03,263:INFO:               tbats: 1.1.3
2025-03-20 17:38:03,263:INFO:            pmdarima: 2.0.4
2025-03-20 17:38:03,263:INFO:              psutil: 6.1.0
2025-03-20 17:38:03,263:INFO:          markupsafe: 2.1.5
2025-03-20 17:38:03,263:INFO:             pickle5: Not installed
2025-03-20 17:38:03,263:INFO:         cloudpickle: 2.2.1
2025-03-20 17:38:03,263:INFO:         deprecation: 2.1.0
2025-03-20 17:38:03,263:INFO:              xxhash: 3.5.0
2025-03-20 17:38:03,263:INFO:           wurlitzer: Not installed
2025-03-20 17:38:03,263:INFO:PyCaret optional dependencies:
2025-03-20 17:38:04,540:INFO:                shap: 0.44.1
2025-03-20 17:38:04,540:INFO:           interpret: 0.6.6
2025-03-20 17:38:04,540:INFO:                umap: 0.5.7
2025-03-20 17:38:04,540:INFO:     ydata_profiling: 4.6.0
2025-03-20 17:38:04,540:INFO:  explainerdashboard: 0.4.7
2025-03-20 17:38:04,540:INFO:             autoviz: Not installed
2025-03-20 17:38:04,540:INFO:           fairlearn: 0.7.0
2025-03-20 17:38:04,540:INFO:          deepchecks: Not installed
2025-03-20 17:38:04,540:INFO:             xgboost: 2.1.3
2025-03-20 17:38:04,540:INFO:            catboost: 1.2.7
2025-03-20 17:38:04,540:INFO:              kmodes: 0.12.2
2025-03-20 17:38:04,540:INFO:             mlxtend: 0.23.1
2025-03-20 17:38:04,540:INFO:       statsforecast: 1.5.0
2025-03-20 17:38:04,540:INFO:        tune_sklearn: 0.5.0
2025-03-20 17:38:04,540:INFO:                 ray: 2.10.0
2025-03-20 17:38:04,540:INFO:            hyperopt: 0.2.7
2025-03-20 17:38:04,540:INFO:              optuna: 4.1.0
2025-03-20 17:38:04,540:INFO:               skopt: 0.10.2
2025-03-20 17:38:04,540:INFO:              mlflow: 1.30.1
2025-03-20 17:38:04,540:INFO:              gradio: 3.50.2
2025-03-20 17:38:04,540:INFO:             fastapi: 0.115.5
2025-03-20 17:38:04,540:INFO:             uvicorn: 0.32.1
2025-03-20 17:38:04,540:INFO:              m2cgen: 0.10.0
2025-03-20 17:38:04,540:INFO:           evidently: 0.2.8
2025-03-20 17:38:04,540:INFO:               fugue: 0.8.6
2025-03-20 17:38:04,540:INFO:           streamlit: Not installed
2025-03-20 17:38:04,540:INFO:             prophet: Not installed
2025-03-20 17:38:04,540:INFO:None
2025-03-20 17:38:04,540:INFO:Set up data.
2025-03-20 17:38:04,545:INFO:Set up folding strategy.
2025-03-20 17:38:04,545:INFO:Set up train/test split.
2025-03-20 17:38:04,545:INFO:Set up data.
2025-03-20 17:38:04,550:INFO:Set up index.
2025-03-20 17:38:04,550:INFO:Assigning column types.
2025-03-20 17:38:04,552:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 17:38:04,552:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,554:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,556:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,581:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,599:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,600:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,610:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,612:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,614:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,658:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,659:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,659:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 17:38:04,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,663:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,687:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,707:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,708:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,710:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,712:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,755:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,756:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,757:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 17:38:04,761:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,804:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,806:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,855:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,856:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,856:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 17:38:04,885:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,905:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,906:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 17:38:04,954:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:04,955:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:04,957:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 17:38:04,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:05,004:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:05,005:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:05,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 17:38:05,052:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:05,053:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:05,053:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 17:38:05,101:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:05,102:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:05,149:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:05,150:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:05,151:INFO:Preparing preprocessing pipeline...
2025-03-20 17:38:05,151:INFO:Set up simple imputation.
2025-03-20 17:38:05,152:INFO:Set up encoding of categorical features.
2025-03-20 17:38:05,152:INFO:Set up feature normalization.
2025-03-20 17:38:05,153:INFO:Set up column name cleaning.
2025-03-20 17:38:05,200:INFO:Finished creating preprocessing pipeline.
2025-03-20 17:38:05,204:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 17:38:05,204:INFO:Creating final display dataframe.
2025-03-20 17:38:05,327:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 23)
4        Transformed data shape        (1769, 36)
5   Transformed train set shape        (1399, 36)
6    Transformed test set shape         (370, 36)
7              Numeric features                19
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              c9cd
2025-03-20 17:38:05,379:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:05,380:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:05,429:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:38:05,430:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 17:38:05,430:INFO:Logging experiment in loggers
2025-03-20 17:38:05,575:INFO:SubProcess save_model() called ==================================
2025-03-20 17:38:05,583:INFO:Initializing save_model()
2025-03-20 17:38:05,583:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmp807f1j6m\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 17:38:05,583:INFO:Adding model into prep_pipe
2025-03-20 17:38:05,583:WARNING:Only Model saved as it was a pipeline.
2025-03-20 17:38:05,586:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmp807f1j6m\Transformation Pipeline.pkl saved in current working directory
2025-03-20 17:38:05,590:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 17:38:05,590:INFO:save_model() successfully completed......................................
2025-03-20 17:38:05,643:INFO:SubProcess save_model() end ==================================
2025-03-20 17:38:05,647:INFO:setup() successfully completed in 2.68s...............
2025-03-20 17:38:05,647:INFO:Initializing compare_models()
2025-03-20 17:38:05,647:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 17:38:05,647:INFO:Checking exceptions
2025-03-20 17:38:05,648:INFO:Preparing display monitor
2025-03-20 17:38:05,660:INFO:Initializing Linear Regression
2025-03-20 17:38:05,660:INFO:Total runtime is 0.0 minutes
2025-03-20 17:38:05,662:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:05,662:INFO:Initializing create_model()
2025-03-20 17:38:05,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:05,662:INFO:Checking exceptions
2025-03-20 17:38:05,662:INFO:Importing libraries
2025-03-20 17:38:05,663:INFO:Copying training dataset
2025-03-20 17:38:05,664:INFO:Defining folds
2025-03-20 17:38:05,664:INFO:Declaring metric variables
2025-03-20 17:38:05,666:INFO:Importing untrained model
2025-03-20 17:38:05,668:INFO:Linear Regression Imported successfully
2025-03-20 17:38:05,672:INFO:Starting cross validation
2025-03-20 17:38:05,675:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:08,144:INFO:Calculating mean and std
2025-03-20 17:38:08,145:INFO:Creating metrics dataframe
2025-03-20 17:38:08,147:INFO:Uploading results into container
2025-03-20 17:38:08,147:INFO:Uploading model into container now
2025-03-20 17:38:08,148:INFO:_master_model_container: 1
2025-03-20 17:38:08,148:INFO:_display_container: 2
2025-03-20 17:38:08,148:INFO:LinearRegression(n_jobs=-1)
2025-03-20 17:38:08,148:INFO:create_model() successfully completed......................................
2025-03-20 17:38:08,202:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:08,202:INFO:Creating metrics dataframe
2025-03-20 17:38:08,207:INFO:Initializing Lasso Regression
2025-03-20 17:38:08,207:INFO:Total runtime is 0.04244010448455811 minutes
2025-03-20 17:38:08,208:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:08,209:INFO:Initializing create_model()
2025-03-20 17:38:08,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:08,209:INFO:Checking exceptions
2025-03-20 17:38:08,209:INFO:Importing libraries
2025-03-20 17:38:08,209:INFO:Copying training dataset
2025-03-20 17:38:08,210:INFO:Defining folds
2025-03-20 17:38:08,211:INFO:Declaring metric variables
2025-03-20 17:38:08,212:INFO:Importing untrained model
2025-03-20 17:38:08,213:INFO:Lasso Regression Imported successfully
2025-03-20 17:38:08,217:INFO:Starting cross validation
2025-03-20 17:38:08,217:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:10,192:INFO:Calculating mean and std
2025-03-20 17:38:10,193:INFO:Creating metrics dataframe
2025-03-20 17:38:10,195:INFO:Uploading results into container
2025-03-20 17:38:10,195:INFO:Uploading model into container now
2025-03-20 17:38:10,196:INFO:_master_model_container: 2
2025-03-20 17:38:10,196:INFO:_display_container: 2
2025-03-20 17:38:10,196:INFO:Lasso(random_state=888)
2025-03-20 17:38:10,196:INFO:create_model() successfully completed......................................
2025-03-20 17:38:10,250:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:10,250:INFO:Creating metrics dataframe
2025-03-20 17:38:10,256:INFO:Initializing Ridge Regression
2025-03-20 17:38:10,256:INFO:Total runtime is 0.07658589680989583 minutes
2025-03-20 17:38:10,257:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:10,258:INFO:Initializing create_model()
2025-03-20 17:38:10,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:10,258:INFO:Checking exceptions
2025-03-20 17:38:10,258:INFO:Importing libraries
2025-03-20 17:38:10,258:INFO:Copying training dataset
2025-03-20 17:38:10,259:INFO:Defining folds
2025-03-20 17:38:10,259:INFO:Declaring metric variables
2025-03-20 17:38:10,261:INFO:Importing untrained model
2025-03-20 17:38:10,262:INFO:Ridge Regression Imported successfully
2025-03-20 17:38:10,265:INFO:Starting cross validation
2025-03-20 17:38:10,266:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:12,240:INFO:Calculating mean and std
2025-03-20 17:38:12,241:INFO:Creating metrics dataframe
2025-03-20 17:38:12,242:INFO:Uploading results into container
2025-03-20 17:38:12,243:INFO:Uploading model into container now
2025-03-20 17:38:12,243:INFO:_master_model_container: 3
2025-03-20 17:38:12,243:INFO:_display_container: 2
2025-03-20 17:38:12,243:INFO:Ridge(random_state=888)
2025-03-20 17:38:12,243:INFO:create_model() successfully completed......................................
2025-03-20 17:38:12,303:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:12,303:INFO:Creating metrics dataframe
2025-03-20 17:38:12,308:INFO:Initializing Elastic Net
2025-03-20 17:38:12,308:INFO:Total runtime is 0.1107911189397176 minutes
2025-03-20 17:38:12,310:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:12,310:INFO:Initializing create_model()
2025-03-20 17:38:12,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:12,310:INFO:Checking exceptions
2025-03-20 17:38:12,310:INFO:Importing libraries
2025-03-20 17:38:12,310:INFO:Copying training dataset
2025-03-20 17:38:12,312:INFO:Defining folds
2025-03-20 17:38:12,312:INFO:Declaring metric variables
2025-03-20 17:38:12,313:INFO:Importing untrained model
2025-03-20 17:38:12,315:INFO:Elastic Net Imported successfully
2025-03-20 17:38:12,318:INFO:Starting cross validation
2025-03-20 17:38:12,319:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:14,303:INFO:Calculating mean and std
2025-03-20 17:38:14,304:INFO:Creating metrics dataframe
2025-03-20 17:38:14,305:INFO:Uploading results into container
2025-03-20 17:38:14,306:INFO:Uploading model into container now
2025-03-20 17:38:14,306:INFO:_master_model_container: 4
2025-03-20 17:38:14,306:INFO:_display_container: 2
2025-03-20 17:38:14,306:INFO:ElasticNet(random_state=888)
2025-03-20 17:38:14,306:INFO:create_model() successfully completed......................................
2025-03-20 17:38:14,367:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:14,367:INFO:Creating metrics dataframe
2025-03-20 17:38:14,372:INFO:Initializing Least Angle Regression
2025-03-20 17:38:14,372:INFO:Total runtime is 0.1452017784118652 minutes
2025-03-20 17:38:14,374:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:14,374:INFO:Initializing create_model()
2025-03-20 17:38:14,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:14,374:INFO:Checking exceptions
2025-03-20 17:38:14,374:INFO:Importing libraries
2025-03-20 17:38:14,374:INFO:Copying training dataset
2025-03-20 17:38:14,376:INFO:Defining folds
2025-03-20 17:38:14,376:INFO:Declaring metric variables
2025-03-20 17:38:14,377:INFO:Importing untrained model
2025-03-20 17:38:14,379:INFO:Least Angle Regression Imported successfully
2025-03-20 17:38:14,382:INFO:Starting cross validation
2025-03-20 17:38:14,383:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:16,287:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,287:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,287:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.073e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,287:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.635e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,287:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.543e-02, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,287:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.543e-02, with an active set of 12 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,288:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.093e-02, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,288:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.734e-02, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,289:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.527e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,289:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.133e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,289:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.170e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,321:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.480e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,321:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.913e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,328:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,328:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,328:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,329:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.834e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,329:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=7.455e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,329:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=7.064e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,329:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.608e-03, with an active set of 33 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,329:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.610e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 17:38:16,351:INFO:Calculating mean and std
2025-03-20 17:38:16,352:INFO:Creating metrics dataframe
2025-03-20 17:38:16,354:INFO:Uploading results into container
2025-03-20 17:38:16,354:INFO:Uploading model into container now
2025-03-20 17:38:16,354:INFO:_master_model_container: 5
2025-03-20 17:38:16,354:INFO:_display_container: 2
2025-03-20 17:38:16,354:INFO:Lars(random_state=888)
2025-03-20 17:38:16,355:INFO:create_model() successfully completed......................................
2025-03-20 17:38:16,413:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:16,414:INFO:Creating metrics dataframe
2025-03-20 17:38:16,419:INFO:Initializing Lasso Least Angle Regression
2025-03-20 17:38:16,419:INFO:Total runtime is 0.1793078541755676 minutes
2025-03-20 17:38:16,420:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:16,420:INFO:Initializing create_model()
2025-03-20 17:38:16,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:16,421:INFO:Checking exceptions
2025-03-20 17:38:16,421:INFO:Importing libraries
2025-03-20 17:38:16,421:INFO:Copying training dataset
2025-03-20 17:38:16,422:INFO:Defining folds
2025-03-20 17:38:16,423:INFO:Declaring metric variables
2025-03-20 17:38:16,424:INFO:Importing untrained model
2025-03-20 17:38:16,426:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 17:38:16,429:INFO:Starting cross validation
2025-03-20 17:38:16,429:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:18,368:INFO:Calculating mean and std
2025-03-20 17:38:18,369:INFO:Creating metrics dataframe
2025-03-20 17:38:18,370:INFO:Uploading results into container
2025-03-20 17:38:18,371:INFO:Uploading model into container now
2025-03-20 17:38:18,371:INFO:_master_model_container: 6
2025-03-20 17:38:18,371:INFO:_display_container: 2
2025-03-20 17:38:18,371:INFO:LassoLars(random_state=888)
2025-03-20 17:38:18,371:INFO:create_model() successfully completed......................................
2025-03-20 17:38:18,430:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:18,430:INFO:Creating metrics dataframe
2025-03-20 17:38:18,435:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 17:38:18,435:INFO:Total runtime is 0.21290731827418008 minutes
2025-03-20 17:38:18,436:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:18,437:INFO:Initializing create_model()
2025-03-20 17:38:18,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:18,437:INFO:Checking exceptions
2025-03-20 17:38:18,437:INFO:Importing libraries
2025-03-20 17:38:18,437:INFO:Copying training dataset
2025-03-20 17:38:18,439:INFO:Defining folds
2025-03-20 17:38:18,439:INFO:Declaring metric variables
2025-03-20 17:38:18,440:INFO:Importing untrained model
2025-03-20 17:38:18,442:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 17:38:18,445:INFO:Starting cross validation
2025-03-20 17:38:18,446:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:20,139:INFO:Calculating mean and std
2025-03-20 17:38:20,140:INFO:Creating metrics dataframe
2025-03-20 17:38:20,141:INFO:Uploading results into container
2025-03-20 17:38:20,142:INFO:Uploading model into container now
2025-03-20 17:38:20,142:INFO:_master_model_container: 7
2025-03-20 17:38:20,142:INFO:_display_container: 2
2025-03-20 17:38:20,142:INFO:OrthogonalMatchingPursuit()
2025-03-20 17:38:20,142:INFO:create_model() successfully completed......................................
2025-03-20 17:38:20,195:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:20,195:INFO:Creating metrics dataframe
2025-03-20 17:38:20,201:INFO:Initializing Bayesian Ridge
2025-03-20 17:38:20,201:INFO:Total runtime is 0.24234306017557777 minutes
2025-03-20 17:38:20,202:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:20,203:INFO:Initializing create_model()
2025-03-20 17:38:20,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:20,203:INFO:Checking exceptions
2025-03-20 17:38:20,203:INFO:Importing libraries
2025-03-20 17:38:20,203:INFO:Copying training dataset
2025-03-20 17:38:20,205:INFO:Defining folds
2025-03-20 17:38:20,205:INFO:Declaring metric variables
2025-03-20 17:38:20,206:INFO:Importing untrained model
2025-03-20 17:38:20,208:INFO:Bayesian Ridge Imported successfully
2025-03-20 17:38:20,210:INFO:Starting cross validation
2025-03-20 17:38:20,211:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:20,292:INFO:Calculating mean and std
2025-03-20 17:38:20,293:INFO:Creating metrics dataframe
2025-03-20 17:38:20,295:INFO:Uploading results into container
2025-03-20 17:38:20,295:INFO:Uploading model into container now
2025-03-20 17:38:20,295:INFO:_master_model_container: 8
2025-03-20 17:38:20,295:INFO:_display_container: 2
2025-03-20 17:38:20,296:INFO:BayesianRidge()
2025-03-20 17:38:20,296:INFO:create_model() successfully completed......................................
2025-03-20 17:38:20,349:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:20,350:INFO:Creating metrics dataframe
2025-03-20 17:38:20,355:INFO:Initializing Passive Aggressive Regressor
2025-03-20 17:38:20,355:INFO:Total runtime is 0.24491395155588783 minutes
2025-03-20 17:38:20,357:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:20,357:INFO:Initializing create_model()
2025-03-20 17:38:20,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:20,357:INFO:Checking exceptions
2025-03-20 17:38:20,357:INFO:Importing libraries
2025-03-20 17:38:20,357:INFO:Copying training dataset
2025-03-20 17:38:20,359:INFO:Defining folds
2025-03-20 17:38:20,359:INFO:Declaring metric variables
2025-03-20 17:38:20,360:INFO:Importing untrained model
2025-03-20 17:38:20,362:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 17:38:20,365:INFO:Starting cross validation
2025-03-20 17:38:20,366:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:20,431:INFO:Calculating mean and std
2025-03-20 17:38:20,431:INFO:Creating metrics dataframe
2025-03-20 17:38:20,433:INFO:Uploading results into container
2025-03-20 17:38:20,433:INFO:Uploading model into container now
2025-03-20 17:38:20,434:INFO:_master_model_container: 9
2025-03-20 17:38:20,434:INFO:_display_container: 2
2025-03-20 17:38:20,434:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 17:38:20,434:INFO:create_model() successfully completed......................................
2025-03-20 17:38:20,488:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:20,488:INFO:Creating metrics dataframe
2025-03-20 17:38:20,493:INFO:Initializing Huber Regressor
2025-03-20 17:38:20,493:INFO:Total runtime is 0.24721632003784177 minutes
2025-03-20 17:38:20,495:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:20,495:INFO:Initializing create_model()
2025-03-20 17:38:20,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:20,495:INFO:Checking exceptions
2025-03-20 17:38:20,495:INFO:Importing libraries
2025-03-20 17:38:20,495:INFO:Copying training dataset
2025-03-20 17:38:20,497:INFO:Defining folds
2025-03-20 17:38:20,497:INFO:Declaring metric variables
2025-03-20 17:38:20,499:INFO:Importing untrained model
2025-03-20 17:38:20,500:INFO:Huber Regressor Imported successfully
2025-03-20 17:38:20,503:INFO:Starting cross validation
2025-03-20 17:38:20,504:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:20,545:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 17:38:20,548:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 17:38:20,550:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 17:38:20,554:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 17:38:20,558:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 17:38:20,585:INFO:Calculating mean and std
2025-03-20 17:38:20,585:INFO:Creating metrics dataframe
2025-03-20 17:38:20,587:INFO:Uploading results into container
2025-03-20 17:38:20,587:INFO:Uploading model into container now
2025-03-20 17:38:20,587:INFO:_master_model_container: 10
2025-03-20 17:38:20,587:INFO:_display_container: 2
2025-03-20 17:38:20,587:INFO:HuberRegressor()
2025-03-20 17:38:20,587:INFO:create_model() successfully completed......................................
2025-03-20 17:38:20,640:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:20,640:INFO:Creating metrics dataframe
2025-03-20 17:38:20,645:INFO:Initializing K Neighbors Regressor
2025-03-20 17:38:20,645:INFO:Total runtime is 0.24974551598230996 minutes
2025-03-20 17:38:20,647:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:20,647:INFO:Initializing create_model()
2025-03-20 17:38:20,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:20,647:INFO:Checking exceptions
2025-03-20 17:38:20,647:INFO:Importing libraries
2025-03-20 17:38:20,647:INFO:Copying training dataset
2025-03-20 17:38:20,649:INFO:Defining folds
2025-03-20 17:38:20,649:INFO:Declaring metric variables
2025-03-20 17:38:20,650:INFO:Importing untrained model
2025-03-20 17:38:20,652:INFO:K Neighbors Regressor Imported successfully
2025-03-20 17:38:20,655:INFO:Starting cross validation
2025-03-20 17:38:20,656:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:20,769:INFO:Calculating mean and std
2025-03-20 17:38:20,770:INFO:Creating metrics dataframe
2025-03-20 17:38:20,772:INFO:Uploading results into container
2025-03-20 17:38:20,772:INFO:Uploading model into container now
2025-03-20 17:38:20,772:INFO:_master_model_container: 11
2025-03-20 17:38:20,772:INFO:_display_container: 2
2025-03-20 17:38:20,773:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 17:38:20,773:INFO:create_model() successfully completed......................................
2025-03-20 17:38:20,825:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:20,825:INFO:Creating metrics dataframe
2025-03-20 17:38:20,830:INFO:Initializing Decision Tree Regressor
2025-03-20 17:38:20,830:INFO:Total runtime is 0.25283306439717607 minutes
2025-03-20 17:38:20,832:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:20,832:INFO:Initializing create_model()
2025-03-20 17:38:20,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:20,832:INFO:Checking exceptions
2025-03-20 17:38:20,832:INFO:Importing libraries
2025-03-20 17:38:20,832:INFO:Copying training dataset
2025-03-20 17:38:20,834:INFO:Defining folds
2025-03-20 17:38:20,834:INFO:Declaring metric variables
2025-03-20 17:38:20,836:INFO:Importing untrained model
2025-03-20 17:38:20,837:INFO:Decision Tree Regressor Imported successfully
2025-03-20 17:38:20,841:INFO:Starting cross validation
2025-03-20 17:38:20,841:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:20,923:INFO:Calculating mean and std
2025-03-20 17:38:20,924:INFO:Creating metrics dataframe
2025-03-20 17:38:20,926:INFO:Uploading results into container
2025-03-20 17:38:20,926:INFO:Uploading model into container now
2025-03-20 17:38:20,926:INFO:_master_model_container: 12
2025-03-20 17:38:20,926:INFO:_display_container: 2
2025-03-20 17:38:20,926:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 17:38:20,926:INFO:create_model() successfully completed......................................
2025-03-20 17:38:20,979:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:20,980:INFO:Creating metrics dataframe
2025-03-20 17:38:20,986:INFO:Initializing Random Forest Regressor
2025-03-20 17:38:20,986:INFO:Total runtime is 0.2554246107737223 minutes
2025-03-20 17:38:20,987:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:20,988:INFO:Initializing create_model()
2025-03-20 17:38:20,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:20,988:INFO:Checking exceptions
2025-03-20 17:38:20,988:INFO:Importing libraries
2025-03-20 17:38:20,988:INFO:Copying training dataset
2025-03-20 17:38:20,990:INFO:Defining folds
2025-03-20 17:38:20,990:INFO:Declaring metric variables
2025-03-20 17:38:20,991:INFO:Importing untrained model
2025-03-20 17:38:20,993:INFO:Random Forest Regressor Imported successfully
2025-03-20 17:38:20,997:INFO:Starting cross validation
2025-03-20 17:38:20,998:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:21,324:INFO:Calculating mean and std
2025-03-20 17:38:21,325:INFO:Creating metrics dataframe
2025-03-20 17:38:21,326:INFO:Uploading results into container
2025-03-20 17:38:21,327:INFO:Uploading model into container now
2025-03-20 17:38:21,327:INFO:_master_model_container: 13
2025-03-20 17:38:21,327:INFO:_display_container: 2
2025-03-20 17:38:21,327:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 17:38:21,327:INFO:create_model() successfully completed......................................
2025-03-20 17:38:21,378:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:21,379:INFO:Creating metrics dataframe
2025-03-20 17:38:21,384:INFO:Initializing Extra Trees Regressor
2025-03-20 17:38:21,384:INFO:Total runtime is 0.2620644927024841 minutes
2025-03-20 17:38:21,386:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:21,386:INFO:Initializing create_model()
2025-03-20 17:38:21,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:21,387:INFO:Checking exceptions
2025-03-20 17:38:21,387:INFO:Importing libraries
2025-03-20 17:38:21,387:INFO:Copying training dataset
2025-03-20 17:38:21,388:INFO:Defining folds
2025-03-20 17:38:21,388:INFO:Declaring metric variables
2025-03-20 17:38:21,390:INFO:Importing untrained model
2025-03-20 17:38:21,392:INFO:Extra Trees Regressor Imported successfully
2025-03-20 17:38:21,395:INFO:Starting cross validation
2025-03-20 17:38:21,396:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:21,585:INFO:Calculating mean and std
2025-03-20 17:38:21,586:INFO:Creating metrics dataframe
2025-03-20 17:38:21,588:INFO:Uploading results into container
2025-03-20 17:38:21,588:INFO:Uploading model into container now
2025-03-20 17:38:21,588:INFO:_master_model_container: 14
2025-03-20 17:38:21,588:INFO:_display_container: 2
2025-03-20 17:38:21,589:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 17:38:21,589:INFO:create_model() successfully completed......................................
2025-03-20 17:38:21,640:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:21,640:INFO:Creating metrics dataframe
2025-03-20 17:38:21,647:INFO:Initializing AdaBoost Regressor
2025-03-20 17:38:21,647:INFO:Total runtime is 0.2664359966913859 minutes
2025-03-20 17:38:21,649:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:21,649:INFO:Initializing create_model()
2025-03-20 17:38:21,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:21,649:INFO:Checking exceptions
2025-03-20 17:38:21,649:INFO:Importing libraries
2025-03-20 17:38:21,649:INFO:Copying training dataset
2025-03-20 17:38:21,651:INFO:Defining folds
2025-03-20 17:38:21,651:INFO:Declaring metric variables
2025-03-20 17:38:21,652:INFO:Importing untrained model
2025-03-20 17:38:21,653:INFO:AdaBoost Regressor Imported successfully
2025-03-20 17:38:21,656:INFO:Starting cross validation
2025-03-20 17:38:21,657:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:21,847:INFO:Calculating mean and std
2025-03-20 17:38:21,848:INFO:Creating metrics dataframe
2025-03-20 17:38:21,850:INFO:Uploading results into container
2025-03-20 17:38:21,850:INFO:Uploading model into container now
2025-03-20 17:38:21,850:INFO:_master_model_container: 15
2025-03-20 17:38:21,850:INFO:_display_container: 2
2025-03-20 17:38:21,851:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 17:38:21,851:INFO:create_model() successfully completed......................................
2025-03-20 17:38:21,905:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:21,905:INFO:Creating metrics dataframe
2025-03-20 17:38:21,911:INFO:Initializing Gradient Boosting Regressor
2025-03-20 17:38:21,911:INFO:Total runtime is 0.27084052562713623 minutes
2025-03-20 17:38:21,913:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:21,913:INFO:Initializing create_model()
2025-03-20 17:38:21,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:21,913:INFO:Checking exceptions
2025-03-20 17:38:21,913:INFO:Importing libraries
2025-03-20 17:38:21,913:INFO:Copying training dataset
2025-03-20 17:38:21,915:INFO:Defining folds
2025-03-20 17:38:21,915:INFO:Declaring metric variables
2025-03-20 17:38:21,916:INFO:Importing untrained model
2025-03-20 17:38:21,918:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 17:38:21,920:INFO:Starting cross validation
2025-03-20 17:38:21,921:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:22,463:INFO:Calculating mean and std
2025-03-20 17:38:22,464:INFO:Creating metrics dataframe
2025-03-20 17:38:22,466:INFO:Uploading results into container
2025-03-20 17:38:22,466:INFO:Uploading model into container now
2025-03-20 17:38:22,466:INFO:_master_model_container: 16
2025-03-20 17:38:22,466:INFO:_display_container: 2
2025-03-20 17:38:22,467:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 17:38:22,467:INFO:create_model() successfully completed......................................
2025-03-20 17:38:22,520:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:22,520:INFO:Creating metrics dataframe
2025-03-20 17:38:22,527:INFO:Initializing Extreme Gradient Boosting
2025-03-20 17:38:22,527:INFO:Total runtime is 0.28110509316126503 minutes
2025-03-20 17:38:22,528:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:22,529:INFO:Initializing create_model()
2025-03-20 17:38:22,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:22,529:INFO:Checking exceptions
2025-03-20 17:38:22,529:INFO:Importing libraries
2025-03-20 17:38:22,529:INFO:Copying training dataset
2025-03-20 17:38:22,530:INFO:Defining folds
2025-03-20 17:38:22,531:INFO:Declaring metric variables
2025-03-20 17:38:22,532:INFO:Importing untrained model
2025-03-20 17:38:22,534:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 17:38:22,537:INFO:Starting cross validation
2025-03-20 17:38:22,538:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:23,002:INFO:Calculating mean and std
2025-03-20 17:38:23,003:INFO:Creating metrics dataframe
2025-03-20 17:38:23,004:INFO:Uploading results into container
2025-03-20 17:38:23,005:INFO:Uploading model into container now
2025-03-20 17:38:23,005:INFO:_master_model_container: 17
2025-03-20 17:38:23,005:INFO:_display_container: 2
2025-03-20 17:38:23,005:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 17:38:23,005:INFO:create_model() successfully completed......................................
2025-03-20 17:38:23,058:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:23,058:INFO:Creating metrics dataframe
2025-03-20 17:38:23,064:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 17:38:23,064:INFO:Total runtime is 0.2900620420773824 minutes
2025-03-20 17:38:23,066:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:23,066:INFO:Initializing create_model()
2025-03-20 17:38:23,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:23,066:INFO:Checking exceptions
2025-03-20 17:38:23,066:INFO:Importing libraries
2025-03-20 17:38:23,066:INFO:Copying training dataset
2025-03-20 17:38:23,068:INFO:Defining folds
2025-03-20 17:38:23,068:INFO:Declaring metric variables
2025-03-20 17:38:23,070:INFO:Importing untrained model
2025-03-20 17:38:23,071:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 17:38:23,074:INFO:Starting cross validation
2025-03-20 17:38:23,075:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:23,556:INFO:Calculating mean and std
2025-03-20 17:38:23,557:INFO:Creating metrics dataframe
2025-03-20 17:38:23,560:INFO:Uploading results into container
2025-03-20 17:38:23,560:INFO:Uploading model into container now
2025-03-20 17:38:23,560:INFO:_master_model_container: 18
2025-03-20 17:38:23,560:INFO:_display_container: 2
2025-03-20 17:38:23,561:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 17:38:23,561:INFO:create_model() successfully completed......................................
2025-03-20 17:38:23,620:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:23,620:INFO:Creating metrics dataframe
2025-03-20 17:38:23,629:INFO:Initializing CatBoost Regressor
2025-03-20 17:38:23,629:INFO:Total runtime is 0.29948214292526243 minutes
2025-03-20 17:38:23,631:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:23,632:INFO:Initializing create_model()
2025-03-20 17:38:23,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:23,632:INFO:Checking exceptions
2025-03-20 17:38:23,632:INFO:Importing libraries
2025-03-20 17:38:23,632:INFO:Copying training dataset
2025-03-20 17:38:23,634:INFO:Defining folds
2025-03-20 17:38:23,635:INFO:Declaring metric variables
2025-03-20 17:38:23,637:INFO:Importing untrained model
2025-03-20 17:38:23,639:INFO:CatBoost Regressor Imported successfully
2025-03-20 17:38:23,643:INFO:Starting cross validation
2025-03-20 17:38:23,644:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:25,928:INFO:Calculating mean and std
2025-03-20 17:38:25,929:INFO:Creating metrics dataframe
2025-03-20 17:38:25,930:INFO:Uploading results into container
2025-03-20 17:38:25,931:INFO:Uploading model into container now
2025-03-20 17:38:25,931:INFO:_master_model_container: 19
2025-03-20 17:38:25,931:INFO:_display_container: 2
2025-03-20 17:38:25,931:INFO:<catboost.core.CatBoostRegressor object at 0x00000247B55B7AF0>
2025-03-20 17:38:25,931:INFO:create_model() successfully completed......................................
2025-03-20 17:38:25,984:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:25,984:INFO:Creating metrics dataframe
2025-03-20 17:38:25,990:INFO:Initializing Dummy Regressor
2025-03-20 17:38:25,990:INFO:Total runtime is 0.33883146842320755 minutes
2025-03-20 17:38:25,992:INFO:SubProcess create_model() called ==================================
2025-03-20 17:38:25,992:INFO:Initializing create_model()
2025-03-20 17:38:25,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B054B670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:25,992:INFO:Checking exceptions
2025-03-20 17:38:25,992:INFO:Importing libraries
2025-03-20 17:38:25,992:INFO:Copying training dataset
2025-03-20 17:38:25,994:INFO:Defining folds
2025-03-20 17:38:25,994:INFO:Declaring metric variables
2025-03-20 17:38:25,996:INFO:Importing untrained model
2025-03-20 17:38:25,997:INFO:Dummy Regressor Imported successfully
2025-03-20 17:38:26,000:INFO:Starting cross validation
2025-03-20 17:38:26,001:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:38:26,066:INFO:Calculating mean and std
2025-03-20 17:38:26,067:INFO:Creating metrics dataframe
2025-03-20 17:38:26,069:INFO:Uploading results into container
2025-03-20 17:38:26,069:INFO:Uploading model into container now
2025-03-20 17:38:26,069:INFO:_master_model_container: 20
2025-03-20 17:38:26,069:INFO:_display_container: 2
2025-03-20 17:38:26,069:INFO:DummyRegressor()
2025-03-20 17:38:26,069:INFO:create_model() successfully completed......................................
2025-03-20 17:38:26,124:INFO:SubProcess create_model() end ==================================
2025-03-20 17:38:26,124:INFO:Creating metrics dataframe
2025-03-20 17:38:26,135:INFO:Initializing create_model()
2025-03-20 17:38:26,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:26,135:INFO:Checking exceptions
2025-03-20 17:38:26,136:INFO:Importing libraries
2025-03-20 17:38:26,136:INFO:Copying training dataset
2025-03-20 17:38:26,138:INFO:Defining folds
2025-03-20 17:38:26,138:INFO:Declaring metric variables
2025-03-20 17:38:26,138:INFO:Importing untrained model
2025-03-20 17:38:26,138:INFO:Declaring custom model
2025-03-20 17:38:26,138:INFO:Bayesian Ridge Imported successfully
2025-03-20 17:38:26,139:INFO:Cross validation set to False
2025-03-20 17:38:26,139:INFO:Fitting Model
2025-03-20 17:38:26,175:INFO:BayesianRidge()
2025-03-20 17:38:26,175:INFO:create_model() successfully completed......................................
2025-03-20 17:38:26,229:INFO:Creating Dashboard logs
2025-03-20 17:38:26,231:INFO:Model: Bayesian Ridge
2025-03-20 17:38:26,246:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 17:38:26,276:INFO:Initializing predict_model()
2025-03-20 17:38:26,276:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247B53DE0D0>)
2025-03-20 17:38:26,276:INFO:Checking exceptions
2025-03-20 17:38:26,276:INFO:Preloading libraries
2025-03-20 17:38:26,401:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 17:38:26,415:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:26,417:INFO:Initializing create_model()
2025-03-20 17:38:26,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:26,418:INFO:Checking exceptions
2025-03-20 17:38:26,418:INFO:Importing libraries
2025-03-20 17:38:26,419:INFO:Copying training dataset
2025-03-20 17:38:26,420:INFO:Defining folds
2025-03-20 17:38:26,420:INFO:Declaring metric variables
2025-03-20 17:38:26,421:INFO:Importing untrained model
2025-03-20 17:38:26,421:INFO:Declaring custom model
2025-03-20 17:38:26,421:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 17:38:26,422:INFO:Cross validation set to False
2025-03-20 17:38:26,422:INFO:Fitting Model
2025-03-20 17:38:27,005:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 17:38:27,005:INFO:create_model() successfully completed......................................
2025-03-20 17:38:27,059:INFO:Creating Dashboard logs
2025-03-20 17:38:27,061:INFO:Model: Gradient Boosting Regressor
2025-03-20 17:38:27,075:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 17:38:27,115:INFO:Initializing predict_model()
2025-03-20 17:38:27,116:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247B558D3A0>)
2025-03-20 17:38:27,116:INFO:Checking exceptions
2025-03-20 17:38:27,116:INFO:Preloading libraries
2025-03-20 17:38:27,251:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:27,254:INFO:Initializing create_model()
2025-03-20 17:38:27,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:27,254:INFO:Checking exceptions
2025-03-20 17:38:27,255:INFO:Importing libraries
2025-03-20 17:38:27,255:INFO:Copying training dataset
2025-03-20 17:38:27,256:INFO:Defining folds
2025-03-20 17:38:27,256:INFO:Declaring metric variables
2025-03-20 17:38:27,256:INFO:Importing untrained model
2025-03-20 17:38:27,256:INFO:Declaring custom model
2025-03-20 17:38:27,257:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 17:38:27,257:INFO:Cross validation set to False
2025-03-20 17:38:27,257:INFO:Fitting Model
2025-03-20 17:38:27,290:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 17:38:27,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-03-20 17:38:27,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 17:38:27,291:INFO:[LightGBM] [Info] Total Bins 3872
2025-03-20 17:38:27,292:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 35
2025-03-20 17:38:27,292:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 17:38:27,374:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 17:38:27,374:INFO:create_model() successfully completed......................................
2025-03-20 17:38:27,470:INFO:Creating Dashboard logs
2025-03-20 17:38:27,472:INFO:Model: Light Gradient Boosting Machine
2025-03-20 17:38:27,486:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 17:38:27,532:INFO:Initializing predict_model()
2025-03-20 17:38:27,532:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247B558C4C0>)
2025-03-20 17:38:27,532:INFO:Checking exceptions
2025-03-20 17:38:27,532:INFO:Preloading libraries
2025-03-20 17:38:27,675:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:27,679:INFO:Initializing create_model()
2025-03-20 17:38:27,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:38:27,679:INFO:Checking exceptions
2025-03-20 17:38:27,680:INFO:Importing libraries
2025-03-20 17:38:27,680:INFO:Copying training dataset
2025-03-20 17:38:27,682:INFO:Defining folds
2025-03-20 17:38:27,682:INFO:Declaring metric variables
2025-03-20 17:38:27,682:INFO:Importing untrained model
2025-03-20 17:38:27,682:INFO:Declaring custom model
2025-03-20 17:38:27,683:INFO:Random Forest Regressor Imported successfully
2025-03-20 17:38:27,683:INFO:Cross validation set to False
2025-03-20 17:38:27,683:INFO:Fitting Model
2025-03-20 17:38:27,899:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 17:38:27,899:INFO:create_model() successfully completed......................................
2025-03-20 17:38:27,957:INFO:Creating Dashboard logs
2025-03-20 17:38:27,959:INFO:Model: Random Forest Regressor
2025-03-20 17:38:27,974:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 17:38:28,027:INFO:Initializing predict_model()
2025-03-20 17:38:28,027:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247B5087940>)
2025-03-20 17:38:28,027:INFO:Checking exceptions
2025-03-20 17:38:28,027:INFO:Preloading libraries
2025-03-20 17:38:28,191:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,192:INFO:Creating Dashboard logs
2025-03-20 17:38:28,194:INFO:Model: Extreme Gradient Boosting
2025-03-20 17:38:28,208:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 17:38:28,291:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,292:INFO:Creating Dashboard logs
2025-03-20 17:38:28,296:INFO:Model: CatBoost Regressor
2025-03-20 17:38:28,321:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 17:38:28,321:INFO:Logged params: {}
2025-03-20 17:38:28,388:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x00000247B55B7AF0> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,388:INFO:Creating Dashboard logs
2025-03-20 17:38:28,390:INFO:Model: AdaBoost Regressor
2025-03-20 17:38:28,404:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 17:38:28,481:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,482:INFO:Creating Dashboard logs
2025-03-20 17:38:28,483:INFO:Model: Ridge Regression
2025-03-20 17:38:28,498:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 17:38:28,579:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,580:INFO:Creating Dashboard logs
2025-03-20 17:38:28,581:INFO:Model: Extra Trees Regressor
2025-03-20 17:38:28,595:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 17:38:28,688:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,688:INFO:Creating Dashboard logs
2025-03-20 17:38:28,690:INFO:Model: Decision Tree Regressor
2025-03-20 17:38:28,705:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 17:38:28,801:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,802:INFO:Creating Dashboard logs
2025-03-20 17:38:28,804:INFO:Model: Huber Regressor
2025-03-20 17:38:28,818:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 17:38:28,917:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:28,918:INFO:Creating Dashboard logs
2025-03-20 17:38:28,920:INFO:Model: Passive Aggressive Regressor
2025-03-20 17:38:28,934:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 17:38:29,043:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:29,044:INFO:Creating Dashboard logs
2025-03-20 17:38:29,045:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 17:38:29,059:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 17:38:29,170:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:29,171:INFO:Creating Dashboard logs
2025-03-20 17:38:29,173:INFO:Model: K Neighbors Regressor
2025-03-20 17:38:29,188:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 17:38:29,306:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:29,307:INFO:Creating Dashboard logs
2025-03-20 17:38:29,309:INFO:Model: Elastic Net
2025-03-20 17:38:29,323:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 17:38:29,447:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:29,448:INFO:Creating Dashboard logs
2025-03-20 17:38:29,450:INFO:Model: Lasso Regression
2025-03-20 17:38:29,464:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 17:38:29,592:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:29,593:INFO:Creating Dashboard logs
2025-03-20 17:38:29,595:INFO:Model: Lasso Least Angle Regression
2025-03-20 17:38:29,609:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 17:38:29,745:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:29,745:INFO:Creating Dashboard logs
2025-03-20 17:38:29,747:INFO:Model: Dummy Regressor
2025-03-20 17:38:29,761:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 17:38:29,898:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:29,899:INFO:Creating Dashboard logs
2025-03-20 17:38:29,901:INFO:Model: Linear Regression
2025-03-20 17:38:29,917:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 17:38:30,059:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:30,060:INFO:Creating Dashboard logs
2025-03-20 17:38:30,062:INFO:Model: Least Angle Regression
2025-03-20 17:38:30,077:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 17:38:30,228:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:38:30,235:INFO:_master_model_container: 20
2025-03-20 17:38:30,235:INFO:_display_container: 2
2025-03-20 17:38:30,236:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), RandomForestRegressor(n_jobs=-1, random_state=888)]
2025-03-20 17:38:30,236:INFO:compare_models() successfully completed......................................
2025-03-20 17:39:46,343:INFO:Initializing tune_model()
2025-03-20 17:39:46,343:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>)
2025-03-20 17:39:46,344:INFO:Checking exceptions
2025-03-20 17:39:46,344:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 17:39:46,400:INFO:Copying training dataset
2025-03-20 17:39:46,401:INFO:Checking base model
2025-03-20 17:39:46,402:INFO:Base model : Bayesian Ridge
2025-03-20 17:39:46,403:INFO:Declaring metric variables
2025-03-20 17:39:46,405:INFO:Defining Hyperparameters
2025-03-20 17:39:46,461:INFO:Tuning with n_jobs=-1
2025-03-20 17:39:46,462:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:39:46,462:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:39:46,462:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 17:39:46,467:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:39:46,467:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 17:39:46,468:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 17:40:14,390:INFO:best_params: {'actual_estimator__alpha_1': 0.0010476781327366928, 'actual_estimator__alpha_2': 5.858592852295242e-07, 'actual_estimator__lambda_1': 0.891900372088813, 'actual_estimator__lambda_2': 1.408836736576288e-07, 'actual_estimator__compute_score': True, 'actual_estimator__fit_intercept': True}
2025-03-20 17:40:14,495:INFO:Hyperparameter search completed
2025-03-20 17:40:14,495:INFO:SubProcess create_model() called ==================================
2025-03-20 17:40:14,495:INFO:Initializing create_model()
2025-03-20 17:40:14,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B3DDF3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 0.0010476781327366928, 'alpha_2': 5.858592852295242e-07, 'lambda_1': 0.891900372088813, 'lambda_2': 1.408836736576288e-07, 'compute_score': True, 'fit_intercept': True})
2025-03-20 17:40:14,496:INFO:Checking exceptions
2025-03-20 17:40:14,496:INFO:Importing libraries
2025-03-20 17:40:14,496:INFO:Copying training dataset
2025-03-20 17:40:14,499:INFO:Defining folds
2025-03-20 17:40:14,500:INFO:Declaring metric variables
2025-03-20 17:40:14,502:INFO:Importing untrained model
2025-03-20 17:40:14,502:INFO:Declaring custom model
2025-03-20 17:40:14,505:INFO:Bayesian Ridge Imported successfully
2025-03-20 17:40:14,509:INFO:Starting cross validation
2025-03-20 17:40:14,510:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:40:14,617:INFO:Calculating mean and std
2025-03-20 17:40:14,618:INFO:Creating metrics dataframe
2025-03-20 17:40:14,623:INFO:Finalizing model
2025-03-20 17:40:14,681:INFO:Uploading results into container
2025-03-20 17:40:14,682:INFO:Uploading model into container now
2025-03-20 17:40:14,682:INFO:_master_model_container: 21
2025-03-20 17:40:14,682:INFO:_display_container: 3
2025-03-20 17:40:14,683:INFO:BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07)
2025-03-20 17:40:14,683:INFO:create_model() successfully completed......................................
2025-03-20 17:40:14,781:INFO:SubProcess create_model() end ==================================
2025-03-20 17:40:14,781:INFO:choose_better activated
2025-03-20 17:40:14,784:INFO:SubProcess create_model() called ==================================
2025-03-20 17:40:14,785:INFO:Initializing create_model()
2025-03-20 17:40:14,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:40:14,785:INFO:Checking exceptions
2025-03-20 17:40:14,786:INFO:Importing libraries
2025-03-20 17:40:14,786:INFO:Copying training dataset
2025-03-20 17:40:14,789:INFO:Defining folds
2025-03-20 17:40:14,789:INFO:Declaring metric variables
2025-03-20 17:40:14,789:INFO:Importing untrained model
2025-03-20 17:40:14,790:INFO:Declaring custom model
2025-03-20 17:40:14,790:INFO:Bayesian Ridge Imported successfully
2025-03-20 17:40:14,790:INFO:Starting cross validation
2025-03-20 17:40:14,791:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:40:14,894:INFO:Calculating mean and std
2025-03-20 17:40:14,895:INFO:Creating metrics dataframe
2025-03-20 17:40:14,896:INFO:Finalizing model
2025-03-20 17:40:14,952:INFO:Uploading results into container
2025-03-20 17:40:14,952:INFO:Uploading model into container now
2025-03-20 17:40:14,952:INFO:_master_model_container: 22
2025-03-20 17:40:14,952:INFO:_display_container: 4
2025-03-20 17:40:14,953:INFO:BayesianRidge()
2025-03-20 17:40:14,953:INFO:create_model() successfully completed......................................
2025-03-20 17:40:15,048:INFO:SubProcess create_model() end ==================================
2025-03-20 17:40:15,048:INFO:BayesianRidge() result for MAPE is 0.0214
2025-03-20 17:40:15,049:INFO:BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07) result for MAPE is 0.0213
2025-03-20 17:40:15,049:INFO:BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07) is best model
2025-03-20 17:40:15,049:INFO:choose_better completed
2025-03-20 17:40:15,049:INFO:Creating Dashboard logs
2025-03-20 17:40:15,052:INFO:Model: Bayesian Ridge
2025-03-20 17:40:15,079:INFO:Logged params: {'alpha_1': 0.0010476781327366928, 'alpha_2': 5.858592852295242e-07, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.891900372088813, 'lambda_2': 1.408836736576288e-07, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 17:40:15,370:INFO:Initializing predict_model()
2025-03-20 17:40:15,370:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247BB9C1550>)
2025-03-20 17:40:15,370:INFO:Checking exceptions
2025-03-20 17:40:15,370:INFO:Preloading libraries
2025-03-20 17:40:15,614:ERROR:_log_model() for BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:40:15,621:INFO:_master_model_container: 22
2025-03-20 17:40:15,621:INFO:_display_container: 3
2025-03-20 17:40:15,622:INFO:BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07)
2025-03-20 17:40:15,622:INFO:tune_model() successfully completed......................................
2025-03-20 17:40:15,723:INFO:Initializing tune_model()
2025-03-20 17:40:15,724:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>)
2025-03-20 17:40:15,724:INFO:Checking exceptions
2025-03-20 17:40:15,724:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 17:40:15,736:INFO:Copying training dataset
2025-03-20 17:40:15,739:INFO:Checking base model
2025-03-20 17:40:15,740:INFO:Base model : Gradient Boosting Regressor
2025-03-20 17:40:15,742:INFO:Declaring metric variables
2025-03-20 17:40:15,745:INFO:Defining Hyperparameters
2025-03-20 17:40:15,846:INFO:Tuning with n_jobs=-1
2025-03-20 17:40:15,847:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:40:15,847:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:40:15,847:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 17:40:15,847:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:40:15,847:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 17:40:15,847:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 17:41:21,440:INFO:best_params: {'actual_estimator__n_estimators': 228, 'actual_estimator__learning_rate': 0.15971188839542688, 'actual_estimator__subsample': 0.4526757240009556, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 4, 'actual_estimator__max_features': 0.619515785082508, 'actual_estimator__min_impurity_decrease': 3.860418952071103e-07}
2025-03-20 17:41:21,445:INFO:Hyperparameter search completed
2025-03-20 17:41:21,445:INFO:SubProcess create_model() called ==================================
2025-03-20 17:41:21,445:INFO:Initializing create_model()
2025-03-20 17:41:21,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247CAC7E9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 228, 'learning_rate': 0.15971188839542688, 'subsample': 0.4526757240009556, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 0.619515785082508, 'min_impurity_decrease': 3.860418952071103e-07})
2025-03-20 17:41:21,445:INFO:Checking exceptions
2025-03-20 17:41:21,446:INFO:Importing libraries
2025-03-20 17:41:21,446:INFO:Copying training dataset
2025-03-20 17:41:21,448:INFO:Defining folds
2025-03-20 17:41:21,448:INFO:Declaring metric variables
2025-03-20 17:41:21,449:INFO:Importing untrained model
2025-03-20 17:41:21,449:INFO:Declaring custom model
2025-03-20 17:41:21,452:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 17:41:21,455:INFO:Starting cross validation
2025-03-20 17:41:21,455:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:41:21,946:INFO:Calculating mean and std
2025-03-20 17:41:21,947:INFO:Creating metrics dataframe
2025-03-20 17:41:21,950:INFO:Finalizing model
2025-03-20 17:41:22,479:INFO:Uploading results into container
2025-03-20 17:41:22,479:INFO:Uploading model into container now
2025-03-20 17:41:22,480:INFO:_master_model_container: 23
2025-03-20 17:41:22,480:INFO:_display_container: 4
2025-03-20 17:41:22,480:INFO:GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556)
2025-03-20 17:41:22,480:INFO:create_model() successfully completed......................................
2025-03-20 17:41:22,535:INFO:SubProcess create_model() end ==================================
2025-03-20 17:41:22,535:INFO:choose_better activated
2025-03-20 17:41:22,536:INFO:SubProcess create_model() called ==================================
2025-03-20 17:41:22,537:INFO:Initializing create_model()
2025-03-20 17:41:22,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:41:22,537:INFO:Checking exceptions
2025-03-20 17:41:22,538:INFO:Importing libraries
2025-03-20 17:41:22,538:INFO:Copying training dataset
2025-03-20 17:41:22,540:INFO:Defining folds
2025-03-20 17:41:22,540:INFO:Declaring metric variables
2025-03-20 17:41:22,540:INFO:Importing untrained model
2025-03-20 17:41:22,540:INFO:Declaring custom model
2025-03-20 17:41:22,540:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 17:41:22,540:INFO:Starting cross validation
2025-03-20 17:41:22,541:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:41:23,055:INFO:Calculating mean and std
2025-03-20 17:41:23,055:INFO:Creating metrics dataframe
2025-03-20 17:41:23,056:INFO:Finalizing model
2025-03-20 17:41:23,633:INFO:Uploading results into container
2025-03-20 17:41:23,633:INFO:Uploading model into container now
2025-03-20 17:41:23,633:INFO:_master_model_container: 24
2025-03-20 17:41:23,633:INFO:_display_container: 5
2025-03-20 17:41:23,633:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 17:41:23,633:INFO:create_model() successfully completed......................................
2025-03-20 17:41:23,686:INFO:SubProcess create_model() end ==================================
2025-03-20 17:41:23,687:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.0217
2025-03-20 17:41:23,687:INFO:GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556) result for MAPE is 0.0206
2025-03-20 17:41:23,687:INFO:GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556) is best model
2025-03-20 17:41:23,687:INFO:choose_better completed
2025-03-20 17:41:23,687:INFO:Creating Dashboard logs
2025-03-20 17:41:23,689:INFO:Model: Gradient Boosting Regressor
2025-03-20 17:41:23,703:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.15971188839542688, 'loss': 'squared_error', 'max_depth': 4, 'max_features': 0.619515785082508, 'max_leaf_nodes': None, 'min_impurity_decrease': 3.860418952071103e-07, 'min_samples_leaf': 1, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 228, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.4526757240009556, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 17:41:23,859:INFO:Initializing predict_model()
2025-03-20 17:41:23,859:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247BB9C14C0>)
2025-03-20 17:41:23,859:INFO:Checking exceptions
2025-03-20 17:41:23,859:INFO:Preloading libraries
2025-03-20 17:41:24,002:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:41:24,006:INFO:_master_model_container: 24
2025-03-20 17:41:24,007:INFO:_display_container: 4
2025-03-20 17:41:24,007:INFO:GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556)
2025-03-20 17:41:24,007:INFO:tune_model() successfully completed......................................
2025-03-20 17:41:24,064:INFO:Initializing tune_model()
2025-03-20 17:41:24,064:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>)
2025-03-20 17:41:24,064:INFO:Checking exceptions
2025-03-20 17:41:24,065:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 17:41:24,074:INFO:Copying training dataset
2025-03-20 17:41:24,075:INFO:Checking base model
2025-03-20 17:41:24,075:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 17:41:24,077:INFO:Declaring metric variables
2025-03-20 17:41:24,079:INFO:Defining Hyperparameters
2025-03-20 17:41:24,134:INFO:Tuning with n_jobs=-1
2025-03-20 17:41:24,135:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:41:24,135:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:41:24,135:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 17:41:24,135:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:41:24,135:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 17:41:24,135:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 17:42:08,041:INFO:best_params: {'actual_estimator__num_leaves': 20, 'actual_estimator__learning_rate': 0.0535387198228409, 'actual_estimator__n_estimators': 231, 'actual_estimator__min_split_gain': 0.07788320522909709, 'actual_estimator__reg_alpha': 1.7180618867810928e-08, 'actual_estimator__reg_lambda': 0.004158548682315826, 'actual_estimator__feature_fraction': 0.8535873548096533, 'actual_estimator__bagging_fraction': 0.8118154899895776, 'actual_estimator__bagging_freq': 6, 'actual_estimator__min_child_samples': 1}
2025-03-20 17:42:08,048:INFO:Hyperparameter search completed
2025-03-20 17:42:08,048:INFO:SubProcess create_model() called ==================================
2025-03-20 17:42:08,048:INFO:Initializing create_model()
2025-03-20 17:42:08,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B39EB970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 20, 'learning_rate': 0.0535387198228409, 'n_estimators': 231, 'min_split_gain': 0.07788320522909709, 'reg_alpha': 1.7180618867810928e-08, 'reg_lambda': 0.004158548682315826, 'feature_fraction': 0.8535873548096533, 'bagging_fraction': 0.8118154899895776, 'bagging_freq': 6, 'min_child_samples': 1})
2025-03-20 17:42:08,048:INFO:Checking exceptions
2025-03-20 17:42:08,048:INFO:Importing libraries
2025-03-20 17:42:08,048:INFO:Copying training dataset
2025-03-20 17:42:08,052:INFO:Defining folds
2025-03-20 17:42:08,052:INFO:Declaring metric variables
2025-03-20 17:42:08,054:INFO:Importing untrained model
2025-03-20 17:42:08,054:INFO:Declaring custom model
2025-03-20 17:42:08,057:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 17:42:08,061:INFO:Starting cross validation
2025-03-20 17:42:08,062:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:42:08,413:INFO:Calculating mean and std
2025-03-20 17:42:08,415:INFO:Creating metrics dataframe
2025-03-20 17:42:08,418:INFO:Finalizing model
2025-03-20 17:42:08,460:INFO:[LightGBM] [Warning] feature_fraction is set=0.8535873548096533, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8535873548096533
2025-03-20 17:42:08,460:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8118154899895776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118154899895776
2025-03-20 17:42:08,460:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 17:42:08,462:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 17:42:08,462:INFO:[LightGBM] [Warning] feature_fraction is set=0.8535873548096533, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8535873548096533
2025-03-20 17:42:08,462:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8118154899895776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118154899895776
2025-03-20 17:42:08,462:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 17:42:08,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
2025-03-20 17:42:08,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 17:42:08,463:INFO:[LightGBM] [Info] Total Bins 3872
2025-03-20 17:42:08,464:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 35
2025-03-20 17:42:08,464:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 17:42:08,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:42:08,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:42:08,557:INFO:Uploading results into container
2025-03-20 17:42:08,557:INFO:Uploading model into container now
2025-03-20 17:42:08,557:INFO:_master_model_container: 25
2025-03-20 17:42:08,558:INFO:_display_container: 5
2025-03-20 17:42:08,558:INFO:LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826)
2025-03-20 17:42:08,558:INFO:create_model() successfully completed......................................
2025-03-20 17:42:08,628:INFO:SubProcess create_model() end ==================================
2025-03-20 17:42:08,628:INFO:choose_better activated
2025-03-20 17:42:08,631:INFO:SubProcess create_model() called ==================================
2025-03-20 17:42:08,631:INFO:Initializing create_model()
2025-03-20 17:42:08,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:42:08,631:INFO:Checking exceptions
2025-03-20 17:42:08,632:INFO:Importing libraries
2025-03-20 17:42:08,633:INFO:Copying training dataset
2025-03-20 17:42:08,636:INFO:Defining folds
2025-03-20 17:42:08,636:INFO:Declaring metric variables
2025-03-20 17:42:08,636:INFO:Importing untrained model
2025-03-20 17:42:08,636:INFO:Declaring custom model
2025-03-20 17:42:08,636:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 17:42:08,637:INFO:Starting cross validation
2025-03-20 17:42:08,638:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:42:09,106:INFO:Calculating mean and std
2025-03-20 17:42:09,107:INFO:Creating metrics dataframe
2025-03-20 17:42:09,108:INFO:Finalizing model
2025-03-20 17:42:09,149:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 17:42:09,150:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-03-20 17:42:09,150:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 17:42:09,150:INFO:[LightGBM] [Info] Total Bins 3872
2025-03-20 17:42:09,151:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 35
2025-03-20 17:42:09,151:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 17:42:09,257:INFO:Uploading results into container
2025-03-20 17:42:09,257:INFO:Uploading model into container now
2025-03-20 17:42:09,257:INFO:_master_model_container: 26
2025-03-20 17:42:09,257:INFO:_display_container: 6
2025-03-20 17:42:09,258:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 17:42:09,258:INFO:create_model() successfully completed......................................
2025-03-20 17:42:09,319:INFO:SubProcess create_model() end ==================================
2025-03-20 17:42:09,320:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0234
2025-03-20 17:42:09,320:INFO:LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826) result for MAPE is 0.0222
2025-03-20 17:42:09,320:INFO:LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826) is best model
2025-03-20 17:42:09,320:INFO:choose_better completed
2025-03-20 17:42:09,321:INFO:Creating Dashboard logs
2025-03-20 17:42:09,323:INFO:Model: Light Gradient Boosting Machine
2025-03-20 17:42:09,343:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.0535387198228409, 'max_depth': -1, 'min_child_samples': 1, 'min_child_weight': 0.001, 'min_split_gain': 0.07788320522909709, 'n_estimators': 231, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 888, 'reg_alpha': 1.7180618867810928e-08, 'reg_lambda': 0.004158548682315826, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.8535873548096533, 'bagging_fraction': 0.8118154899895776, 'bagging_freq': 6}
2025-03-20 17:42:09,520:INFO:Initializing predict_model()
2025-03-20 17:42:09,520:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247BB9DADC0>)
2025-03-20 17:42:09,520:INFO:Checking exceptions
2025-03-20 17:42:09,520:INFO:Preloading libraries
2025-03-20 17:42:09,671:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:42:09,676:INFO:_master_model_container: 26
2025-03-20 17:42:09,676:INFO:_display_container: 5
2025-03-20 17:42:09,677:INFO:LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826)
2025-03-20 17:42:09,677:INFO:tune_model() successfully completed......................................
2025-03-20 17:42:09,740:INFO:Initializing tune_model()
2025-03-20 17:42:09,741:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>)
2025-03-20 17:42:09,741:INFO:Checking exceptions
2025-03-20 17:42:09,741:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 17:42:09,751:INFO:Copying training dataset
2025-03-20 17:42:09,755:INFO:Checking base model
2025-03-20 17:42:09,755:INFO:Base model : Random Forest Regressor
2025-03-20 17:42:09,758:INFO:Declaring metric variables
2025-03-20 17:42:09,761:INFO:Defining Hyperparameters
2025-03-20 17:42:09,824:INFO:Tuning with n_jobs=-1
2025-03-20 17:42:09,824:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:42:09,825:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 17:42:09,825:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 17:42:09,825:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 17:42:09,825:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 17:42:09,826:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 17:43:46,649:INFO:best_params: {'actual_estimator__n_estimators': 113, 'actual_estimator__max_depth': 11, 'actual_estimator__min_impurity_decrease': 2.2336845690726795e-07, 'actual_estimator__max_features': 0.46245443790470414, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__bootstrap': False, 'actual_estimator__criterion': 'squared_error'}
2025-03-20 17:43:46,654:INFO:Hyperparameter search completed
2025-03-20 17:43:46,654:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:46,657:INFO:Initializing create_model()
2025-03-20 17:43:46,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247CAC7E9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 113, 'max_depth': 11, 'min_impurity_decrease': 2.2336845690726795e-07, 'max_features': 0.46245443790470414, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'squared_error'})
2025-03-20 17:43:46,657:INFO:Checking exceptions
2025-03-20 17:43:46,657:INFO:Importing libraries
2025-03-20 17:43:46,657:INFO:Copying training dataset
2025-03-20 17:43:46,661:INFO:Defining folds
2025-03-20 17:43:46,661:INFO:Declaring metric variables
2025-03-20 17:43:46,663:INFO:Importing untrained model
2025-03-20 17:43:46,663:INFO:Declaring custom model
2025-03-20 17:43:46,665:INFO:Random Forest Regressor Imported successfully
2025-03-20 17:43:46,668:INFO:Starting cross validation
2025-03-20 17:43:46,669:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:46,891:INFO:Calculating mean and std
2025-03-20 17:43:46,892:INFO:Creating metrics dataframe
2025-03-20 17:43:46,895:INFO:Finalizing model
2025-03-20 17:43:47,019:INFO:Uploading results into container
2025-03-20 17:43:47,019:INFO:Uploading model into container now
2025-03-20 17:43:47,019:INFO:_master_model_container: 27
2025-03-20 17:43:47,019:INFO:_display_container: 6
2025-03-20 17:43:47,020:INFO:RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888)
2025-03-20 17:43:47,020:INFO:create_model() successfully completed......................................
2025-03-20 17:43:47,077:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:47,077:INFO:choose_better activated
2025-03-20 17:43:47,079:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:47,079:INFO:Initializing create_model()
2025-03-20 17:43:47,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:47,079:INFO:Checking exceptions
2025-03-20 17:43:47,080:INFO:Importing libraries
2025-03-20 17:43:47,080:INFO:Copying training dataset
2025-03-20 17:43:47,082:INFO:Defining folds
2025-03-20 17:43:47,082:INFO:Declaring metric variables
2025-03-20 17:43:47,083:INFO:Importing untrained model
2025-03-20 17:43:47,083:INFO:Declaring custom model
2025-03-20 17:43:47,083:INFO:Random Forest Regressor Imported successfully
2025-03-20 17:43:47,083:INFO:Starting cross validation
2025-03-20 17:43:47,084:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:47,430:INFO:Calculating mean and std
2025-03-20 17:43:47,430:INFO:Creating metrics dataframe
2025-03-20 17:43:47,431:INFO:Finalizing model
2025-03-20 17:43:47,601:INFO:Uploading results into container
2025-03-20 17:43:47,601:INFO:Uploading model into container now
2025-03-20 17:43:47,601:INFO:_master_model_container: 28
2025-03-20 17:43:47,601:INFO:_display_container: 7
2025-03-20 17:43:47,601:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 17:43:47,602:INFO:create_model() successfully completed......................................
2025-03-20 17:43:47,657:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:47,657:INFO:RandomForestRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0234
2025-03-20 17:43:47,658:INFO:RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888) result for MAPE is 0.0209
2025-03-20 17:43:47,658:INFO:RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888) is best model
2025-03-20 17:43:47,658:INFO:choose_better completed
2025-03-20 17:43:47,658:INFO:Creating Dashboard logs
2025-03-20 17:43:47,661:INFO:Model: Random Forest Regressor
2025-03-20 17:43:47,677:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 11, 'max_features': 0.46245443790470414, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 2.2336845690726795e-07, 'min_samples_leaf': 2, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 113, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 17:43:47,857:INFO:Initializing predict_model()
2025-03-20 17:43:47,857:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247BB96C670>)
2025-03-20 17:43:47,857:INFO:Checking exceptions
2025-03-20 17:43:47,857:INFO:Preloading libraries
2025-03-20 17:43:48,039:ERROR:_log_model() for RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:48,044:INFO:_master_model_container: 28
2025-03-20 17:43:48,044:INFO:_display_container: 6
2025-03-20 17:43:48,044:INFO:RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888)
2025-03-20 17:43:48,044:INFO:tune_model() successfully completed......................................
2025-03-20 17:43:48,105:INFO:Initializing blend_models()
2025-03-20 17:43:48,105:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator_list=[BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556), LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826), RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 17:43:48,106:INFO:Checking exceptions
2025-03-20 17:43:48,115:INFO:Importing libraries
2025-03-20 17:43:48,115:INFO:Copying training dataset
2025-03-20 17:43:48,117:INFO:Getting model names
2025-03-20 17:43:48,120:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:48,125:INFO:Initializing create_model()
2025-03-20 17:43:48,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B55B1610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:48,125:INFO:Checking exceptions
2025-03-20 17:43:48,125:INFO:Importing libraries
2025-03-20 17:43:48,125:INFO:Copying training dataset
2025-03-20 17:43:48,127:INFO:Defining folds
2025-03-20 17:43:48,128:INFO:Declaring metric variables
2025-03-20 17:43:48,130:INFO:Importing untrained model
2025-03-20 17:43:48,130:INFO:Declaring custom model
2025-03-20 17:43:48,133:INFO:Voting Regressor Imported successfully
2025-03-20 17:43:48,137:INFO:Starting cross validation
2025-03-20 17:43:48,137:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:49,062:INFO:Calculating mean and std
2025-03-20 17:43:49,062:INFO:Creating metrics dataframe
2025-03-20 17:43:49,066:INFO:Finalizing model
2025-03-20 17:43:49,683:INFO:Uploading results into container
2025-03-20 17:43:49,683:INFO:Uploading model into container now
2025-03-20 17:43:49,683:INFO:_master_model_container: 29
2025-03-20 17:43:49,683:INFO:_display_container: 7
2025-03-20 17:43:49,687:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)
2025-03-20 17:43:49,688:INFO:create_model() successfully completed......................................
2025-03-20 17:43:49,758:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:49,758:INFO:Creating Dashboard logs
2025-03-20 17:43:49,760:INFO:Model: Voting Regressor
2025-03-20 17:43:49,778:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), 'Bayesian Ridge__alpha_1': 0.0010476781327366928, 'Bayesian Ridge__alpha_2': 5.858592852295242e-07, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': True, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.891900372088813, 'Bayesian Ridge__lambda_2': 1.408836736576288e-07, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.15971188839542688, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 4, 'Gradient Boosting Regressor__max_features': 0.619515785082508, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 3.860418952071103e-07, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 228, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.4526757240009556, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.0535387198228409, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 1, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.07788320522909709, 'Light Gradient Boosting Machine__n_estimators': 231, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 20, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 1.7180618867810928e-08, 'Light Gradient Boosting Machine__reg_lambda': 0.004158548682315826, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.8535873548096533, 'Light Gradient Boosting Machine__bagging_fraction': 0.8118154899895776, 'Light Gradient Boosting Machine__bagging_freq': 6, 'Random Forest Regressor__bootstrap': False, 'Random Forest Regressor__ccp_alpha': 0.0, 'Random Forest Regressor__criterion': 'squared_error', 'Random Forest Regressor__max_depth': 11, 'Random Forest Regressor__max_features': 0.46245443790470414, 'Random Forest Regressor__max_leaf_nodes': None, 'Random Forest Regressor__max_samples': None, 'Random Forest Regressor__min_impurity_decrease': 2.2336845690726795e-07, 'Random Forest Regressor__min_samples_leaf': 2, 'Random Forest Regressor__min_samples_split': 3, 'Random Forest Regressor__min_weight_fraction_leaf': 0.0, 'Random Forest Regressor__n_estimators': 113, 'Random Forest Regressor__n_jobs': -1, 'Random Forest Regressor__oob_score': False, 'Random Forest Regressor__random_state': 888, 'Random Forest Regressor__verbose': 0, 'Random Forest Regressor__warm_start': False}
2025-03-20 17:43:50,002:INFO:Initializing predict_model()
2025-03-20 17:43:50,002:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247BB96C0D0>)
2025-03-20 17:43:50,002:INFO:Checking exceptions
2025-03-20 17:43:50,002:INFO:Preloading libraries
2025-03-20 17:43:50,203:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:50,210:INFO:_master_model_container: 29
2025-03-20 17:43:50,210:INFO:_display_container: 7
2025-03-20 17:43:50,216:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)
2025-03-20 17:43:50,216:INFO:blend_models() successfully completed......................................
2025-03-20 17:43:50,289:INFO:Initializing compare_models()
2025-03-20 17:43:50,289:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, include=[BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556), LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826), RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888), VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, 'include': [BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556), LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826), RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888), VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 17:43:50,289:INFO:Checking exceptions
2025-03-20 17:43:50,291:INFO:Preparing display monitor
2025-03-20 17:43:50,302:INFO:Initializing custom model Bayesian Ridge
2025-03-20 17:43:50,302:INFO:Total runtime is 0.0 minutes
2025-03-20 17:43:50,303:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:50,303:INFO:Initializing create_model()
2025-03-20 17:43:50,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B57D6AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:50,303:INFO:Checking exceptions
2025-03-20 17:43:50,304:INFO:Importing libraries
2025-03-20 17:43:50,304:INFO:Copying training dataset
2025-03-20 17:43:50,308:INFO:Defining folds
2025-03-20 17:43:50,308:INFO:Declaring metric variables
2025-03-20 17:43:50,310:INFO:Importing untrained model
2025-03-20 17:43:50,310:INFO:Declaring custom model
2025-03-20 17:43:50,312:INFO:Bayesian Ridge Imported successfully
2025-03-20 17:43:50,316:INFO:Starting cross validation
2025-03-20 17:43:50,317:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:50,386:INFO:Calculating mean and std
2025-03-20 17:43:50,386:INFO:Creating metrics dataframe
2025-03-20 17:43:50,388:INFO:Uploading results into container
2025-03-20 17:43:50,388:INFO:Uploading model into container now
2025-03-20 17:43:50,388:INFO:_master_model_container: 30
2025-03-20 17:43:50,388:INFO:_display_container: 8
2025-03-20 17:43:50,388:INFO:BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07)
2025-03-20 17:43:50,388:INFO:create_model() successfully completed......................................
2025-03-20 17:43:50,445:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:50,445:INFO:Creating metrics dataframe
2025-03-20 17:43:50,450:INFO:Initializing custom model Gradient Boosting Regressor
2025-03-20 17:43:50,450:INFO:Total runtime is 0.0024670521418253583 minutes
2025-03-20 17:43:50,452:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:50,452:INFO:Initializing create_model()
2025-03-20 17:43:50,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B57D6AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:50,452:INFO:Checking exceptions
2025-03-20 17:43:50,452:INFO:Importing libraries
2025-03-20 17:43:50,452:INFO:Copying training dataset
2025-03-20 17:43:50,454:INFO:Defining folds
2025-03-20 17:43:50,454:INFO:Declaring metric variables
2025-03-20 17:43:50,456:INFO:Importing untrained model
2025-03-20 17:43:50,456:INFO:Declaring custom model
2025-03-20 17:43:50,458:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 17:43:50,461:INFO:Starting cross validation
2025-03-20 17:43:50,462:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:50,956:INFO:Calculating mean and std
2025-03-20 17:43:50,956:INFO:Creating metrics dataframe
2025-03-20 17:43:50,957:INFO:Uploading results into container
2025-03-20 17:43:50,957:INFO:Uploading model into container now
2025-03-20 17:43:50,958:INFO:_master_model_container: 31
2025-03-20 17:43:50,958:INFO:_display_container: 8
2025-03-20 17:43:50,958:INFO:GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556)
2025-03-20 17:43:50,958:INFO:create_model() successfully completed......................................
2025-03-20 17:43:51,014:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:51,014:INFO:Creating metrics dataframe
2025-03-20 17:43:51,019:INFO:Initializing custom model Light Gradient Boosting Machine
2025-03-20 17:43:51,019:INFO:Total runtime is 0.011950822671254475 minutes
2025-03-20 17:43:51,021:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:51,021:INFO:Initializing create_model()
2025-03-20 17:43:51,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B57D6AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:51,022:INFO:Checking exceptions
2025-03-20 17:43:51,022:INFO:Importing libraries
2025-03-20 17:43:51,022:INFO:Copying training dataset
2025-03-20 17:43:51,024:INFO:Defining folds
2025-03-20 17:43:51,024:INFO:Declaring metric variables
2025-03-20 17:43:51,026:INFO:Importing untrained model
2025-03-20 17:43:51,026:INFO:Declaring custom model
2025-03-20 17:43:51,028:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 17:43:51,032:INFO:Starting cross validation
2025-03-20 17:43:51,033:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:52,973:INFO:Calculating mean and std
2025-03-20 17:43:52,974:INFO:Creating metrics dataframe
2025-03-20 17:43:52,976:INFO:Uploading results into container
2025-03-20 17:43:52,976:INFO:Uploading model into container now
2025-03-20 17:43:52,977:INFO:_master_model_container: 32
2025-03-20 17:43:52,977:INFO:_display_container: 8
2025-03-20 17:43:52,978:INFO:LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826)
2025-03-20 17:43:52,978:INFO:create_model() successfully completed......................................
2025-03-20 17:43:53,046:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:53,046:INFO:Creating metrics dataframe
2025-03-20 17:43:53,053:INFO:Initializing custom model Random Forest Regressor
2025-03-20 17:43:53,053:INFO:Total runtime is 0.04585026105244954 minutes
2025-03-20 17:43:53,055:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:53,056:INFO:Initializing create_model()
2025-03-20 17:43:53,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B57D6AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:53,056:INFO:Checking exceptions
2025-03-20 17:43:53,056:INFO:Importing libraries
2025-03-20 17:43:53,056:INFO:Copying training dataset
2025-03-20 17:43:53,059:INFO:Defining folds
2025-03-20 17:43:53,059:INFO:Declaring metric variables
2025-03-20 17:43:53,061:INFO:Importing untrained model
2025-03-20 17:43:53,061:INFO:Declaring custom model
2025-03-20 17:43:53,064:INFO:Random Forest Regressor Imported successfully
2025-03-20 17:43:53,069:INFO:Starting cross validation
2025-03-20 17:43:53,070:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:53,265:INFO:Calculating mean and std
2025-03-20 17:43:53,266:INFO:Creating metrics dataframe
2025-03-20 17:43:53,267:INFO:Uploading results into container
2025-03-20 17:43:53,268:INFO:Uploading model into container now
2025-03-20 17:43:53,268:INFO:_master_model_container: 33
2025-03-20 17:43:53,268:INFO:_display_container: 8
2025-03-20 17:43:53,268:INFO:RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888)
2025-03-20 17:43:53,269:INFO:create_model() successfully completed......................................
2025-03-20 17:43:53,325:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:53,326:INFO:Creating metrics dataframe
2025-03-20 17:43:53,331:INFO:Initializing custom model Voting Regressor
2025-03-20 17:43:53,331:INFO:Total runtime is 0.050491853555043535 minutes
2025-03-20 17:43:53,333:INFO:SubProcess create_model() called ==================================
2025-03-20 17:43:53,337:INFO:Initializing create_model()
2025-03-20 17:43:53,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247B57D6AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:53,337:INFO:Checking exceptions
2025-03-20 17:43:53,337:INFO:Importing libraries
2025-03-20 17:43:53,337:INFO:Copying training dataset
2025-03-20 17:43:53,339:INFO:Defining folds
2025-03-20 17:43:53,339:INFO:Declaring metric variables
2025-03-20 17:43:53,341:INFO:Importing untrained model
2025-03-20 17:43:53,341:INFO:Declaring custom model
2025-03-20 17:43:53,344:INFO:Voting Regressor Imported successfully
2025-03-20 17:43:53,348:INFO:Starting cross validation
2025-03-20 17:43:53,348:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 17:43:54,173:INFO:Calculating mean and std
2025-03-20 17:43:54,175:INFO:Creating metrics dataframe
2025-03-20 17:43:54,177:INFO:Uploading results into container
2025-03-20 17:43:54,177:INFO:Uploading model into container now
2025-03-20 17:43:54,177:INFO:_master_model_container: 34
2025-03-20 17:43:54,177:INFO:_display_container: 8
2025-03-20 17:43:54,183:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)
2025-03-20 17:43:54,184:INFO:create_model() successfully completed......................................
2025-03-20 17:43:54,249:INFO:SubProcess create_model() end ==================================
2025-03-20 17:43:54,249:INFO:Creating metrics dataframe
2025-03-20 17:43:54,264:INFO:Initializing create_model()
2025-03-20 17:43:54,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:54,264:INFO:Checking exceptions
2025-03-20 17:43:54,265:INFO:Importing libraries
2025-03-20 17:43:54,265:INFO:Copying training dataset
2025-03-20 17:43:54,268:INFO:Defining folds
2025-03-20 17:43:54,268:INFO:Declaring metric variables
2025-03-20 17:43:54,268:INFO:Importing untrained model
2025-03-20 17:43:54,268:INFO:Declaring custom model
2025-03-20 17:43:54,269:INFO:Voting Regressor Imported successfully
2025-03-20 17:43:54,270:INFO:Cross validation set to False
2025-03-20 17:43:54,270:INFO:Fitting Model
2025-03-20 17:43:54,855:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)
2025-03-20 17:43:54,855:INFO:create_model() successfully completed......................................
2025-03-20 17:43:54,915:INFO:Creating Dashboard logs
2025-03-20 17:43:54,918:INFO:Model: Voting Regressor
2025-03-20 17:43:54,936:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), 'Bayesian Ridge__alpha_1': 0.0010476781327366928, 'Bayesian Ridge__alpha_2': 5.858592852295242e-07, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': True, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.891900372088813, 'Bayesian Ridge__lambda_2': 1.408836736576288e-07, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.15971188839542688, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 4, 'Gradient Boosting Regressor__max_features': 0.619515785082508, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 3.860418952071103e-07, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 228, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.4526757240009556, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.0535387198228409, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 1, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.07788320522909709, 'Light Gradient Boosting Machine__n_estimators': 231, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 20, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 1.7180618867810928e-08, 'Light Gradient Boosting Machine__reg_lambda': 0.004158548682315826, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.8535873548096533, 'Light Gradient Boosting Machine__bagging_fraction': 0.8118154899895776, 'Light Gradient Boosting Machine__bagging_freq': 6, 'Random Forest Regressor__bootstrap': False, 'Random Forest Regressor__ccp_alpha': 0.0, 'Random Forest Regressor__criterion': 'squared_error', 'Random Forest Regressor__max_depth': 11, 'Random Forest Regressor__max_features': 0.46245443790470414, 'Random Forest Regressor__max_leaf_nodes': None, 'Random Forest Regressor__max_samples': None, 'Random Forest Regressor__min_impurity_decrease': 2.2336845690726795e-07, 'Random Forest Regressor__min_samples_leaf': 2, 'Random Forest Regressor__min_samples_split': 3, 'Random Forest Regressor__min_weight_fraction_leaf': 0.0, 'Random Forest Regressor__n_estimators': 113, 'Random Forest Regressor__n_jobs': -1, 'Random Forest Regressor__oob_score': False, 'Random Forest Regressor__random_state': 888, 'Random Forest Regressor__verbose': 0, 'Random Forest Regressor__warm_start': False}
2025-03-20 17:43:55,174:INFO:Initializing predict_model()
2025-03-20 17:43:55,174:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000247BB95EC10>)
2025-03-20 17:43:55,174:INFO:Checking exceptions
2025-03-20 17:43:55,174:INFO:Preloading libraries
2025-03-20 17:43:55,365:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:55,366:INFO:Creating Dashboard logs
2025-03-20 17:43:55,369:INFO:Model: Bayesian Ridge
2025-03-20 17:43:55,388:INFO:Logged params: {'alpha_1': 0.0010476781327366928, 'alpha_2': 5.858592852295242e-07, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.891900372088813, 'lambda_2': 1.408836736576288e-07, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 17:43:55,616:ERROR:_log_model() for BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:55,617:INFO:Creating Dashboard logs
2025-03-20 17:43:55,619:INFO:Model: Random Forest Regressor
2025-03-20 17:43:55,634:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 11, 'max_features': 0.46245443790470414, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 2.2336845690726795e-07, 'min_samples_leaf': 2, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 113, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 17:43:55,852:ERROR:_log_model() for RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:55,853:INFO:Creating Dashboard logs
2025-03-20 17:43:55,855:INFO:Model: Gradient Boosting Regressor
2025-03-20 17:43:55,869:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.15971188839542688, 'loss': 'squared_error', 'max_depth': 4, 'max_features': 0.619515785082508, 'max_leaf_nodes': None, 'min_impurity_decrease': 3.860418952071103e-07, 'min_samples_leaf': 1, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 228, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.4526757240009556, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 17:43:56,093:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:56,093:INFO:Creating Dashboard logs
2025-03-20 17:43:56,095:INFO:Model: Light Gradient Boosting Machine
2025-03-20 17:43:56,115:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.0535387198228409, 'max_depth': -1, 'min_child_samples': 1, 'min_child_weight': 0.001, 'min_split_gain': 0.07788320522909709, 'n_estimators': 231, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 888, 'reg_alpha': 1.7180618867810928e-08, 'reg_lambda': 0.004158548682315826, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.8535873548096533, 'bagging_fraction': 0.8118154899895776, 'bagging_freq': 6}
2025-03-20 17:43:56,354:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:56,360:INFO:_master_model_container: 34
2025-03-20 17:43:56,361:INFO:_display_container: 8
2025-03-20 17:43:56,365:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)
2025-03-20 17:43:56,365:INFO:compare_models() successfully completed......................................
2025-03-20 17:43:56,456:INFO:Initializing finalize_model()
2025-03-20 17:43:56,456:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 17:43:56,457:INFO:Finalizing BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07)
2025-03-20 17:43:56,458:INFO:Initializing create_model()
2025-03-20 17:43:56,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:56,459:INFO:Checking exceptions
2025-03-20 17:43:56,459:INFO:Importing libraries
2025-03-20 17:43:56,459:INFO:Copying training dataset
2025-03-20 17:43:56,460:INFO:Defining folds
2025-03-20 17:43:56,460:INFO:Declaring metric variables
2025-03-20 17:43:56,460:INFO:Importing untrained model
2025-03-20 17:43:56,460:INFO:Declaring custom model
2025-03-20 17:43:56,460:INFO:Bayesian Ridge Imported successfully
2025-03-20 17:43:56,461:INFO:Cross validation set to False
2025-03-20 17:43:56,461:INFO:Fitting Model
2025-03-20 17:43:56,504:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0010476781327366928,
                               alpha_2=5.858592852295242e-07,
                               compute_score=True, lambda_1=0.891900372088813,
                               lambda_2=1.408836736576288e-07))])
2025-03-20 17:43:56,504:INFO:create_model() successfully completed......................................
2025-03-20 17:43:56,563:INFO:Creating Dashboard logs
2025-03-20 17:43:56,563:INFO:Model: Bayesian Ridge
2025-03-20 17:43:56,578:INFO:Logged params: {'alpha_1': 0.0010476781327366928, 'alpha_2': 5.858592852295242e-07, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.891900372088813, 'lambda_2': 1.408836736576288e-07, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 17:43:56,815:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0010476781327366928,
                               alpha_2=5.858592852295242e-07,
                               compute_score=True, lambda_1=0.891900372088813,
                               lambda_2=1.408836736576288e-07))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:56,815:INFO:_master_model_container: 34
2025-03-20 17:43:56,815:INFO:_display_container: 8
2025-03-20 17:43:56,820:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0010476781327366928,
                               alpha_2=5.858592852295242e-07,
                               compute_score=True, lambda_1=0.891900372088813,
                               lambda_2=1.408836736576288e-07))])
2025-03-20 17:43:56,820:INFO:finalize_model() successfully completed......................................
2025-03-20 17:43:56,889:INFO:Initializing save_model()
2025-03-20 17:43:56,889:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0010476781327366928,
                               alpha_2=5.858592852295242e-07,
                               compute_score=True, lambda_1=0.891900372088813,
                               lambda_2=1.408836736576288e-07))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_174356, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 17:43:56,889:INFO:Adding model into prep_pipe
2025-03-20 17:43:56,889:WARNING:Only Model saved as it was a pipeline.
2025-03-20 17:43:56,893:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_174356.pkl saved in current working directory
2025-03-20 17:43:56,898:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0010476781327366928,
                               alpha_2=5.858592852295242e-07,
                               compute_score=True, lambda_1=0.891900372088813,
                               lambda_2=1.408836736576288e-07))])
2025-03-20 17:43:56,898:INFO:save_model() successfully completed......................................
2025-03-20 17:43:56,957:INFO:Initializing finalize_model()
2025-03-20 17:43:56,957:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 17:43:56,957:INFO:Finalizing GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556)
2025-03-20 17:43:56,959:INFO:Initializing create_model()
2025-03-20 17:43:56,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=GradientBoostingRegressor(learning_rate=0.15971188839542688, max_depth=4,
                          max_features=0.619515785082508,
                          min_impurity_decrease=3.860418952071103e-07,
                          min_samples_split=3, n_estimators=228,
                          random_state=888, subsample=0.4526757240009556), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:56,959:INFO:Checking exceptions
2025-03-20 17:43:56,960:INFO:Importing libraries
2025-03-20 17:43:56,960:INFO:Copying training dataset
2025-03-20 17:43:56,960:INFO:Defining folds
2025-03-20 17:43:56,961:INFO:Declaring metric variables
2025-03-20 17:43:56,961:INFO:Importing untrained model
2025-03-20 17:43:56,961:INFO:Declaring custom model
2025-03-20 17:43:56,961:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 17:43:56,962:INFO:Cross validation set to False
2025-03-20 17:43:56,962:INFO:Fitting Model
2025-03-20 17:43:57,623:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                           max_depth=4,
                                           max_features=0.619515785082508,
                                           min_impurity_decrease=3.860418952071103e-07,
                                           min_samples_split=3,
                                           n_estimators=228, random_state=888,
                                           subsample=0.4526757240009556))])
2025-03-20 17:43:57,623:INFO:create_model() successfully completed......................................
2025-03-20 17:43:57,681:INFO:Creating Dashboard logs
2025-03-20 17:43:57,681:INFO:Model: Gradient Boosting Regressor
2025-03-20 17:43:57,697:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.15971188839542688, 'loss': 'squared_error', 'max_depth': 4, 'max_features': 0.619515785082508, 'max_leaf_nodes': None, 'min_impurity_decrease': 3.860418952071103e-07, 'min_samples_leaf': 1, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 228, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.4526757240009556, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 17:43:57,962:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                           max_depth=4,
                                           max_features=0.619515785082508,
                                           min_impurity_decrease=3.860418952071103e-07,
                                           min_samples_split=3,
                                           n_estimators=228, random_state=888,
                                           subsample=0.4526757240009556))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:57,962:INFO:_master_model_container: 34
2025-03-20 17:43:57,962:INFO:_display_container: 8
2025-03-20 17:43:57,967:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                           max_depth=4,
                                           max_features=0.619515785082508,
                                           min_impurity_decrease=3.860418952071103e-07,
                                           min_samples_split=3,
                                           n_estimators=228, random_state=888,
                                           subsample=0.4526757240009556))])
2025-03-20 17:43:57,967:INFO:finalize_model() successfully completed......................................
2025-03-20 17:43:58,035:INFO:Initializing save_model()
2025-03-20 17:43:58,035:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                           max_depth=4,
                                           max_features=0.619515785082508,
                                           min_impurity_decrease=3.860418952071103e-07,
                                           min_samples_split=3,
                                           n_estimators=228, random_state=888,
                                           subsample=0.4526757240009556))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_174356, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 17:43:58,035:INFO:Adding model into prep_pipe
2025-03-20 17:43:58,035:WARNING:Only Model saved as it was a pipeline.
2025-03-20 17:43:58,043:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_174356.pkl saved in current working directory
2025-03-20 17:43:58,048:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                           max_depth=4,
                                           max_features=0.619515785082508,
                                           min_impurity_decrease=3.860418952071103e-07,
                                           min_samples_split=3,
                                           n_estimators=228, random_state=888,
                                           subsample=0.4526757240009556))])
2025-03-20 17:43:58,048:INFO:save_model() successfully completed......................................
2025-03-20 17:43:58,107:INFO:Initializing finalize_model()
2025-03-20 17:43:58,107:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 17:43:58,107:INFO:Finalizing LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826)
2025-03-20 17:43:58,109:INFO:Initializing create_model()
2025-03-20 17:43:58,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=LGBMRegressor(bagging_fraction=0.8118154899895776, bagging_freq=6,
              feature_fraction=0.8535873548096533,
              learning_rate=0.0535387198228409, min_child_samples=1,
              min_split_gain=0.07788320522909709, n_estimators=231, n_jobs=-1,
              num_leaves=20, random_state=888, reg_alpha=1.7180618867810928e-08,
              reg_lambda=0.004158548682315826), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:58,109:INFO:Checking exceptions
2025-03-20 17:43:58,110:INFO:Importing libraries
2025-03-20 17:43:58,110:INFO:Copying training dataset
2025-03-20 17:43:58,110:INFO:Defining folds
2025-03-20 17:43:58,110:INFO:Declaring metric variables
2025-03-20 17:43:58,110:INFO:Importing untrained model
2025-03-20 17:43:58,110:INFO:Declaring custom model
2025-03-20 17:43:58,111:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 17:43:58,112:INFO:Cross validation set to False
2025-03-20 17:43:58,112:INFO:Fitting Model
2025-03-20 17:43:58,146:INFO:[LightGBM] [Warning] feature_fraction is set=0.8535873548096533, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8535873548096533
2025-03-20 17:43:58,147:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8118154899895776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118154899895776
2025-03-20 17:43:58,147:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 17:43:58,148:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 17:43:58,148:INFO:[LightGBM] [Warning] feature_fraction is set=0.8535873548096533, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8535873548096533
2025-03-20 17:43:58,149:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8118154899895776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118154899895776
2025-03-20 17:43:58,149:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 17:43:58,149:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.
2025-03-20 17:43:58,150:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 17:43:58,150:INFO:[LightGBM] [Info] Total Bins 3884
2025-03-20 17:43:58,150:INFO:[LightGBM] [Info] Number of data points in the train set: 1769, number of used features: 35
2025-03-20 17:43:58,151:INFO:[LightGBM] [Info] Start training from score 15.920889
2025-03-20 17:43:58,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 17:43:58,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 17:43:58,233:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8118154899895776,
                               bagging_freq=6,
                               feature_fraction=0.8535873548096533,
                               learning_rate=0.0535387198228409,
                               min_child_samples=1,
                               min_split_gain=0.07788320522909709,
                               n_estimators=231, n_jobs=-1, num_leaves=20,
                               random_state=888,
                               reg_alpha=1.7180618867810928e-08,
                               reg_lambda=0.004158548682315826))])
2025-03-20 17:43:58,233:INFO:create_model() successfully completed......................................
2025-03-20 17:43:58,304:INFO:Creating Dashboard logs
2025-03-20 17:43:58,304:INFO:Model: Light Gradient Boosting Machine
2025-03-20 17:43:58,324:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.0535387198228409, 'max_depth': -1, 'min_child_samples': 1, 'min_child_weight': 0.001, 'min_split_gain': 0.07788320522909709, 'n_estimators': 231, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 888, 'reg_alpha': 1.7180618867810928e-08, 'reg_lambda': 0.004158548682315826, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.8535873548096533, 'bagging_fraction': 0.8118154899895776, 'bagging_freq': 6}
2025-03-20 17:43:58,597:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8118154899895776,
                               bagging_freq=6,
                               feature_fraction=0.8535873548096533,
                               learning_rate=0.0535387198228409,
                               min_child_samples=1,
                               min_split_gain=0.07788320522909709,
                               n_estimators=231, n_jobs=-1, num_leaves=20,
                               random_state=888,
                               reg_alpha=1.7180618867810928e-08,
                               reg_lambda=0.004158548682315826))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:58,597:INFO:_master_model_container: 34
2025-03-20 17:43:58,597:INFO:_display_container: 8
2025-03-20 17:43:58,604:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8118154899895776,
                               bagging_freq=6,
                               feature_fraction=0.8535873548096533,
                               learning_rate=0.0535387198228409,
                               min_child_samples=1,
                               min_split_gain=0.07788320522909709,
                               n_estimators=231, n_jobs=-1, num_leaves=20,
                               random_state=888,
                               reg_alpha=1.7180618867810928e-08,
                               reg_lambda=0.004158548682315826))])
2025-03-20 17:43:58,604:INFO:finalize_model() successfully completed......................................
2025-03-20 17:43:58,685:INFO:Initializing save_model()
2025-03-20 17:43:58,685:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8118154899895776,
                               bagging_freq=6,
                               feature_fraction=0.8535873548096533,
                               learning_rate=0.0535387198228409,
                               min_child_samples=1,
                               min_split_gain=0.07788320522909709,
                               n_estimators=231, n_jobs=-1, num_leaves=20,
                               random_state=888,
                               reg_alpha=1.7180618867810928e-08,
                               reg_lambda=0.004158548682315826))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_174358, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 17:43:58,685:INFO:Adding model into prep_pipe
2025-03-20 17:43:58,685:WARNING:Only Model saved as it was a pipeline.
2025-03-20 17:43:58,695:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_174358.pkl saved in current working directory
2025-03-20 17:43:58,703:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8118154899895776,
                               bagging_freq=6,
                               feature_fraction=0.8535873548096533,
                               learning_rate=0.0535387198228409,
                               min_child_samples=1,
                               min_split_gain=0.07788320522909709,
                               n_estimators=231, n_jobs=-1, num_leaves=20,
                               random_state=888,
                               reg_alpha=1.7180618867810928e-08,
                               reg_lambda=0.004158548682315826))])
2025-03-20 17:43:58,703:INFO:save_model() successfully completed......................................
2025-03-20 17:43:58,782:INFO:Initializing finalize_model()
2025-03-20 17:43:58,782:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 17:43:58,782:INFO:Finalizing RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888)
2025-03-20 17:43:58,785:INFO:Initializing create_model()
2025-03-20 17:43:58,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=RandomForestRegressor(bootstrap=False, max_depth=11,
                      max_features=0.46245443790470414,
                      min_impurity_decrease=2.2336845690726795e-07,
                      min_samples_leaf=2, min_samples_split=3, n_estimators=113,
                      n_jobs=-1, random_state=888), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:58,785:INFO:Checking exceptions
2025-03-20 17:43:58,786:INFO:Importing libraries
2025-03-20 17:43:58,786:INFO:Copying training dataset
2025-03-20 17:43:58,786:INFO:Defining folds
2025-03-20 17:43:58,786:INFO:Declaring metric variables
2025-03-20 17:43:58,786:INFO:Importing untrained model
2025-03-20 17:43:58,786:INFO:Declaring custom model
2025-03-20 17:43:58,786:INFO:Random Forest Regressor Imported successfully
2025-03-20 17:43:58,787:INFO:Cross validation set to False
2025-03-20 17:43:58,787:INFO:Fitting Model
2025-03-20 17:43:58,922:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(bootstrap=False, max_depth=11,
                                       max_features=0.46245443790470414,
                                       min_impurity_decrease=2.2336845690726795e-07,
                                       min_samples_leaf=2, min_samples_split=3,
                                       n_estimators=113, n_jobs=-1,
                                       random_state=888))])
2025-03-20 17:43:58,922:INFO:create_model() successfully completed......................................
2025-03-20 17:43:58,981:INFO:Creating Dashboard logs
2025-03-20 17:43:58,981:INFO:Model: Random Forest Regressor
2025-03-20 17:43:58,998:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 11, 'max_features': 0.46245443790470414, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 2.2336845690726795e-07, 'min_samples_leaf': 2, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 113, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 17:43:59,268:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(bootstrap=False, max_depth=11,
                                       max_features=0.46245443790470414,
                                       min_impurity_decrease=2.2336845690726795e-07,
                                       min_samples_leaf=2, min_samples_split=3,
                                       n_estimators=113, n_jobs=-1,
                                       random_state=888))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:43:59,268:INFO:_master_model_container: 34
2025-03-20 17:43:59,268:INFO:_display_container: 8
2025-03-20 17:43:59,273:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(bootstrap=False, max_depth=11,
                                       max_features=0.46245443790470414,
                                       min_impurity_decrease=2.2336845690726795e-07,
                                       min_samples_leaf=2, min_samples_split=3,
                                       n_estimators=113, n_jobs=-1,
                                       random_state=888))])
2025-03-20 17:43:59,273:INFO:finalize_model() successfully completed......................................
2025-03-20 17:43:59,341:INFO:Initializing save_model()
2025-03-20 17:43:59,341:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(bootstrap=False, max_depth=11,
                                       max_features=0.46245443790470414,
                                       min_impurity_decrease=2.2336845690726795e-07,
                                       min_samples_leaf=2, min_samples_split=3,
                                       n_estimators=113, n_jobs=-1,
                                       random_state=888))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\rf_250320_174358, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 17:43:59,341:INFO:Adding model into prep_pipe
2025-03-20 17:43:59,341:WARNING:Only Model saved as it was a pipeline.
2025-03-20 17:43:59,365:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\rf_250320_174358.pkl saved in current working directory
2025-03-20 17:43:59,370:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(bootstrap=False, max_depth=11,
                                       max_features=0.46245443790470414,
                                       min_impurity_decrease=2.2336845690726795e-07,
                                       min_samples_leaf=2, min_samples_split=3,
                                       n_estimators=113, n_jobs=-1,
                                       random_state=888))])
2025-03-20 17:43:59,370:INFO:save_model() successfully completed......................................
2025-03-20 17:43:59,437:INFO:Initializing finalize_model()
2025-03-20 17:43:59,437:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 17:43:59,441:INFO:Finalizing VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1)
2025-03-20 17:43:59,447:INFO:Initializing create_model()
2025-03-20 17:43:59,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000247CAC7E8B0>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.0010476781327366928,
                                           alpha_2=5.858592852295242e-07,
                                           compute_score=True,
                                           lambda_1=0.891900372088813,
                                           lambda_2=1.408836736576288e-07)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.15971188839542688,
                                                       max_depth=4,
                                                       max_features=0.619515785082508,
                                                       min_impurity_decreas...
                                           n_estimators=231, n_jobs=-1,
                                           num_leaves=20, random_state=888,
                                           reg_alpha=1.7180618867810928e-08,
                                           reg_lambda=0.004158548682315826)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(bootstrap=False,
                                                   max_depth=11,
                                                   max_features=0.46245443790470414,
                                                   min_impurity_decrease=2.2336845690726795e-07,
                                                   min_samples_leaf=2,
                                                   min_samples_split=3,
                                                   n_estimators=113, n_jobs=-1,
                                                   random_state=888))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 17:43:59,447:INFO:Checking exceptions
2025-03-20 17:43:59,448:INFO:Importing libraries
2025-03-20 17:43:59,448:INFO:Copying training dataset
2025-03-20 17:43:59,448:INFO:Defining folds
2025-03-20 17:43:59,448:INFO:Declaring metric variables
2025-03-20 17:43:59,448:INFO:Importing untrained model
2025-03-20 17:43:59,448:INFO:Declaring custom model
2025-03-20 17:43:59,449:INFO:Voting Regressor Imported successfully
2025-03-20 17:43:59,450:INFO:Cross validation set to False
2025-03-20 17:43:59,450:INFO:Fitting Model
2025-03-20 17:44:00,192:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))])
2025-03-20 17:44:00,192:INFO:create_model() successfully completed......................................
2025-03-20 17:44:00,253:INFO:Creating Dashboard logs
2025-03-20 17:44:00,254:INFO:Model: Voting Regressor
2025-03-20 17:44:00,272:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=0.0010476781327366928, alpha_2=5.858592852295242e-07,
              compute_score=True, lambda_1=0.891900372088813,
              lambda_2=1.408836736576288e-07), 'Bayesian Ridge__alpha_1': 0.0010476781327366928, 'Bayesian Ridge__alpha_2': 5.858592852295242e-07, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': True, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.891900372088813, 'Bayesian Ridge__lambda_2': 1.408836736576288e-07, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.15971188839542688, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 4, 'Gradient Boosting Regressor__max_features': 0.619515785082508, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 3.860418952071103e-07, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 228, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.4526757240009556, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.0535387198228409, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 1, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.07788320522909709, 'Light Gradient Boosting Machine__n_estimators': 231, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 20, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 1.7180618867810928e-08, 'Light Gradient Boosting Machine__reg_lambda': 0.004158548682315826, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.8535873548096533, 'Light Gradient Boosting Machine__bagging_fraction': 0.8118154899895776, 'Light Gradient Boosting Machine__bagging_freq': 6, 'Random Forest Regressor__bootstrap': False, 'Random Forest Regressor__ccp_alpha': 0.0, 'Random Forest Regressor__criterion': 'squared_error', 'Random Forest Regressor__max_depth': 11, 'Random Forest Regressor__max_features': 0.46245443790470414, 'Random Forest Regressor__max_leaf_nodes': None, 'Random Forest Regressor__max_samples': None, 'Random Forest Regressor__min_impurity_decrease': 2.2336845690726795e-07, 'Random Forest Regressor__min_samples_leaf': 2, 'Random Forest Regressor__min_samples_split': 3, 'Random Forest Regressor__min_weight_fraction_leaf': 0.0, 'Random Forest Regressor__n_estimators': 113, 'Random Forest Regressor__n_jobs': -1, 'Random Forest Regressor__oob_score': False, 'Random Forest Regressor__random_state': 888, 'Random Forest Regressor__verbose': 0, 'Random Forest Regressor__warm_start': False}
2025-03-20 17:44:00,624:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 17:44:00,624:INFO:_master_model_container: 34
2025-03-20 17:44:00,624:INFO:_display_container: 8
2025-03-20 17:44:00,643:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))])
2025-03-20 17:44:00,643:INFO:finalize_model() successfully completed......................................
2025-03-20 17:44:00,726:INFO:Initializing save_model()
2025-03-20 17:44:00,726:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 17:44:00,726:INFO:Adding model into prep_pipe
2025-03-20 17:44:00,726:WARNING:Only Model saved as it was a pipeline.
2025-03-20 17:44:00,768:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359.pkl saved in current working directory
2025-03-20 17:44:00,790:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))])
2025-03-20 17:44:00,790:INFO:save_model() successfully completed......................................
2025-03-20 17:49:39,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:49:39,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:49:39,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:49:39,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:50:47,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:50:47,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:50:47,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:50:47,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:51:07,726:INFO:Initializing load_model()
2025-03-20 17:51:07,726:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 17:51:08,344:INFO:Initializing predict_model()
2025-03-20 17:51:08,344:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021320E86310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021321235940>)
2025-03-20 17:51:08,344:INFO:Checking exceptions
2025-03-20 17:51:08,344:INFO:Preloading libraries
2025-03-20 17:51:08,344:INFO:Set up data.
2025-03-20 17:51:08,352:INFO:Set up index.
2025-03-20 17:51:21,101:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:51:21,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:51:21,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:51:21,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 17:51:21,223:INFO:Initializing load_model()
2025-03-20 17:51:21,223:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 17:51:21,773:INFO:Initializing predict_model()
2025-03-20 17:51:21,773:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B2A4B7DC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002B2A4BD7EE0>)
2025-03-20 17:51:21,773:INFO:Checking exceptions
2025-03-20 17:51:21,773:INFO:Preloading libraries
2025-03-20 17:51:21,773:INFO:Set up data.
2025-03-20 17:51:21,778:INFO:Set up index.
2025-03-20 18:13:32,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:13:32,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:13:32,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:13:32,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:13:34,148:INFO:Initializing load_model()
2025-03-20 18:13:34,148:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:13:34,721:INFO:Initializing predict_model()
2025-03-20 18:13:34,721:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000015DB0958370>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015D95289E50>)
2025-03-20 18:13:34,721:INFO:Checking exceptions
2025-03-20 18:13:34,721:INFO:Preloading libraries
2025-03-20 18:13:34,722:INFO:Set up data.
2025-03-20 18:13:34,728:INFO:Set up index.
2025-03-20 18:15:30,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:15:30,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:15:30,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:15:30,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:15:33,897:INFO:Initializing load_model()
2025-03-20 18:15:33,897:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:15:34,454:INFO:Initializing predict_model()
2025-03-20 18:15:34,454:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028138278250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002811EAAD9D0>)
2025-03-20 18:15:34,454:INFO:Checking exceptions
2025-03-20 18:15:34,454:INFO:Preloading libraries
2025-03-20 18:15:34,454:INFO:Set up data.
2025-03-20 18:15:34,460:INFO:Set up index.
2025-03-20 18:15:34,556:INFO:Initializing load_model()
2025-03-20 18:15:34,556:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:15:34,607:INFO:Initializing predict_model()
2025-03-20 18:15:34,607:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000281393C1550>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002811FB78C10>)
2025-03-20 18:15:34,607:INFO:Checking exceptions
2025-03-20 18:15:34,607:INFO:Preloading libraries
2025-03-20 18:15:34,607:INFO:Set up data.
2025-03-20 18:15:34,612:INFO:Set up index.
2025-03-20 18:16:54,221:INFO:Initializing load_model()
2025-03-20 18:16:54,221:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:16:54,286:INFO:Initializing predict_model()
2025-03-20 18:16:54,286:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002811DC9EAC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002813925C5E0>)
2025-03-20 18:16:54,286:INFO:Checking exceptions
2025-03-20 18:16:54,286:INFO:Preloading libraries
2025-03-20 18:16:54,286:INFO:Set up data.
2025-03-20 18:16:54,291:INFO:Set up index.
2025-03-20 18:16:54,395:INFO:Initializing load_model()
2025-03-20 18:16:54,395:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:16:54,447:INFO:Initializing predict_model()
2025-03-20 18:16:54,447:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000281393AAEB0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000281393BF310>)
2025-03-20 18:16:54,447:INFO:Checking exceptions
2025-03-20 18:16:54,447:INFO:Preloading libraries
2025-03-20 18:16:54,447:INFO:Set up data.
2025-03-20 18:16:54,452:INFO:Set up index.
2025-03-20 18:17:01,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:17:01,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:17:01,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:17:01,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:17:02,971:INFO:Initializing load_model()
2025-03-20 18:17:02,971:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:17:03,522:INFO:Initializing predict_model()
2025-03-20 18:17:03,522:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AEA25D3340>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEA1525DC0>)
2025-03-20 18:17:03,522:INFO:Checking exceptions
2025-03-20 18:17:03,522:INFO:Preloading libraries
2025-03-20 18:17:03,522:INFO:Set up data.
2025-03-20 18:17:03,528:INFO:Set up index.
2025-03-20 18:17:03,625:INFO:Initializing load_model()
2025-03-20 18:17:03,625:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:17:03,679:INFO:Initializing predict_model()
2025-03-20 18:17:03,679:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AEEB969850>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEA1525E50>)
2025-03-20 18:17:03,679:INFO:Checking exceptions
2025-03-20 18:17:03,679:INFO:Preloading libraries
2025-03-20 18:17:03,679:INFO:Set up data.
2025-03-20 18:17:03,684:INFO:Set up index.
2025-03-20 18:19:16,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:19:16,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:19:16,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:19:16,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:19:48,725:INFO:Initializing load_model()
2025-03-20 18:19:48,725:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:19:48,789:INFO:Initializing predict_model()
2025-03-20 18:19:48,789:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AEBAD0D880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEEB9C6E50>)
2025-03-20 18:19:48,789:INFO:Checking exceptions
2025-03-20 18:19:48,789:INFO:Preloading libraries
2025-03-20 18:19:48,789:INFO:Set up data.
2025-03-20 18:19:48,797:INFO:Set up index.
2025-03-20 18:19:48,906:INFO:Initializing load_model()
2025-03-20 18:19:48,906:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:19:48,955:INFO:Initializing predict_model()
2025-03-20 18:19:48,956:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AEBAD0D880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AEA5CF04C0>)
2025-03-20 18:19:48,956:INFO:Checking exceptions
2025-03-20 18:19:48,956:INFO:Preloading libraries
2025-03-20 18:19:48,956:INFO:Set up data.
2025-03-20 18:19:48,962:INFO:Set up index.
2025-03-20 18:20:48,706:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:21:16,403:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:24:56,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:24:56,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:24:56,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:24:56,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:24:56,828:INFO:Initializing load_model()
2025-03-20 18:24:56,828:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:24:57,393:INFO:Initializing predict_model()
2025-03-20 18:24:57,393:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002940A7AEAF0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002946FF8AE50>)
2025-03-20 18:24:57,394:INFO:Checking exceptions
2025-03-20 18:24:57,394:INFO:Preloading libraries
2025-03-20 18:24:57,394:INFO:Set up data.
2025-03-20 18:24:57,402:INFO:Set up index.
2025-03-20 18:24:57,495:INFO:Initializing load_model()
2025-03-20 18:24:57,495:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_174359, platform=None, authentication=None, verbose=True)
2025-03-20 18:24:57,548:INFO:Initializing predict_model()
2025-03-20 18:24:57,548:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002943ADFA370>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_trend', 'pop_trend',
                                             'gdp_per...
                                                            num_leaves=20,
                                                            random_state=888,
                                                            reg_alpha=1.7180618867810928e-08,
                                                            reg_lambda=0.004158548682315826)),
                                             ('Random Forest Regressor',
                                              RandomForestRegressor(bootstrap=False,
                                                                    max_depth=11,
                                                                    max_features=0.46245443790470414,
                                                                    min_impurity_decrease=2.2336845690726795e-07,
                                                                    min_samples_leaf=2,
                                                                    min_samples_split=3,
                                                                    n_estimators=113,
                                                                    n_jobs=-1,
                                                                    random_state=888))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029473E4CF70>)
2025-03-20 18:24:57,548:INFO:Checking exceptions
2025-03-20 18:24:57,548:INFO:Preloading libraries
2025-03-20 18:24:57,548:INFO:Set up data.
2025-03-20 18:24:57,554:INFO:Set up index.
2025-03-20 18:25:00,913:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:25:03,003:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:34:11,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:11,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:11,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:11,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:12,199:INFO:PyCaret RegressionExperiment
2025-03-20 18:34:12,199:INFO:Logging name: reg-default-name
2025-03-20 18:34:12,199:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 18:34:12,199:INFO:version 3.2.0
2025-03-20 18:34:12,199:INFO:Initializing setup()
2025-03-20 18:34:12,199:INFO:self.USI: 10a9
2025-03-20 18:34:12,199:INFO:self._variable_keys: {'n_jobs_param', 'seed', 'gpu_n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'memory', 'y', 'X', 'X_test', 'idx', 'USI', 'fold_generator', 'y_train', 'X_train', 'gpu_param', '_available_plots', 'y_test', 'fold_groups_param', 'transform_target_param', 'data', 'log_plots_param', 'exp_name_log', 'target_param', 'fold_shuffle_param', 'html_param', 'pipeline'}
2025-03-20 18:34:12,199:INFO:Checking environment
2025-03-20 18:34:12,199:INFO:python_version: 3.8.20
2025-03-20 18:34:12,199:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 18:34:12,199:INFO:machine: AMD64
2025-03-20 18:34:12,199:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 18:34:12,205:INFO:Memory: svmem(total=68447973376, available=39415328768, percent=42.4, used=29032644608, free=39415328768)
2025-03-20 18:34:12,205:INFO:Physical Core: 24
2025-03-20 18:34:12,205:INFO:Logical Core: 32
2025-03-20 18:34:12,205:INFO:Checking libraries
2025-03-20 18:34:12,205:INFO:System:
2025-03-20 18:34:12,205:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 18:34:12,205:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 18:34:12,205:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 18:34:12,205:INFO:PyCaret required dependencies:
2025-03-20 18:34:12,686:INFO:                 pip: 24.2
2025-03-20 18:34:12,686:INFO:          setuptools: 75.1.0
2025-03-20 18:34:12,686:INFO:             pycaret: 3.2.0
2025-03-20 18:34:12,686:INFO:             IPython: 8.12.3
2025-03-20 18:34:12,686:INFO:          ipywidgets: 8.1.5
2025-03-20 18:34:12,686:INFO:                tqdm: 4.67.1
2025-03-20 18:34:12,686:INFO:               numpy: 1.24.4
2025-03-20 18:34:12,686:INFO:              pandas: 1.5.3
2025-03-20 18:34:12,686:INFO:              jinja2: 3.1.4
2025-03-20 18:34:12,686:INFO:               scipy: 1.10.1
2025-03-20 18:34:12,686:INFO:              joblib: 1.3.2
2025-03-20 18:34:12,686:INFO:             sklearn: 1.2.2
2025-03-20 18:34:12,686:INFO:                pyod: 2.0.2
2025-03-20 18:34:12,686:INFO:            imblearn: 0.12.4
2025-03-20 18:34:12,686:INFO:   category_encoders: 2.6.4
2025-03-20 18:34:12,686:INFO:            lightgbm: 4.5.0
2025-03-20 18:34:12,686:INFO:               numba: 0.58.1
2025-03-20 18:34:12,686:INFO:            requests: 2.32.3
2025-03-20 18:34:12,686:INFO:          matplotlib: 3.6.0
2025-03-20 18:34:12,686:INFO:          scikitplot: 0.3.7
2025-03-20 18:34:12,686:INFO:         yellowbrick: 1.5
2025-03-20 18:34:12,686:INFO:              plotly: 5.24.1
2025-03-20 18:34:12,686:INFO:    plotly-resampler: Not installed
2025-03-20 18:34:12,686:INFO:             kaleido: 0.2.1
2025-03-20 18:34:12,686:INFO:           schemdraw: 0.15
2025-03-20 18:34:12,686:INFO:         statsmodels: 0.14.1
2025-03-20 18:34:12,686:INFO:              sktime: 0.21.1
2025-03-20 18:34:12,686:INFO:               tbats: 1.1.3
2025-03-20 18:34:12,686:INFO:            pmdarima: 2.0.4
2025-03-20 18:34:12,686:INFO:              psutil: 6.1.0
2025-03-20 18:34:12,686:INFO:          markupsafe: 2.1.5
2025-03-20 18:34:12,686:INFO:             pickle5: Not installed
2025-03-20 18:34:12,686:INFO:         cloudpickle: 2.2.1
2025-03-20 18:34:12,686:INFO:         deprecation: 2.1.0
2025-03-20 18:34:12,686:INFO:              xxhash: 3.5.0
2025-03-20 18:34:12,686:INFO:           wurlitzer: Not installed
2025-03-20 18:34:12,686:INFO:PyCaret optional dependencies:
2025-03-20 18:34:13,972:INFO:                shap: 0.44.1
2025-03-20 18:34:13,972:INFO:           interpret: 0.6.6
2025-03-20 18:34:13,972:INFO:                umap: 0.5.7
2025-03-20 18:34:13,972:INFO:     ydata_profiling: 4.6.0
2025-03-20 18:34:13,972:INFO:  explainerdashboard: 0.4.7
2025-03-20 18:34:13,972:INFO:             autoviz: Not installed
2025-03-20 18:34:13,972:INFO:           fairlearn: 0.7.0
2025-03-20 18:34:13,972:INFO:          deepchecks: Not installed
2025-03-20 18:34:13,972:INFO:             xgboost: 2.1.3
2025-03-20 18:34:13,972:INFO:            catboost: 1.2.7
2025-03-20 18:34:13,973:INFO:              kmodes: 0.12.2
2025-03-20 18:34:13,973:INFO:             mlxtend: 0.23.1
2025-03-20 18:34:13,973:INFO:       statsforecast: 1.5.0
2025-03-20 18:34:13,973:INFO:        tune_sklearn: 0.5.0
2025-03-20 18:34:13,973:INFO:                 ray: 2.10.0
2025-03-20 18:34:13,973:INFO:            hyperopt: 0.2.7
2025-03-20 18:34:13,973:INFO:              optuna: 4.1.0
2025-03-20 18:34:13,973:INFO:               skopt: 0.10.2
2025-03-20 18:34:13,973:INFO:              mlflow: 1.30.1
2025-03-20 18:34:13,973:INFO:              gradio: 3.50.2
2025-03-20 18:34:13,973:INFO:             fastapi: 0.115.5
2025-03-20 18:34:13,973:INFO:             uvicorn: 0.32.1
2025-03-20 18:34:13,973:INFO:              m2cgen: 0.10.0
2025-03-20 18:34:13,973:INFO:           evidently: 0.2.8
2025-03-20 18:34:13,973:INFO:               fugue: 0.8.6
2025-03-20 18:34:13,973:INFO:           streamlit: Not installed
2025-03-20 18:34:13,973:INFO:             prophet: Not installed
2025-03-20 18:34:13,973:INFO:None
2025-03-20 18:34:13,973:INFO:Set up data.
2025-03-20 18:34:13,978:INFO:Set up folding strategy.
2025-03-20 18:34:13,978:INFO:Set up train/test split.
2025-03-20 18:34:13,978:INFO:Set up data.
2025-03-20 18:34:13,983:INFO:Set up index.
2025-03-20 18:34:13,983:INFO:Assigning column types.
2025-03-20 18:34:13,984:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 18:34:13,985:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:34:13,986:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:13,988:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,013:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,032:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,033:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,044:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,046:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,092:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,093:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,093:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 18:34:14,095:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,097:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,121:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,140:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,141:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,144:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,146:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,169:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,188:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,189:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,189:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 18:34:14,193:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,218:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,236:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,237:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,238:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,242:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,286:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,287:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,287:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 18:34:14,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,333:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,333:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,335:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,382:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,383:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,383:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 18:34:14,411:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,430:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,431:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:14,479:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,480:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,481:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 18:34:14,529:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,530:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,578:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,579:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,580:INFO:Preparing preprocessing pipeline...
2025-03-20 18:34:14,580:INFO:Set up simple imputation.
2025-03-20 18:34:14,582:INFO:Set up encoding of categorical features.
2025-03-20 18:34:14,582:INFO:Set up feature normalization.
2025-03-20 18:34:14,582:INFO:Set up column name cleaning.
2025-03-20 18:34:14,630:INFO:Finished creating preprocessing pipeline.
2025-03-20 18:34:14,635:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:34:14,635:INFO:Creating final display dataframe.
2025-03-20 18:34:14,759:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 23)
4        Transformed data shape        (1769, 36)
5   Transformed train set shape        (1399, 36)
6    Transformed test set shape         (370, 36)
7              Numeric features                19
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              10a9
2025-03-20 18:34:14,811:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,813:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,861:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:14,862:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:14,862:INFO:Logging experiment in loggers
2025-03-20 18:34:15,002:INFO:SubProcess save_model() called ==================================
2025-03-20 18:34:15,009:INFO:Initializing save_model()
2025-03-20 18:34:15,009:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmphhu1unla\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:34:15,009:INFO:Adding model into prep_pipe
2025-03-20 18:34:15,009:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:34:15,013:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmphhu1unla\Transformation Pipeline.pkl saved in current working directory
2025-03-20 18:34:15,017:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:34:15,017:INFO:save_model() successfully completed......................................
2025-03-20 18:34:15,071:INFO:SubProcess save_model() end ==================================
2025-03-20 18:34:15,077:INFO:setup() successfully completed in 2.67s...............
2025-03-20 18:34:15,077:INFO:Initializing compare_models()
2025-03-20 18:34:15,077:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018A1CAEED60>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000018A1CAEED60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 18:34:15,077:INFO:Checking exceptions
2025-03-20 18:34:15,078:INFO:Preparing display monitor
2025-03-20 18:34:15,091:INFO:Initializing Linear Regression
2025-03-20 18:34:15,091:INFO:Total runtime is 0.0 minutes
2025-03-20 18:34:15,093:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:15,093:INFO:Initializing create_model()
2025-03-20 18:34:15,093:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018A1CAEED60>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A06D5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:15,093:INFO:Checking exceptions
2025-03-20 18:34:15,093:INFO:Importing libraries
2025-03-20 18:34:15,093:INFO:Copying training dataset
2025-03-20 18:34:15,096:INFO:Defining folds
2025-03-20 18:34:15,096:INFO:Declaring metric variables
2025-03-20 18:34:15,098:INFO:Importing untrained model
2025-03-20 18:34:15,101:INFO:Linear Regression Imported successfully
2025-03-20 18:34:15,106:INFO:Starting cross validation
2025-03-20 18:34:15,109:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:34:17,581:INFO:Calculating mean and std
2025-03-20 18:34:17,582:INFO:Creating metrics dataframe
2025-03-20 18:34:17,584:INFO:Uploading results into container
2025-03-20 18:34:17,584:INFO:Uploading model into container now
2025-03-20 18:34:17,585:INFO:_master_model_container: 1
2025-03-20 18:34:17,585:INFO:_display_container: 2
2025-03-20 18:34:17,585:INFO:LinearRegression(n_jobs=-1)
2025-03-20 18:34:17,585:INFO:create_model() successfully completed......................................
2025-03-20 18:34:17,643:INFO:SubProcess create_model() end ==================================
2025-03-20 18:34:17,643:INFO:Creating metrics dataframe
2025-03-20 18:34:17,648:INFO:Initializing Lasso Regression
2025-03-20 18:34:17,648:INFO:Total runtime is 0.042605674266815184 minutes
2025-03-20 18:34:17,649:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:17,650:INFO:Initializing create_model()
2025-03-20 18:34:17,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018A1CAEED60>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A06D5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:17,650:INFO:Checking exceptions
2025-03-20 18:34:17,650:INFO:Importing libraries
2025-03-20 18:34:17,650:INFO:Copying training dataset
2025-03-20 18:34:17,651:INFO:Defining folds
2025-03-20 18:34:17,651:INFO:Declaring metric variables
2025-03-20 18:34:17,653:INFO:Importing untrained model
2025-03-20 18:34:17,655:INFO:Lasso Regression Imported successfully
2025-03-20 18:34:17,658:INFO:Starting cross validation
2025-03-20 18:34:17,659:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:34:45,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:45,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:45,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:45,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:34:45,500:INFO:PyCaret RegressionExperiment
2025-03-20 18:34:45,500:INFO:Logging name: reg-default-name
2025-03-20 18:34:45,500:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 18:34:45,500:INFO:version 3.2.0
2025-03-20 18:34:45,500:INFO:Initializing setup()
2025-03-20 18:34:45,500:INFO:self.USI: cefa
2025-03-20 18:34:45,500:INFO:self._variable_keys: {'exp_id', 'pipeline', 'fold_groups_param', 'memory', 'exp_name_log', 'logging_param', 'USI', 'y_train', 'X_train', 'fold_shuffle_param', 'html_param', 'gpu_n_jobs_param', 'seed', 'fold_generator', 'target_param', 'y', 'data', '_available_plots', 'y_test', 'transform_target_param', 'idx', 'X_test', 'log_plots_param', 'gpu_param', '_ml_usecase', 'X', 'n_jobs_param'}
2025-03-20 18:34:45,500:INFO:Checking environment
2025-03-20 18:34:45,500:INFO:python_version: 3.8.20
2025-03-20 18:34:45,500:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 18:34:45,500:INFO:machine: AMD64
2025-03-20 18:34:45,500:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 18:34:45,507:INFO:Memory: svmem(total=68447973376, available=37735481344, percent=44.9, used=30712492032, free=37735481344)
2025-03-20 18:34:45,507:INFO:Physical Core: 24
2025-03-20 18:34:45,507:INFO:Logical Core: 32
2025-03-20 18:34:45,507:INFO:Checking libraries
2025-03-20 18:34:45,507:INFO:System:
2025-03-20 18:34:45,507:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 18:34:45,507:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 18:34:45,507:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 18:34:45,507:INFO:PyCaret required dependencies:
2025-03-20 18:34:46,007:INFO:                 pip: 24.2
2025-03-20 18:34:46,007:INFO:          setuptools: 75.1.0
2025-03-20 18:34:46,007:INFO:             pycaret: 3.2.0
2025-03-20 18:34:46,007:INFO:             IPython: 8.12.3
2025-03-20 18:34:46,008:INFO:          ipywidgets: 8.1.5
2025-03-20 18:34:46,008:INFO:                tqdm: 4.67.1
2025-03-20 18:34:46,008:INFO:               numpy: 1.24.4
2025-03-20 18:34:46,008:INFO:              pandas: 1.5.3
2025-03-20 18:34:46,008:INFO:              jinja2: 3.1.4
2025-03-20 18:34:46,008:INFO:               scipy: 1.10.1
2025-03-20 18:34:46,008:INFO:              joblib: 1.3.2
2025-03-20 18:34:46,008:INFO:             sklearn: 1.2.2
2025-03-20 18:34:46,008:INFO:                pyod: 2.0.2
2025-03-20 18:34:46,008:INFO:            imblearn: 0.12.4
2025-03-20 18:34:46,008:INFO:   category_encoders: 2.6.4
2025-03-20 18:34:46,008:INFO:            lightgbm: 4.5.0
2025-03-20 18:34:46,008:INFO:               numba: 0.58.1
2025-03-20 18:34:46,008:INFO:            requests: 2.32.3
2025-03-20 18:34:46,008:INFO:          matplotlib: 3.6.0
2025-03-20 18:34:46,008:INFO:          scikitplot: 0.3.7
2025-03-20 18:34:46,008:INFO:         yellowbrick: 1.5
2025-03-20 18:34:46,008:INFO:              plotly: 5.24.1
2025-03-20 18:34:46,008:INFO:    plotly-resampler: Not installed
2025-03-20 18:34:46,008:INFO:             kaleido: 0.2.1
2025-03-20 18:34:46,008:INFO:           schemdraw: 0.15
2025-03-20 18:34:46,008:INFO:         statsmodels: 0.14.1
2025-03-20 18:34:46,008:INFO:              sktime: 0.21.1
2025-03-20 18:34:46,008:INFO:               tbats: 1.1.3
2025-03-20 18:34:46,008:INFO:            pmdarima: 2.0.4
2025-03-20 18:34:46,008:INFO:              psutil: 6.1.0
2025-03-20 18:34:46,008:INFO:          markupsafe: 2.1.5
2025-03-20 18:34:46,008:INFO:             pickle5: Not installed
2025-03-20 18:34:46,008:INFO:         cloudpickle: 2.2.1
2025-03-20 18:34:46,008:INFO:         deprecation: 2.1.0
2025-03-20 18:34:46,008:INFO:              xxhash: 3.5.0
2025-03-20 18:34:46,008:INFO:           wurlitzer: Not installed
2025-03-20 18:34:46,008:INFO:PyCaret optional dependencies:
2025-03-20 18:34:47,292:INFO:                shap: 0.44.1
2025-03-20 18:34:47,292:INFO:           interpret: 0.6.6
2025-03-20 18:34:47,292:INFO:                umap: 0.5.7
2025-03-20 18:34:47,292:INFO:     ydata_profiling: 4.6.0
2025-03-20 18:34:47,292:INFO:  explainerdashboard: 0.4.7
2025-03-20 18:34:47,292:INFO:             autoviz: Not installed
2025-03-20 18:34:47,292:INFO:           fairlearn: 0.7.0
2025-03-20 18:34:47,292:INFO:          deepchecks: Not installed
2025-03-20 18:34:47,292:INFO:             xgboost: 2.1.3
2025-03-20 18:34:47,292:INFO:            catboost: 1.2.7
2025-03-20 18:34:47,292:INFO:              kmodes: 0.12.2
2025-03-20 18:34:47,292:INFO:             mlxtend: 0.23.1
2025-03-20 18:34:47,292:INFO:       statsforecast: 1.5.0
2025-03-20 18:34:47,292:INFO:        tune_sklearn: 0.5.0
2025-03-20 18:34:47,292:INFO:                 ray: 2.10.0
2025-03-20 18:34:47,292:INFO:            hyperopt: 0.2.7
2025-03-20 18:34:47,292:INFO:              optuna: 4.1.0
2025-03-20 18:34:47,292:INFO:               skopt: 0.10.2
2025-03-20 18:34:47,292:INFO:              mlflow: 1.30.1
2025-03-20 18:34:47,292:INFO:              gradio: 3.50.2
2025-03-20 18:34:47,292:INFO:             fastapi: 0.115.5
2025-03-20 18:34:47,292:INFO:             uvicorn: 0.32.1
2025-03-20 18:34:47,292:INFO:              m2cgen: 0.10.0
2025-03-20 18:34:47,292:INFO:           evidently: 0.2.8
2025-03-20 18:34:47,292:INFO:               fugue: 0.8.6
2025-03-20 18:34:47,292:INFO:           streamlit: Not installed
2025-03-20 18:34:47,292:INFO:             prophet: Not installed
2025-03-20 18:34:47,292:INFO:None
2025-03-20 18:34:47,292:INFO:Set up data.
2025-03-20 18:34:47,298:INFO:Set up folding strategy.
2025-03-20 18:34:47,298:INFO:Set up train/test split.
2025-03-20 18:34:47,298:INFO:Set up data.
2025-03-20 18:34:47,302:INFO:Set up index.
2025-03-20 18:34:47,302:INFO:Assigning column types.
2025-03-20 18:34:47,304:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 18:34:47,304:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,306:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,352:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,353:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,364:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,366:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,368:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,392:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,411:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,412:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,413:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 18:34:47,415:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,417:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,459:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,460:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,461:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,463:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,465:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,489:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,508:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,509:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,510:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 18:34:47,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,538:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,557:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,558:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,562:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,607:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,608:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,608:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 18:34:47,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,655:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,656:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,657:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,704:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,705:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,705:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 18:34:47,735:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,753:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,754:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:34:47,802:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,803:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,804:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 18:34:47,850:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,851:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,898:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:47,900:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:47,901:INFO:Preparing preprocessing pipeline...
2025-03-20 18:34:47,901:INFO:Set up simple imputation.
2025-03-20 18:34:47,902:INFO:Set up encoding of categorical features.
2025-03-20 18:34:47,902:INFO:Set up feature normalization.
2025-03-20 18:34:47,903:INFO:Set up column name cleaning.
2025-03-20 18:34:47,950:INFO:Finished creating preprocessing pipeline.
2025-03-20 18:34:47,954:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:34:47,954:INFO:Creating final display dataframe.
2025-03-20 18:34:48,078:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 27)
4        Transformed data shape        (1769, 40)
5   Transformed train set shape        (1399, 40)
6    Transformed test set shape         (370, 40)
7              Numeric features                23
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              cefa
2025-03-20 18:34:48,131:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:48,132:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:48,181:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:34:48,182:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:34:48,183:INFO:Logging experiment in loggers
2025-03-20 18:34:48,325:INFO:SubProcess save_model() called ==================================
2025-03-20 18:34:48,332:INFO:Initializing save_model()
2025-03-20 18:34:48,333:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmps86jbrh7\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:34:48,333:INFO:Adding model into prep_pipe
2025-03-20 18:34:48,333:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:34:48,336:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmps86jbrh7\Transformation Pipeline.pkl saved in current working directory
2025-03-20 18:34:48,340:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:34:48,340:INFO:save_model() successfully completed......................................
2025-03-20 18:34:48,391:INFO:SubProcess save_model() end ==================================
2025-03-20 18:34:48,396:INFO:setup() successfully completed in 2.68s...............
2025-03-20 18:34:48,396:INFO:Initializing compare_models()
2025-03-20 18:34:48,396:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 18:34:48,396:INFO:Checking exceptions
2025-03-20 18:34:48,397:INFO:Preparing display monitor
2025-03-20 18:34:48,410:INFO:Initializing Linear Regression
2025-03-20 18:34:48,410:INFO:Total runtime is 0.0 minutes
2025-03-20 18:34:48,412:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:48,412:INFO:Initializing create_model()
2025-03-20 18:34:48,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:48,412:INFO:Checking exceptions
2025-03-20 18:34:48,412:INFO:Importing libraries
2025-03-20 18:34:48,412:INFO:Copying training dataset
2025-03-20 18:34:48,414:INFO:Defining folds
2025-03-20 18:34:48,414:INFO:Declaring metric variables
2025-03-20 18:34:48,416:INFO:Importing untrained model
2025-03-20 18:34:48,418:INFO:Linear Regression Imported successfully
2025-03-20 18:34:48,422:INFO:Starting cross validation
2025-03-20 18:34:48,426:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:34:50,919:INFO:Calculating mean and std
2025-03-20 18:34:50,920:INFO:Creating metrics dataframe
2025-03-20 18:34:50,922:INFO:Uploading results into container
2025-03-20 18:34:50,922:INFO:Uploading model into container now
2025-03-20 18:34:50,923:INFO:_master_model_container: 1
2025-03-20 18:34:50,923:INFO:_display_container: 2
2025-03-20 18:34:50,923:INFO:LinearRegression(n_jobs=-1)
2025-03-20 18:34:50,923:INFO:create_model() successfully completed......................................
2025-03-20 18:34:50,982:INFO:SubProcess create_model() end ==================================
2025-03-20 18:34:50,982:INFO:Creating metrics dataframe
2025-03-20 18:34:50,986:INFO:Initializing Lasso Regression
2025-03-20 18:34:50,986:INFO:Total runtime is 0.042945051193237306 minutes
2025-03-20 18:34:50,988:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:50,988:INFO:Initializing create_model()
2025-03-20 18:34:50,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:50,988:INFO:Checking exceptions
2025-03-20 18:34:50,988:INFO:Importing libraries
2025-03-20 18:34:50,988:INFO:Copying training dataset
2025-03-20 18:34:50,990:INFO:Defining folds
2025-03-20 18:34:50,990:INFO:Declaring metric variables
2025-03-20 18:34:50,992:INFO:Importing untrained model
2025-03-20 18:34:50,993:INFO:Lasso Regression Imported successfully
2025-03-20 18:34:50,997:INFO:Starting cross validation
2025-03-20 18:34:50,997:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:34:53,013:INFO:Calculating mean and std
2025-03-20 18:34:53,014:INFO:Creating metrics dataframe
2025-03-20 18:34:53,016:INFO:Uploading results into container
2025-03-20 18:34:53,017:INFO:Uploading model into container now
2025-03-20 18:34:53,018:INFO:_master_model_container: 2
2025-03-20 18:34:53,018:INFO:_display_container: 2
2025-03-20 18:34:53,018:INFO:Lasso(random_state=888)
2025-03-20 18:34:53,018:INFO:create_model() successfully completed......................................
2025-03-20 18:34:53,078:INFO:SubProcess create_model() end ==================================
2025-03-20 18:34:53,078:INFO:Creating metrics dataframe
2025-03-20 18:34:53,083:INFO:Initializing Ridge Regression
2025-03-20 18:34:53,083:INFO:Total runtime is 0.07788550853729248 minutes
2025-03-20 18:34:53,085:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:53,085:INFO:Initializing create_model()
2025-03-20 18:34:53,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:53,085:INFO:Checking exceptions
2025-03-20 18:34:53,085:INFO:Importing libraries
2025-03-20 18:34:53,085:INFO:Copying training dataset
2025-03-20 18:34:53,087:INFO:Defining folds
2025-03-20 18:34:53,087:INFO:Declaring metric variables
2025-03-20 18:34:53,088:INFO:Importing untrained model
2025-03-20 18:34:53,090:INFO:Ridge Regression Imported successfully
2025-03-20 18:34:53,093:INFO:Starting cross validation
2025-03-20 18:34:53,094:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:34:55,076:INFO:Calculating mean and std
2025-03-20 18:34:55,077:INFO:Creating metrics dataframe
2025-03-20 18:34:55,078:INFO:Uploading results into container
2025-03-20 18:34:55,079:INFO:Uploading model into container now
2025-03-20 18:34:55,079:INFO:_master_model_container: 3
2025-03-20 18:34:55,079:INFO:_display_container: 2
2025-03-20 18:34:55,079:INFO:Ridge(random_state=888)
2025-03-20 18:34:55,079:INFO:create_model() successfully completed......................................
2025-03-20 18:34:55,135:INFO:SubProcess create_model() end ==================================
2025-03-20 18:34:55,135:INFO:Creating metrics dataframe
2025-03-20 18:34:55,140:INFO:Initializing Elastic Net
2025-03-20 18:34:55,140:INFO:Total runtime is 0.11217208703358969 minutes
2025-03-20 18:34:55,141:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:55,142:INFO:Initializing create_model()
2025-03-20 18:34:55,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:55,142:INFO:Checking exceptions
2025-03-20 18:34:55,142:INFO:Importing libraries
2025-03-20 18:34:55,142:INFO:Copying training dataset
2025-03-20 18:34:55,144:INFO:Defining folds
2025-03-20 18:34:55,144:INFO:Declaring metric variables
2025-03-20 18:34:55,145:INFO:Importing untrained model
2025-03-20 18:34:55,147:INFO:Elastic Net Imported successfully
2025-03-20 18:34:55,150:INFO:Starting cross validation
2025-03-20 18:34:55,151:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:34:57,139:INFO:Calculating mean and std
2025-03-20 18:34:57,140:INFO:Creating metrics dataframe
2025-03-20 18:34:57,141:INFO:Uploading results into container
2025-03-20 18:34:57,142:INFO:Uploading model into container now
2025-03-20 18:34:57,142:INFO:_master_model_container: 4
2025-03-20 18:34:57,142:INFO:_display_container: 2
2025-03-20 18:34:57,143:INFO:ElasticNet(random_state=888)
2025-03-20 18:34:57,143:INFO:create_model() successfully completed......................................
2025-03-20 18:34:57,199:INFO:SubProcess create_model() end ==================================
2025-03-20 18:34:57,199:INFO:Creating metrics dataframe
2025-03-20 18:34:57,204:INFO:Initializing Least Angle Regression
2025-03-20 18:34:57,204:INFO:Total runtime is 0.14657442569732668 minutes
2025-03-20 18:34:57,206:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:57,206:INFO:Initializing create_model()
2025-03-20 18:34:57,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:57,206:INFO:Checking exceptions
2025-03-20 18:34:57,206:INFO:Importing libraries
2025-03-20 18:34:57,206:INFO:Copying training dataset
2025-03-20 18:34:57,208:INFO:Defining folds
2025-03-20 18:34:57,208:INFO:Declaring metric variables
2025-03-20 18:34:57,209:INFO:Importing untrained model
2025-03-20 18:34:57,211:INFO:Least Angle Regression Imported successfully
2025-03-20 18:34:57,214:INFO:Starting cross validation
2025-03-20 18:34:57,215:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:34:59,180:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.994e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,181:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,181:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.459e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,181:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,181:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,181:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.155e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,182:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,182:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.722e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,182:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,182:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,182:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.548e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,183:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.221e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,183:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.499e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,183:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.753e-02, with an active set of 32 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,183:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=8.502e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,184:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.305e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:34:59,202:INFO:Calculating mean and std
2025-03-20 18:34:59,203:INFO:Creating metrics dataframe
2025-03-20 18:34:59,205:INFO:Uploading results into container
2025-03-20 18:34:59,206:INFO:Uploading model into container now
2025-03-20 18:34:59,206:INFO:_master_model_container: 5
2025-03-20 18:34:59,206:INFO:_display_container: 2
2025-03-20 18:34:59,206:INFO:Lars(random_state=888)
2025-03-20 18:34:59,206:INFO:create_model() successfully completed......................................
2025-03-20 18:34:59,267:INFO:SubProcess create_model() end ==================================
2025-03-20 18:34:59,267:INFO:Creating metrics dataframe
2025-03-20 18:34:59,271:INFO:Initializing Lasso Least Angle Regression
2025-03-20 18:34:59,271:INFO:Total runtime is 0.18102649450302127 minutes
2025-03-20 18:34:59,273:INFO:SubProcess create_model() called ==================================
2025-03-20 18:34:59,273:INFO:Initializing create_model()
2025-03-20 18:34:59,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:34:59,273:INFO:Checking exceptions
2025-03-20 18:34:59,273:INFO:Importing libraries
2025-03-20 18:34:59,273:INFO:Copying training dataset
2025-03-20 18:34:59,275:INFO:Defining folds
2025-03-20 18:34:59,275:INFO:Declaring metric variables
2025-03-20 18:34:59,277:INFO:Importing untrained model
2025-03-20 18:34:59,278:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 18:34:59,281:INFO:Starting cross validation
2025-03-20 18:34:59,282:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:01,234:INFO:Calculating mean and std
2025-03-20 18:35:01,235:INFO:Creating metrics dataframe
2025-03-20 18:35:01,237:INFO:Uploading results into container
2025-03-20 18:35:01,237:INFO:Uploading model into container now
2025-03-20 18:35:01,238:INFO:_master_model_container: 6
2025-03-20 18:35:01,238:INFO:_display_container: 2
2025-03-20 18:35:01,238:INFO:LassoLars(random_state=888)
2025-03-20 18:35:01,238:INFO:create_model() successfully completed......................................
2025-03-20 18:35:01,296:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:01,296:INFO:Creating metrics dataframe
2025-03-20 18:35:01,301:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 18:35:01,302:INFO:Total runtime is 0.21486606995264693 minutes
2025-03-20 18:35:01,303:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:01,304:INFO:Initializing create_model()
2025-03-20 18:35:01,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:01,304:INFO:Checking exceptions
2025-03-20 18:35:01,304:INFO:Importing libraries
2025-03-20 18:35:01,304:INFO:Copying training dataset
2025-03-20 18:35:01,305:INFO:Defining folds
2025-03-20 18:35:01,305:INFO:Declaring metric variables
2025-03-20 18:35:01,306:INFO:Importing untrained model
2025-03-20 18:35:01,308:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 18:35:01,311:INFO:Starting cross validation
2025-03-20 18:35:01,312:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:02,990:INFO:Calculating mean and std
2025-03-20 18:35:02,991:INFO:Creating metrics dataframe
2025-03-20 18:35:02,992:INFO:Uploading results into container
2025-03-20 18:35:02,993:INFO:Uploading model into container now
2025-03-20 18:35:02,993:INFO:_master_model_container: 7
2025-03-20 18:35:02,993:INFO:_display_container: 2
2025-03-20 18:35:02,993:INFO:OrthogonalMatchingPursuit()
2025-03-20 18:35:02,993:INFO:create_model() successfully completed......................................
2025-03-20 18:35:03,049:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:03,049:INFO:Creating metrics dataframe
2025-03-20 18:35:03,054:INFO:Initializing Bayesian Ridge
2025-03-20 18:35:03,054:INFO:Total runtime is 0.2440782507260641 minutes
2025-03-20 18:35:03,056:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:03,056:INFO:Initializing create_model()
2025-03-20 18:35:03,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:03,056:INFO:Checking exceptions
2025-03-20 18:35:03,056:INFO:Importing libraries
2025-03-20 18:35:03,056:INFO:Copying training dataset
2025-03-20 18:35:03,058:INFO:Defining folds
2025-03-20 18:35:03,058:INFO:Declaring metric variables
2025-03-20 18:35:03,060:INFO:Importing untrained model
2025-03-20 18:35:03,061:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:35:03,064:INFO:Starting cross validation
2025-03-20 18:35:03,065:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:03,128:INFO:Calculating mean and std
2025-03-20 18:35:03,129:INFO:Creating metrics dataframe
2025-03-20 18:35:03,131:INFO:Uploading results into container
2025-03-20 18:35:03,131:INFO:Uploading model into container now
2025-03-20 18:35:03,131:INFO:_master_model_container: 8
2025-03-20 18:35:03,131:INFO:_display_container: 2
2025-03-20 18:35:03,132:INFO:BayesianRidge()
2025-03-20 18:35:03,132:INFO:create_model() successfully completed......................................
2025-03-20 18:35:03,185:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:03,185:INFO:Creating metrics dataframe
2025-03-20 18:35:03,191:INFO:Initializing Passive Aggressive Regressor
2025-03-20 18:35:03,191:INFO:Total runtime is 0.24635463953018194 minutes
2025-03-20 18:35:03,192:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:03,192:INFO:Initializing create_model()
2025-03-20 18:35:03,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:03,192:INFO:Checking exceptions
2025-03-20 18:35:03,192:INFO:Importing libraries
2025-03-20 18:35:03,192:INFO:Copying training dataset
2025-03-20 18:35:03,194:INFO:Defining folds
2025-03-20 18:35:03,194:INFO:Declaring metric variables
2025-03-20 18:35:03,196:INFO:Importing untrained model
2025-03-20 18:35:03,197:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 18:35:03,201:INFO:Starting cross validation
2025-03-20 18:35:03,202:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:03,267:INFO:Calculating mean and std
2025-03-20 18:35:03,268:INFO:Creating metrics dataframe
2025-03-20 18:35:03,269:INFO:Uploading results into container
2025-03-20 18:35:03,270:INFO:Uploading model into container now
2025-03-20 18:35:03,270:INFO:_master_model_container: 9
2025-03-20 18:35:03,270:INFO:_display_container: 2
2025-03-20 18:35:03,270:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 18:35:03,270:INFO:create_model() successfully completed......................................
2025-03-20 18:35:03,323:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:03,323:INFO:Creating metrics dataframe
2025-03-20 18:35:03,329:INFO:Initializing Huber Regressor
2025-03-20 18:35:03,329:INFO:Total runtime is 0.2486558636029562 minutes
2025-03-20 18:35:03,330:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:03,331:INFO:Initializing create_model()
2025-03-20 18:35:03,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:03,331:INFO:Checking exceptions
2025-03-20 18:35:03,331:INFO:Importing libraries
2025-03-20 18:35:03,331:INFO:Copying training dataset
2025-03-20 18:35:03,333:INFO:Defining folds
2025-03-20 18:35:03,333:INFO:Declaring metric variables
2025-03-20 18:35:03,334:INFO:Importing untrained model
2025-03-20 18:35:03,336:INFO:Huber Regressor Imported successfully
2025-03-20 18:35:03,339:INFO:Starting cross validation
2025-03-20 18:35:03,340:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:03,380:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:35:03,384:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:35:03,387:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:35:03,391:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:35:03,394:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:35:03,421:INFO:Calculating mean and std
2025-03-20 18:35:03,422:INFO:Creating metrics dataframe
2025-03-20 18:35:03,423:INFO:Uploading results into container
2025-03-20 18:35:03,424:INFO:Uploading model into container now
2025-03-20 18:35:03,424:INFO:_master_model_container: 10
2025-03-20 18:35:03,424:INFO:_display_container: 2
2025-03-20 18:35:03,424:INFO:HuberRegressor()
2025-03-20 18:35:03,424:INFO:create_model() successfully completed......................................
2025-03-20 18:35:03,477:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:03,477:INFO:Creating metrics dataframe
2025-03-20 18:35:03,482:INFO:Initializing K Neighbors Regressor
2025-03-20 18:35:03,483:INFO:Total runtime is 0.25121481815973923 minutes
2025-03-20 18:35:03,484:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:03,484:INFO:Initializing create_model()
2025-03-20 18:35:03,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:03,485:INFO:Checking exceptions
2025-03-20 18:35:03,485:INFO:Importing libraries
2025-03-20 18:35:03,485:INFO:Copying training dataset
2025-03-20 18:35:03,486:INFO:Defining folds
2025-03-20 18:35:03,487:INFO:Declaring metric variables
2025-03-20 18:35:03,488:INFO:Importing untrained model
2025-03-20 18:35:03,490:INFO:K Neighbors Regressor Imported successfully
2025-03-20 18:35:03,492:INFO:Starting cross validation
2025-03-20 18:35:03,493:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:03,590:INFO:Calculating mean and std
2025-03-20 18:35:03,591:INFO:Creating metrics dataframe
2025-03-20 18:35:03,593:INFO:Uploading results into container
2025-03-20 18:35:03,593:INFO:Uploading model into container now
2025-03-20 18:35:03,593:INFO:_master_model_container: 11
2025-03-20 18:35:03,593:INFO:_display_container: 2
2025-03-20 18:35:03,594:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 18:35:03,594:INFO:create_model() successfully completed......................................
2025-03-20 18:35:03,646:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:03,646:INFO:Creating metrics dataframe
2025-03-20 18:35:03,651:INFO:Initializing Decision Tree Regressor
2025-03-20 18:35:03,652:INFO:Total runtime is 0.25403628746668505 minutes
2025-03-20 18:35:03,654:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:03,654:INFO:Initializing create_model()
2025-03-20 18:35:03,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:03,654:INFO:Checking exceptions
2025-03-20 18:35:03,654:INFO:Importing libraries
2025-03-20 18:35:03,654:INFO:Copying training dataset
2025-03-20 18:35:03,656:INFO:Defining folds
2025-03-20 18:35:03,656:INFO:Declaring metric variables
2025-03-20 18:35:03,657:INFO:Importing untrained model
2025-03-20 18:35:03,659:INFO:Decision Tree Regressor Imported successfully
2025-03-20 18:35:03,662:INFO:Starting cross validation
2025-03-20 18:35:03,663:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:03,744:INFO:Calculating mean and std
2025-03-20 18:35:03,745:INFO:Creating metrics dataframe
2025-03-20 18:35:03,747:INFO:Uploading results into container
2025-03-20 18:35:03,747:INFO:Uploading model into container now
2025-03-20 18:35:03,747:INFO:_master_model_container: 12
2025-03-20 18:35:03,747:INFO:_display_container: 2
2025-03-20 18:35:03,747:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 18:35:03,747:INFO:create_model() successfully completed......................................
2025-03-20 18:35:03,801:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:03,802:INFO:Creating metrics dataframe
2025-03-20 18:35:03,807:INFO:Initializing Random Forest Regressor
2025-03-20 18:35:03,807:INFO:Total runtime is 0.2566288669904074 minutes
2025-03-20 18:35:03,809:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:03,809:INFO:Initializing create_model()
2025-03-20 18:35:03,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:03,809:INFO:Checking exceptions
2025-03-20 18:35:03,809:INFO:Importing libraries
2025-03-20 18:35:03,809:INFO:Copying training dataset
2025-03-20 18:35:03,811:INFO:Defining folds
2025-03-20 18:35:03,811:INFO:Declaring metric variables
2025-03-20 18:35:03,813:INFO:Importing untrained model
2025-03-20 18:35:03,814:INFO:Random Forest Regressor Imported successfully
2025-03-20 18:35:03,817:INFO:Starting cross validation
2025-03-20 18:35:03,818:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:04,175:INFO:Calculating mean and std
2025-03-20 18:35:04,176:INFO:Creating metrics dataframe
2025-03-20 18:35:04,178:INFO:Uploading results into container
2025-03-20 18:35:04,178:INFO:Uploading model into container now
2025-03-20 18:35:04,178:INFO:_master_model_container: 13
2025-03-20 18:35:04,178:INFO:_display_container: 2
2025-03-20 18:35:04,179:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:35:04,179:INFO:create_model() successfully completed......................................
2025-03-20 18:35:04,232:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:04,232:INFO:Creating metrics dataframe
2025-03-20 18:35:04,238:INFO:Initializing Extra Trees Regressor
2025-03-20 18:35:04,238:INFO:Total runtime is 0.263806708653768 minutes
2025-03-20 18:35:04,240:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:04,240:INFO:Initializing create_model()
2025-03-20 18:35:04,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:04,240:INFO:Checking exceptions
2025-03-20 18:35:04,240:INFO:Importing libraries
2025-03-20 18:35:04,240:INFO:Copying training dataset
2025-03-20 18:35:04,242:INFO:Defining folds
2025-03-20 18:35:04,242:INFO:Declaring metric variables
2025-03-20 18:35:04,243:INFO:Importing untrained model
2025-03-20 18:35:04,245:INFO:Extra Trees Regressor Imported successfully
2025-03-20 18:35:04,248:INFO:Starting cross validation
2025-03-20 18:35:04,248:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:04,468:INFO:Calculating mean and std
2025-03-20 18:35:04,469:INFO:Creating metrics dataframe
2025-03-20 18:35:04,470:INFO:Uploading results into container
2025-03-20 18:35:04,471:INFO:Uploading model into container now
2025-03-20 18:35:04,471:INFO:_master_model_container: 14
2025-03-20 18:35:04,471:INFO:_display_container: 2
2025-03-20 18:35:04,471:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:35:04,471:INFO:create_model() successfully completed......................................
2025-03-20 18:35:04,524:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:04,524:INFO:Creating metrics dataframe
2025-03-20 18:35:04,530:INFO:Initializing AdaBoost Regressor
2025-03-20 18:35:04,530:INFO:Total runtime is 0.26867403586705535 minutes
2025-03-20 18:35:04,531:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:04,532:INFO:Initializing create_model()
2025-03-20 18:35:04,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:04,532:INFO:Checking exceptions
2025-03-20 18:35:04,532:INFO:Importing libraries
2025-03-20 18:35:04,532:INFO:Copying training dataset
2025-03-20 18:35:04,534:INFO:Defining folds
2025-03-20 18:35:04,534:INFO:Declaring metric variables
2025-03-20 18:35:04,535:INFO:Importing untrained model
2025-03-20 18:35:04,537:INFO:AdaBoost Regressor Imported successfully
2025-03-20 18:35:04,541:INFO:Starting cross validation
2025-03-20 18:35:04,541:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:04,745:INFO:Calculating mean and std
2025-03-20 18:35:04,746:INFO:Creating metrics dataframe
2025-03-20 18:35:04,747:INFO:Uploading results into container
2025-03-20 18:35:04,748:INFO:Uploading model into container now
2025-03-20 18:35:04,748:INFO:_master_model_container: 15
2025-03-20 18:35:04,748:INFO:_display_container: 2
2025-03-20 18:35:04,748:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 18:35:04,748:INFO:create_model() successfully completed......................................
2025-03-20 18:35:04,803:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:04,803:INFO:Creating metrics dataframe
2025-03-20 18:35:04,809:INFO:Initializing Gradient Boosting Regressor
2025-03-20 18:35:04,809:INFO:Total runtime is 0.2733249862988791 minutes
2025-03-20 18:35:04,811:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:04,811:INFO:Initializing create_model()
2025-03-20 18:35:04,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:04,811:INFO:Checking exceptions
2025-03-20 18:35:04,812:INFO:Importing libraries
2025-03-20 18:35:04,812:INFO:Copying training dataset
2025-03-20 18:35:04,813:INFO:Defining folds
2025-03-20 18:35:04,813:INFO:Declaring metric variables
2025-03-20 18:35:04,815:INFO:Importing untrained model
2025-03-20 18:35:04,816:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:35:04,819:INFO:Starting cross validation
2025-03-20 18:35:04,820:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:05,438:INFO:Calculating mean and std
2025-03-20 18:35:05,439:INFO:Creating metrics dataframe
2025-03-20 18:35:05,441:INFO:Uploading results into container
2025-03-20 18:35:05,441:INFO:Uploading model into container now
2025-03-20 18:35:05,441:INFO:_master_model_container: 16
2025-03-20 18:35:05,441:INFO:_display_container: 2
2025-03-20 18:35:05,441:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:35:05,441:INFO:create_model() successfully completed......................................
2025-03-20 18:35:05,494:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:05,494:INFO:Creating metrics dataframe
2025-03-20 18:35:05,500:INFO:Initializing Extreme Gradient Boosting
2025-03-20 18:35:05,500:INFO:Total runtime is 0.2848478873570761 minutes
2025-03-20 18:35:05,502:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:05,502:INFO:Initializing create_model()
2025-03-20 18:35:05,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:05,502:INFO:Checking exceptions
2025-03-20 18:35:05,502:INFO:Importing libraries
2025-03-20 18:35:05,502:INFO:Copying training dataset
2025-03-20 18:35:05,504:INFO:Defining folds
2025-03-20 18:35:05,504:INFO:Declaring metric variables
2025-03-20 18:35:05,506:INFO:Importing untrained model
2025-03-20 18:35:05,508:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 18:35:05,511:INFO:Starting cross validation
2025-03-20 18:35:05,512:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:06,008:INFO:Calculating mean and std
2025-03-20 18:35:06,009:INFO:Creating metrics dataframe
2025-03-20 18:35:06,010:INFO:Uploading results into container
2025-03-20 18:35:06,010:INFO:Uploading model into container now
2025-03-20 18:35:06,011:INFO:_master_model_container: 17
2025-03-20 18:35:06,011:INFO:_display_container: 2
2025-03-20 18:35:06,011:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 18:35:06,011:INFO:create_model() successfully completed......................................
2025-03-20 18:35:06,075:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:06,075:INFO:Creating metrics dataframe
2025-03-20 18:35:06,081:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 18:35:06,081:INFO:Total runtime is 0.29452459812164317 minutes
2025-03-20 18:35:06,083:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:06,083:INFO:Initializing create_model()
2025-03-20 18:35:06,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:06,083:INFO:Checking exceptions
2025-03-20 18:35:06,083:INFO:Importing libraries
2025-03-20 18:35:06,083:INFO:Copying training dataset
2025-03-20 18:35:06,085:INFO:Defining folds
2025-03-20 18:35:06,085:INFO:Declaring metric variables
2025-03-20 18:35:06,087:INFO:Importing untrained model
2025-03-20 18:35:06,088:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:35:06,092:INFO:Starting cross validation
2025-03-20 18:35:06,092:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:06,577:INFO:Calculating mean and std
2025-03-20 18:35:06,578:INFO:Creating metrics dataframe
2025-03-20 18:35:06,581:INFO:Uploading results into container
2025-03-20 18:35:06,581:INFO:Uploading model into container now
2025-03-20 18:35:06,581:INFO:_master_model_container: 18
2025-03-20 18:35:06,581:INFO:_display_container: 2
2025-03-20 18:35:06,582:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:35:06,582:INFO:create_model() successfully completed......................................
2025-03-20 18:35:06,642:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:06,642:INFO:Creating metrics dataframe
2025-03-20 18:35:06,651:INFO:Initializing CatBoost Regressor
2025-03-20 18:35:06,651:INFO:Total runtime is 0.30401919285456347 minutes
2025-03-20 18:35:06,653:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:06,653:INFO:Initializing create_model()
2025-03-20 18:35:06,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:06,653:INFO:Checking exceptions
2025-03-20 18:35:06,653:INFO:Importing libraries
2025-03-20 18:35:06,653:INFO:Copying training dataset
2025-03-20 18:35:06,656:INFO:Defining folds
2025-03-20 18:35:06,656:INFO:Declaring metric variables
2025-03-20 18:35:06,658:INFO:Importing untrained model
2025-03-20 18:35:06,660:INFO:CatBoost Regressor Imported successfully
2025-03-20 18:35:06,663:INFO:Starting cross validation
2025-03-20 18:35:06,664:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:09,056:INFO:Calculating mean and std
2025-03-20 18:35:09,057:INFO:Creating metrics dataframe
2025-03-20 18:35:09,059:INFO:Uploading results into container
2025-03-20 18:35:09,059:INFO:Uploading model into container now
2025-03-20 18:35:09,059:INFO:_master_model_container: 19
2025-03-20 18:35:09,059:INFO:_display_container: 2
2025-03-20 18:35:09,059:INFO:<catboost.core.CatBoostRegressor object at 0x0000016E68DF1A30>
2025-03-20 18:35:09,060:INFO:create_model() successfully completed......................................
2025-03-20 18:35:09,111:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:09,111:INFO:Creating metrics dataframe
2025-03-20 18:35:09,117:INFO:Initializing Dummy Regressor
2025-03-20 18:35:09,117:INFO:Total runtime is 0.34512954155604053 minutes
2025-03-20 18:35:09,119:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:09,119:INFO:Initializing create_model()
2025-03-20 18:35:09,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E66352430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:09,119:INFO:Checking exceptions
2025-03-20 18:35:09,119:INFO:Importing libraries
2025-03-20 18:35:09,119:INFO:Copying training dataset
2025-03-20 18:35:09,121:INFO:Defining folds
2025-03-20 18:35:09,121:INFO:Declaring metric variables
2025-03-20 18:35:09,122:INFO:Importing untrained model
2025-03-20 18:35:09,124:INFO:Dummy Regressor Imported successfully
2025-03-20 18:35:09,127:INFO:Starting cross validation
2025-03-20 18:35:09,128:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:09,195:INFO:Calculating mean and std
2025-03-20 18:35:09,195:INFO:Creating metrics dataframe
2025-03-20 18:35:09,197:INFO:Uploading results into container
2025-03-20 18:35:09,197:INFO:Uploading model into container now
2025-03-20 18:35:09,198:INFO:_master_model_container: 20
2025-03-20 18:35:09,198:INFO:_display_container: 2
2025-03-20 18:35:09,198:INFO:DummyRegressor()
2025-03-20 18:35:09,198:INFO:create_model() successfully completed......................................
2025-03-20 18:35:09,250:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:09,250:INFO:Creating metrics dataframe
2025-03-20 18:35:09,260:INFO:Initializing create_model()
2025-03-20 18:35:09,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:09,260:INFO:Checking exceptions
2025-03-20 18:35:09,261:INFO:Importing libraries
2025-03-20 18:35:09,261:INFO:Copying training dataset
2025-03-20 18:35:09,263:INFO:Defining folds
2025-03-20 18:35:09,263:INFO:Declaring metric variables
2025-03-20 18:35:09,263:INFO:Importing untrained model
2025-03-20 18:35:09,263:INFO:Declaring custom model
2025-03-20 18:35:09,263:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:35:09,264:INFO:Cross validation set to False
2025-03-20 18:35:09,264:INFO:Fitting Model
2025-03-20 18:35:09,301:INFO:BayesianRidge()
2025-03-20 18:35:09,301:INFO:create_model() successfully completed......................................
2025-03-20 18:35:09,354:INFO:Creating Dashboard logs
2025-03-20 18:35:09,357:INFO:Model: Bayesian Ridge
2025-03-20 18:35:09,371:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:35:09,401:INFO:Initializing predict_model()
2025-03-20 18:35:09,401:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6A64D160>)
2025-03-20 18:35:09,401:INFO:Checking exceptions
2025-03-20 18:35:09,401:INFO:Preloading libraries
2025-03-20 18:35:09,526:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 18:35:09,538:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:09,541:INFO:Initializing create_model()
2025-03-20 18:35:09,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:09,541:INFO:Checking exceptions
2025-03-20 18:35:09,542:INFO:Importing libraries
2025-03-20 18:35:09,542:INFO:Copying training dataset
2025-03-20 18:35:09,544:INFO:Defining folds
2025-03-20 18:35:09,544:INFO:Declaring metric variables
2025-03-20 18:35:09,544:INFO:Importing untrained model
2025-03-20 18:35:09,544:INFO:Declaring custom model
2025-03-20 18:35:09,544:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:35:09,545:INFO:Cross validation set to False
2025-03-20 18:35:09,545:INFO:Fitting Model
2025-03-20 18:35:10,214:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:35:10,214:INFO:create_model() successfully completed......................................
2025-03-20 18:35:10,268:INFO:Creating Dashboard logs
2025-03-20 18:35:10,270:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:35:10,285:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:35:10,326:INFO:Initializing predict_model()
2025-03-20 18:35:10,326:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6A46A430>)
2025-03-20 18:35:10,326:INFO:Checking exceptions
2025-03-20 18:35:10,326:INFO:Preloading libraries
2025-03-20 18:35:10,459:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:10,462:INFO:Initializing create_model()
2025-03-20 18:35:10,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:10,462:INFO:Checking exceptions
2025-03-20 18:35:10,463:INFO:Importing libraries
2025-03-20 18:35:10,463:INFO:Copying training dataset
2025-03-20 18:35:10,465:INFO:Defining folds
2025-03-20 18:35:10,465:INFO:Declaring metric variables
2025-03-20 18:35:10,466:INFO:Importing untrained model
2025-03-20 18:35:10,466:INFO:Declaring custom model
2025-03-20 18:35:10,466:INFO:Ridge Regression Imported successfully
2025-03-20 18:35:10,466:INFO:Cross validation set to False
2025-03-20 18:35:10,466:INFO:Fitting Model
2025-03-20 18:35:10,496:INFO:Ridge(random_state=888)
2025-03-20 18:35:10,496:INFO:create_model() successfully completed......................................
2025-03-20 18:35:10,549:INFO:Creating Dashboard logs
2025-03-20 18:35:10,551:INFO:Model: Ridge Regression
2025-03-20 18:35:10,565:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:35:10,607:INFO:Initializing predict_model()
2025-03-20 18:35:10,607:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6A464550>)
2025-03-20 18:35:10,607:INFO:Checking exceptions
2025-03-20 18:35:10,607:INFO:Preloading libraries
2025-03-20 18:35:10,744:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:10,746:INFO:Initializing create_model()
2025-03-20 18:35:10,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:10,746:INFO:Checking exceptions
2025-03-20 18:35:10,747:INFO:Importing libraries
2025-03-20 18:35:10,747:INFO:Copying training dataset
2025-03-20 18:35:10,749:INFO:Defining folds
2025-03-20 18:35:10,749:INFO:Declaring metric variables
2025-03-20 18:35:10,749:INFO:Importing untrained model
2025-03-20 18:35:10,749:INFO:Declaring custom model
2025-03-20 18:35:10,750:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:35:10,750:INFO:Cross validation set to False
2025-03-20 18:35:10,750:INFO:Fitting Model
2025-03-20 18:35:10,784:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:35:10,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.
2025-03-20 18:35:10,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:35:10,785:INFO:[LightGBM] [Info] Total Bins 4665
2025-03-20 18:35:10,786:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 39
2025-03-20 18:35:10,786:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 18:35:10,860:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:35:10,860:INFO:create_model() successfully completed......................................
2025-03-20 18:35:10,922:INFO:Creating Dashboard logs
2025-03-20 18:35:10,924:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:35:10,944:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 18:35:11,000:INFO:Initializing predict_model()
2025-03-20 18:35:11,000:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6A3C4700>)
2025-03-20 18:35:11,000:INFO:Checking exceptions
2025-03-20 18:35:11,000:INFO:Preloading libraries
2025-03-20 18:35:11,143:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,144:INFO:Creating Dashboard logs
2025-03-20 18:35:11,146:INFO:Model: Extreme Gradient Boosting
2025-03-20 18:35:11,165:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 18:35:11,261:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,262:INFO:Creating Dashboard logs
2025-03-20 18:35:11,264:INFO:Model: Random Forest Regressor
2025-03-20 18:35:11,279:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 18:35:11,360:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,360:INFO:Creating Dashboard logs
2025-03-20 18:35:11,362:INFO:Model: AdaBoost Regressor
2025-03-20 18:35:11,377:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 18:35:11,454:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,455:INFO:Creating Dashboard logs
2025-03-20 18:35:11,457:INFO:Model: CatBoost Regressor
2025-03-20 18:35:11,474:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 18:35:11,474:INFO:Logged params: {}
2025-03-20 18:35:11,554:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x0000016E68DF1A30> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,554:INFO:Creating Dashboard logs
2025-03-20 18:35:11,556:INFO:Model: Extra Trees Regressor
2025-03-20 18:35:11,571:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 18:35:11,665:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,666:INFO:Creating Dashboard logs
2025-03-20 18:35:11,667:INFO:Model: Decision Tree Regressor
2025-03-20 18:35:11,683:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 18:35:11,779:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,780:INFO:Creating Dashboard logs
2025-03-20 18:35:11,782:INFO:Model: Huber Regressor
2025-03-20 18:35:11,796:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 18:35:11,903:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:11,904:INFO:Creating Dashboard logs
2025-03-20 18:35:11,906:INFO:Model: Passive Aggressive Regressor
2025-03-20 18:35:11,922:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:35:12,039:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:12,040:INFO:Creating Dashboard logs
2025-03-20 18:35:12,041:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 18:35:12,056:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 18:35:12,165:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:12,166:INFO:Creating Dashboard logs
2025-03-20 18:35:12,168:INFO:Model: K Neighbors Regressor
2025-03-20 18:35:12,182:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 18:35:12,300:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:12,301:INFO:Creating Dashboard logs
2025-03-20 18:35:12,303:INFO:Model: Elastic Net
2025-03-20 18:35:12,318:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 18:35:12,444:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:12,445:INFO:Creating Dashboard logs
2025-03-20 18:35:12,447:INFO:Model: Lasso Regression
2025-03-20 18:35:12,462:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 18:35:12,591:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:12,592:INFO:Creating Dashboard logs
2025-03-20 18:35:12,594:INFO:Model: Lasso Least Angle Regression
2025-03-20 18:35:12,608:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 18:35:12,748:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:12,748:INFO:Creating Dashboard logs
2025-03-20 18:35:12,750:INFO:Model: Dummy Regressor
2025-03-20 18:35:12,764:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 18:35:12,903:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:12,904:INFO:Creating Dashboard logs
2025-03-20 18:35:12,905:INFO:Model: Linear Regression
2025-03-20 18:35:12,920:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 18:35:13,063:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:13,064:INFO:Creating Dashboard logs
2025-03-20 18:35:13,066:INFO:Model: Least Angle Regression
2025-03-20 18:35:13,081:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 18:35:13,232:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:13,240:INFO:_master_model_container: 20
2025-03-20 18:35:13,241:INFO:_display_container: 2
2025-03-20 18:35:13,241:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888)]
2025-03-20 18:35:13,241:INFO:compare_models() successfully completed......................................
2025-03-20 18:35:13,258:INFO:Initializing tune_model()
2025-03-20 18:35:13,258:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>)
2025-03-20 18:35:13,258:INFO:Checking exceptions
2025-03-20 18:35:13,258:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:35:13,303:INFO:Copying training dataset
2025-03-20 18:35:13,305:INFO:Checking base model
2025-03-20 18:35:13,305:INFO:Base model : Bayesian Ridge
2025-03-20 18:35:13,307:INFO:Declaring metric variables
2025-03-20 18:35:13,309:INFO:Defining Hyperparameters
2025-03-20 18:35:13,366:INFO:Tuning with n_jobs=-1
2025-03-20 18:35:13,367:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:35:13,367:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:35:13,367:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:35:13,373:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:35:13,374:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:35:13,374:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:35:41,091:INFO:best_params: {'actual_estimator__alpha_1': 2.7545472961420178e-09, 'actual_estimator__alpha_2': 4.066609119105379e-06, 'actual_estimator__lambda_1': 0.990445553962634, 'actual_estimator__lambda_2': 0.0035328966263404715, 'actual_estimator__compute_score': False, 'actual_estimator__fit_intercept': True}
2025-03-20 18:35:41,098:INFO:Hyperparameter search completed
2025-03-20 18:35:41,098:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:41,099:INFO:Initializing create_model()
2025-03-20 18:35:41,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E3057E460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 2.7545472961420178e-09, 'alpha_2': 4.066609119105379e-06, 'lambda_1': 0.990445553962634, 'lambda_2': 0.0035328966263404715, 'compute_score': False, 'fit_intercept': True})
2025-03-20 18:35:41,099:INFO:Checking exceptions
2025-03-20 18:35:41,099:INFO:Importing libraries
2025-03-20 18:35:41,099:INFO:Copying training dataset
2025-03-20 18:35:41,102:INFO:Defining folds
2025-03-20 18:35:41,102:INFO:Declaring metric variables
2025-03-20 18:35:41,105:INFO:Importing untrained model
2025-03-20 18:35:41,105:INFO:Declaring custom model
2025-03-20 18:35:41,108:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:35:41,112:INFO:Starting cross validation
2025-03-20 18:35:41,113:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:41,220:INFO:Calculating mean and std
2025-03-20 18:35:41,221:INFO:Creating metrics dataframe
2025-03-20 18:35:41,226:INFO:Finalizing model
2025-03-20 18:35:41,288:INFO:Uploading results into container
2025-03-20 18:35:41,289:INFO:Uploading model into container now
2025-03-20 18:35:41,289:INFO:_master_model_container: 21
2025-03-20 18:35:41,289:INFO:_display_container: 3
2025-03-20 18:35:41,290:INFO:BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715)
2025-03-20 18:35:41,290:INFO:create_model() successfully completed......................................
2025-03-20 18:35:41,385:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:41,385:INFO:choose_better activated
2025-03-20 18:35:41,388:INFO:SubProcess create_model() called ==================================
2025-03-20 18:35:41,388:INFO:Initializing create_model()
2025-03-20 18:35:41,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:35:41,388:INFO:Checking exceptions
2025-03-20 18:35:41,389:INFO:Importing libraries
2025-03-20 18:35:41,390:INFO:Copying training dataset
2025-03-20 18:35:41,393:INFO:Defining folds
2025-03-20 18:35:41,393:INFO:Declaring metric variables
2025-03-20 18:35:41,393:INFO:Importing untrained model
2025-03-20 18:35:41,393:INFO:Declaring custom model
2025-03-20 18:35:41,393:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:35:41,394:INFO:Starting cross validation
2025-03-20 18:35:41,395:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:35:41,497:INFO:Calculating mean and std
2025-03-20 18:35:41,497:INFO:Creating metrics dataframe
2025-03-20 18:35:41,499:INFO:Finalizing model
2025-03-20 18:35:41,556:INFO:Uploading results into container
2025-03-20 18:35:41,557:INFO:Uploading model into container now
2025-03-20 18:35:41,557:INFO:_master_model_container: 22
2025-03-20 18:35:41,557:INFO:_display_container: 4
2025-03-20 18:35:41,557:INFO:BayesianRidge()
2025-03-20 18:35:41,557:INFO:create_model() successfully completed......................................
2025-03-20 18:35:41,652:INFO:SubProcess create_model() end ==================================
2025-03-20 18:35:41,653:INFO:BayesianRidge() result for MAPE is 0.0213
2025-03-20 18:35:41,653:INFO:BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715) result for MAPE is 0.0212
2025-03-20 18:35:41,654:INFO:BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715) is best model
2025-03-20 18:35:41,654:INFO:choose_better completed
2025-03-20 18:35:41,654:INFO:Creating Dashboard logs
2025-03-20 18:35:41,657:INFO:Model: Bayesian Ridge
2025-03-20 18:35:41,686:INFO:Logged params: {'alpha_1': 2.7545472961420178e-09, 'alpha_2': 4.066609119105379e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.990445553962634, 'lambda_2': 0.0035328966263404715, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:35:41,987:INFO:Initializing predict_model()
2025-03-20 18:35:41,987:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6FADCCA0>)
2025-03-20 18:35:41,987:INFO:Checking exceptions
2025-03-20 18:35:41,987:INFO:Preloading libraries
2025-03-20 18:35:42,224:ERROR:_log_model() for BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:35:42,231:INFO:_master_model_container: 22
2025-03-20 18:35:42,231:INFO:_display_container: 3
2025-03-20 18:35:42,231:INFO:BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715)
2025-03-20 18:35:42,231:INFO:tune_model() successfully completed......................................
2025-03-20 18:35:42,325:INFO:Initializing predict_model()
2025-03-20 18:35:42,325:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6A247550>)
2025-03-20 18:35:42,326:INFO:Checking exceptions
2025-03-20 18:35:42,326:INFO:Preloading libraries
2025-03-20 18:35:42,550:INFO:Initializing tune_model()
2025-03-20 18:35:42,550:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>)
2025-03-20 18:35:42,550:INFO:Checking exceptions
2025-03-20 18:35:42,550:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:35:42,562:INFO:Copying training dataset
2025-03-20 18:35:42,566:INFO:Checking base model
2025-03-20 18:35:42,566:INFO:Base model : Gradient Boosting Regressor
2025-03-20 18:35:42,569:INFO:Declaring metric variables
2025-03-20 18:35:42,571:INFO:Defining Hyperparameters
2025-03-20 18:35:42,668:INFO:Tuning with n_jobs=-1
2025-03-20 18:35:42,669:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:35:42,669:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:35:42,669:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:35:42,669:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:35:42,669:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:35:42,669:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:36:34,940:INFO:best_params: {'actual_estimator__n_estimators': 256, 'actual_estimator__learning_rate': 0.22464638711727086, 'actual_estimator__subsample': 0.4966749921104084, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_depth': 3, 'actual_estimator__max_features': 0.5625928552305157, 'actual_estimator__min_impurity_decrease': 0.09998994563739698}
2025-03-20 18:36:34,944:INFO:Hyperparameter search completed
2025-03-20 18:36:34,945:INFO:SubProcess create_model() called ==================================
2025-03-20 18:36:34,945:INFO:Initializing create_model()
2025-03-20 18:36:34,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6A30C820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 256, 'learning_rate': 0.22464638711727086, 'subsample': 0.4966749921104084, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 0.5625928552305157, 'min_impurity_decrease': 0.09998994563739698})
2025-03-20 18:36:34,945:INFO:Checking exceptions
2025-03-20 18:36:34,945:INFO:Importing libraries
2025-03-20 18:36:34,945:INFO:Copying training dataset
2025-03-20 18:36:34,947:INFO:Defining folds
2025-03-20 18:36:34,947:INFO:Declaring metric variables
2025-03-20 18:36:34,949:INFO:Importing untrained model
2025-03-20 18:36:34,949:INFO:Declaring custom model
2025-03-20 18:36:34,951:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:36:34,955:INFO:Starting cross validation
2025-03-20 18:36:34,956:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:36:35,293:INFO:Calculating mean and std
2025-03-20 18:36:35,293:INFO:Creating metrics dataframe
2025-03-20 18:36:35,297:INFO:Finalizing model
2025-03-20 18:36:35,626:INFO:Uploading results into container
2025-03-20 18:36:35,626:INFO:Uploading model into container now
2025-03-20 18:36:35,627:INFO:_master_model_container: 23
2025-03-20 18:36:35,627:INFO:_display_container: 5
2025-03-20 18:36:35,627:INFO:GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084)
2025-03-20 18:36:35,627:INFO:create_model() successfully completed......................................
2025-03-20 18:36:35,683:INFO:SubProcess create_model() end ==================================
2025-03-20 18:36:35,683:INFO:choose_better activated
2025-03-20 18:36:35,686:INFO:SubProcess create_model() called ==================================
2025-03-20 18:36:35,686:INFO:Initializing create_model()
2025-03-20 18:36:35,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:36:35,686:INFO:Checking exceptions
2025-03-20 18:36:35,687:INFO:Importing libraries
2025-03-20 18:36:35,687:INFO:Copying training dataset
2025-03-20 18:36:35,689:INFO:Defining folds
2025-03-20 18:36:35,689:INFO:Declaring metric variables
2025-03-20 18:36:35,689:INFO:Importing untrained model
2025-03-20 18:36:35,689:INFO:Declaring custom model
2025-03-20 18:36:35,690:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:36:35,690:INFO:Starting cross validation
2025-03-20 18:36:35,690:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:36:36,309:INFO:Calculating mean and std
2025-03-20 18:36:36,310:INFO:Creating metrics dataframe
2025-03-20 18:36:36,311:INFO:Finalizing model
2025-03-20 18:36:36,994:INFO:Uploading results into container
2025-03-20 18:36:36,994:INFO:Uploading model into container now
2025-03-20 18:36:36,994:INFO:_master_model_container: 24
2025-03-20 18:36:36,994:INFO:_display_container: 6
2025-03-20 18:36:36,994:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:36:36,994:INFO:create_model() successfully completed......................................
2025-03-20 18:36:37,051:INFO:SubProcess create_model() end ==================================
2025-03-20 18:36:37,051:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.022
2025-03-20 18:36:37,051:INFO:GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084) result for MAPE is 0.0208
2025-03-20 18:36:37,052:INFO:GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084) is best model
2025-03-20 18:36:37,052:INFO:choose_better completed
2025-03-20 18:36:37,052:INFO:Creating Dashboard logs
2025-03-20 18:36:37,053:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:36:37,069:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.22464638711727086, 'loss': 'squared_error', 'max_depth': 3, 'max_features': 0.5625928552305157, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.09998994563739698, 'min_samples_leaf': 2, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 256, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.4966749921104084, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:36:37,240:INFO:Initializing predict_model()
2025-03-20 18:36:37,241:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6FA9E430>)
2025-03-20 18:36:37,241:INFO:Checking exceptions
2025-03-20 18:36:37,241:INFO:Preloading libraries
2025-03-20 18:36:37,385:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:36:37,389:INFO:_master_model_container: 24
2025-03-20 18:36:37,389:INFO:_display_container: 5
2025-03-20 18:36:37,390:INFO:GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084)
2025-03-20 18:36:37,390:INFO:tune_model() successfully completed......................................
2025-03-20 18:36:37,445:INFO:Initializing predict_model()
2025-03-20 18:36:37,445:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6A81F820>)
2025-03-20 18:36:37,445:INFO:Checking exceptions
2025-03-20 18:36:37,445:INFO:Preloading libraries
2025-03-20 18:36:37,575:INFO:Initializing tune_model()
2025-03-20 18:36:37,576:INFO:tune_model(estimator=Ridge(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>)
2025-03-20 18:36:37,576:INFO:Checking exceptions
2025-03-20 18:36:37,576:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:36:37,583:INFO:Copying training dataset
2025-03-20 18:36:37,585:INFO:Checking base model
2025-03-20 18:36:37,585:INFO:Base model : Ridge Regression
2025-03-20 18:36:37,587:INFO:Declaring metric variables
2025-03-20 18:36:37,589:INFO:Defining Hyperparameters
2025-03-20 18:36:37,646:INFO:Tuning with n_jobs=-1
2025-03-20 18:36:37,646:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:36:37,646:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:36:37,647:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:36:37,647:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:36:37,647:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:36:37,647:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:37:00,951:INFO:best_params: {'actual_estimator__alpha': 0.15837846234533687, 'actual_estimator__fit_intercept': True}
2025-03-20 18:37:00,955:INFO:Hyperparameter search completed
2025-03-20 18:37:00,955:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:00,955:INFO:Initializing create_model()
2025-03-20 18:37:00,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6E890E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 0.15837846234533687, 'fit_intercept': True})
2025-03-20 18:37:00,955:INFO:Checking exceptions
2025-03-20 18:37:00,956:INFO:Importing libraries
2025-03-20 18:37:00,956:INFO:Copying training dataset
2025-03-20 18:37:00,957:INFO:Defining folds
2025-03-20 18:37:00,957:INFO:Declaring metric variables
2025-03-20 18:37:00,959:INFO:Importing untrained model
2025-03-20 18:37:00,959:INFO:Declaring custom model
2025-03-20 18:37:00,961:INFO:Ridge Regression Imported successfully
2025-03-20 18:37:00,965:INFO:Starting cross validation
2025-03-20 18:37:00,965:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:01,037:INFO:Calculating mean and std
2025-03-20 18:37:01,037:INFO:Creating metrics dataframe
2025-03-20 18:37:01,040:INFO:Finalizing model
2025-03-20 18:37:01,072:INFO:Uploading results into container
2025-03-20 18:37:01,072:INFO:Uploading model into container now
2025-03-20 18:37:01,073:INFO:_master_model_container: 25
2025-03-20 18:37:01,073:INFO:_display_container: 7
2025-03-20 18:37:01,073:INFO:Ridge(alpha=0.15837846234533687, random_state=888)
2025-03-20 18:37:01,073:INFO:create_model() successfully completed......................................
2025-03-20 18:37:01,128:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:01,128:INFO:choose_better activated
2025-03-20 18:37:01,130:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:01,130:INFO:Initializing create_model()
2025-03-20 18:37:01,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:01,131:INFO:Checking exceptions
2025-03-20 18:37:01,131:INFO:Importing libraries
2025-03-20 18:37:01,132:INFO:Copying training dataset
2025-03-20 18:37:01,133:INFO:Defining folds
2025-03-20 18:37:01,133:INFO:Declaring metric variables
2025-03-20 18:37:01,133:INFO:Importing untrained model
2025-03-20 18:37:01,134:INFO:Declaring custom model
2025-03-20 18:37:01,134:INFO:Ridge Regression Imported successfully
2025-03-20 18:37:01,134:INFO:Starting cross validation
2025-03-20 18:37:01,134:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:01,206:INFO:Calculating mean and std
2025-03-20 18:37:01,206:INFO:Creating metrics dataframe
2025-03-20 18:37:01,207:INFO:Finalizing model
2025-03-20 18:37:01,236:INFO:Uploading results into container
2025-03-20 18:37:01,237:INFO:Uploading model into container now
2025-03-20 18:37:01,237:INFO:_master_model_container: 26
2025-03-20 18:37:01,237:INFO:_display_container: 8
2025-03-20 18:37:01,237:INFO:Ridge(random_state=888)
2025-03-20 18:37:01,237:INFO:create_model() successfully completed......................................
2025-03-20 18:37:01,291:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:01,292:INFO:Ridge(random_state=888) result for MAPE is 0.0223
2025-03-20 18:37:01,292:INFO:Ridge(alpha=0.15837846234533687, random_state=888) result for MAPE is 0.0205
2025-03-20 18:37:01,292:INFO:Ridge(alpha=0.15837846234533687, random_state=888) is best model
2025-03-20 18:37:01,292:INFO:choose_better completed
2025-03-20 18:37:01,292:INFO:Creating Dashboard logs
2025-03-20 18:37:01,294:INFO:Model: Ridge Regression
2025-03-20 18:37:01,309:INFO:Logged params: {'alpha': 0.15837846234533687, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:37:01,480:INFO:Initializing predict_model()
2025-03-20 18:37:01,480:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(alpha=0.15837846234533687, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6FB140D0>)
2025-03-20 18:37:01,480:INFO:Checking exceptions
2025-03-20 18:37:01,480:INFO:Preloading libraries
2025-03-20 18:37:01,620:ERROR:_log_model() for Ridge(alpha=0.15837846234533687, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:01,624:INFO:_master_model_container: 26
2025-03-20 18:37:01,624:INFO:_display_container: 7
2025-03-20 18:37:01,625:INFO:Ridge(alpha=0.15837846234533687, random_state=888)
2025-03-20 18:37:01,625:INFO:tune_model() successfully completed......................................
2025-03-20 18:37:01,682:INFO:Initializing predict_model()
2025-03-20 18:37:01,682:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(alpha=0.15837846234533687, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6A3DAC10>)
2025-03-20 18:37:01,682:INFO:Checking exceptions
2025-03-20 18:37:01,682:INFO:Preloading libraries
2025-03-20 18:37:01,810:INFO:Initializing tune_model()
2025-03-20 18:37:01,811:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>)
2025-03-20 18:37:01,811:INFO:Checking exceptions
2025-03-20 18:37:01,811:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:37:01,819:INFO:Copying training dataset
2025-03-20 18:37:01,821:INFO:Checking base model
2025-03-20 18:37:01,821:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 18:37:01,823:INFO:Declaring metric variables
2025-03-20 18:37:01,825:INFO:Defining Hyperparameters
2025-03-20 18:37:01,881:INFO:Tuning with n_jobs=-1
2025-03-20 18:37:01,881:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:37:01,881:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:37:01,882:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:37:01,882:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:37:01,882:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:37:01,882:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:37:47,058:INFO:best_params: {'actual_estimator__num_leaves': 6, 'actual_estimator__learning_rate': 0.023440572956879818, 'actual_estimator__n_estimators': 174, 'actual_estimator__min_split_gain': 0.8740177905873542, 'actual_estimator__reg_alpha': 6.152517400724381e-05, 'actual_estimator__reg_lambda': 8.192347594113466e-07, 'actual_estimator__feature_fraction': 0.7894782239999676, 'actual_estimator__bagging_fraction': 0.6323468745016072, 'actual_estimator__bagging_freq': 6, 'actual_estimator__min_child_samples': 11}
2025-03-20 18:37:47,065:INFO:Hyperparameter search completed
2025-03-20 18:37:47,065:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:47,065:INFO:Initializing create_model()
2025-03-20 18:37:47,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6A526430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 6, 'learning_rate': 0.023440572956879818, 'n_estimators': 174, 'min_split_gain': 0.8740177905873542, 'reg_alpha': 6.152517400724381e-05, 'reg_lambda': 8.192347594113466e-07, 'feature_fraction': 0.7894782239999676, 'bagging_fraction': 0.6323468745016072, 'bagging_freq': 6, 'min_child_samples': 11})
2025-03-20 18:37:47,065:INFO:Checking exceptions
2025-03-20 18:37:47,066:INFO:Importing libraries
2025-03-20 18:37:47,066:INFO:Copying training dataset
2025-03-20 18:37:47,069:INFO:Defining folds
2025-03-20 18:37:47,069:INFO:Declaring metric variables
2025-03-20 18:37:47,072:INFO:Importing untrained model
2025-03-20 18:37:47,072:INFO:Declaring custom model
2025-03-20 18:37:47,074:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:37:47,079:INFO:Starting cross validation
2025-03-20 18:37:47,080:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:47,350:INFO:Calculating mean and std
2025-03-20 18:37:47,351:INFO:Creating metrics dataframe
2025-03-20 18:37:47,355:INFO:Finalizing model
2025-03-20 18:37:47,396:INFO:[LightGBM] [Warning] feature_fraction is set=0.7894782239999676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7894782239999676
2025-03-20 18:37:47,396:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6323468745016072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6323468745016072
2025-03-20 18:37:47,397:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 18:37:47,398:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:37:47,398:INFO:[LightGBM] [Warning] feature_fraction is set=0.7894782239999676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7894782239999676
2025-03-20 18:37:47,398:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6323468745016072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6323468745016072
2025-03-20 18:37:47,398:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 18:37:47,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000988 seconds.
2025-03-20 18:37:47,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:37:47,400:INFO:[LightGBM] [Info] Total Bins 4665
2025-03-20 18:37:47,400:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 39
2025-03-20 18:37:47,400:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 18:37:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:47,464:INFO:Uploading results into container
2025-03-20 18:37:47,464:INFO:Uploading model into container now
2025-03-20 18:37:47,465:INFO:_master_model_container: 27
2025-03-20 18:37:47,465:INFO:_display_container: 9
2025-03-20 18:37:47,466:INFO:LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07)
2025-03-20 18:37:47,466:INFO:create_model() successfully completed......................................
2025-03-20 18:37:47,528:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:47,529:INFO:choose_better activated
2025-03-20 18:37:47,531:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:47,531:INFO:Initializing create_model()
2025-03-20 18:37:47,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:47,532:INFO:Checking exceptions
2025-03-20 18:37:47,533:INFO:Importing libraries
2025-03-20 18:37:47,533:INFO:Copying training dataset
2025-03-20 18:37:47,536:INFO:Defining folds
2025-03-20 18:37:47,536:INFO:Declaring metric variables
2025-03-20 18:37:47,536:INFO:Importing untrained model
2025-03-20 18:37:47,536:INFO:Declaring custom model
2025-03-20 18:37:47,536:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:37:47,536:INFO:Starting cross validation
2025-03-20 18:37:47,537:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:48,027:INFO:Calculating mean and std
2025-03-20 18:37:48,027:INFO:Creating metrics dataframe
2025-03-20 18:37:48,028:INFO:Finalizing model
2025-03-20 18:37:48,070:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:37:48,071:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.
2025-03-20 18:37:48,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:37:48,071:INFO:[LightGBM] [Info] Total Bins 4665
2025-03-20 18:37:48,072:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 39
2025-03-20 18:37:48,072:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 18:37:48,184:INFO:Uploading results into container
2025-03-20 18:37:48,184:INFO:Uploading model into container now
2025-03-20 18:37:48,184:INFO:_master_model_container: 28
2025-03-20 18:37:48,184:INFO:_display_container: 10
2025-03-20 18:37:48,185:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:37:48,185:INFO:create_model() successfully completed......................................
2025-03-20 18:37:48,247:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:48,247:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0225
2025-03-20 18:37:48,247:INFO:LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07) result for MAPE is 0.0216
2025-03-20 18:37:48,248:INFO:LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07) is best model
2025-03-20 18:37:48,248:INFO:choose_better completed
2025-03-20 18:37:48,248:INFO:Creating Dashboard logs
2025-03-20 18:37:48,250:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:37:48,273:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.023440572956879818, 'max_depth': -1, 'min_child_samples': 11, 'min_child_weight': 0.001, 'min_split_gain': 0.8740177905873542, 'n_estimators': 174, 'n_jobs': -1, 'num_leaves': 6, 'objective': None, 'random_state': 888, 'reg_alpha': 6.152517400724381e-05, 'reg_lambda': 8.192347594113466e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7894782239999676, 'bagging_fraction': 0.6323468745016072, 'bagging_freq': 6}
2025-03-20 18:37:48,462:INFO:Initializing predict_model()
2025-03-20 18:37:48,462:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6FB14160>)
2025-03-20 18:37:48,462:INFO:Checking exceptions
2025-03-20 18:37:48,462:INFO:Preloading libraries
2025-03-20 18:37:48,626:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:48,632:INFO:_master_model_container: 28
2025-03-20 18:37:48,632:INFO:_display_container: 9
2025-03-20 18:37:48,633:INFO:LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07)
2025-03-20 18:37:48,633:INFO:tune_model() successfully completed......................................
2025-03-20 18:37:48,696:INFO:Initializing predict_model()
2025-03-20 18:37:48,696:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6E92BCA0>)
2025-03-20 18:37:48,696:INFO:Checking exceptions
2025-03-20 18:37:48,696:INFO:Preloading libraries
2025-03-20 18:37:48,846:INFO:Initializing blend_models()
2025-03-20 18:37:48,846:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator_list=[BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), Ridge(alpha=0.15837846234533687, random_state=888), LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 18:37:48,846:INFO:Checking exceptions
2025-03-20 18:37:48,857:INFO:Importing libraries
2025-03-20 18:37:48,858:INFO:Copying training dataset
2025-03-20 18:37:48,860:INFO:Getting model names
2025-03-20 18:37:48,863:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:48,869:INFO:Initializing create_model()
2025-03-20 18:37:48,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6A4F5850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:48,869:INFO:Checking exceptions
2025-03-20 18:37:48,870:INFO:Importing libraries
2025-03-20 18:37:48,870:INFO:Copying training dataset
2025-03-20 18:37:48,876:INFO:Defining folds
2025-03-20 18:37:48,876:INFO:Declaring metric variables
2025-03-20 18:37:48,878:INFO:Importing untrained model
2025-03-20 18:37:48,878:INFO:Declaring custom model
2025-03-20 18:37:48,882:INFO:Voting Regressor Imported successfully
2025-03-20 18:37:48,885:INFO:Starting cross validation
2025-03-20 18:37:48,886:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:49,428:INFO:Calculating mean and std
2025-03-20 18:37:49,429:INFO:Creating metrics dataframe
2025-03-20 18:37:49,432:INFO:Finalizing model
2025-03-20 18:37:49,864:INFO:Uploading results into container
2025-03-20 18:37:49,864:INFO:Uploading model into container now
2025-03-20 18:37:49,865:INFO:_master_model_container: 29
2025-03-20 18:37:49,865:INFO:_display_container: 11
2025-03-20 18:37:49,868:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)
2025-03-20 18:37:49,868:INFO:create_model() successfully completed......................................
2025-03-20 18:37:49,922:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:49,923:INFO:Creating Dashboard logs
2025-03-20 18:37:49,925:INFO:Model: Voting Regressor
2025-03-20 18:37:49,944:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), 'Ridge Regression': Ridge(alpha=0.15837846234533687, random_state=888), 'Bayesian Ridge__alpha_1': 2.7545472961420178e-09, 'Bayesian Ridge__alpha_2': 4.066609119105379e-06, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.990445553962634, 'Bayesian Ridge__lambda_2': 0.0035328966263404715, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.22464638711727086, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': 0.5625928552305157, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.09998994563739698, 'Gradient Boosting Regressor__min_samples_leaf': 2, 'Gradient Boosting Regressor__min_samples_split': 5, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 256, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.4966749921104084, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.15837846234533687, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.023440572956879818, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 11, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.8740177905873542, 'Light Gradient Boosting Machine__n_estimators': 174, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 6, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 6.152517400724381e-05, 'Light Gradient Boosting Machine__reg_lambda': 8.192347594113466e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.7894782239999676, 'Light Gradient Boosting Machine__bagging_fraction': 0.6323468745016072, 'Light Gradient Boosting Machine__bagging_freq': 6}
2025-03-20 18:37:50,170:INFO:Initializing predict_model()
2025-03-20 18:37:50,170:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6FB14EE0>)
2025-03-20 18:37:50,170:INFO:Checking exceptions
2025-03-20 18:37:50,170:INFO:Preloading libraries
2025-03-20 18:37:50,351:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:50,357:INFO:_master_model_container: 29
2025-03-20 18:37:50,357:INFO:_display_container: 11
2025-03-20 18:37:50,362:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)
2025-03-20 18:37:50,362:INFO:blend_models() successfully completed......................................
2025-03-20 18:37:50,441:INFO:Initializing compare_models()
2025-03-20 18:37:50,441:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, include=[BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), Ridge(alpha=0.15837846234533687, random_state=888), LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07), VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, 'include': [BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), Ridge(alpha=0.15837846234533687, random_state=888), LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07), VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 18:37:50,441:INFO:Checking exceptions
2025-03-20 18:37:50,442:INFO:Preparing display monitor
2025-03-20 18:37:50,454:INFO:Initializing custom model Bayesian Ridge
2025-03-20 18:37:50,454:INFO:Total runtime is 0.0 minutes
2025-03-20 18:37:50,456:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:50,456:INFO:Initializing create_model()
2025-03-20 18:37:50,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6E8901F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:50,457:INFO:Checking exceptions
2025-03-20 18:37:50,457:INFO:Importing libraries
2025-03-20 18:37:50,457:INFO:Copying training dataset
2025-03-20 18:37:50,459:INFO:Defining folds
2025-03-20 18:37:50,459:INFO:Declaring metric variables
2025-03-20 18:37:50,461:INFO:Importing untrained model
2025-03-20 18:37:50,461:INFO:Declaring custom model
2025-03-20 18:37:50,463:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:37:50,467:INFO:Starting cross validation
2025-03-20 18:37:50,468:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:50,537:INFO:Calculating mean and std
2025-03-20 18:37:50,537:INFO:Creating metrics dataframe
2025-03-20 18:37:50,539:INFO:Uploading results into container
2025-03-20 18:37:50,539:INFO:Uploading model into container now
2025-03-20 18:37:50,540:INFO:_master_model_container: 30
2025-03-20 18:37:50,540:INFO:_display_container: 12
2025-03-20 18:37:50,540:INFO:BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715)
2025-03-20 18:37:50,540:INFO:create_model() successfully completed......................................
2025-03-20 18:37:50,599:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:50,599:INFO:Creating metrics dataframe
2025-03-20 18:37:50,603:INFO:Initializing custom model Gradient Boosting Regressor
2025-03-20 18:37:50,603:INFO:Total runtime is 0.00248333215713501 minutes
2025-03-20 18:37:50,606:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:50,607:INFO:Initializing create_model()
2025-03-20 18:37:50,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6E8901F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:50,607:INFO:Checking exceptions
2025-03-20 18:37:50,607:INFO:Importing libraries
2025-03-20 18:37:50,607:INFO:Copying training dataset
2025-03-20 18:37:50,609:INFO:Defining folds
2025-03-20 18:37:50,609:INFO:Declaring metric variables
2025-03-20 18:37:50,611:INFO:Importing untrained model
2025-03-20 18:37:50,611:INFO:Declaring custom model
2025-03-20 18:37:50,613:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:37:50,617:INFO:Starting cross validation
2025-03-20 18:37:50,618:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:50,952:INFO:Calculating mean and std
2025-03-20 18:37:50,953:INFO:Creating metrics dataframe
2025-03-20 18:37:50,954:INFO:Uploading results into container
2025-03-20 18:37:50,954:INFO:Uploading model into container now
2025-03-20 18:37:50,955:INFO:_master_model_container: 31
2025-03-20 18:37:50,955:INFO:_display_container: 12
2025-03-20 18:37:50,955:INFO:GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084)
2025-03-20 18:37:50,955:INFO:create_model() successfully completed......................................
2025-03-20 18:37:51,010:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:51,010:INFO:Creating metrics dataframe
2025-03-20 18:37:51,015:INFO:Initializing custom model Ridge Regression
2025-03-20 18:37:51,015:INFO:Total runtime is 0.009353876113891602 minutes
2025-03-20 18:37:51,017:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:51,017:INFO:Initializing create_model()
2025-03-20 18:37:51,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(alpha=0.15837846234533687, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6E8901F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:51,018:INFO:Checking exceptions
2025-03-20 18:37:51,018:INFO:Importing libraries
2025-03-20 18:37:51,018:INFO:Copying training dataset
2025-03-20 18:37:51,020:INFO:Defining folds
2025-03-20 18:37:51,020:INFO:Declaring metric variables
2025-03-20 18:37:51,022:INFO:Importing untrained model
2025-03-20 18:37:51,022:INFO:Declaring custom model
2025-03-20 18:37:51,023:INFO:Ridge Regression Imported successfully
2025-03-20 18:37:51,027:INFO:Starting cross validation
2025-03-20 18:37:51,028:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:51,091:INFO:Calculating mean and std
2025-03-20 18:37:51,091:INFO:Creating metrics dataframe
2025-03-20 18:37:51,093:INFO:Uploading results into container
2025-03-20 18:37:51,093:INFO:Uploading model into container now
2025-03-20 18:37:51,093:INFO:_master_model_container: 32
2025-03-20 18:37:51,093:INFO:_display_container: 12
2025-03-20 18:37:51,093:INFO:Ridge(alpha=0.15837846234533687, random_state=888)
2025-03-20 18:37:51,093:INFO:create_model() successfully completed......................................
2025-03-20 18:37:51,150:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:51,150:INFO:Creating metrics dataframe
2025-03-20 18:37:51,155:INFO:Initializing custom model Light Gradient Boosting Machine
2025-03-20 18:37:51,155:INFO:Total runtime is 0.01167993148167928 minutes
2025-03-20 18:37:51,156:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:51,157:INFO:Initializing create_model()
2025-03-20 18:37:51,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6E8901F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:51,157:INFO:Checking exceptions
2025-03-20 18:37:51,157:INFO:Importing libraries
2025-03-20 18:37:51,157:INFO:Copying training dataset
2025-03-20 18:37:51,159:INFO:Defining folds
2025-03-20 18:37:51,159:INFO:Declaring metric variables
2025-03-20 18:37:51,161:INFO:Importing untrained model
2025-03-20 18:37:51,161:INFO:Declaring custom model
2025-03-20 18:37:51,163:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:37:51,166:INFO:Starting cross validation
2025-03-20 18:37:51,166:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:51,414:INFO:Calculating mean and std
2025-03-20 18:37:51,415:INFO:Creating metrics dataframe
2025-03-20 18:37:51,417:INFO:Uploading results into container
2025-03-20 18:37:51,417:INFO:Uploading model into container now
2025-03-20 18:37:51,417:INFO:_master_model_container: 33
2025-03-20 18:37:51,417:INFO:_display_container: 12
2025-03-20 18:37:51,418:INFO:LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07)
2025-03-20 18:37:51,418:INFO:create_model() successfully completed......................................
2025-03-20 18:37:51,478:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:51,479:INFO:Creating metrics dataframe
2025-03-20 18:37:51,485:INFO:Initializing custom model Voting Regressor
2025-03-20 18:37:51,485:INFO:Total runtime is 0.017184638977050783 minutes
2025-03-20 18:37:51,488:INFO:SubProcess create_model() called ==================================
2025-03-20 18:37:51,493:INFO:Initializing create_model()
2025-03-20 18:37:51,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E6E8901F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:51,493:INFO:Checking exceptions
2025-03-20 18:37:51,493:INFO:Importing libraries
2025-03-20 18:37:51,493:INFO:Copying training dataset
2025-03-20 18:37:51,497:INFO:Defining folds
2025-03-20 18:37:51,497:INFO:Declaring metric variables
2025-03-20 18:37:51,499:INFO:Importing untrained model
2025-03-20 18:37:51,500:INFO:Declaring custom model
2025-03-20 18:37:51,504:INFO:Voting Regressor Imported successfully
2025-03-20 18:37:51,507:INFO:Starting cross validation
2025-03-20 18:37:51,508:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:37:51,999:INFO:Calculating mean and std
2025-03-20 18:37:52,000:INFO:Creating metrics dataframe
2025-03-20 18:37:52,003:INFO:Uploading results into container
2025-03-20 18:37:52,003:INFO:Uploading model into container now
2025-03-20 18:37:52,003:INFO:_master_model_container: 34
2025-03-20 18:37:52,003:INFO:_display_container: 12
2025-03-20 18:37:52,008:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)
2025-03-20 18:37:52,008:INFO:create_model() successfully completed......................................
2025-03-20 18:37:52,070:INFO:SubProcess create_model() end ==================================
2025-03-20 18:37:52,071:INFO:Creating metrics dataframe
2025-03-20 18:37:52,088:INFO:Initializing create_model()
2025-03-20 18:37:52,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:52,088:INFO:Checking exceptions
2025-03-20 18:37:52,089:INFO:Importing libraries
2025-03-20 18:37:52,089:INFO:Copying training dataset
2025-03-20 18:37:52,092:INFO:Defining folds
2025-03-20 18:37:52,092:INFO:Declaring metric variables
2025-03-20 18:37:52,092:INFO:Importing untrained model
2025-03-20 18:37:52,092:INFO:Declaring custom model
2025-03-20 18:37:52,093:INFO:Voting Regressor Imported successfully
2025-03-20 18:37:52,094:INFO:Cross validation set to False
2025-03-20 18:37:52,094:INFO:Fitting Model
2025-03-20 18:37:52,496:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)
2025-03-20 18:37:52,496:INFO:create_model() successfully completed......................................
2025-03-20 18:37:52,558:INFO:Creating Dashboard logs
2025-03-20 18:37:52,560:INFO:Model: Voting Regressor
2025-03-20 18:37:52,579:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), 'Ridge Regression': Ridge(alpha=0.15837846234533687, random_state=888), 'Bayesian Ridge__alpha_1': 2.7545472961420178e-09, 'Bayesian Ridge__alpha_2': 4.066609119105379e-06, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.990445553962634, 'Bayesian Ridge__lambda_2': 0.0035328966263404715, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.22464638711727086, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': 0.5625928552305157, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.09998994563739698, 'Gradient Boosting Regressor__min_samples_leaf': 2, 'Gradient Boosting Regressor__min_samples_split': 5, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 256, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.4966749921104084, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.15837846234533687, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.023440572956879818, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 11, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.8740177905873542, 'Light Gradient Boosting Machine__n_estimators': 174, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 6, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 6.152517400724381e-05, 'Light Gradient Boosting Machine__reg_lambda': 8.192347594113466e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.7894782239999676, 'Light Gradient Boosting Machine__bagging_fraction': 0.6323468745016072, 'Light Gradient Boosting Machine__bagging_freq': 6}
2025-03-20 18:37:52,820:INFO:Initializing predict_model()
2025-03-20 18:37:52,820:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016E6FC43AF0>)
2025-03-20 18:37:52,820:INFO:Checking exceptions
2025-03-20 18:37:52,820:INFO:Preloading libraries
2025-03-20 18:37:52,989:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:52,989:INFO:Creating Dashboard logs
2025-03-20 18:37:52,992:INFO:Model: Bayesian Ridge
2025-03-20 18:37:53,014:INFO:Logged params: {'alpha_1': 2.7545472961420178e-09, 'alpha_2': 4.066609119105379e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.990445553962634, 'lambda_2': 0.0035328966263404715, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:37:53,250:ERROR:_log_model() for BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:53,251:INFO:Creating Dashboard logs
2025-03-20 18:37:53,252:INFO:Model: Ridge Regression
2025-03-20 18:37:53,269:INFO:Logged params: {'alpha': 0.15837846234533687, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:37:53,497:ERROR:_log_model() for Ridge(alpha=0.15837846234533687, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:53,497:INFO:Creating Dashboard logs
2025-03-20 18:37:53,499:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:37:53,515:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.22464638711727086, 'loss': 'squared_error', 'max_depth': 3, 'max_features': 0.5625928552305157, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.09998994563739698, 'min_samples_leaf': 2, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 256, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.4966749921104084, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:37:53,744:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:53,744:INFO:Creating Dashboard logs
2025-03-20 18:37:53,746:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:37:53,761:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.023440572956879818, 'max_depth': -1, 'min_child_samples': 11, 'min_child_weight': 0.001, 'min_split_gain': 0.8740177905873542, 'n_estimators': 174, 'n_jobs': -1, 'num_leaves': 6, 'objective': None, 'random_state': 888, 'reg_alpha': 6.152517400724381e-05, 'reg_lambda': 8.192347594113466e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7894782239999676, 'bagging_fraction': 0.6323468745016072, 'bagging_freq': 6}
2025-03-20 18:37:53,994:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:54,001:INFO:_master_model_container: 34
2025-03-20 18:37:54,001:INFO:_display_container: 12
2025-03-20 18:37:54,004:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)
2025-03-20 18:37:54,004:INFO:compare_models() successfully completed......................................
2025-03-20 18:37:54,093:INFO:Initializing finalize_model()
2025-03-20 18:37:54,093:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:37:54,093:INFO:Finalizing BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715)
2025-03-20 18:37:54,095:INFO:Initializing create_model()
2025-03-20 18:37:54,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:54,095:INFO:Checking exceptions
2025-03-20 18:37:54,096:INFO:Importing libraries
2025-03-20 18:37:54,096:INFO:Copying training dataset
2025-03-20 18:37:54,096:INFO:Defining folds
2025-03-20 18:37:54,096:INFO:Declaring metric variables
2025-03-20 18:37:54,097:INFO:Importing untrained model
2025-03-20 18:37:54,097:INFO:Declaring custom model
2025-03-20 18:37:54,097:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:37:54,097:INFO:Cross validation set to False
2025-03-20 18:37:54,098:INFO:Fitting Model
2025-03-20 18:37:54,149:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=2.7545472961420178e-09,
                               alpha_2=4.066609119105379e-06,
                               lambda_1=0.990445553962634,
                               lambda_2=0.0035328966263404715))])
2025-03-20 18:37:54,149:INFO:create_model() successfully completed......................................
2025-03-20 18:37:54,207:INFO:Creating Dashboard logs
2025-03-20 18:37:54,207:INFO:Model: Bayesian Ridge
2025-03-20 18:37:54,222:INFO:Logged params: {'alpha_1': 2.7545472961420178e-09, 'alpha_2': 4.066609119105379e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.990445553962634, 'lambda_2': 0.0035328966263404715, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:37:54,457:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=2.7545472961420178e-09,
                               alpha_2=4.066609119105379e-06,
                               lambda_1=0.990445553962634,
                               lambda_2=0.0035328966263404715))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:54,457:INFO:_master_model_container: 34
2025-03-20 18:37:54,457:INFO:_display_container: 12
2025-03-20 18:37:54,462:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=2.7545472961420178e-09,
                               alpha_2=4.066609119105379e-06,
                               lambda_1=0.990445553962634,
                               lambda_2=0.0035328966263404715))])
2025-03-20 18:37:54,462:INFO:finalize_model() successfully completed......................................
2025-03-20 18:37:54,529:INFO:Initializing save_model()
2025-03-20 18:37:54,529:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=2.7545472961420178e-09,
                               alpha_2=4.066609119105379e-06,
                               lambda_1=0.990445553962634,
                               lambda_2=0.0035328966263404715))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_183754, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:37:54,529:INFO:Adding model into prep_pipe
2025-03-20 18:37:54,529:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:37:54,533:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_183754.pkl saved in current working directory
2025-03-20 18:37:54,538:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=2.7545472961420178e-09,
                               alpha_2=4.066609119105379e-06,
                               lambda_1=0.990445553962634,
                               lambda_2=0.0035328966263404715))])
2025-03-20 18:37:54,538:INFO:save_model() successfully completed......................................
2025-03-20 18:37:54,597:INFO:Initializing finalize_model()
2025-03-20 18:37:54,597:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:37:54,597:INFO:Finalizing GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084)
2025-03-20 18:37:54,599:INFO:Initializing create_model()
2025-03-20 18:37:54,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=GradientBoostingRegressor(learning_rate=0.22464638711727086,
                          max_features=0.5625928552305157,
                          min_impurity_decrease=0.09998994563739698,
                          min_samples_leaf=2, min_samples_split=5,
                          n_estimators=256, random_state=888,
                          subsample=0.4966749921104084), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:54,599:INFO:Checking exceptions
2025-03-20 18:37:54,600:INFO:Importing libraries
2025-03-20 18:37:54,600:INFO:Copying training dataset
2025-03-20 18:37:54,600:INFO:Defining folds
2025-03-20 18:37:54,600:INFO:Declaring metric variables
2025-03-20 18:37:54,600:INFO:Importing untrained model
2025-03-20 18:37:54,600:INFO:Declaring custom model
2025-03-20 18:37:54,600:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:37:54,601:INFO:Cross validation set to False
2025-03-20 18:37:54,601:INFO:Fitting Model
2025-03-20 18:37:55,030:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                           max_features=0.5625928552305157,
                                           min_impurity_decrease=0.09998994563739698,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=256, random_state=888,
                                           subsample=0.4966749921104084))])
2025-03-20 18:37:55,030:INFO:create_model() successfully completed......................................
2025-03-20 18:37:55,086:INFO:Creating Dashboard logs
2025-03-20 18:37:55,086:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:37:55,107:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.22464638711727086, 'loss': 'squared_error', 'max_depth': 3, 'max_features': 0.5625928552305157, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.09998994563739698, 'min_samples_leaf': 2, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 256, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.4966749921104084, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:37:55,377:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                           max_features=0.5625928552305157,
                                           min_impurity_decrease=0.09998994563739698,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=256, random_state=888,
                                           subsample=0.4966749921104084))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:55,377:INFO:_master_model_container: 34
2025-03-20 18:37:55,377:INFO:_display_container: 12
2025-03-20 18:37:55,382:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                           max_features=0.5625928552305157,
                                           min_impurity_decrease=0.09998994563739698,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=256, random_state=888,
                                           subsample=0.4966749921104084))])
2025-03-20 18:37:55,382:INFO:finalize_model() successfully completed......................................
2025-03-20 18:37:55,448:INFO:Initializing save_model()
2025-03-20 18:37:55,448:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                           max_features=0.5625928552305157,
                                           min_impurity_decrease=0.09998994563739698,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=256, random_state=888,
                                           subsample=0.4966749921104084))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_183754, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:37:55,448:INFO:Adding model into prep_pipe
2025-03-20 18:37:55,448:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:37:55,455:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_183754.pkl saved in current working directory
2025-03-20 18:37:55,460:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                           max_features=0.5625928552305157,
                                           min_impurity_decrease=0.09998994563739698,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=256, random_state=888,
                                           subsample=0.4966749921104084))])
2025-03-20 18:37:55,460:INFO:save_model() successfully completed......................................
2025-03-20 18:37:55,520:INFO:Initializing finalize_model()
2025-03-20 18:37:55,520:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(alpha=0.15837846234533687, random_state=888), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:37:55,520:INFO:Finalizing Ridge(alpha=0.15837846234533687, random_state=888)
2025-03-20 18:37:55,522:INFO:Initializing create_model()
2025-03-20 18:37:55,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=Ridge(alpha=0.15837846234533687, random_state=888), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:55,522:INFO:Checking exceptions
2025-03-20 18:37:55,523:INFO:Importing libraries
2025-03-20 18:37:55,523:INFO:Copying training dataset
2025-03-20 18:37:55,523:INFO:Defining folds
2025-03-20 18:37:55,523:INFO:Declaring metric variables
2025-03-20 18:37:55,523:INFO:Importing untrained model
2025-03-20 18:37:55,523:INFO:Declaring custom model
2025-03-20 18:37:55,523:INFO:Ridge Regression Imported successfully
2025-03-20 18:37:55,524:INFO:Cross validation set to False
2025-03-20 18:37:55,524:INFO:Fitting Model
2025-03-20 18:37:55,561:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.15837846234533687, random_state=888))])
2025-03-20 18:37:55,561:INFO:create_model() successfully completed......................................
2025-03-20 18:37:55,619:INFO:Creating Dashboard logs
2025-03-20 18:37:55,620:INFO:Model: Ridge Regression
2025-03-20 18:37:55,635:INFO:Logged params: {'alpha': 0.15837846234533687, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:37:55,894:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.15837846234533687, random_state=888))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:55,894:INFO:_master_model_container: 34
2025-03-20 18:37:55,894:INFO:_display_container: 12
2025-03-20 18:37:55,898:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.15837846234533687, random_state=888))])
2025-03-20 18:37:55,898:INFO:finalize_model() successfully completed......................................
2025-03-20 18:37:55,964:INFO:Initializing save_model()
2025-03-20 18:37:55,964:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.15837846234533687, random_state=888))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\ridge_250320_183755, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:37:55,964:INFO:Adding model into prep_pipe
2025-03-20 18:37:55,964:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:37:55,967:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\ridge_250320_183755.pkl saved in current working directory
2025-03-20 18:37:55,972:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.15837846234533687, random_state=888))])
2025-03-20 18:37:55,972:INFO:save_model() successfully completed......................................
2025-03-20 18:37:56,031:INFO:Initializing finalize_model()
2025-03-20 18:37:56,031:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:37:56,031:INFO:Finalizing LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07)
2025-03-20 18:37:56,033:INFO:Initializing create_model()
2025-03-20 18:37:56,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=LGBMRegressor(bagging_fraction=0.6323468745016072, bagging_freq=6,
              feature_fraction=0.7894782239999676,
              learning_rate=0.023440572956879818, min_child_samples=11,
              min_split_gain=0.8740177905873542, n_estimators=174, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=6.152517400724381e-05,
              reg_lambda=8.192347594113466e-07), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:56,033:INFO:Checking exceptions
2025-03-20 18:37:56,034:INFO:Importing libraries
2025-03-20 18:37:56,034:INFO:Copying training dataset
2025-03-20 18:37:56,035:INFO:Defining folds
2025-03-20 18:37:56,035:INFO:Declaring metric variables
2025-03-20 18:37:56,035:INFO:Importing untrained model
2025-03-20 18:37:56,035:INFO:Declaring custom model
2025-03-20 18:37:56,035:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:37:56,036:INFO:Cross validation set to False
2025-03-20 18:37:56,036:INFO:Fitting Model
2025-03-20 18:37:56,068:INFO:[LightGBM] [Warning] feature_fraction is set=0.7894782239999676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7894782239999676
2025-03-20 18:37:56,068:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6323468745016072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6323468745016072
2025-03-20 18:37:56,068:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 18:37:56,069:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:37:56,070:INFO:[LightGBM] [Warning] feature_fraction is set=0.7894782239999676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7894782239999676
2025-03-20 18:37:56,070:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6323468745016072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6323468745016072
2025-03-20 18:37:56,070:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 18:37:56,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2025-03-20 18:37:56,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:37:56,070:INFO:[LightGBM] [Info] Total Bins 4678
2025-03-20 18:37:56,071:INFO:[LightGBM] [Info] Number of data points in the train set: 1769, number of used features: 39
2025-03-20 18:37:56,071:INFO:[LightGBM] [Info] Start training from score 15.920889
2025-03-20 18:37:56,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:37:56,132:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6323468745016072,
                               bagging_freq=6,
                               feature_fraction=0.7894782239999676,
                               learning_rate=0.023440572956879818,
                               min_child_samples=11,
                               min_split_gain=0.8740177905873542,
                               n_estimators=174, n_jobs=-1, num_leaves=6,
                               random_state=888,
                               reg_alpha=6.152517400724381e-05,
                               reg_lambda=8.192347594113466e-07))])
2025-03-20 18:37:56,132:INFO:create_model() successfully completed......................................
2025-03-20 18:37:56,227:INFO:Creating Dashboard logs
2025-03-20 18:37:56,228:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:37:56,244:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.023440572956879818, 'max_depth': -1, 'min_child_samples': 11, 'min_child_weight': 0.001, 'min_split_gain': 0.8740177905873542, 'n_estimators': 174, 'n_jobs': -1, 'num_leaves': 6, 'objective': None, 'random_state': 888, 'reg_alpha': 6.152517400724381e-05, 'reg_lambda': 8.192347594113466e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7894782239999676, 'bagging_fraction': 0.6323468745016072, 'bagging_freq': 6}
2025-03-20 18:37:56,526:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6323468745016072,
                               bagging_freq=6,
                               feature_fraction=0.7894782239999676,
                               learning_rate=0.023440572956879818,
                               min_child_samples=11,
                               min_split_gain=0.8740177905873542,
                               n_estimators=174, n_jobs=-1, num_leaves=6,
                               random_state=888,
                               reg_alpha=6.152517400724381e-05,
                               reg_lambda=8.192347594113466e-07))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:56,526:INFO:_master_model_container: 34
2025-03-20 18:37:56,526:INFO:_display_container: 12
2025-03-20 18:37:56,533:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6323468745016072,
                               bagging_freq=6,
                               feature_fraction=0.7894782239999676,
                               learning_rate=0.023440572956879818,
                               min_child_samples=11,
                               min_split_gain=0.8740177905873542,
                               n_estimators=174, n_jobs=-1, num_leaves=6,
                               random_state=888,
                               reg_alpha=6.152517400724381e-05,
                               reg_lambda=8.192347594113466e-07))])
2025-03-20 18:37:56,533:INFO:finalize_model() successfully completed......................................
2025-03-20 18:37:56,612:INFO:Initializing save_model()
2025-03-20 18:37:56,612:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6323468745016072,
                               bagging_freq=6,
                               feature_fraction=0.7894782239999676,
                               learning_rate=0.023440572956879818,
                               min_child_samples=11,
                               min_split_gain=0.8740177905873542,
                               n_estimators=174, n_jobs=-1, num_leaves=6,
                               random_state=888,
                               reg_alpha=6.152517400724381e-05,
                               reg_lambda=8.192347594113466e-07))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_183756, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:37:56,612:INFO:Adding model into prep_pipe
2025-03-20 18:37:56,612:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:37:56,623:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_183756.pkl saved in current working directory
2025-03-20 18:37:56,630:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6323468745016072,
                               bagging_freq=6,
                               feature_fraction=0.7894782239999676,
                               learning_rate=0.023440572956879818,
                               min_child_samples=11,
                               min_split_gain=0.8740177905873542,
                               n_estimators=174, n_jobs=-1, num_leaves=6,
                               random_state=888,
                               reg_alpha=6.152517400724381e-05,
                               reg_lambda=8.192347594113466e-07))])
2025-03-20 18:37:56,630:INFO:save_model() successfully completed......................................
2025-03-20 18:37:56,699:INFO:Initializing finalize_model()
2025-03-20 18:37:56,699:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:37:56,704:INFO:Finalizing VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1)
2025-03-20 18:37:56,711:INFO:Initializing create_model()
2025-03-20 18:37:56,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016E7FE15760>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=2.7545472961420178e-09,
                                           alpha_2=4.066609119105379e-06,
                                           lambda_1=0.990445553962634,
                                           lambda_2=0.0035328966263404715)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.22464638711727086,
                                                       max_features=0.5625928552305157,
                                                       min_impurity_decrease=0.09998994563739698,
                                                       min_sam...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.6323468745016072,
                                           bagging_freq=6,
                                           feature_fraction=0.7894782239999676,
                                           learning_rate=0.023440572956879818,
                                           min_child_samples=11,
                                           min_split_gain=0.8740177905873542,
                                           n_estimators=174, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=6.152517400724381e-05,
                                           reg_lambda=8.192347594113466e-07))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:37:56,711:INFO:Checking exceptions
2025-03-20 18:37:56,712:INFO:Importing libraries
2025-03-20 18:37:56,712:INFO:Copying training dataset
2025-03-20 18:37:56,712:INFO:Defining folds
2025-03-20 18:37:56,712:INFO:Declaring metric variables
2025-03-20 18:37:56,712:INFO:Importing untrained model
2025-03-20 18:37:56,712:INFO:Declaring custom model
2025-03-20 18:37:56,713:INFO:Voting Regressor Imported successfully
2025-03-20 18:37:56,714:INFO:Cross validation set to False
2025-03-20 18:37:56,714:INFO:Fitting Model
2025-03-20 18:37:57,201:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.6323468745016072,
                                                            bagging_freq=6,
                                                            feature_fraction=0.7894782239999676,
                                                            learning_rate=0.023440572956879818,
                                                            min_child_samples=11,
                                                            min_split_gain=0.8740177905873542,
                                                            n_estimators=174,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=6.152517400724381e-05,
                                                            reg_lambda=8.192347594113466e-07))],
                                 n_jobs=-1))])
2025-03-20 18:37:57,201:INFO:create_model() successfully completed......................................
2025-03-20 18:37:57,261:INFO:Creating Dashboard logs
2025-03-20 18:37:57,261:INFO:Model: Voting Regressor
2025-03-20 18:37:57,279:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=2.7545472961420178e-09, alpha_2=4.066609119105379e-06,
              lambda_1=0.990445553962634, lambda_2=0.0035328966263404715), 'Ridge Regression': Ridge(alpha=0.15837846234533687, random_state=888), 'Bayesian Ridge__alpha_1': 2.7545472961420178e-09, 'Bayesian Ridge__alpha_2': 4.066609119105379e-06, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.990445553962634, 'Bayesian Ridge__lambda_2': 0.0035328966263404715, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.22464638711727086, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': 0.5625928552305157, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.09998994563739698, 'Gradient Boosting Regressor__min_samples_leaf': 2, 'Gradient Boosting Regressor__min_samples_split': 5, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 256, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.4966749921104084, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.15837846234533687, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.023440572956879818, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 11, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.8740177905873542, 'Light Gradient Boosting Machine__n_estimators': 174, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 6, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 6.152517400724381e-05, 'Light Gradient Boosting Machine__reg_lambda': 8.192347594113466e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.7894782239999676, 'Light Gradient Boosting Machine__bagging_fraction': 0.6323468745016072, 'Light Gradient Boosting Machine__bagging_freq': 6}
2025-03-20 18:37:57,601:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.6323468745016072,
                                                            bagging_freq=6,
                                                            feature_fraction=0.7894782239999676,
                                                            learning_rate=0.023440572956879818,
                                                            min_child_samples=11,
                                                            min_split_gain=0.8740177905873542,
                                                            n_estimators=174,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=6.152517400724381e-05,
                                                            reg_lambda=8.192347594113466e-07))],
                                 n_jobs=-1))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:37:57,602:INFO:_master_model_container: 34
2025-03-20 18:37:57,602:INFO:_display_container: 12
2025-03-20 18:37:57,619:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.6323468745016072,
                                                            bagging_freq=6,
                                                            feature_fraction=0.7894782239999676,
                                                            learning_rate=0.023440572956879818,
                                                            min_child_samples=11,
                                                            min_split_gain=0.8740177905873542,
                                                            n_estimators=174,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=6.152517400724381e-05,
                                                            reg_lambda=8.192347594113466e-07))],
                                 n_jobs=-1))])
2025-03-20 18:37:57,619:INFO:finalize_model() successfully completed......................................
2025-03-20 18:37:57,698:INFO:Initializing save_model()
2025-03-20 18:37:57,698:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.6323468745016072,
                                                            bagging_freq=6,
                                                            feature_fraction=0.7894782239999676,
                                                            learning_rate=0.023440572956879818,
                                                            min_child_samples=11,
                                                            min_split_gain=0.8740177905873542,
                                                            n_estimators=174,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=6.152517400724381e-05,
                                                            reg_lambda=8.192347594113466e-07))],
                                 n_jobs=-1))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_183756, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:37:57,698:INFO:Adding model into prep_pipe
2025-03-20 18:37:57,698:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:37:57,714:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_183756.pkl saved in current working directory
2025-03-20 18:37:57,734:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.6323468745016072,
                                                            bagging_freq=6,
                                                            feature_fraction=0.7894782239999676,
                                                            learning_rate=0.023440572956879818,
                                                            min_child_samples=11,
                                                            min_split_gain=0.8740177905873542,
                                                            n_estimators=174,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=6.152517400724381e-05,
                                                            reg_lambda=8.192347594113466e-07))],
                                 n_jobs=-1))])
2025-03-20 18:37:57,735:INFO:save_model() successfully completed......................................
2025-03-20 18:39:10,429:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:39:10,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:39:10,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:39:10,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:39:10,554:INFO:Initializing load_model()
2025-03-20 18:39:10,554:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_183756, platform=None, authentication=None, verbose=True)
2025-03-20 18:39:11,098:INFO:Initializing predict_model()
2025-03-20 18:39:11,098:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000012790072C10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.6323468745016072,
                                                            bagging_freq=6,
                                                            feature_fraction=0.7894782239999676,
                                                            learning_rate=0.023440572956879818,
                                                            min_child_samples=11,
                                                            min_split_gain=0.8740177905873542,
                                                            n_estimators=174,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=6.152517400724381e-05,
                                                            reg_lambda=8.192347594113466e-07))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001278F2FBAF0>)
2025-03-20 18:39:11,098:INFO:Checking exceptions
2025-03-20 18:39:11,098:INFO:Preloading libraries
2025-03-20 18:39:11,098:INFO:Set up data.
2025-03-20 18:39:11,108:INFO:Set up index.
2025-03-20 18:39:11,181:INFO:Initializing load_model()
2025-03-20 18:39:11,181:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_183756, platform=None, authentication=None, verbose=True)
2025-03-20 18:39:11,214:INFO:Initializing predict_model()
2025-03-20 18:39:11,214:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000012790039FD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.6323468745016072,
                                                            bagging_freq=6,
                                                            feature_fraction=0.7894782239999676,
                                                            learning_rate=0.023440572956879818,
                                                            min_child_samples=11,
                                                            min_split_gain=0.8740177905873542,
                                                            n_estimators=174,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=6.152517400724381e-05,
                                                            reg_lambda=8.192347594113466e-07))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001278F2FBAF0>)
2025-03-20 18:39:11,214:INFO:Checking exceptions
2025-03-20 18:39:11,214:INFO:Preloading libraries
2025-03-20 18:39:11,214:INFO:Set up data.
2025-03-20 18:39:11,223:INFO:Set up index.
2025-03-20 18:39:14,606:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:39:16,662:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:42:14,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:42:14,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:42:14,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:42:14,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:42:15,151:INFO:PyCaret RegressionExperiment
2025-03-20 18:42:15,151:INFO:Logging name: reg-default-name
2025-03-20 18:42:15,151:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 18:42:15,151:INFO:version 3.2.0
2025-03-20 18:42:15,151:INFO:Initializing setup()
2025-03-20 18:42:15,151:INFO:self.USI: 9722
2025-03-20 18:42:15,151:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'data', 'fold_groups_param', 'exp_id', 'html_param', 'X', '_available_plots', 'target_param', 'fold_generator', 'logging_param', 'log_plots_param', 'seed', 'X_test', 'fold_shuffle_param', 'gpu_param', 'n_jobs_param', 'y_train', 'X_train', 'pipeline', 'y', 'exp_name_log', 'y_test', 'USI', 'memory', 'transform_target_param', '_ml_usecase'}
2025-03-20 18:42:15,151:INFO:Checking environment
2025-03-20 18:42:15,151:INFO:python_version: 3.8.20
2025-03-20 18:42:15,151:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 18:42:15,151:INFO:machine: AMD64
2025-03-20 18:42:15,151:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 18:42:15,158:INFO:Memory: svmem(total=68447973376, available=39912259584, percent=41.7, used=28535713792, free=39912259584)
2025-03-20 18:42:15,158:INFO:Physical Core: 24
2025-03-20 18:42:15,158:INFO:Logical Core: 32
2025-03-20 18:42:15,158:INFO:Checking libraries
2025-03-20 18:42:15,158:INFO:System:
2025-03-20 18:42:15,158:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 18:42:15,158:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 18:42:15,158:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 18:42:15,158:INFO:PyCaret required dependencies:
2025-03-20 18:42:15,679:INFO:                 pip: 24.2
2025-03-20 18:42:15,679:INFO:          setuptools: 75.1.0
2025-03-20 18:42:15,679:INFO:             pycaret: 3.2.0
2025-03-20 18:42:15,679:INFO:             IPython: 8.12.3
2025-03-20 18:42:15,680:INFO:          ipywidgets: 8.1.5
2025-03-20 18:42:15,680:INFO:                tqdm: 4.67.1
2025-03-20 18:42:15,680:INFO:               numpy: 1.24.4
2025-03-20 18:42:15,680:INFO:              pandas: 1.5.3
2025-03-20 18:42:15,680:INFO:              jinja2: 3.1.4
2025-03-20 18:42:15,680:INFO:               scipy: 1.10.1
2025-03-20 18:42:15,680:INFO:              joblib: 1.3.2
2025-03-20 18:42:15,680:INFO:             sklearn: 1.2.2
2025-03-20 18:42:15,680:INFO:                pyod: 2.0.2
2025-03-20 18:42:15,680:INFO:            imblearn: 0.12.4
2025-03-20 18:42:15,680:INFO:   category_encoders: 2.6.4
2025-03-20 18:42:15,680:INFO:            lightgbm: 4.5.0
2025-03-20 18:42:15,680:INFO:               numba: 0.58.1
2025-03-20 18:42:15,680:INFO:            requests: 2.32.3
2025-03-20 18:42:15,680:INFO:          matplotlib: 3.6.0
2025-03-20 18:42:15,680:INFO:          scikitplot: 0.3.7
2025-03-20 18:42:15,680:INFO:         yellowbrick: 1.5
2025-03-20 18:42:15,680:INFO:              plotly: 5.24.1
2025-03-20 18:42:15,680:INFO:    plotly-resampler: Not installed
2025-03-20 18:42:15,680:INFO:             kaleido: 0.2.1
2025-03-20 18:42:15,680:INFO:           schemdraw: 0.15
2025-03-20 18:42:15,680:INFO:         statsmodels: 0.14.1
2025-03-20 18:42:15,680:INFO:              sktime: 0.21.1
2025-03-20 18:42:15,680:INFO:               tbats: 1.1.3
2025-03-20 18:42:15,680:INFO:            pmdarima: 2.0.4
2025-03-20 18:42:15,680:INFO:              psutil: 6.1.0
2025-03-20 18:42:15,680:INFO:          markupsafe: 2.1.5
2025-03-20 18:42:15,680:INFO:             pickle5: Not installed
2025-03-20 18:42:15,680:INFO:         cloudpickle: 2.2.1
2025-03-20 18:42:15,680:INFO:         deprecation: 2.1.0
2025-03-20 18:42:15,680:INFO:              xxhash: 3.5.0
2025-03-20 18:42:15,680:INFO:           wurlitzer: Not installed
2025-03-20 18:42:15,680:INFO:PyCaret optional dependencies:
2025-03-20 18:42:16,998:INFO:                shap: 0.44.1
2025-03-20 18:42:16,998:INFO:           interpret: 0.6.6
2025-03-20 18:42:16,998:INFO:                umap: 0.5.7
2025-03-20 18:42:16,998:INFO:     ydata_profiling: 4.6.0
2025-03-20 18:42:16,999:INFO:  explainerdashboard: 0.4.7
2025-03-20 18:42:16,999:INFO:             autoviz: Not installed
2025-03-20 18:42:16,999:INFO:           fairlearn: 0.7.0
2025-03-20 18:42:16,999:INFO:          deepchecks: Not installed
2025-03-20 18:42:16,999:INFO:             xgboost: 2.1.3
2025-03-20 18:42:16,999:INFO:            catboost: 1.2.7
2025-03-20 18:42:16,999:INFO:              kmodes: 0.12.2
2025-03-20 18:42:16,999:INFO:             mlxtend: 0.23.1
2025-03-20 18:42:16,999:INFO:       statsforecast: 1.5.0
2025-03-20 18:42:16,999:INFO:        tune_sklearn: 0.5.0
2025-03-20 18:42:16,999:INFO:                 ray: 2.10.0
2025-03-20 18:42:16,999:INFO:            hyperopt: 0.2.7
2025-03-20 18:42:16,999:INFO:              optuna: 4.1.0
2025-03-20 18:42:16,999:INFO:               skopt: 0.10.2
2025-03-20 18:42:16,999:INFO:              mlflow: 1.30.1
2025-03-20 18:42:16,999:INFO:              gradio: 3.50.2
2025-03-20 18:42:16,999:INFO:             fastapi: 0.115.5
2025-03-20 18:42:16,999:INFO:             uvicorn: 0.32.1
2025-03-20 18:42:16,999:INFO:              m2cgen: 0.10.0
2025-03-20 18:42:16,999:INFO:           evidently: 0.2.8
2025-03-20 18:42:16,999:INFO:               fugue: 0.8.6
2025-03-20 18:42:16,999:INFO:           streamlit: Not installed
2025-03-20 18:42:16,999:INFO:             prophet: Not installed
2025-03-20 18:42:16,999:INFO:None
2025-03-20 18:42:16,999:INFO:Set up data.
2025-03-20 18:42:17,004:INFO:Set up folding strategy.
2025-03-20 18:42:17,004:INFO:Set up train/test split.
2025-03-20 18:42:17,004:INFO:Set up data.
2025-03-20 18:42:17,009:INFO:Set up index.
2025-03-20 18:42:17,009:INFO:Assigning column types.
2025-03-20 18:42:17,011:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 18:42:17,011:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,013:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,015:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,040:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,059:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,060:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,071:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,073:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,075:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,118:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,119:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,120:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 18:42:17,122:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,124:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,167:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,168:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,171:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,216:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,217:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,217:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 18:42:17,221:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,264:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,266:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,313:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,314:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,315:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 18:42:17,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,361:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,361:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,362:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,390:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,409:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,411:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,412:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 18:42:17,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,459:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,460:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:42:17,507:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,508:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,508:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 18:42:17,555:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,556:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,604:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,605:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,606:INFO:Preparing preprocessing pipeline...
2025-03-20 18:42:17,606:INFO:Set up simple imputation.
2025-03-20 18:42:17,607:INFO:Set up encoding of categorical features.
2025-03-20 18:42:17,607:INFO:Set up feature normalization.
2025-03-20 18:42:17,608:INFO:Set up column name cleaning.
2025-03-20 18:42:17,655:INFO:Finished creating preprocessing pipeline.
2025-03-20 18:42:17,659:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:42:17,659:INFO:Creating final display dataframe.
2025-03-20 18:42:17,784:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              9722
2025-03-20 18:42:17,837:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,839:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,888:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:17,889:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:42:17,890:INFO:Logging experiment in loggers
2025-03-20 18:42:18,031:INFO:SubProcess save_model() called ==================================
2025-03-20 18:42:18,039:INFO:Initializing save_model()
2025-03-20 18:42:18,039:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmp_uhmprrv\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:42:18,039:INFO:Adding model into prep_pipe
2025-03-20 18:42:18,039:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:42:18,043:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmp_uhmprrv\Transformation Pipeline.pkl saved in current working directory
2025-03-20 18:42:18,046:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:42:18,046:INFO:save_model() successfully completed......................................
2025-03-20 18:42:18,101:INFO:SubProcess save_model() end ==================================
2025-03-20 18:42:18,105:INFO:setup() successfully completed in 2.74s...............
2025-03-20 18:42:18,105:INFO:Initializing compare_models()
2025-03-20 18:42:18,105:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 18:42:18,105:INFO:Checking exceptions
2025-03-20 18:42:18,106:INFO:Preparing display monitor
2025-03-20 18:42:18,119:INFO:Initializing Linear Regression
2025-03-20 18:42:18,119:INFO:Total runtime is 0.0 minutes
2025-03-20 18:42:18,121:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:18,121:INFO:Initializing create_model()
2025-03-20 18:42:18,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:18,121:INFO:Checking exceptions
2025-03-20 18:42:18,121:INFO:Importing libraries
2025-03-20 18:42:18,121:INFO:Copying training dataset
2025-03-20 18:42:18,123:INFO:Defining folds
2025-03-20 18:42:18,123:INFO:Declaring metric variables
2025-03-20 18:42:18,125:INFO:Importing untrained model
2025-03-20 18:42:18,127:INFO:Linear Regression Imported successfully
2025-03-20 18:42:18,131:INFO:Starting cross validation
2025-03-20 18:42:18,134:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:20,560:INFO:Calculating mean and std
2025-03-20 18:42:20,561:INFO:Creating metrics dataframe
2025-03-20 18:42:20,563:INFO:Uploading results into container
2025-03-20 18:42:20,563:INFO:Uploading model into container now
2025-03-20 18:42:20,563:INFO:_master_model_container: 1
2025-03-20 18:42:20,563:INFO:_display_container: 2
2025-03-20 18:42:20,563:INFO:LinearRegression(n_jobs=-1)
2025-03-20 18:42:20,563:INFO:create_model() successfully completed......................................
2025-03-20 18:42:20,620:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:20,621:INFO:Creating metrics dataframe
2025-03-20 18:42:20,625:INFO:Initializing Lasso Regression
2025-03-20 18:42:20,625:INFO:Total runtime is 0.04176961183547974 minutes
2025-03-20 18:42:20,626:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:20,626:INFO:Initializing create_model()
2025-03-20 18:42:20,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:20,626:INFO:Checking exceptions
2025-03-20 18:42:20,626:INFO:Importing libraries
2025-03-20 18:42:20,626:INFO:Copying training dataset
2025-03-20 18:42:20,628:INFO:Defining folds
2025-03-20 18:42:20,628:INFO:Declaring metric variables
2025-03-20 18:42:20,630:INFO:Importing untrained model
2025-03-20 18:42:20,631:INFO:Lasso Regression Imported successfully
2025-03-20 18:42:20,634:INFO:Starting cross validation
2025-03-20 18:42:20,635:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:22,623:INFO:Calculating mean and std
2025-03-20 18:42:22,624:INFO:Creating metrics dataframe
2025-03-20 18:42:22,626:INFO:Uploading results into container
2025-03-20 18:42:22,626:INFO:Uploading model into container now
2025-03-20 18:42:22,627:INFO:_master_model_container: 2
2025-03-20 18:42:22,627:INFO:_display_container: 2
2025-03-20 18:42:22,627:INFO:Lasso(random_state=888)
2025-03-20 18:42:22,627:INFO:create_model() successfully completed......................................
2025-03-20 18:42:22,691:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:22,691:INFO:Creating metrics dataframe
2025-03-20 18:42:22,696:INFO:Initializing Ridge Regression
2025-03-20 18:42:22,696:INFO:Total runtime is 0.07627962430318197 minutes
2025-03-20 18:42:22,697:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:22,698:INFO:Initializing create_model()
2025-03-20 18:42:22,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:22,698:INFO:Checking exceptions
2025-03-20 18:42:22,698:INFO:Importing libraries
2025-03-20 18:42:22,698:INFO:Copying training dataset
2025-03-20 18:42:22,700:INFO:Defining folds
2025-03-20 18:42:22,700:INFO:Declaring metric variables
2025-03-20 18:42:22,702:INFO:Importing untrained model
2025-03-20 18:42:22,703:INFO:Ridge Regression Imported successfully
2025-03-20 18:42:22,705:INFO:Starting cross validation
2025-03-20 18:42:22,706:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:24,687:INFO:Calculating mean and std
2025-03-20 18:42:24,688:INFO:Creating metrics dataframe
2025-03-20 18:42:24,689:INFO:Uploading results into container
2025-03-20 18:42:24,690:INFO:Uploading model into container now
2025-03-20 18:42:24,690:INFO:_master_model_container: 3
2025-03-20 18:42:24,690:INFO:_display_container: 2
2025-03-20 18:42:24,691:INFO:Ridge(random_state=888)
2025-03-20 18:42:24,691:INFO:create_model() successfully completed......................................
2025-03-20 18:42:24,744:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:24,744:INFO:Creating metrics dataframe
2025-03-20 18:42:24,749:INFO:Initializing Elastic Net
2025-03-20 18:42:24,749:INFO:Total runtime is 0.11050818761189779 minutes
2025-03-20 18:42:24,751:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:24,751:INFO:Initializing create_model()
2025-03-20 18:42:24,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:24,751:INFO:Checking exceptions
2025-03-20 18:42:24,751:INFO:Importing libraries
2025-03-20 18:42:24,751:INFO:Copying training dataset
2025-03-20 18:42:24,753:INFO:Defining folds
2025-03-20 18:42:24,753:INFO:Declaring metric variables
2025-03-20 18:42:24,755:INFO:Importing untrained model
2025-03-20 18:42:24,757:INFO:Elastic Net Imported successfully
2025-03-20 18:42:24,760:INFO:Starting cross validation
2025-03-20 18:42:24,760:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:26,749:INFO:Calculating mean and std
2025-03-20 18:42:26,750:INFO:Creating metrics dataframe
2025-03-20 18:42:26,752:INFO:Uploading results into container
2025-03-20 18:42:26,752:INFO:Uploading model into container now
2025-03-20 18:42:26,752:INFO:_master_model_container: 4
2025-03-20 18:42:26,752:INFO:_display_container: 2
2025-03-20 18:42:26,753:INFO:ElasticNet(random_state=888)
2025-03-20 18:42:26,753:INFO:create_model() successfully completed......................................
2025-03-20 18:42:26,808:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:26,808:INFO:Creating metrics dataframe
2025-03-20 18:42:26,813:INFO:Initializing Least Angle Regression
2025-03-20 18:42:26,813:INFO:Total runtime is 0.14490725994110107 minutes
2025-03-20 18:42:26,815:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:26,815:INFO:Initializing create_model()
2025-03-20 18:42:26,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:26,815:INFO:Checking exceptions
2025-03-20 18:42:26,815:INFO:Importing libraries
2025-03-20 18:42:26,815:INFO:Copying training dataset
2025-03-20 18:42:26,817:INFO:Defining folds
2025-03-20 18:42:26,817:INFO:Declaring metric variables
2025-03-20 18:42:26,819:INFO:Importing untrained model
2025-03-20 18:42:26,820:INFO:Least Angle Regression Imported successfully
2025-03-20 18:42:26,823:INFO:Starting cross validation
2025-03-20 18:42:26,824:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:28,763:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,763:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,763:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,764:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.452e-02, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.567e-02, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.231e-02, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.862e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.762e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,765:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.398e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,766:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.688e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,767:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=8.145e-02, with an active set of 33 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,767:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=4.510e-02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,767:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.800e-02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,767:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.505e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,767:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.816e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,767:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.549e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:42:28,797:INFO:Calculating mean and std
2025-03-20 18:42:28,798:INFO:Creating metrics dataframe
2025-03-20 18:42:28,800:INFO:Uploading results into container
2025-03-20 18:42:28,800:INFO:Uploading model into container now
2025-03-20 18:42:28,800:INFO:_master_model_container: 5
2025-03-20 18:42:28,800:INFO:_display_container: 2
2025-03-20 18:42:28,800:INFO:Lars(random_state=888)
2025-03-20 18:42:28,801:INFO:create_model() successfully completed......................................
2025-03-20 18:42:28,855:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:28,856:INFO:Creating metrics dataframe
2025-03-20 18:42:28,860:INFO:Initializing Lasso Least Angle Regression
2025-03-20 18:42:28,860:INFO:Total runtime is 0.1790199359258016 minutes
2025-03-20 18:42:28,862:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:28,862:INFO:Initializing create_model()
2025-03-20 18:42:28,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:28,862:INFO:Checking exceptions
2025-03-20 18:42:28,862:INFO:Importing libraries
2025-03-20 18:42:28,862:INFO:Copying training dataset
2025-03-20 18:42:28,864:INFO:Defining folds
2025-03-20 18:42:28,864:INFO:Declaring metric variables
2025-03-20 18:42:28,865:INFO:Importing untrained model
2025-03-20 18:42:28,867:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 18:42:28,870:INFO:Starting cross validation
2025-03-20 18:42:28,871:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:30,829:INFO:Calculating mean and std
2025-03-20 18:42:30,831:INFO:Creating metrics dataframe
2025-03-20 18:42:30,833:INFO:Uploading results into container
2025-03-20 18:42:30,833:INFO:Uploading model into container now
2025-03-20 18:42:30,833:INFO:_master_model_container: 6
2025-03-20 18:42:30,833:INFO:_display_container: 2
2025-03-20 18:42:30,834:INFO:LassoLars(random_state=888)
2025-03-20 18:42:30,834:INFO:create_model() successfully completed......................................
2025-03-20 18:42:30,891:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:30,891:INFO:Creating metrics dataframe
2025-03-20 18:42:30,896:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 18:42:30,896:INFO:Total runtime is 0.2129587928454081 minutes
2025-03-20 18:42:30,898:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:30,898:INFO:Initializing create_model()
2025-03-20 18:42:30,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:30,898:INFO:Checking exceptions
2025-03-20 18:42:30,898:INFO:Importing libraries
2025-03-20 18:42:30,898:INFO:Copying training dataset
2025-03-20 18:42:30,900:INFO:Defining folds
2025-03-20 18:42:30,900:INFO:Declaring metric variables
2025-03-20 18:42:30,902:INFO:Importing untrained model
2025-03-20 18:42:30,903:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 18:42:30,906:INFO:Starting cross validation
2025-03-20 18:42:30,907:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:32,584:INFO:Calculating mean and std
2025-03-20 18:42:32,585:INFO:Creating metrics dataframe
2025-03-20 18:42:32,587:INFO:Uploading results into container
2025-03-20 18:42:32,587:INFO:Uploading model into container now
2025-03-20 18:42:32,588:INFO:_master_model_container: 7
2025-03-20 18:42:32,588:INFO:_display_container: 2
2025-03-20 18:42:32,588:INFO:OrthogonalMatchingPursuit()
2025-03-20 18:42:32,588:INFO:create_model() successfully completed......................................
2025-03-20 18:42:32,646:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:32,646:INFO:Creating metrics dataframe
2025-03-20 18:42:32,651:INFO:Initializing Bayesian Ridge
2025-03-20 18:42:32,652:INFO:Total runtime is 0.24221248229344686 minutes
2025-03-20 18:42:32,653:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:32,653:INFO:Initializing create_model()
2025-03-20 18:42:32,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:32,654:INFO:Checking exceptions
2025-03-20 18:42:32,654:INFO:Importing libraries
2025-03-20 18:42:32,654:INFO:Copying training dataset
2025-03-20 18:42:32,655:INFO:Defining folds
2025-03-20 18:42:32,655:INFO:Declaring metric variables
2025-03-20 18:42:32,656:INFO:Importing untrained model
2025-03-20 18:42:32,658:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:42:32,662:INFO:Starting cross validation
2025-03-20 18:42:32,662:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:32,723:INFO:Calculating mean and std
2025-03-20 18:42:32,724:INFO:Creating metrics dataframe
2025-03-20 18:42:32,726:INFO:Uploading results into container
2025-03-20 18:42:32,726:INFO:Uploading model into container now
2025-03-20 18:42:32,726:INFO:_master_model_container: 8
2025-03-20 18:42:32,727:INFO:_display_container: 2
2025-03-20 18:42:32,727:INFO:BayesianRidge()
2025-03-20 18:42:32,727:INFO:create_model() successfully completed......................................
2025-03-20 18:42:32,780:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:32,780:INFO:Creating metrics dataframe
2025-03-20 18:42:32,785:INFO:Initializing Passive Aggressive Regressor
2025-03-20 18:42:32,786:INFO:Total runtime is 0.24444931348164875 minutes
2025-03-20 18:42:32,787:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:32,787:INFO:Initializing create_model()
2025-03-20 18:42:32,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:32,787:INFO:Checking exceptions
2025-03-20 18:42:32,787:INFO:Importing libraries
2025-03-20 18:42:32,787:INFO:Copying training dataset
2025-03-20 18:42:32,789:INFO:Defining folds
2025-03-20 18:42:32,789:INFO:Declaring metric variables
2025-03-20 18:42:32,791:INFO:Importing untrained model
2025-03-20 18:42:32,793:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 18:42:32,796:INFO:Starting cross validation
2025-03-20 18:42:32,797:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:32,862:INFO:Calculating mean and std
2025-03-20 18:42:32,863:INFO:Creating metrics dataframe
2025-03-20 18:42:32,864:INFO:Uploading results into container
2025-03-20 18:42:32,865:INFO:Uploading model into container now
2025-03-20 18:42:32,865:INFO:_master_model_container: 9
2025-03-20 18:42:32,865:INFO:_display_container: 2
2025-03-20 18:42:32,865:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 18:42:32,865:INFO:create_model() successfully completed......................................
2025-03-20 18:42:32,918:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:32,918:INFO:Creating metrics dataframe
2025-03-20 18:42:32,924:INFO:Initializing Huber Regressor
2025-03-20 18:42:32,924:INFO:Total runtime is 0.24675916830698646 minutes
2025-03-20 18:42:32,926:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:32,926:INFO:Initializing create_model()
2025-03-20 18:42:32,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:32,926:INFO:Checking exceptions
2025-03-20 18:42:32,926:INFO:Importing libraries
2025-03-20 18:42:32,926:INFO:Copying training dataset
2025-03-20 18:42:32,928:INFO:Defining folds
2025-03-20 18:42:32,928:INFO:Declaring metric variables
2025-03-20 18:42:32,929:INFO:Importing untrained model
2025-03-20 18:42:32,931:INFO:Huber Regressor Imported successfully
2025-03-20 18:42:32,934:INFO:Starting cross validation
2025-03-20 18:42:32,935:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:32,976:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:42:32,980:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:42:32,991:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:42:32,992:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:42:33,000:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:42:33,016:INFO:Calculating mean and std
2025-03-20 18:42:33,016:INFO:Creating metrics dataframe
2025-03-20 18:42:33,018:INFO:Uploading results into container
2025-03-20 18:42:33,018:INFO:Uploading model into container now
2025-03-20 18:42:33,018:INFO:_master_model_container: 10
2025-03-20 18:42:33,019:INFO:_display_container: 2
2025-03-20 18:42:33,019:INFO:HuberRegressor()
2025-03-20 18:42:33,019:INFO:create_model() successfully completed......................................
2025-03-20 18:42:33,072:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:33,072:INFO:Creating metrics dataframe
2025-03-20 18:42:33,078:INFO:Initializing K Neighbors Regressor
2025-03-20 18:42:33,078:INFO:Total runtime is 0.24931699037551877 minutes
2025-03-20 18:42:33,079:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:33,080:INFO:Initializing create_model()
2025-03-20 18:42:33,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:33,080:INFO:Checking exceptions
2025-03-20 18:42:33,080:INFO:Importing libraries
2025-03-20 18:42:33,080:INFO:Copying training dataset
2025-03-20 18:42:33,081:INFO:Defining folds
2025-03-20 18:42:33,082:INFO:Declaring metric variables
2025-03-20 18:42:33,083:INFO:Importing untrained model
2025-03-20 18:42:33,085:INFO:K Neighbors Regressor Imported successfully
2025-03-20 18:42:33,089:INFO:Starting cross validation
2025-03-20 18:42:33,089:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:33,200:INFO:Calculating mean and std
2025-03-20 18:42:33,201:INFO:Creating metrics dataframe
2025-03-20 18:42:33,203:INFO:Uploading results into container
2025-03-20 18:42:33,203:INFO:Uploading model into container now
2025-03-20 18:42:33,203:INFO:_master_model_container: 11
2025-03-20 18:42:33,203:INFO:_display_container: 2
2025-03-20 18:42:33,203:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 18:42:33,203:INFO:create_model() successfully completed......................................
2025-03-20 18:42:33,260:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:33,260:INFO:Creating metrics dataframe
2025-03-20 18:42:33,266:INFO:Initializing Decision Tree Regressor
2025-03-20 18:42:33,266:INFO:Total runtime is 0.25245451529820756 minutes
2025-03-20 18:42:33,268:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:33,268:INFO:Initializing create_model()
2025-03-20 18:42:33,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:33,269:INFO:Checking exceptions
2025-03-20 18:42:33,269:INFO:Importing libraries
2025-03-20 18:42:33,269:INFO:Copying training dataset
2025-03-20 18:42:33,270:INFO:Defining folds
2025-03-20 18:42:33,271:INFO:Declaring metric variables
2025-03-20 18:42:33,272:INFO:Importing untrained model
2025-03-20 18:42:33,274:INFO:Decision Tree Regressor Imported successfully
2025-03-20 18:42:33,277:INFO:Starting cross validation
2025-03-20 18:42:33,278:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:33,355:INFO:Calculating mean and std
2025-03-20 18:42:33,355:INFO:Creating metrics dataframe
2025-03-20 18:42:33,357:INFO:Uploading results into container
2025-03-20 18:42:33,357:INFO:Uploading model into container now
2025-03-20 18:42:33,357:INFO:_master_model_container: 12
2025-03-20 18:42:33,357:INFO:_display_container: 2
2025-03-20 18:42:33,357:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 18:42:33,357:INFO:create_model() successfully completed......................................
2025-03-20 18:42:33,412:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:33,412:INFO:Creating metrics dataframe
2025-03-20 18:42:33,418:INFO:Initializing Random Forest Regressor
2025-03-20 18:42:33,418:INFO:Total runtime is 0.2549799760182698 minutes
2025-03-20 18:42:33,420:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:33,420:INFO:Initializing create_model()
2025-03-20 18:42:33,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:33,420:INFO:Checking exceptions
2025-03-20 18:42:33,420:INFO:Importing libraries
2025-03-20 18:42:33,420:INFO:Copying training dataset
2025-03-20 18:42:33,422:INFO:Defining folds
2025-03-20 18:42:33,422:INFO:Declaring metric variables
2025-03-20 18:42:33,424:INFO:Importing untrained model
2025-03-20 18:42:33,425:INFO:Random Forest Regressor Imported successfully
2025-03-20 18:42:33,428:INFO:Starting cross validation
2025-03-20 18:42:33,429:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:33,801:INFO:Calculating mean and std
2025-03-20 18:42:33,802:INFO:Creating metrics dataframe
2025-03-20 18:42:33,804:INFO:Uploading results into container
2025-03-20 18:42:33,805:INFO:Uploading model into container now
2025-03-20 18:42:33,805:INFO:_master_model_container: 13
2025-03-20 18:42:33,805:INFO:_display_container: 2
2025-03-20 18:42:33,805:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:42:33,805:INFO:create_model() successfully completed......................................
2025-03-20 18:42:33,859:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:33,860:INFO:Creating metrics dataframe
2025-03-20 18:42:33,865:INFO:Initializing Extra Trees Regressor
2025-03-20 18:42:33,865:INFO:Total runtime is 0.26243971188863113 minutes
2025-03-20 18:42:33,867:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:33,867:INFO:Initializing create_model()
2025-03-20 18:42:33,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:33,867:INFO:Checking exceptions
2025-03-20 18:42:33,867:INFO:Importing libraries
2025-03-20 18:42:33,867:INFO:Copying training dataset
2025-03-20 18:42:33,869:INFO:Defining folds
2025-03-20 18:42:33,869:INFO:Declaring metric variables
2025-03-20 18:42:33,871:INFO:Importing untrained model
2025-03-20 18:42:33,872:INFO:Extra Trees Regressor Imported successfully
2025-03-20 18:42:33,875:INFO:Starting cross validation
2025-03-20 18:42:33,876:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:34,078:INFO:Calculating mean and std
2025-03-20 18:42:34,079:INFO:Creating metrics dataframe
2025-03-20 18:42:34,081:INFO:Uploading results into container
2025-03-20 18:42:34,081:INFO:Uploading model into container now
2025-03-20 18:42:34,081:INFO:_master_model_container: 14
2025-03-20 18:42:34,081:INFO:_display_container: 2
2025-03-20 18:42:34,081:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:42:34,081:INFO:create_model() successfully completed......................................
2025-03-20 18:42:34,136:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:34,136:INFO:Creating metrics dataframe
2025-03-20 18:42:34,142:INFO:Initializing AdaBoost Regressor
2025-03-20 18:42:34,142:INFO:Total runtime is 0.2670609593391418 minutes
2025-03-20 18:42:34,144:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:34,145:INFO:Initializing create_model()
2025-03-20 18:42:34,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:34,145:INFO:Checking exceptions
2025-03-20 18:42:34,145:INFO:Importing libraries
2025-03-20 18:42:34,145:INFO:Copying training dataset
2025-03-20 18:42:34,146:INFO:Defining folds
2025-03-20 18:42:34,146:INFO:Declaring metric variables
2025-03-20 18:42:34,148:INFO:Importing untrained model
2025-03-20 18:42:34,150:INFO:AdaBoost Regressor Imported successfully
2025-03-20 18:42:34,153:INFO:Starting cross validation
2025-03-20 18:42:34,153:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:34,371:INFO:Calculating mean and std
2025-03-20 18:42:34,372:INFO:Creating metrics dataframe
2025-03-20 18:42:34,373:INFO:Uploading results into container
2025-03-20 18:42:34,374:INFO:Uploading model into container now
2025-03-20 18:42:34,374:INFO:_master_model_container: 15
2025-03-20 18:42:34,374:INFO:_display_container: 2
2025-03-20 18:42:34,374:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 18:42:34,374:INFO:create_model() successfully completed......................................
2025-03-20 18:42:34,428:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:34,428:INFO:Creating metrics dataframe
2025-03-20 18:42:34,434:INFO:Initializing Gradient Boosting Regressor
2025-03-20 18:42:34,435:INFO:Total runtime is 0.2719321886698405 minutes
2025-03-20 18:42:34,436:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:34,437:INFO:Initializing create_model()
2025-03-20 18:42:34,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:34,437:INFO:Checking exceptions
2025-03-20 18:42:34,437:INFO:Importing libraries
2025-03-20 18:42:34,437:INFO:Copying training dataset
2025-03-20 18:42:34,439:INFO:Defining folds
2025-03-20 18:42:34,439:INFO:Declaring metric variables
2025-03-20 18:42:34,440:INFO:Importing untrained model
2025-03-20 18:42:34,442:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:42:34,446:INFO:Starting cross validation
2025-03-20 18:42:34,446:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:35,033:INFO:Calculating mean and std
2025-03-20 18:42:35,034:INFO:Creating metrics dataframe
2025-03-20 18:42:35,035:INFO:Uploading results into container
2025-03-20 18:42:35,036:INFO:Uploading model into container now
2025-03-20 18:42:35,036:INFO:_master_model_container: 16
2025-03-20 18:42:35,036:INFO:_display_container: 2
2025-03-20 18:42:35,036:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:42:35,036:INFO:create_model() successfully completed......................................
2025-03-20 18:42:35,089:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:35,089:INFO:Creating metrics dataframe
2025-03-20 18:42:35,095:INFO:Initializing Extreme Gradient Boosting
2025-03-20 18:42:35,095:INFO:Total runtime is 0.2829366286595662 minutes
2025-03-20 18:42:35,096:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:35,097:INFO:Initializing create_model()
2025-03-20 18:42:35,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:35,097:INFO:Checking exceptions
2025-03-20 18:42:35,097:INFO:Importing libraries
2025-03-20 18:42:35,097:INFO:Copying training dataset
2025-03-20 18:42:35,099:INFO:Defining folds
2025-03-20 18:42:35,099:INFO:Declaring metric variables
2025-03-20 18:42:35,100:INFO:Importing untrained model
2025-03-20 18:42:35,102:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 18:42:35,105:INFO:Starting cross validation
2025-03-20 18:42:35,106:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:35,557:INFO:Calculating mean and std
2025-03-20 18:42:35,557:INFO:Creating metrics dataframe
2025-03-20 18:42:35,559:INFO:Uploading results into container
2025-03-20 18:42:35,559:INFO:Uploading model into container now
2025-03-20 18:42:35,560:INFO:_master_model_container: 17
2025-03-20 18:42:35,560:INFO:_display_container: 2
2025-03-20 18:42:35,560:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 18:42:35,560:INFO:create_model() successfully completed......................................
2025-03-20 18:42:35,617:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:35,618:INFO:Creating metrics dataframe
2025-03-20 18:42:35,625:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 18:42:35,625:INFO:Total runtime is 0.291769003868103 minutes
2025-03-20 18:42:35,627:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:35,627:INFO:Initializing create_model()
2025-03-20 18:42:35,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:35,627:INFO:Checking exceptions
2025-03-20 18:42:35,627:INFO:Importing libraries
2025-03-20 18:42:35,627:INFO:Copying training dataset
2025-03-20 18:42:35,629:INFO:Defining folds
2025-03-20 18:42:35,629:INFO:Declaring metric variables
2025-03-20 18:42:35,631:INFO:Importing untrained model
2025-03-20 18:42:35,633:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:42:35,638:INFO:Starting cross validation
2025-03-20 18:42:35,638:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:36,111:INFO:Calculating mean and std
2025-03-20 18:42:36,112:INFO:Creating metrics dataframe
2025-03-20 18:42:36,114:INFO:Uploading results into container
2025-03-20 18:42:36,114:INFO:Uploading model into container now
2025-03-20 18:42:36,115:INFO:_master_model_container: 18
2025-03-20 18:42:36,115:INFO:_display_container: 2
2025-03-20 18:42:36,115:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:42:36,115:INFO:create_model() successfully completed......................................
2025-03-20 18:42:36,175:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:36,175:INFO:Creating metrics dataframe
2025-03-20 18:42:36,184:INFO:Initializing CatBoost Regressor
2025-03-20 18:42:36,184:INFO:Total runtime is 0.3010897636413574 minutes
2025-03-20 18:42:36,186:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:36,186:INFO:Initializing create_model()
2025-03-20 18:42:36,186:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:36,186:INFO:Checking exceptions
2025-03-20 18:42:36,187:INFO:Importing libraries
2025-03-20 18:42:36,187:INFO:Copying training dataset
2025-03-20 18:42:36,189:INFO:Defining folds
2025-03-20 18:42:36,189:INFO:Declaring metric variables
2025-03-20 18:42:36,191:INFO:Importing untrained model
2025-03-20 18:42:36,193:INFO:CatBoost Regressor Imported successfully
2025-03-20 18:42:36,197:INFO:Starting cross validation
2025-03-20 18:42:36,198:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:38,543:INFO:Calculating mean and std
2025-03-20 18:42:38,544:INFO:Creating metrics dataframe
2025-03-20 18:42:38,546:INFO:Uploading results into container
2025-03-20 18:42:38,546:INFO:Uploading model into container now
2025-03-20 18:42:38,547:INFO:_master_model_container: 19
2025-03-20 18:42:38,547:INFO:_display_container: 2
2025-03-20 18:42:38,547:INFO:<catboost.core.CatBoostRegressor object at 0x0000023110E84E20>
2025-03-20 18:42:38,547:INFO:create_model() successfully completed......................................
2025-03-20 18:42:38,600:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:38,600:INFO:Creating metrics dataframe
2025-03-20 18:42:38,607:INFO:Initializing Dummy Regressor
2025-03-20 18:42:38,607:INFO:Total runtime is 0.3414734164873759 minutes
2025-03-20 18:42:38,609:INFO:SubProcess create_model() called ==================================
2025-03-20 18:42:38,609:INFO:Initializing create_model()
2025-03-20 18:42:38,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311257D520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:38,609:INFO:Checking exceptions
2025-03-20 18:42:38,609:INFO:Importing libraries
2025-03-20 18:42:38,609:INFO:Copying training dataset
2025-03-20 18:42:38,611:INFO:Defining folds
2025-03-20 18:42:38,611:INFO:Declaring metric variables
2025-03-20 18:42:38,613:INFO:Importing untrained model
2025-03-20 18:42:38,614:INFO:Dummy Regressor Imported successfully
2025-03-20 18:42:38,617:INFO:Starting cross validation
2025-03-20 18:42:38,618:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:42:38,697:INFO:Calculating mean and std
2025-03-20 18:42:38,698:INFO:Creating metrics dataframe
2025-03-20 18:42:38,700:INFO:Uploading results into container
2025-03-20 18:42:38,701:INFO:Uploading model into container now
2025-03-20 18:42:38,701:INFO:_master_model_container: 20
2025-03-20 18:42:38,701:INFO:_display_container: 2
2025-03-20 18:42:38,701:INFO:DummyRegressor()
2025-03-20 18:42:38,701:INFO:create_model() successfully completed......................................
2025-03-20 18:42:38,753:INFO:SubProcess create_model() end ==================================
2025-03-20 18:42:38,753:INFO:Creating metrics dataframe
2025-03-20 18:42:38,764:INFO:Initializing create_model()
2025-03-20 18:42:38,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:38,764:INFO:Checking exceptions
2025-03-20 18:42:38,765:INFO:Importing libraries
2025-03-20 18:42:38,765:INFO:Copying training dataset
2025-03-20 18:42:38,767:INFO:Defining folds
2025-03-20 18:42:38,767:INFO:Declaring metric variables
2025-03-20 18:42:38,767:INFO:Importing untrained model
2025-03-20 18:42:38,767:INFO:Declaring custom model
2025-03-20 18:42:38,767:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:42:38,768:INFO:Cross validation set to False
2025-03-20 18:42:38,768:INFO:Fitting Model
2025-03-20 18:42:38,801:INFO:BayesianRidge()
2025-03-20 18:42:38,801:INFO:create_model() successfully completed......................................
2025-03-20 18:42:38,857:INFO:Creating Dashboard logs
2025-03-20 18:42:38,858:INFO:Model: Bayesian Ridge
2025-03-20 18:42:38,874:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:42:38,905:INFO:Initializing predict_model()
2025-03-20 18:42:38,905:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231125525E0>)
2025-03-20 18:42:38,905:INFO:Checking exceptions
2025-03-20 18:42:38,905:INFO:Preloading libraries
2025-03-20 18:42:39,034:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 18:42:39,048:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:39,051:INFO:Initializing create_model()
2025-03-20 18:42:39,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:39,051:INFO:Checking exceptions
2025-03-20 18:42:39,052:INFO:Importing libraries
2025-03-20 18:42:39,052:INFO:Copying training dataset
2025-03-20 18:42:39,054:INFO:Defining folds
2025-03-20 18:42:39,054:INFO:Declaring metric variables
2025-03-20 18:42:39,054:INFO:Importing untrained model
2025-03-20 18:42:39,054:INFO:Declaring custom model
2025-03-20 18:42:39,054:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:42:39,055:INFO:Cross validation set to False
2025-03-20 18:42:39,055:INFO:Fitting Model
2025-03-20 18:42:39,886:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:42:39,886:INFO:create_model() successfully completed......................................
2025-03-20 18:42:39,978:INFO:Creating Dashboard logs
2025-03-20 18:42:39,982:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:42:40,012:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:42:40,092:INFO:Initializing predict_model()
2025-03-20 18:42:40,092:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002311230E8B0>)
2025-03-20 18:42:40,092:INFO:Checking exceptions
2025-03-20 18:42:40,092:INFO:Preloading libraries
2025-03-20 18:42:40,326:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:40,330:INFO:Initializing create_model()
2025-03-20 18:42:40,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:40,330:INFO:Checking exceptions
2025-03-20 18:42:40,331:INFO:Importing libraries
2025-03-20 18:42:40,332:INFO:Copying training dataset
2025-03-20 18:42:40,334:INFO:Defining folds
2025-03-20 18:42:40,335:INFO:Declaring metric variables
2025-03-20 18:42:40,335:INFO:Importing untrained model
2025-03-20 18:42:40,335:INFO:Declaring custom model
2025-03-20 18:42:40,335:INFO:Ridge Regression Imported successfully
2025-03-20 18:42:40,336:INFO:Cross validation set to False
2025-03-20 18:42:40,336:INFO:Fitting Model
2025-03-20 18:42:40,382:INFO:Ridge(random_state=888)
2025-03-20 18:42:40,382:INFO:create_model() successfully completed......................................
2025-03-20 18:42:40,477:INFO:Creating Dashboard logs
2025-03-20 18:42:40,480:INFO:Model: Ridge Regression
2025-03-20 18:42:40,510:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:42:40,593:INFO:Initializing predict_model()
2025-03-20 18:42:40,593:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231122C49D0>)
2025-03-20 18:42:40,593:INFO:Checking exceptions
2025-03-20 18:42:40,593:INFO:Preloading libraries
2025-03-20 18:42:40,826:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:40,830:INFO:Initializing create_model()
2025-03-20 18:42:40,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:42:40,830:INFO:Checking exceptions
2025-03-20 18:42:40,831:INFO:Importing libraries
2025-03-20 18:42:40,831:INFO:Copying training dataset
2025-03-20 18:42:40,834:INFO:Defining folds
2025-03-20 18:42:40,834:INFO:Declaring metric variables
2025-03-20 18:42:40,834:INFO:Importing untrained model
2025-03-20 18:42:40,834:INFO:Declaring custom model
2025-03-20 18:42:40,835:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:42:40,836:INFO:Cross validation set to False
2025-03-20 18:42:40,836:INFO:Fitting Model
2025-03-20 18:42:40,887:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:42:40,888:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.
2025-03-20 18:42:40,888:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:42:40,888:INFO:[LightGBM] [Info] Total Bins 4382
2025-03-20 18:42:40,889:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 18:42:40,889:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 18:42:41,134:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:42:41,134:INFO:create_model() successfully completed......................................
2025-03-20 18:42:41,233:INFO:Creating Dashboard logs
2025-03-20 18:42:41,236:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:42:41,268:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 18:42:41,373:INFO:Initializing predict_model()
2025-03-20 18:42:41,373:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231121C7B80>)
2025-03-20 18:42:41,373:INFO:Checking exceptions
2025-03-20 18:42:41,373:INFO:Preloading libraries
2025-03-20 18:42:41,608:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:41,609:INFO:Creating Dashboard logs
2025-03-20 18:42:41,612:INFO:Model: Random Forest Regressor
2025-03-20 18:42:41,643:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 18:42:41,773:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:41,774:INFO:Creating Dashboard logs
2025-03-20 18:42:41,777:INFO:Model: Extreme Gradient Boosting
2025-03-20 18:42:41,806:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 18:42:41,971:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:41,972:INFO:Creating Dashboard logs
2025-03-20 18:42:41,975:INFO:Model: AdaBoost Regressor
2025-03-20 18:42:42,003:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 18:42:42,094:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,094:INFO:Creating Dashboard logs
2025-03-20 18:42:42,096:INFO:Model: CatBoost Regressor
2025-03-20 18:42:42,114:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 18:42:42,114:INFO:Logged params: {}
2025-03-20 18:42:42,196:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x0000023110E84E20> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,197:INFO:Creating Dashboard logs
2025-03-20 18:42:42,199:INFO:Model: Extra Trees Regressor
2025-03-20 18:42:42,214:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 18:42:42,316:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,316:INFO:Creating Dashboard logs
2025-03-20 18:42:42,318:INFO:Model: Decision Tree Regressor
2025-03-20 18:42:42,334:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 18:42:42,436:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,437:INFO:Creating Dashboard logs
2025-03-20 18:42:42,439:INFO:Model: Huber Regressor
2025-03-20 18:42:42,454:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 18:42:42,558:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,559:INFO:Creating Dashboard logs
2025-03-20 18:42:42,561:INFO:Model: Passive Aggressive Regressor
2025-03-20 18:42:42,576:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:42:42,690:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,690:INFO:Creating Dashboard logs
2025-03-20 18:42:42,692:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 18:42:42,707:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 18:42:42,822:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,823:INFO:Creating Dashboard logs
2025-03-20 18:42:42,824:INFO:Model: K Neighbors Regressor
2025-03-20 18:42:42,840:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 18:42:42,961:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:42,962:INFO:Creating Dashboard logs
2025-03-20 18:42:42,963:INFO:Model: Elastic Net
2025-03-20 18:42:42,979:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 18:42:43,105:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:43,106:INFO:Creating Dashboard logs
2025-03-20 18:42:43,108:INFO:Model: Lasso Regression
2025-03-20 18:42:43,123:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 18:42:43,260:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:43,260:INFO:Creating Dashboard logs
2025-03-20 18:42:43,262:INFO:Model: Lasso Least Angle Regression
2025-03-20 18:42:43,278:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 18:42:43,420:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:43,420:INFO:Creating Dashboard logs
2025-03-20 18:42:43,422:INFO:Model: Dummy Regressor
2025-03-20 18:42:43,438:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 18:42:43,582:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:43,582:INFO:Creating Dashboard logs
2025-03-20 18:42:43,584:INFO:Model: Linear Regression
2025-03-20 18:42:43,600:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 18:42:43,752:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:43,753:INFO:Creating Dashboard logs
2025-03-20 18:42:43,754:INFO:Model: Least Angle Regression
2025-03-20 18:42:43,771:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 18:42:43,927:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:42:43,935:INFO:_master_model_container: 20
2025-03-20 18:42:43,935:INFO:_display_container: 2
2025-03-20 18:42:43,935:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888)]
2025-03-20 18:42:43,935:INFO:compare_models() successfully completed......................................
2025-03-20 18:42:43,965:INFO:Initializing tune_model()
2025-03-20 18:42:43,965:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>)
2025-03-20 18:42:43,965:INFO:Checking exceptions
2025-03-20 18:42:43,965:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:42:44,009:INFO:Copying training dataset
2025-03-20 18:42:44,010:INFO:Checking base model
2025-03-20 18:42:44,010:INFO:Base model : Bayesian Ridge
2025-03-20 18:42:44,012:INFO:Declaring metric variables
2025-03-20 18:42:44,014:INFO:Defining Hyperparameters
2025-03-20 18:42:44,070:INFO:Tuning with n_jobs=-1
2025-03-20 18:42:44,070:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:42:44,070:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:42:44,071:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:42:44,075:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:42:44,075:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:42:44,076:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:43:08,441:INFO:best_params: {'actual_estimator__alpha_1': 0.07072750772862774, 'actual_estimator__alpha_2': 0.007919031709587356, 'actual_estimator__lambda_1': 0.973777760198768, 'actual_estimator__lambda_2': 0.0025067523515749563, 'actual_estimator__compute_score': False, 'actual_estimator__fit_intercept': True}
2025-03-20 18:43:08,445:INFO:Hyperparameter search completed
2025-03-20 18:43:08,445:INFO:SubProcess create_model() called ==================================
2025-03-20 18:43:08,446:INFO:Initializing create_model()
2025-03-20 18:43:08,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023128E899A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 0.07072750772862774, 'alpha_2': 0.007919031709587356, 'lambda_1': 0.973777760198768, 'lambda_2': 0.0025067523515749563, 'compute_score': False, 'fit_intercept': True})
2025-03-20 18:43:08,446:INFO:Checking exceptions
2025-03-20 18:43:08,446:INFO:Importing libraries
2025-03-20 18:43:08,446:INFO:Copying training dataset
2025-03-20 18:43:08,448:INFO:Defining folds
2025-03-20 18:43:08,448:INFO:Declaring metric variables
2025-03-20 18:43:08,450:INFO:Importing untrained model
2025-03-20 18:43:08,450:INFO:Declaring custom model
2025-03-20 18:43:08,451:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:43:08,454:INFO:Starting cross validation
2025-03-20 18:43:08,455:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:43:08,522:INFO:Calculating mean and std
2025-03-20 18:43:08,522:INFO:Creating metrics dataframe
2025-03-20 18:43:08,525:INFO:Finalizing model
2025-03-20 18:43:08,560:INFO:Uploading results into container
2025-03-20 18:43:08,560:INFO:Uploading model into container now
2025-03-20 18:43:08,560:INFO:_master_model_container: 21
2025-03-20 18:43:08,560:INFO:_display_container: 3
2025-03-20 18:43:08,560:INFO:BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563)
2025-03-20 18:43:08,560:INFO:create_model() successfully completed......................................
2025-03-20 18:43:08,615:INFO:SubProcess create_model() end ==================================
2025-03-20 18:43:08,615:INFO:choose_better activated
2025-03-20 18:43:08,617:INFO:SubProcess create_model() called ==================================
2025-03-20 18:43:08,617:INFO:Initializing create_model()
2025-03-20 18:43:08,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:43:08,617:INFO:Checking exceptions
2025-03-20 18:43:08,618:INFO:Importing libraries
2025-03-20 18:43:08,618:INFO:Copying training dataset
2025-03-20 18:43:08,621:INFO:Defining folds
2025-03-20 18:43:08,621:INFO:Declaring metric variables
2025-03-20 18:43:08,621:INFO:Importing untrained model
2025-03-20 18:43:08,621:INFO:Declaring custom model
2025-03-20 18:43:08,621:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:43:08,621:INFO:Starting cross validation
2025-03-20 18:43:08,622:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:43:08,691:INFO:Calculating mean and std
2025-03-20 18:43:08,692:INFO:Creating metrics dataframe
2025-03-20 18:43:08,692:INFO:Finalizing model
2025-03-20 18:43:08,727:INFO:Uploading results into container
2025-03-20 18:43:08,727:INFO:Uploading model into container now
2025-03-20 18:43:08,727:INFO:_master_model_container: 22
2025-03-20 18:43:08,727:INFO:_display_container: 4
2025-03-20 18:43:08,727:INFO:BayesianRidge()
2025-03-20 18:43:08,727:INFO:create_model() successfully completed......................................
2025-03-20 18:43:08,781:INFO:SubProcess create_model() end ==================================
2025-03-20 18:43:08,781:INFO:BayesianRidge() result for MAPE is 0.0212
2025-03-20 18:43:08,782:INFO:BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563) result for MAPE is 0.0211
2025-03-20 18:43:08,782:INFO:BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563) is best model
2025-03-20 18:43:08,782:INFO:choose_better completed
2025-03-20 18:43:08,782:INFO:Creating Dashboard logs
2025-03-20 18:43:08,784:INFO:Model: Bayesian Ridge
2025-03-20 18:43:08,800:INFO:Logged params: {'alpha_1': 0.07072750772862774, 'alpha_2': 0.007919031709587356, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.973777760198768, 'lambda_2': 0.0025067523515749563, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:43:08,958:INFO:Initializing predict_model()
2025-03-20 18:43:08,958:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231125EB820>)
2025-03-20 18:43:08,958:INFO:Checking exceptions
2025-03-20 18:43:08,958:INFO:Preloading libraries
2025-03-20 18:43:09,095:ERROR:_log_model() for BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:43:09,099:INFO:_master_model_container: 22
2025-03-20 18:43:09,100:INFO:_display_container: 3
2025-03-20 18:43:09,100:INFO:BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563)
2025-03-20 18:43:09,100:INFO:tune_model() successfully completed......................................
2025-03-20 18:43:09,155:INFO:Initializing predict_model()
2025-03-20 18:43:09,155:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023116A6CDC0>)
2025-03-20 18:43:09,155:INFO:Checking exceptions
2025-03-20 18:43:09,155:INFO:Preloading libraries
2025-03-20 18:43:09,283:INFO:Initializing tune_model()
2025-03-20 18:43:09,283:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>)
2025-03-20 18:43:09,283:INFO:Checking exceptions
2025-03-20 18:43:09,283:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:43:09,291:INFO:Copying training dataset
2025-03-20 18:43:09,292:INFO:Checking base model
2025-03-20 18:43:09,292:INFO:Base model : Gradient Boosting Regressor
2025-03-20 18:43:09,294:INFO:Declaring metric variables
2025-03-20 18:43:09,296:INFO:Defining Hyperparameters
2025-03-20 18:43:09,349:INFO:Tuning with n_jobs=-1
2025-03-20 18:43:09,349:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:43:09,349:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:43:09,349:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:43:09,349:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:43:09,349:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:43:09,349:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:44:03,246:INFO:best_params: {'actual_estimator__n_estimators': 87, 'actual_estimator__learning_rate': 0.1671388862015314, 'actual_estimator__subsample': 0.9892043946600393, 'actual_estimator__min_samples_split': 6, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__max_depth': 2, 'actual_estimator__max_features': 0.6265551099006795, 'actual_estimator__min_impurity_decrease': 2.1417223511402424e-07}
2025-03-20 18:44:03,251:INFO:Hyperparameter search completed
2025-03-20 18:44:03,251:INFO:SubProcess create_model() called ==================================
2025-03-20 18:44:03,251:INFO:Initializing create_model()
2025-03-20 18:44:03,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023110E9DE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 87, 'learning_rate': 0.1671388862015314, 'subsample': 0.9892043946600393, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 0.6265551099006795, 'min_impurity_decrease': 2.1417223511402424e-07})
2025-03-20 18:44:03,251:INFO:Checking exceptions
2025-03-20 18:44:03,251:INFO:Importing libraries
2025-03-20 18:44:03,251:INFO:Copying training dataset
2025-03-20 18:44:03,254:INFO:Defining folds
2025-03-20 18:44:03,254:INFO:Declaring metric variables
2025-03-20 18:44:03,256:INFO:Importing untrained model
2025-03-20 18:44:03,256:INFO:Declaring custom model
2025-03-20 18:44:03,258:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:44:03,261:INFO:Starting cross validation
2025-03-20 18:44:03,262:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:44:03,518:INFO:Calculating mean and std
2025-03-20 18:44:03,519:INFO:Creating metrics dataframe
2025-03-20 18:44:03,522:INFO:Finalizing model
2025-03-20 18:44:03,789:INFO:Uploading results into container
2025-03-20 18:44:03,789:INFO:Uploading model into container now
2025-03-20 18:44:03,790:INFO:_master_model_container: 23
2025-03-20 18:44:03,790:INFO:_display_container: 5
2025-03-20 18:44:03,790:INFO:GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393)
2025-03-20 18:44:03,790:INFO:create_model() successfully completed......................................
2025-03-20 18:44:03,844:INFO:SubProcess create_model() end ==================================
2025-03-20 18:44:03,844:INFO:choose_better activated
2025-03-20 18:44:03,846:INFO:SubProcess create_model() called ==================================
2025-03-20 18:44:03,846:INFO:Initializing create_model()
2025-03-20 18:44:03,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:44:03,847:INFO:Checking exceptions
2025-03-20 18:44:03,848:INFO:Importing libraries
2025-03-20 18:44:03,848:INFO:Copying training dataset
2025-03-20 18:44:03,850:INFO:Defining folds
2025-03-20 18:44:03,850:INFO:Declaring metric variables
2025-03-20 18:44:03,850:INFO:Importing untrained model
2025-03-20 18:44:03,850:INFO:Declaring custom model
2025-03-20 18:44:03,850:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:44:03,850:INFO:Starting cross validation
2025-03-20 18:44:03,851:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:44:04,442:INFO:Calculating mean and std
2025-03-20 18:44:04,442:INFO:Creating metrics dataframe
2025-03-20 18:44:04,443:INFO:Finalizing model
2025-03-20 18:44:05,098:INFO:Uploading results into container
2025-03-20 18:44:05,098:INFO:Uploading model into container now
2025-03-20 18:44:05,098:INFO:_master_model_container: 24
2025-03-20 18:44:05,098:INFO:_display_container: 6
2025-03-20 18:44:05,098:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:44:05,098:INFO:create_model() successfully completed......................................
2025-03-20 18:44:05,154:INFO:SubProcess create_model() end ==================================
2025-03-20 18:44:05,154:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.0215
2025-03-20 18:44:05,155:INFO:GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393) result for MAPE is 0.0208
2025-03-20 18:44:05,155:INFO:GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393) is best model
2025-03-20 18:44:05,155:INFO:choose_better completed
2025-03-20 18:44:05,155:INFO:Creating Dashboard logs
2025-03-20 18:44:05,157:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:44:05,174:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1671388862015314, 'loss': 'squared_error', 'max_depth': 2, 'max_features': 0.6265551099006795, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.1417223511402424e-07, 'min_samples_leaf': 3, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 87, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.9892043946600393, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:44:05,345:INFO:Initializing predict_model()
2025-03-20 18:44:05,345:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023117B00040>)
2025-03-20 18:44:05,345:INFO:Checking exceptions
2025-03-20 18:44:05,345:INFO:Preloading libraries
2025-03-20 18:44:05,489:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:44:05,494:INFO:_master_model_container: 24
2025-03-20 18:44:05,494:INFO:_display_container: 5
2025-03-20 18:44:05,495:INFO:GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393)
2025-03-20 18:44:05,495:INFO:tune_model() successfully completed......................................
2025-03-20 18:44:05,552:INFO:Initializing predict_model()
2025-03-20 18:44:05,553:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023117AA21F0>)
2025-03-20 18:44:05,553:INFO:Checking exceptions
2025-03-20 18:44:05,553:INFO:Preloading libraries
2025-03-20 18:44:05,681:INFO:Initializing tune_model()
2025-03-20 18:44:05,682:INFO:tune_model(estimator=Ridge(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>)
2025-03-20 18:44:05,682:INFO:Checking exceptions
2025-03-20 18:44:05,682:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:44:05,690:INFO:Copying training dataset
2025-03-20 18:44:05,692:INFO:Checking base model
2025-03-20 18:44:05,692:INFO:Base model : Ridge Regression
2025-03-20 18:44:05,694:INFO:Declaring metric variables
2025-03-20 18:44:05,696:INFO:Defining Hyperparameters
2025-03-20 18:44:05,752:INFO:Tuning with n_jobs=-1
2025-03-20 18:44:05,753:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:44:05,753:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:44:05,753:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:44:05,753:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:44:05,753:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:44:05,753:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:44:28,201:INFO:best_params: {'actual_estimator__alpha': 0.13125991502283976, 'actual_estimator__fit_intercept': True}
2025-03-20 18:44:28,204:INFO:Hyperparameter search completed
2025-03-20 18:44:28,204:INFO:SubProcess create_model() called ==================================
2025-03-20 18:44:28,204:INFO:Initializing create_model()
2025-03-20 18:44:28,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000231121BFA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 0.13125991502283976, 'fit_intercept': True})
2025-03-20 18:44:28,204:INFO:Checking exceptions
2025-03-20 18:44:28,204:INFO:Importing libraries
2025-03-20 18:44:28,205:INFO:Copying training dataset
2025-03-20 18:44:28,207:INFO:Defining folds
2025-03-20 18:44:28,207:INFO:Declaring metric variables
2025-03-20 18:44:28,208:INFO:Importing untrained model
2025-03-20 18:44:28,208:INFO:Declaring custom model
2025-03-20 18:44:28,210:INFO:Ridge Regression Imported successfully
2025-03-20 18:44:28,213:INFO:Starting cross validation
2025-03-20 18:44:28,214:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:44:28,291:INFO:Calculating mean and std
2025-03-20 18:44:28,291:INFO:Creating metrics dataframe
2025-03-20 18:44:28,294:INFO:Finalizing model
2025-03-20 18:44:28,326:INFO:Uploading results into container
2025-03-20 18:44:28,326:INFO:Uploading model into container now
2025-03-20 18:44:28,326:INFO:_master_model_container: 25
2025-03-20 18:44:28,326:INFO:_display_container: 7
2025-03-20 18:44:28,327:INFO:Ridge(alpha=0.13125991502283976, random_state=888)
2025-03-20 18:44:28,327:INFO:create_model() successfully completed......................................
2025-03-20 18:44:28,391:INFO:SubProcess create_model() end ==================================
2025-03-20 18:44:28,392:INFO:choose_better activated
2025-03-20 18:44:28,393:INFO:SubProcess create_model() called ==================================
2025-03-20 18:44:28,394:INFO:Initializing create_model()
2025-03-20 18:44:28,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:44:28,394:INFO:Checking exceptions
2025-03-20 18:44:28,394:INFO:Importing libraries
2025-03-20 18:44:28,395:INFO:Copying training dataset
2025-03-20 18:44:28,396:INFO:Defining folds
2025-03-20 18:44:28,396:INFO:Declaring metric variables
2025-03-20 18:44:28,396:INFO:Importing untrained model
2025-03-20 18:44:28,396:INFO:Declaring custom model
2025-03-20 18:44:28,397:INFO:Ridge Regression Imported successfully
2025-03-20 18:44:28,397:INFO:Starting cross validation
2025-03-20 18:44:28,397:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:44:28,460:INFO:Calculating mean and std
2025-03-20 18:44:28,461:INFO:Creating metrics dataframe
2025-03-20 18:44:28,462:INFO:Finalizing model
2025-03-20 18:44:28,490:INFO:Uploading results into container
2025-03-20 18:44:28,491:INFO:Uploading model into container now
2025-03-20 18:44:28,491:INFO:_master_model_container: 26
2025-03-20 18:44:28,491:INFO:_display_container: 8
2025-03-20 18:44:28,491:INFO:Ridge(random_state=888)
2025-03-20 18:44:28,491:INFO:create_model() successfully completed......................................
2025-03-20 18:44:28,544:INFO:SubProcess create_model() end ==================================
2025-03-20 18:44:28,544:INFO:Ridge(random_state=888) result for MAPE is 0.0222
2025-03-20 18:44:28,544:INFO:Ridge(alpha=0.13125991502283976, random_state=888) result for MAPE is 0.0204
2025-03-20 18:44:28,544:INFO:Ridge(alpha=0.13125991502283976, random_state=888) is best model
2025-03-20 18:44:28,544:INFO:choose_better completed
2025-03-20 18:44:28,544:INFO:Creating Dashboard logs
2025-03-20 18:44:28,546:INFO:Model: Ridge Regression
2025-03-20 18:44:28,563:INFO:Logged params: {'alpha': 0.13125991502283976, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:44:28,727:INFO:Initializing predict_model()
2025-03-20 18:44:28,727:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(alpha=0.13125991502283976, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023116A6C040>)
2025-03-20 18:44:28,727:INFO:Checking exceptions
2025-03-20 18:44:28,727:INFO:Preloading libraries
2025-03-20 18:44:28,872:ERROR:_log_model() for Ridge(alpha=0.13125991502283976, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:44:28,877:INFO:_master_model_container: 26
2025-03-20 18:44:28,877:INFO:_display_container: 7
2025-03-20 18:44:28,877:INFO:Ridge(alpha=0.13125991502283976, random_state=888)
2025-03-20 18:44:28,877:INFO:tune_model() successfully completed......................................
2025-03-20 18:44:28,931:INFO:Initializing predict_model()
2025-03-20 18:44:28,931:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(alpha=0.13125991502283976, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023117AA2700>)
2025-03-20 18:44:28,931:INFO:Checking exceptions
2025-03-20 18:44:28,931:INFO:Preloading libraries
2025-03-20 18:44:29,065:INFO:Initializing tune_model()
2025-03-20 18:44:29,065:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>)
2025-03-20 18:44:29,065:INFO:Checking exceptions
2025-03-20 18:44:29,065:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:44:29,074:INFO:Copying training dataset
2025-03-20 18:44:29,076:INFO:Checking base model
2025-03-20 18:44:29,076:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 18:44:29,078:INFO:Declaring metric variables
2025-03-20 18:44:29,081:INFO:Defining Hyperparameters
2025-03-20 18:44:29,141:INFO:Tuning with n_jobs=-1
2025-03-20 18:44:29,142:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:44:29,142:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:44:29,142:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:44:29,142:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:44:29,142:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:44:29,142:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:45:11,512:INFO:best_params: {'actual_estimator__num_leaves': 6, 'actual_estimator__learning_rate': 0.1631715792275228, 'actual_estimator__n_estimators': 78, 'actual_estimator__min_split_gain': 0.9481089011532335, 'actual_estimator__reg_alpha': 0.007821045441807511, 'actual_estimator__reg_lambda': 9.742039349773055e-05, 'actual_estimator__feature_fraction': 0.8947973500799077, 'actual_estimator__bagging_fraction': 0.8445486404643138, 'actual_estimator__bagging_freq': 5, 'actual_estimator__min_child_samples': 4}
2025-03-20 18:45:11,520:INFO:Hyperparameter search completed
2025-03-20 18:45:11,520:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:11,520:INFO:Initializing create_model()
2025-03-20 18:45:11,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023110E84D30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 6, 'learning_rate': 0.1631715792275228, 'n_estimators': 78, 'min_split_gain': 0.9481089011532335, 'reg_alpha': 0.007821045441807511, 'reg_lambda': 9.742039349773055e-05, 'feature_fraction': 0.8947973500799077, 'bagging_fraction': 0.8445486404643138, 'bagging_freq': 5, 'min_child_samples': 4})
2025-03-20 18:45:11,521:INFO:Checking exceptions
2025-03-20 18:45:11,521:INFO:Importing libraries
2025-03-20 18:45:11,521:INFO:Copying training dataset
2025-03-20 18:45:11,524:INFO:Defining folds
2025-03-20 18:45:11,524:INFO:Declaring metric variables
2025-03-20 18:45:11,526:INFO:Importing untrained model
2025-03-20 18:45:11,526:INFO:Declaring custom model
2025-03-20 18:45:11,529:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:45:11,533:INFO:Starting cross validation
2025-03-20 18:45:11,534:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:11,663:INFO:Calculating mean and std
2025-03-20 18:45:11,665:INFO:Creating metrics dataframe
2025-03-20 18:45:11,668:INFO:Finalizing model
2025-03-20 18:45:11,711:INFO:[LightGBM] [Warning] feature_fraction is set=0.8947973500799077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947973500799077
2025-03-20 18:45:11,711:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8445486404643138, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8445486404643138
2025-03-20 18:45:11,711:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 18:45:11,716:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:45:11,716:INFO:[LightGBM] [Warning] feature_fraction is set=0.8947973500799077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947973500799077
2025-03-20 18:45:11,716:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8445486404643138, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8445486404643138
2025-03-20 18:45:11,716:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 18:45:11,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-03-20 18:45:11,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:45:11,717:INFO:[LightGBM] [Info] Total Bins 4382
2025-03-20 18:45:11,717:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 18:45:11,718:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 18:45:11,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:11,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:11,758:INFO:Uploading results into container
2025-03-20 18:45:11,759:INFO:Uploading model into container now
2025-03-20 18:45:11,759:INFO:_master_model_container: 27
2025-03-20 18:45:11,759:INFO:_display_container: 9
2025-03-20 18:45:11,760:INFO:LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05)
2025-03-20 18:45:11,760:INFO:create_model() successfully completed......................................
2025-03-20 18:45:11,826:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:11,827:INFO:choose_better activated
2025-03-20 18:45:11,829:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:11,829:INFO:Initializing create_model()
2025-03-20 18:45:11,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:11,830:INFO:Checking exceptions
2025-03-20 18:45:11,831:INFO:Importing libraries
2025-03-20 18:45:11,831:INFO:Copying training dataset
2025-03-20 18:45:11,834:INFO:Defining folds
2025-03-20 18:45:11,834:INFO:Declaring metric variables
2025-03-20 18:45:11,834:INFO:Importing untrained model
2025-03-20 18:45:11,834:INFO:Declaring custom model
2025-03-20 18:45:11,835:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:45:11,835:INFO:Starting cross validation
2025-03-20 18:45:11,836:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:12,325:INFO:Calculating mean and std
2025-03-20 18:45:12,326:INFO:Creating metrics dataframe
2025-03-20 18:45:12,327:INFO:Finalizing model
2025-03-20 18:45:12,368:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:45:12,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-03-20 18:45:12,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:45:12,369:INFO:[LightGBM] [Info] Total Bins 4382
2025-03-20 18:45:12,370:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 18:45:12,370:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 18:45:12,479:INFO:Uploading results into container
2025-03-20 18:45:12,479:INFO:Uploading model into container now
2025-03-20 18:45:12,480:INFO:_master_model_container: 28
2025-03-20 18:45:12,480:INFO:_display_container: 10
2025-03-20 18:45:12,480:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:45:12,480:INFO:create_model() successfully completed......................................
2025-03-20 18:45:12,544:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:12,544:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0235
2025-03-20 18:45:12,545:INFO:LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05) result for MAPE is 0.0218
2025-03-20 18:45:12,545:INFO:LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05) is best model
2025-03-20 18:45:12,545:INFO:choose_better completed
2025-03-20 18:45:12,545:INFO:Creating Dashboard logs
2025-03-20 18:45:12,548:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:45:12,571:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1631715792275228, 'max_depth': -1, 'min_child_samples': 4, 'min_child_weight': 0.001, 'min_split_gain': 0.9481089011532335, 'n_estimators': 78, 'n_jobs': -1, 'num_leaves': 6, 'objective': None, 'random_state': 888, 'reg_alpha': 0.007821045441807511, 'reg_lambda': 9.742039349773055e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.8947973500799077, 'bagging_fraction': 0.8445486404643138, 'bagging_freq': 5}
2025-03-20 18:45:12,775:INFO:Initializing predict_model()
2025-03-20 18:45:12,775:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231125EB8B0>)
2025-03-20 18:45:12,775:INFO:Checking exceptions
2025-03-20 18:45:12,775:INFO:Preloading libraries
2025-03-20 18:45:12,934:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:12,940:INFO:_master_model_container: 28
2025-03-20 18:45:12,940:INFO:_display_container: 9
2025-03-20 18:45:12,940:INFO:LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05)
2025-03-20 18:45:12,941:INFO:tune_model() successfully completed......................................
2025-03-20 18:45:13,006:INFO:Initializing predict_model()
2025-03-20 18:45:13,006:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231124CCAF0>)
2025-03-20 18:45:13,006:INFO:Checking exceptions
2025-03-20 18:45:13,006:INFO:Preloading libraries
2025-03-20 18:45:13,161:INFO:Initializing blend_models()
2025-03-20 18:45:13,161:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator_list=[BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), Ridge(alpha=0.13125991502283976, random_state=888), LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 18:45:13,161:INFO:Checking exceptions
2025-03-20 18:45:13,172:INFO:Importing libraries
2025-03-20 18:45:13,172:INFO:Copying training dataset
2025-03-20 18:45:13,174:INFO:Getting model names
2025-03-20 18:45:13,177:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:13,184:INFO:Initializing create_model()
2025-03-20 18:45:13,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311219C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:13,184:INFO:Checking exceptions
2025-03-20 18:45:13,184:INFO:Importing libraries
2025-03-20 18:45:13,184:INFO:Copying training dataset
2025-03-20 18:45:13,190:INFO:Defining folds
2025-03-20 18:45:13,190:INFO:Declaring metric variables
2025-03-20 18:45:13,192:INFO:Importing untrained model
2025-03-20 18:45:13,193:INFO:Declaring custom model
2025-03-20 18:45:13,196:INFO:Voting Regressor Imported successfully
2025-03-20 18:45:13,199:INFO:Starting cross validation
2025-03-20 18:45:13,200:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:13,665:INFO:Calculating mean and std
2025-03-20 18:45:13,665:INFO:Creating metrics dataframe
2025-03-20 18:45:13,669:INFO:Finalizing model
2025-03-20 18:45:13,992:INFO:Uploading results into container
2025-03-20 18:45:13,992:INFO:Uploading model into container now
2025-03-20 18:45:13,993:INFO:_master_model_container: 29
2025-03-20 18:45:13,993:INFO:_display_container: 11
2025-03-20 18:45:13,996:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)
2025-03-20 18:45:13,996:INFO:create_model() successfully completed......................................
2025-03-20 18:45:14,052:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:14,052:INFO:Creating Dashboard logs
2025-03-20 18:45:14,054:INFO:Model: Voting Regressor
2025-03-20 18:45:14,073:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), 'Ridge Regression': Ridge(alpha=0.13125991502283976, random_state=888), 'Bayesian Ridge__alpha_1': 0.07072750772862774, 'Bayesian Ridge__alpha_2': 0.007919031709587356, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.973777760198768, 'Bayesian Ridge__lambda_2': 0.0025067523515749563, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.1671388862015314, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 2, 'Gradient Boosting Regressor__max_features': 0.6265551099006795, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 2.1417223511402424e-07, 'Gradient Boosting Regressor__min_samples_leaf': 3, 'Gradient Boosting Regressor__min_samples_split': 6, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 87, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.9892043946600393, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.13125991502283976, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1631715792275228, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 4, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.9481089011532335, 'Light Gradient Boosting Machine__n_estimators': 78, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 6, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.007821045441807511, 'Light Gradient Boosting Machine__reg_lambda': 9.742039349773055e-05, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.8947973500799077, 'Light Gradient Boosting Machine__bagging_fraction': 0.8445486404643138, 'Light Gradient Boosting Machine__bagging_freq': 5}
2025-03-20 18:45:14,310:INFO:Initializing predict_model()
2025-03-20 18:45:14,310:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231125EB3A0>)
2025-03-20 18:45:14,310:INFO:Checking exceptions
2025-03-20 18:45:14,310:INFO:Preloading libraries
2025-03-20 18:45:14,460:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:14,466:INFO:_master_model_container: 29
2025-03-20 18:45:14,467:INFO:_display_container: 11
2025-03-20 18:45:14,472:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)
2025-03-20 18:45:14,472:INFO:blend_models() successfully completed......................................
2025-03-20 18:45:14,545:INFO:Initializing compare_models()
2025-03-20 18:45:14,545:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, include=[BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), Ridge(alpha=0.13125991502283976, random_state=888), LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05), VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, 'include': [BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), Ridge(alpha=0.13125991502283976, random_state=888), LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05), VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 18:45:14,545:INFO:Checking exceptions
2025-03-20 18:45:14,547:INFO:Preparing display monitor
2025-03-20 18:45:14,560:INFO:Initializing custom model Bayesian Ridge
2025-03-20 18:45:14,560:INFO:Total runtime is 8.27312469482422e-06 minutes
2025-03-20 18:45:14,562:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:14,563:INFO:Initializing create_model()
2025-03-20 18:45:14,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023110F06190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:14,563:INFO:Checking exceptions
2025-03-20 18:45:14,563:INFO:Importing libraries
2025-03-20 18:45:14,563:INFO:Copying training dataset
2025-03-20 18:45:14,565:INFO:Defining folds
2025-03-20 18:45:14,565:INFO:Declaring metric variables
2025-03-20 18:45:14,568:INFO:Importing untrained model
2025-03-20 18:45:14,568:INFO:Declaring custom model
2025-03-20 18:45:14,570:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:45:14,573:INFO:Starting cross validation
2025-03-20 18:45:14,574:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:14,650:INFO:Calculating mean and std
2025-03-20 18:45:14,651:INFO:Creating metrics dataframe
2025-03-20 18:45:14,652:INFO:Uploading results into container
2025-03-20 18:45:14,653:INFO:Uploading model into container now
2025-03-20 18:45:14,653:INFO:_master_model_container: 30
2025-03-20 18:45:14,653:INFO:_display_container: 12
2025-03-20 18:45:14,653:INFO:BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563)
2025-03-20 18:45:14,653:INFO:create_model() successfully completed......................................
2025-03-20 18:45:14,713:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:14,713:INFO:Creating metrics dataframe
2025-03-20 18:45:14,717:INFO:Initializing custom model Gradient Boosting Regressor
2025-03-20 18:45:14,717:INFO:Total runtime is 0.002624015013376872 minutes
2025-03-20 18:45:14,720:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:14,721:INFO:Initializing create_model()
2025-03-20 18:45:14,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023110F06190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:14,721:INFO:Checking exceptions
2025-03-20 18:45:14,721:INFO:Importing libraries
2025-03-20 18:45:14,721:INFO:Copying training dataset
2025-03-20 18:45:14,724:INFO:Defining folds
2025-03-20 18:45:14,724:INFO:Declaring metric variables
2025-03-20 18:45:14,726:INFO:Importing untrained model
2025-03-20 18:45:14,727:INFO:Declaring custom model
2025-03-20 18:45:14,730:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:45:14,737:INFO:Starting cross validation
2025-03-20 18:45:14,738:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:15,020:INFO:Calculating mean and std
2025-03-20 18:45:15,020:INFO:Creating metrics dataframe
2025-03-20 18:45:15,022:INFO:Uploading results into container
2025-03-20 18:45:15,022:INFO:Uploading model into container now
2025-03-20 18:45:15,022:INFO:_master_model_container: 31
2025-03-20 18:45:15,022:INFO:_display_container: 12
2025-03-20 18:45:15,022:INFO:GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393)
2025-03-20 18:45:15,022:INFO:create_model() successfully completed......................................
2025-03-20 18:45:15,078:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:15,078:INFO:Creating metrics dataframe
2025-03-20 18:45:15,083:INFO:Initializing custom model Ridge Regression
2025-03-20 18:45:15,083:INFO:Total runtime is 0.008716817696889242 minutes
2025-03-20 18:45:15,085:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:15,085:INFO:Initializing create_model()
2025-03-20 18:45:15,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(alpha=0.13125991502283976, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023110F06190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:15,085:INFO:Checking exceptions
2025-03-20 18:45:15,085:INFO:Importing libraries
2025-03-20 18:45:15,085:INFO:Copying training dataset
2025-03-20 18:45:15,087:INFO:Defining folds
2025-03-20 18:45:15,087:INFO:Declaring metric variables
2025-03-20 18:45:15,089:INFO:Importing untrained model
2025-03-20 18:45:15,089:INFO:Declaring custom model
2025-03-20 18:45:15,091:INFO:Ridge Regression Imported successfully
2025-03-20 18:45:15,094:INFO:Starting cross validation
2025-03-20 18:45:15,095:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:15,158:INFO:Calculating mean and std
2025-03-20 18:45:15,159:INFO:Creating metrics dataframe
2025-03-20 18:45:15,160:INFO:Uploading results into container
2025-03-20 18:45:15,160:INFO:Uploading model into container now
2025-03-20 18:45:15,160:INFO:_master_model_container: 32
2025-03-20 18:45:15,160:INFO:_display_container: 12
2025-03-20 18:45:15,161:INFO:Ridge(alpha=0.13125991502283976, random_state=888)
2025-03-20 18:45:15,161:INFO:create_model() successfully completed......................................
2025-03-20 18:45:15,217:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:15,217:INFO:Creating metrics dataframe
2025-03-20 18:45:15,222:INFO:Initializing custom model Light Gradient Boosting Machine
2025-03-20 18:45:15,222:INFO:Total runtime is 0.011034595966339112 minutes
2025-03-20 18:45:15,224:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:15,224:INFO:Initializing create_model()
2025-03-20 18:45:15,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023110F06190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:15,225:INFO:Checking exceptions
2025-03-20 18:45:15,225:INFO:Importing libraries
2025-03-20 18:45:15,225:INFO:Copying training dataset
2025-03-20 18:45:15,227:INFO:Defining folds
2025-03-20 18:45:15,227:INFO:Declaring metric variables
2025-03-20 18:45:15,229:INFO:Importing untrained model
2025-03-20 18:45:15,229:INFO:Declaring custom model
2025-03-20 18:45:15,231:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:45:15,233:INFO:Starting cross validation
2025-03-20 18:45:15,234:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:15,343:INFO:Calculating mean and std
2025-03-20 18:45:15,344:INFO:Creating metrics dataframe
2025-03-20 18:45:15,345:INFO:Uploading results into container
2025-03-20 18:45:15,346:INFO:Uploading model into container now
2025-03-20 18:45:15,346:INFO:_master_model_container: 33
2025-03-20 18:45:15,346:INFO:_display_container: 12
2025-03-20 18:45:15,346:INFO:LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05)
2025-03-20 18:45:15,346:INFO:create_model() successfully completed......................................
2025-03-20 18:45:15,408:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:15,408:INFO:Creating metrics dataframe
2025-03-20 18:45:15,414:INFO:Initializing custom model Voting Regressor
2025-03-20 18:45:15,414:INFO:Total runtime is 0.014238071441650391 minutes
2025-03-20 18:45:15,417:INFO:SubProcess create_model() called ==================================
2025-03-20 18:45:15,422:INFO:Initializing create_model()
2025-03-20 18:45:15,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023110F06190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:15,422:INFO:Checking exceptions
2025-03-20 18:45:15,422:INFO:Importing libraries
2025-03-20 18:45:15,422:INFO:Copying training dataset
2025-03-20 18:45:15,425:INFO:Defining folds
2025-03-20 18:45:15,425:INFO:Declaring metric variables
2025-03-20 18:45:15,427:INFO:Importing untrained model
2025-03-20 18:45:15,428:INFO:Declaring custom model
2025-03-20 18:45:15,431:INFO:Voting Regressor Imported successfully
2025-03-20 18:45:15,435:INFO:Starting cross validation
2025-03-20 18:45:15,436:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:45:15,821:INFO:Calculating mean and std
2025-03-20 18:45:15,822:INFO:Creating metrics dataframe
2025-03-20 18:45:15,824:INFO:Uploading results into container
2025-03-20 18:45:15,824:INFO:Uploading model into container now
2025-03-20 18:45:15,825:INFO:_master_model_container: 34
2025-03-20 18:45:15,825:INFO:_display_container: 12
2025-03-20 18:45:15,829:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)
2025-03-20 18:45:15,829:INFO:create_model() successfully completed......................................
2025-03-20 18:45:15,893:INFO:SubProcess create_model() end ==================================
2025-03-20 18:45:15,894:INFO:Creating metrics dataframe
2025-03-20 18:45:15,910:INFO:Initializing create_model()
2025-03-20 18:45:15,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:15,910:INFO:Checking exceptions
2025-03-20 18:45:15,911:INFO:Importing libraries
2025-03-20 18:45:15,911:INFO:Copying training dataset
2025-03-20 18:45:15,914:INFO:Defining folds
2025-03-20 18:45:15,914:INFO:Declaring metric variables
2025-03-20 18:45:15,914:INFO:Importing untrained model
2025-03-20 18:45:15,914:INFO:Declaring custom model
2025-03-20 18:45:15,915:INFO:Voting Regressor Imported successfully
2025-03-20 18:45:15,915:INFO:Cross validation set to False
2025-03-20 18:45:15,915:INFO:Fitting Model
2025-03-20 18:45:16,225:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)
2025-03-20 18:45:16,225:INFO:create_model() successfully completed......................................
2025-03-20 18:45:16,286:INFO:Creating Dashboard logs
2025-03-20 18:45:16,289:INFO:Model: Voting Regressor
2025-03-20 18:45:16,309:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), 'Ridge Regression': Ridge(alpha=0.13125991502283976, random_state=888), 'Bayesian Ridge__alpha_1': 0.07072750772862774, 'Bayesian Ridge__alpha_2': 0.007919031709587356, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.973777760198768, 'Bayesian Ridge__lambda_2': 0.0025067523515749563, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.1671388862015314, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 2, 'Gradient Boosting Regressor__max_features': 0.6265551099006795, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 2.1417223511402424e-07, 'Gradient Boosting Regressor__min_samples_leaf': 3, 'Gradient Boosting Regressor__min_samples_split': 6, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 87, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.9892043946600393, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.13125991502283976, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1631715792275228, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 4, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.9481089011532335, 'Light Gradient Boosting Machine__n_estimators': 78, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 6, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.007821045441807511, 'Light Gradient Boosting Machine__reg_lambda': 9.742039349773055e-05, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.8947973500799077, 'Light Gradient Boosting Machine__bagging_fraction': 0.8445486404643138, 'Light Gradient Boosting Machine__bagging_freq': 5}
2025-03-20 18:45:16,557:INFO:Initializing predict_model()
2025-03-20 18:45:16,558:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023116A6C5E0>)
2025-03-20 18:45:16,558:INFO:Checking exceptions
2025-03-20 18:45:16,558:INFO:Preloading libraries
2025-03-20 18:45:16,717:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:16,718:INFO:Creating Dashboard logs
2025-03-20 18:45:16,720:INFO:Model: Bayesian Ridge
2025-03-20 18:45:16,742:INFO:Logged params: {'alpha_1': 0.07072750772862774, 'alpha_2': 0.007919031709587356, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.973777760198768, 'lambda_2': 0.0025067523515749563, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:45:17,001:ERROR:_log_model() for BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:17,002:INFO:Creating Dashboard logs
2025-03-20 18:45:17,004:INFO:Model: Ridge Regression
2025-03-20 18:45:17,021:INFO:Logged params: {'alpha': 0.13125991502283976, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:45:17,264:ERROR:_log_model() for Ridge(alpha=0.13125991502283976, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:17,265:INFO:Creating Dashboard logs
2025-03-20 18:45:17,267:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:45:17,284:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1671388862015314, 'loss': 'squared_error', 'max_depth': 2, 'max_features': 0.6265551099006795, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.1417223511402424e-07, 'min_samples_leaf': 3, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 87, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.9892043946600393, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:45:17,535:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:17,536:INFO:Creating Dashboard logs
2025-03-20 18:45:17,538:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:45:17,554:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1631715792275228, 'max_depth': -1, 'min_child_samples': 4, 'min_child_weight': 0.001, 'min_split_gain': 0.9481089011532335, 'n_estimators': 78, 'n_jobs': -1, 'num_leaves': 6, 'objective': None, 'random_state': 888, 'reg_alpha': 0.007821045441807511, 'reg_lambda': 9.742039349773055e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.8947973500799077, 'bagging_fraction': 0.8445486404643138, 'bagging_freq': 5}
2025-03-20 18:45:17,810:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:17,817:INFO:_master_model_container: 34
2025-03-20 18:45:17,817:INFO:_display_container: 12
2025-03-20 18:45:17,821:INFO:VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)
2025-03-20 18:45:17,821:INFO:compare_models() successfully completed......................................
2025-03-20 18:45:17,913:INFO:Initializing finalize_model()
2025-03-20 18:45:17,913:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:45:17,914:INFO:Finalizing BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563)
2025-03-20 18:45:17,916:INFO:Initializing create_model()
2025-03-20 18:45:17,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:17,916:INFO:Checking exceptions
2025-03-20 18:45:17,917:INFO:Importing libraries
2025-03-20 18:45:17,917:INFO:Copying training dataset
2025-03-20 18:45:17,917:INFO:Defining folds
2025-03-20 18:45:17,917:INFO:Declaring metric variables
2025-03-20 18:45:17,917:INFO:Importing untrained model
2025-03-20 18:45:17,917:INFO:Declaring custom model
2025-03-20 18:45:17,917:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:45:17,917:INFO:Cross validation set to False
2025-03-20 18:45:17,917:INFO:Fitting Model
2025-03-20 18:45:17,963:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.07072750772862774,
                               alpha_2=0.007919031709587356,
                               lambda_1=0.973777760198768,
                               lambda_2=0.0025067523515749563))])
2025-03-20 18:45:17,964:INFO:create_model() successfully completed......................................
2025-03-20 18:45:18,022:INFO:Creating Dashboard logs
2025-03-20 18:45:18,023:INFO:Model: Bayesian Ridge
2025-03-20 18:45:18,039:INFO:Logged params: {'alpha_1': 0.07072750772862774, 'alpha_2': 0.007919031709587356, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 0.973777760198768, 'lambda_2': 0.0025067523515749563, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:45:18,303:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.07072750772862774,
                               alpha_2=0.007919031709587356,
                               lambda_1=0.973777760198768,
                               lambda_2=0.0025067523515749563))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:18,303:INFO:_master_model_container: 34
2025-03-20 18:45:18,303:INFO:_display_container: 12
2025-03-20 18:45:18,308:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.07072750772862774,
                               alpha_2=0.007919031709587356,
                               lambda_1=0.973777760198768,
                               lambda_2=0.0025067523515749563))])
2025-03-20 18:45:18,308:INFO:finalize_model() successfully completed......................................
2025-03-20 18:45:18,375:INFO:Initializing save_model()
2025-03-20 18:45:18,375:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.07072750772862774,
                               alpha_2=0.007919031709587356,
                               lambda_1=0.973777760198768,
                               lambda_2=0.0025067523515749563))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_184517, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:45:18,375:INFO:Adding model into prep_pipe
2025-03-20 18:45:18,375:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:45:18,379:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_184517.pkl saved in current working directory
2025-03-20 18:45:18,384:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.07072750772862774,
                               alpha_2=0.007919031709587356,
                               lambda_1=0.973777760198768,
                               lambda_2=0.0025067523515749563))])
2025-03-20 18:45:18,384:INFO:save_model() successfully completed......................................
2025-03-20 18:45:18,445:INFO:Initializing finalize_model()
2025-03-20 18:45:18,445:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:45:18,446:INFO:Finalizing GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393)
2025-03-20 18:45:18,448:INFO:Initializing create_model()
2025-03-20 18:45:18,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=GradientBoostingRegressor(learning_rate=0.1671388862015314, max_depth=2,
                          max_features=0.6265551099006795,
                          min_impurity_decrease=2.1417223511402424e-07,
                          min_samples_leaf=3, min_samples_split=6,
                          n_estimators=87, random_state=888,
                          subsample=0.9892043946600393), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:18,448:INFO:Checking exceptions
2025-03-20 18:45:18,449:INFO:Importing libraries
2025-03-20 18:45:18,449:INFO:Copying training dataset
2025-03-20 18:45:18,449:INFO:Defining folds
2025-03-20 18:45:18,449:INFO:Declaring metric variables
2025-03-20 18:45:18,449:INFO:Importing untrained model
2025-03-20 18:45:18,449:INFO:Declaring custom model
2025-03-20 18:45:18,449:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:45:18,450:INFO:Cross validation set to False
2025-03-20 18:45:18,450:INFO:Fitting Model
2025-03-20 18:45:18,787:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                           max_depth=2,
                                           max_features=0.6265551099006795,
                                           min_impurity_decrease=2.1417223511402424e-07,
                                           min_samples_leaf=3,
                                           min_samples_split=6, n_estimators=87,
                                           random_state=888,
                                           subsample=0.9892043946600393))])
2025-03-20 18:45:18,787:INFO:create_model() successfully completed......................................
2025-03-20 18:45:18,847:INFO:Creating Dashboard logs
2025-03-20 18:45:18,847:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:45:18,864:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1671388862015314, 'loss': 'squared_error', 'max_depth': 2, 'max_features': 0.6265551099006795, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.1417223511402424e-07, 'min_samples_leaf': 3, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 87, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.9892043946600393, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:45:19,126:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                           max_depth=2,
                                           max_features=0.6265551099006795,
                                           min_impurity_decrease=2.1417223511402424e-07,
                                           min_samples_leaf=3,
                                           min_samples_split=6, n_estimators=87,
                                           random_state=888,
                                           subsample=0.9892043946600393))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:19,126:INFO:_master_model_container: 34
2025-03-20 18:45:19,126:INFO:_display_container: 12
2025-03-20 18:45:19,131:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                           max_depth=2,
                                           max_features=0.6265551099006795,
                                           min_impurity_decrease=2.1417223511402424e-07,
                                           min_samples_leaf=3,
                                           min_samples_split=6, n_estimators=87,
                                           random_state=888,
                                           subsample=0.9892043946600393))])
2025-03-20 18:45:19,131:INFO:finalize_model() successfully completed......................................
2025-03-20 18:45:19,201:INFO:Initializing save_model()
2025-03-20 18:45:19,201:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                           max_depth=2,
                                           max_features=0.6265551099006795,
                                           min_impurity_decrease=2.1417223511402424e-07,
                                           min_samples_leaf=3,
                                           min_samples_split=6, n_estimators=87,
                                           random_state=888,
                                           subsample=0.9892043946600393))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_184518, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:45:19,201:INFO:Adding model into prep_pipe
2025-03-20 18:45:19,201:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:45:19,206:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_184518.pkl saved in current working directory
2025-03-20 18:45:19,211:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                           max_depth=2,
                                           max_features=0.6265551099006795,
                                           min_impurity_decrease=2.1417223511402424e-07,
                                           min_samples_leaf=3,
                                           min_samples_split=6, n_estimators=87,
                                           random_state=888,
                                           subsample=0.9892043946600393))])
2025-03-20 18:45:19,211:INFO:save_model() successfully completed......................................
2025-03-20 18:45:19,267:INFO:Initializing finalize_model()
2025-03-20 18:45:19,267:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(alpha=0.13125991502283976, random_state=888), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:45:19,267:INFO:Finalizing Ridge(alpha=0.13125991502283976, random_state=888)
2025-03-20 18:45:19,270:INFO:Initializing create_model()
2025-03-20 18:45:19,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=Ridge(alpha=0.13125991502283976, random_state=888), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:19,270:INFO:Checking exceptions
2025-03-20 18:45:19,270:INFO:Importing libraries
2025-03-20 18:45:19,271:INFO:Copying training dataset
2025-03-20 18:45:19,271:INFO:Defining folds
2025-03-20 18:45:19,271:INFO:Declaring metric variables
2025-03-20 18:45:19,271:INFO:Importing untrained model
2025-03-20 18:45:19,271:INFO:Declaring custom model
2025-03-20 18:45:19,271:INFO:Ridge Regression Imported successfully
2025-03-20 18:45:19,272:INFO:Cross validation set to False
2025-03-20 18:45:19,272:INFO:Fitting Model
2025-03-20 18:45:19,310:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.13125991502283976, random_state=888))])
2025-03-20 18:45:19,310:INFO:create_model() successfully completed......................................
2025-03-20 18:45:19,368:INFO:Creating Dashboard logs
2025-03-20 18:45:19,368:INFO:Model: Ridge Regression
2025-03-20 18:45:19,385:INFO:Logged params: {'alpha': 0.13125991502283976, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:45:19,651:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.13125991502283976, random_state=888))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:19,651:INFO:_master_model_container: 34
2025-03-20 18:45:19,651:INFO:_display_container: 12
2025-03-20 18:45:19,655:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.13125991502283976, random_state=888))])
2025-03-20 18:45:19,655:INFO:finalize_model() successfully completed......................................
2025-03-20 18:45:19,721:INFO:Initializing save_model()
2025-03-20 18:45:19,721:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.13125991502283976, random_state=888))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\ridge_250320_184519, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:45:19,721:INFO:Adding model into prep_pipe
2025-03-20 18:45:19,721:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:45:19,725:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\ridge_250320_184519.pkl saved in current working directory
2025-03-20 18:45:19,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.13125991502283976, random_state=888))])
2025-03-20 18:45:19,730:INFO:save_model() successfully completed......................................
2025-03-20 18:45:19,787:INFO:Initializing finalize_model()
2025-03-20 18:45:19,787:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:45:19,787:INFO:Finalizing LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05)
2025-03-20 18:45:19,789:INFO:Initializing create_model()
2025-03-20 18:45:19,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=LGBMRegressor(bagging_fraction=0.8445486404643138, bagging_freq=5,
              feature_fraction=0.8947973500799077,
              learning_rate=0.1631715792275228, min_child_samples=4,
              min_split_gain=0.9481089011532335, n_estimators=78, n_jobs=-1,
              num_leaves=6, random_state=888, reg_alpha=0.007821045441807511,
              reg_lambda=9.742039349773055e-05), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:19,790:INFO:Checking exceptions
2025-03-20 18:45:19,790:INFO:Importing libraries
2025-03-20 18:45:19,790:INFO:Copying training dataset
2025-03-20 18:45:19,790:INFO:Defining folds
2025-03-20 18:45:19,791:INFO:Declaring metric variables
2025-03-20 18:45:19,791:INFO:Importing untrained model
2025-03-20 18:45:19,791:INFO:Declaring custom model
2025-03-20 18:45:19,791:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:45:19,792:INFO:Cross validation set to False
2025-03-20 18:45:19,792:INFO:Fitting Model
2025-03-20 18:45:19,825:INFO:[LightGBM] [Warning] feature_fraction is set=0.8947973500799077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947973500799077
2025-03-20 18:45:19,825:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8445486404643138, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8445486404643138
2025-03-20 18:45:19,825:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 18:45:19,826:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:45:19,827:INFO:[LightGBM] [Warning] feature_fraction is set=0.8947973500799077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947973500799077
2025-03-20 18:45:19,827:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8445486404643138, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8445486404643138
2025-03-20 18:45:19,827:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 18:45:19,827:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-03-20 18:45:19,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:45:19,827:INFO:[LightGBM] [Info] Total Bins 4394
2025-03-20 18:45:19,828:INFO:[LightGBM] [Info] Number of data points in the train set: 1769, number of used features: 37
2025-03-20 18:45:19,828:INFO:[LightGBM] [Info] Start training from score 15.920889
2025-03-20 18:45:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 18:45:19,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 18:45:19,850:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8445486404643138,
                               bagging_freq=5,
                               feature_fraction=0.8947973500799077,
                               learning_rate=0.1631715792275228,
                               min_child_samples=4,
                               min_split_gain=0.9481089011532335,
                               n_estimators=78, n_jobs=-1, num_leaves=6,
                               random_state=888, reg_alpha=0.007821045441807511,
                               reg_lambda=9.742039349773055e-05))])
2025-03-20 18:45:19,850:INFO:create_model() successfully completed......................................
2025-03-20 18:45:19,916:INFO:Creating Dashboard logs
2025-03-20 18:45:19,917:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:45:19,939:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1631715792275228, 'max_depth': -1, 'min_child_samples': 4, 'min_child_weight': 0.001, 'min_split_gain': 0.9481089011532335, 'n_estimators': 78, 'n_jobs': -1, 'num_leaves': 6, 'objective': None, 'random_state': 888, 'reg_alpha': 0.007821045441807511, 'reg_lambda': 9.742039349773055e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.8947973500799077, 'bagging_fraction': 0.8445486404643138, 'bagging_freq': 5}
2025-03-20 18:45:20,211:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8445486404643138,
                               bagging_freq=5,
                               feature_fraction=0.8947973500799077,
                               learning_rate=0.1631715792275228,
                               min_child_samples=4,
                               min_split_gain=0.9481089011532335,
                               n_estimators=78, n_jobs=-1, num_leaves=6,
                               random_state=888, reg_alpha=0.007821045441807511,
                               reg_lambda=9.742039349773055e-05))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:20,211:INFO:_master_model_container: 34
2025-03-20 18:45:20,212:INFO:_display_container: 12
2025-03-20 18:45:20,217:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8445486404643138,
                               bagging_freq=5,
                               feature_fraction=0.8947973500799077,
                               learning_rate=0.1631715792275228,
                               min_child_samples=4,
                               min_split_gain=0.9481089011532335,
                               n_estimators=78, n_jobs=-1, num_leaves=6,
                               random_state=888, reg_alpha=0.007821045441807511,
                               reg_lambda=9.742039349773055e-05))])
2025-03-20 18:45:20,217:INFO:finalize_model() successfully completed......................................
2025-03-20 18:45:20,302:INFO:Initializing save_model()
2025-03-20 18:45:20,302:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8445486404643138,
                               bagging_freq=5,
                               feature_fraction=0.8947973500799077,
                               learning_rate=0.1631715792275228,
                               min_child_samples=4,
                               min_split_gain=0.9481089011532335,
                               n_estimators=78, n_jobs=-1, num_leaves=6,
                               random_state=888, reg_alpha=0.007821045441807511,
                               reg_lambda=9.742039349773055e-05))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_184519, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:45:20,302:INFO:Adding model into prep_pipe
2025-03-20 18:45:20,302:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:45:20,307:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_184519.pkl saved in current working directory
2025-03-20 18:45:20,314:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8445486404643138,
                               bagging_freq=5,
                               feature_fraction=0.8947973500799077,
                               learning_rate=0.1631715792275228,
                               min_child_samples=4,
                               min_split_gain=0.9481089011532335,
                               n_estimators=78, n_jobs=-1, num_leaves=6,
                               random_state=888, reg_alpha=0.007821045441807511,
                               reg_lambda=9.742039349773055e-05))])
2025-03-20 18:45:20,314:INFO:save_model() successfully completed......................................
2025-03-20 18:45:20,388:INFO:Initializing finalize_model()
2025-03-20 18:45:20,388:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 18:45:20,393:INFO:Finalizing VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1)
2025-03-20 18:45:20,400:INFO:Initializing create_model()
2025-03-20 18:45:20,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002310D613490>, estimator=VotingRegressor(estimators=[('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.07072750772862774,
                                           alpha_2=0.007919031709587356,
                                           lambda_1=0.973777760198768,
                                           lambda_2=0.0025067523515749563)),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.1671388862015314,
                                                       max_depth=2,
                                                       max_features=0.6265551099006795,
                                                       min_impurity_decrease=2.1417223511402424e-...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8445486404643138,
                                           bagging_freq=5,
                                           feature_fraction=0.8947973500799077,
                                           learning_rate=0.1631715792275228,
                                           min_child_samples=4,
                                           min_split_gain=0.9481089011532335,
                                           n_estimators=78, n_jobs=-1,
                                           num_leaves=6, random_state=888,
                                           reg_alpha=0.007821045441807511,
                                           reg_lambda=9.742039349773055e-05))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:45:20,400:INFO:Checking exceptions
2025-03-20 18:45:20,401:INFO:Importing libraries
2025-03-20 18:45:20,401:INFO:Copying training dataset
2025-03-20 18:45:20,401:INFO:Defining folds
2025-03-20 18:45:20,401:INFO:Declaring metric variables
2025-03-20 18:45:20,401:INFO:Importing untrained model
2025-03-20 18:45:20,401:INFO:Declaring custom model
2025-03-20 18:45:20,402:INFO:Voting Regressor Imported successfully
2025-03-20 18:45:20,403:INFO:Cross validation set to False
2025-03-20 18:45:20,403:INFO:Fitting Model
2025-03-20 18:45:20,791:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8445486404643138,
                                                            bagging_freq=5,
                                                            feature_fraction=0.8947973500799077,
                                                            learning_rate=0.1631715792275228,
                                                            min_child_samples=4,
                                                            min_split_gain=0.9481089011532335,
                                                            n_estimators=78,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=0.007821045441807511,
                                                            reg_lambda=9.742039349773055e-05))],
                                 n_jobs=-1))])
2025-03-20 18:45:20,791:INFO:create_model() successfully completed......................................
2025-03-20 18:45:20,848:INFO:Creating Dashboard logs
2025-03-20 18:45:20,849:INFO:Model: Voting Regressor
2025-03-20 18:45:20,868:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(alpha_1=0.07072750772862774, alpha_2=0.007919031709587356,
              lambda_1=0.973777760198768, lambda_2=0.0025067523515749563), 'Ridge Regression': Ridge(alpha=0.13125991502283976, random_state=888), 'Bayesian Ridge__alpha_1': 0.07072750772862774, 'Bayesian Ridge__alpha_2': 0.007919031709587356, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 0.973777760198768, 'Bayesian Ridge__lambda_2': 0.0025067523515749563, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.1671388862015314, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 2, 'Gradient Boosting Regressor__max_features': 0.6265551099006795, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 2.1417223511402424e-07, 'Gradient Boosting Regressor__min_samples_leaf': 3, 'Gradient Boosting Regressor__min_samples_split': 6, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 87, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.9892043946600393, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.13125991502283976, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1631715792275228, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 4, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.9481089011532335, 'Light Gradient Boosting Machine__n_estimators': 78, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 6, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.007821045441807511, 'Light Gradient Boosting Machine__reg_lambda': 9.742039349773055e-05, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.8947973500799077, 'Light Gradient Boosting Machine__bagging_fraction': 0.8445486404643138, 'Light Gradient Boosting Machine__bagging_freq': 5}
2025-03-20 18:45:21,211:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8445486404643138,
                                                            bagging_freq=5,
                                                            feature_fraction=0.8947973500799077,
                                                            learning_rate=0.1631715792275228,
                                                            min_child_samples=4,
                                                            min_split_gain=0.9481089011532335,
                                                            n_estimators=78,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=0.007821045441807511,
                                                            reg_lambda=9.742039349773055e-05))],
                                 n_jobs=-1))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:45:21,211:INFO:_master_model_container: 34
2025-03-20 18:45:21,211:INFO:_display_container: 12
2025-03-20 18:45:21,229:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8445486404643138,
                                                            bagging_freq=5,
                                                            feature_fraction=0.8947973500799077,
                                                            learning_rate=0.1631715792275228,
                                                            min_child_samples=4,
                                                            min_split_gain=0.9481089011532335,
                                                            n_estimators=78,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=0.007821045441807511,
                                                            reg_lambda=9.742039349773055e-05))],
                                 n_jobs=-1))])
2025-03-20 18:45:21,229:INFO:finalize_model() successfully completed......................................
2025-03-20 18:45:21,308:INFO:Initializing save_model()
2025-03-20 18:45:21,308:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8445486404643138,
                                                            bagging_freq=5,
                                                            feature_fraction=0.8947973500799077,
                                                            learning_rate=0.1631715792275228,
                                                            min_child_samples=4,
                                                            min_split_gain=0.9481089011532335,
                                                            n_estimators=78,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=0.007821045441807511,
                                                            reg_lambda=9.742039349773055e-05))],
                                 n_jobs=-1))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_184520, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:45:21,308:INFO:Adding model into prep_pipe
2025-03-20 18:45:21,308:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:45:21,316:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_184520.pkl saved in current working directory
2025-03-20 18:45:21,334:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8445486404643138,
                                                            bagging_freq=5,
                                                            feature_fraction=0.8947973500799077,
                                                            learning_rate=0.1631715792275228,
                                                            min_child_samples=4,
                                                            min_split_gain=0.9481089011532335,
                                                            n_estimators=78,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=0.007821045441807511,
                                                            reg_lambda=9.742039349773055e-05))],
                                 n_jobs=-1))])
2025-03-20 18:45:21,334:INFO:save_model() successfully completed......................................
2025-03-20 18:46:07,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:07,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:07,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:07,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:07,327:INFO:Initializing load_model()
2025-03-20 18:46:07,327:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_183756, platform=None, authentication=None, verbose=True)
2025-03-20 18:46:25,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:25,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:25,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:25,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:46:25,869:INFO:Initializing load_model()
2025-03-20 18:46:25,869:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_184520, platform=None, authentication=None, verbose=True)
2025-03-20 18:46:26,400:INFO:Initializing predict_model()
2025-03-20 18:46:26,400:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000012A021829D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8445486404643138,
                                                            bagging_freq=5,
                                                            feature_fraction=0.8947973500799077,
                                                            learning_rate=0.1631715792275228,
                                                            min_child_samples=4,
                                                            min_split_gain=0.9481089011532335,
                                                            n_estimators=78,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=0.007821045441807511,
                                                            reg_lambda=9.742039349773055e-05))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000012A013F8A60>)
2025-03-20 18:46:26,400:INFO:Checking exceptions
2025-03-20 18:46:26,400:INFO:Preloading libraries
2025-03-20 18:46:26,400:INFO:Set up data.
2025-03-20 18:46:26,405:INFO:Set up index.
2025-03-20 18:46:26,503:INFO:Initializing load_model()
2025-03-20 18:46:26,503:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_184520, platform=None, authentication=None, verbose=True)
2025-03-20 18:46:26,534:INFO:Initializing predict_model()
2025-03-20 18:46:26,534:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000012A02193490>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8445486404643138,
                                                            bagging_freq=5,
                                                            feature_fraction=0.8947973500799077,
                                                            learning_rate=0.1631715792275228,
                                                            min_child_samples=4,
                                                            min_split_gain=0.9481089011532335,
                                                            n_estimators=78,
                                                            n_jobs=-1,
                                                            num_leaves=6,
                                                            random_state=888,
                                                            reg_alpha=0.007821045441807511,
                                                            reg_lambda=9.742039349773055e-05))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000012A013F8A60>)
2025-03-20 18:46:26,534:INFO:Checking exceptions
2025-03-20 18:46:26,534:INFO:Preloading libraries
2025-03-20 18:46:26,534:INFO:Set up data.
2025-03-20 18:46:26,540:INFO:Set up index.
2025-03-20 18:46:29,902:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:46:31,986:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 18:58:27,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:58:27,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:58:27,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:58:27,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 18:58:27,503:INFO:PyCaret RegressionExperiment
2025-03-20 18:58:27,504:INFO:Logging name: reg-default-name
2025-03-20 18:58:27,504:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 18:58:27,504:INFO:version 3.2.0
2025-03-20 18:58:27,504:INFO:Initializing setup()
2025-03-20 18:58:27,504:INFO:self.USI: 80c3
2025-03-20 18:58:27,504:INFO:self._variable_keys: {'_ml_usecase', 'exp_name_log', 'logging_param', 'seed', 'data', 'X_train', 'y', 'transform_target_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X_test', '_available_plots', 'exp_id', 'idx', 'gpu_param', 'memory', 'target_param', 'log_plots_param', 'y_train', 'gpu_n_jobs_param', 'X', 'USI', 'n_jobs_param', 'pipeline', 'html_param', 'y_test'}
2025-03-20 18:58:27,504:INFO:Checking environment
2025-03-20 18:58:27,504:INFO:python_version: 3.8.20
2025-03-20 18:58:27,504:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 18:58:27,504:INFO:machine: AMD64
2025-03-20 18:58:27,504:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 18:58:27,520:INFO:Memory: svmem(total=68447973376, available=39728517120, percent=42.0, used=28719456256, free=39728517120)
2025-03-20 18:58:27,520:INFO:Physical Core: 24
2025-03-20 18:58:27,520:INFO:Logical Core: 32
2025-03-20 18:58:27,520:INFO:Checking libraries
2025-03-20 18:58:27,520:INFO:System:
2025-03-20 18:58:27,520:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 18:58:27,520:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 18:58:27,520:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 18:58:27,520:INFO:PyCaret required dependencies:
2025-03-20 18:58:28,038:INFO:                 pip: 24.2
2025-03-20 18:58:28,039:INFO:          setuptools: 75.1.0
2025-03-20 18:58:28,039:INFO:             pycaret: 3.2.0
2025-03-20 18:58:28,039:INFO:             IPython: 8.12.3
2025-03-20 18:58:28,039:INFO:          ipywidgets: 8.1.5
2025-03-20 18:58:28,039:INFO:                tqdm: 4.67.1
2025-03-20 18:58:28,039:INFO:               numpy: 1.24.4
2025-03-20 18:58:28,039:INFO:              pandas: 1.5.3
2025-03-20 18:58:28,039:INFO:              jinja2: 3.1.4
2025-03-20 18:58:28,039:INFO:               scipy: 1.10.1
2025-03-20 18:58:28,039:INFO:              joblib: 1.3.2
2025-03-20 18:58:28,039:INFO:             sklearn: 1.2.2
2025-03-20 18:58:28,039:INFO:                pyod: 2.0.2
2025-03-20 18:58:28,039:INFO:            imblearn: 0.12.4
2025-03-20 18:58:28,039:INFO:   category_encoders: 2.6.4
2025-03-20 18:58:28,039:INFO:            lightgbm: 4.5.0
2025-03-20 18:58:28,039:INFO:               numba: 0.58.1
2025-03-20 18:58:28,039:INFO:            requests: 2.32.3
2025-03-20 18:58:28,039:INFO:          matplotlib: 3.6.0
2025-03-20 18:58:28,039:INFO:          scikitplot: 0.3.7
2025-03-20 18:58:28,039:INFO:         yellowbrick: 1.5
2025-03-20 18:58:28,039:INFO:              plotly: 5.24.1
2025-03-20 18:58:28,039:INFO:    plotly-resampler: Not installed
2025-03-20 18:58:28,039:INFO:             kaleido: 0.2.1
2025-03-20 18:58:28,039:INFO:           schemdraw: 0.15
2025-03-20 18:58:28,039:INFO:         statsmodels: 0.14.1
2025-03-20 18:58:28,039:INFO:              sktime: 0.21.1
2025-03-20 18:58:28,039:INFO:               tbats: 1.1.3
2025-03-20 18:58:28,039:INFO:            pmdarima: 2.0.4
2025-03-20 18:58:28,039:INFO:              psutil: 6.1.0
2025-03-20 18:58:28,039:INFO:          markupsafe: 2.1.5
2025-03-20 18:58:28,039:INFO:             pickle5: Not installed
2025-03-20 18:58:28,039:INFO:         cloudpickle: 2.2.1
2025-03-20 18:58:28,039:INFO:         deprecation: 2.1.0
2025-03-20 18:58:28,039:INFO:              xxhash: 3.5.0
2025-03-20 18:58:28,039:INFO:           wurlitzer: Not installed
2025-03-20 18:58:28,039:INFO:PyCaret optional dependencies:
2025-03-20 18:58:29,325:INFO:                shap: 0.44.1
2025-03-20 18:58:29,325:INFO:           interpret: 0.6.6
2025-03-20 18:58:29,325:INFO:                umap: 0.5.7
2025-03-20 18:58:29,325:INFO:     ydata_profiling: 4.6.0
2025-03-20 18:58:29,326:INFO:  explainerdashboard: 0.4.7
2025-03-20 18:58:29,326:INFO:             autoviz: Not installed
2025-03-20 18:58:29,326:INFO:           fairlearn: 0.7.0
2025-03-20 18:58:29,326:INFO:          deepchecks: Not installed
2025-03-20 18:58:29,326:INFO:             xgboost: 2.1.3
2025-03-20 18:58:29,326:INFO:            catboost: 1.2.7
2025-03-20 18:58:29,326:INFO:              kmodes: 0.12.2
2025-03-20 18:58:29,326:INFO:             mlxtend: 0.23.1
2025-03-20 18:58:29,326:INFO:       statsforecast: 1.5.0
2025-03-20 18:58:29,326:INFO:        tune_sklearn: 0.5.0
2025-03-20 18:58:29,326:INFO:                 ray: 2.10.0
2025-03-20 18:58:29,326:INFO:            hyperopt: 0.2.7
2025-03-20 18:58:29,326:INFO:              optuna: 4.1.0
2025-03-20 18:58:29,326:INFO:               skopt: 0.10.2
2025-03-20 18:58:29,326:INFO:              mlflow: 1.30.1
2025-03-20 18:58:29,326:INFO:              gradio: 3.50.2
2025-03-20 18:58:29,326:INFO:             fastapi: 0.115.5
2025-03-20 18:58:29,326:INFO:             uvicorn: 0.32.1
2025-03-20 18:58:29,326:INFO:              m2cgen: 0.10.0
2025-03-20 18:58:29,326:INFO:           evidently: 0.2.8
2025-03-20 18:58:29,326:INFO:               fugue: 0.8.6
2025-03-20 18:58:29,326:INFO:           streamlit: Not installed
2025-03-20 18:58:29,326:INFO:             prophet: Not installed
2025-03-20 18:58:29,326:INFO:None
2025-03-20 18:58:29,326:INFO:Set up data.
2025-03-20 18:58:29,331:INFO:Set up folding strategy.
2025-03-20 18:58:29,331:INFO:Set up train/test split.
2025-03-20 18:58:29,331:INFO:Set up data.
2025-03-20 18:58:29,336:INFO:Set up index.
2025-03-20 18:58:29,336:INFO:Assigning column types.
2025-03-20 18:58:29,338:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 18:58:29,338:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,340:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,342:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,366:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,385:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,386:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,397:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,399:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,401:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,427:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,446:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,447:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,447:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 18:58:29,449:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,451:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,495:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,496:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,498:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,544:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,545:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,545:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 18:58:29,549:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,593:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,594:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,623:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,642:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,643:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,644:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 18:58:29,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,691:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,692:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,740:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,741:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,741:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 18:58:29,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,790:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,791:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,819:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 18:58:29,838:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,839:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,840:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 18:58:29,886:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,888:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,935:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:29,936:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:29,937:INFO:Preparing preprocessing pipeline...
2025-03-20 18:58:29,937:INFO:Set up simple imputation.
2025-03-20 18:58:29,939:INFO:Set up encoding of categorical features.
2025-03-20 18:58:29,939:INFO:Set up feature normalization.
2025-03-20 18:58:29,939:INFO:Set up column name cleaning.
2025-03-20 18:58:29,988:INFO:Finished creating preprocessing pipeline.
2025-03-20 18:58:29,992:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:58:29,992:INFO:Creating final display dataframe.
2025-03-20 18:58:30,125:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              80c3
2025-03-20 18:58:30,177:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:30,179:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:30,227:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:30,229:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 18:58:30,229:INFO:Logging experiment in loggers
2025-03-20 18:58:30,370:INFO:SubProcess save_model() called ==================================
2025-03-20 18:58:30,378:INFO:Initializing save_model()
2025-03-20 18:58:30,378:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpii0x0qdi\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 18:58:30,378:INFO:Adding model into prep_pipe
2025-03-20 18:58:30,378:WARNING:Only Model saved as it was a pipeline.
2025-03-20 18:58:30,382:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpii0x0qdi\Transformation Pipeline.pkl saved in current working directory
2025-03-20 18:58:30,386:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 18:58:30,386:INFO:save_model() successfully completed......................................
2025-03-20 18:58:30,438:INFO:SubProcess save_model() end ==================================
2025-03-20 18:58:30,444:INFO:setup() successfully completed in 2.73s...............
2025-03-20 18:58:30,444:INFO:Initializing compare_models()
2025-03-20 18:58:30,444:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 18:58:30,444:INFO:Checking exceptions
2025-03-20 18:58:30,445:INFO:Preparing display monitor
2025-03-20 18:58:30,460:INFO:Initializing Linear Regression
2025-03-20 18:58:30,460:INFO:Total runtime is 0.0 minutes
2025-03-20 18:58:30,462:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:30,462:INFO:Initializing create_model()
2025-03-20 18:58:30,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:30,462:INFO:Checking exceptions
2025-03-20 18:58:30,462:INFO:Importing libraries
2025-03-20 18:58:30,462:INFO:Copying training dataset
2025-03-20 18:58:30,464:INFO:Defining folds
2025-03-20 18:58:30,464:INFO:Declaring metric variables
2025-03-20 18:58:30,466:INFO:Importing untrained model
2025-03-20 18:58:30,468:INFO:Linear Regression Imported successfully
2025-03-20 18:58:30,471:INFO:Starting cross validation
2025-03-20 18:58:30,475:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:32,948:INFO:Calculating mean and std
2025-03-20 18:58:32,949:INFO:Creating metrics dataframe
2025-03-20 18:58:32,952:INFO:Uploading results into container
2025-03-20 18:58:32,952:INFO:Uploading model into container now
2025-03-20 18:58:32,952:INFO:_master_model_container: 1
2025-03-20 18:58:32,952:INFO:_display_container: 2
2025-03-20 18:58:32,952:INFO:LinearRegression(n_jobs=-1)
2025-03-20 18:58:32,952:INFO:create_model() successfully completed......................................
2025-03-20 18:58:33,010:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:33,010:INFO:Creating metrics dataframe
2025-03-20 18:58:33,014:INFO:Initializing Lasso Regression
2025-03-20 18:58:33,014:INFO:Total runtime is 0.04258083502451579 minutes
2025-03-20 18:58:33,015:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:33,016:INFO:Initializing create_model()
2025-03-20 18:58:33,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:33,016:INFO:Checking exceptions
2025-03-20 18:58:33,016:INFO:Importing libraries
2025-03-20 18:58:33,016:INFO:Copying training dataset
2025-03-20 18:58:33,018:INFO:Defining folds
2025-03-20 18:58:33,018:INFO:Declaring metric variables
2025-03-20 18:58:33,020:INFO:Importing untrained model
2025-03-20 18:58:33,021:INFO:Lasso Regression Imported successfully
2025-03-20 18:58:33,024:INFO:Starting cross validation
2025-03-20 18:58:33,025:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:35,027:INFO:Calculating mean and std
2025-03-20 18:58:35,028:INFO:Creating metrics dataframe
2025-03-20 18:58:35,029:INFO:Uploading results into container
2025-03-20 18:58:35,030:INFO:Uploading model into container now
2025-03-20 18:58:35,030:INFO:_master_model_container: 2
2025-03-20 18:58:35,030:INFO:_display_container: 2
2025-03-20 18:58:35,030:INFO:Lasso(random_state=888)
2025-03-20 18:58:35,030:INFO:create_model() successfully completed......................................
2025-03-20 18:58:35,087:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:35,087:INFO:Creating metrics dataframe
2025-03-20 18:58:35,091:INFO:Initializing Ridge Regression
2025-03-20 18:58:35,091:INFO:Total runtime is 0.07719846566518149 minutes
2025-03-20 18:58:35,093:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:35,093:INFO:Initializing create_model()
2025-03-20 18:58:35,093:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:35,093:INFO:Checking exceptions
2025-03-20 18:58:35,093:INFO:Importing libraries
2025-03-20 18:58:35,093:INFO:Copying training dataset
2025-03-20 18:58:35,095:INFO:Defining folds
2025-03-20 18:58:35,095:INFO:Declaring metric variables
2025-03-20 18:58:35,096:INFO:Importing untrained model
2025-03-20 18:58:35,098:INFO:Ridge Regression Imported successfully
2025-03-20 18:58:35,101:INFO:Starting cross validation
2025-03-20 18:58:35,102:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:37,090:INFO:Calculating mean and std
2025-03-20 18:58:37,092:INFO:Creating metrics dataframe
2025-03-20 18:58:37,094:INFO:Uploading results into container
2025-03-20 18:58:37,094:INFO:Uploading model into container now
2025-03-20 18:58:37,095:INFO:_master_model_container: 3
2025-03-20 18:58:37,095:INFO:_display_container: 2
2025-03-20 18:58:37,095:INFO:Ridge(random_state=888)
2025-03-20 18:58:37,095:INFO:create_model() successfully completed......................................
2025-03-20 18:58:37,147:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:37,147:INFO:Creating metrics dataframe
2025-03-20 18:58:37,152:INFO:Initializing Elastic Net
2025-03-20 18:58:37,152:INFO:Total runtime is 0.1115429202715556 minutes
2025-03-20 18:58:37,155:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:37,155:INFO:Initializing create_model()
2025-03-20 18:58:37,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:37,155:INFO:Checking exceptions
2025-03-20 18:58:37,155:INFO:Importing libraries
2025-03-20 18:58:37,155:INFO:Copying training dataset
2025-03-20 18:58:37,157:INFO:Defining folds
2025-03-20 18:58:37,157:INFO:Declaring metric variables
2025-03-20 18:58:37,158:INFO:Importing untrained model
2025-03-20 18:58:37,160:INFO:Elastic Net Imported successfully
2025-03-20 18:58:37,163:INFO:Starting cross validation
2025-03-20 18:58:37,164:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:39,138:INFO:Calculating mean and std
2025-03-20 18:58:39,139:INFO:Creating metrics dataframe
2025-03-20 18:58:39,140:INFO:Uploading results into container
2025-03-20 18:58:39,141:INFO:Uploading model into container now
2025-03-20 18:58:39,141:INFO:_master_model_container: 4
2025-03-20 18:58:39,141:INFO:_display_container: 2
2025-03-20 18:58:39,141:INFO:ElasticNet(random_state=888)
2025-03-20 18:58:39,141:INFO:create_model() successfully completed......................................
2025-03-20 18:58:39,198:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:39,199:INFO:Creating metrics dataframe
2025-03-20 18:58:39,204:INFO:Initializing Least Angle Regression
2025-03-20 18:58:39,204:INFO:Total runtime is 0.1457454323768616 minutes
2025-03-20 18:58:39,206:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:39,206:INFO:Initializing create_model()
2025-03-20 18:58:39,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:39,206:INFO:Checking exceptions
2025-03-20 18:58:39,206:INFO:Importing libraries
2025-03-20 18:58:39,206:INFO:Copying training dataset
2025-03-20 18:58:39,208:INFO:Defining folds
2025-03-20 18:58:39,208:INFO:Declaring metric variables
2025-03-20 18:58:39,209:INFO:Importing untrained model
2025-03-20 18:58:39,211:INFO:Least Angle Regression Imported successfully
2025-03-20 18:58:39,214:INFO:Starting cross validation
2025-03-20 18:58:39,215:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:41,170:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.010e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,170:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-03-20 18:58:41,170:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,171:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,171:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.688e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,172:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.707e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,172:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.503e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,172:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.186e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,177:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,177:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,178:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,179:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.114e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,179:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.912e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,179:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.216e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,179:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.848e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,179:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.737e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 18:58:41,201:INFO:Calculating mean and std
2025-03-20 18:58:41,202:INFO:Creating metrics dataframe
2025-03-20 18:58:41,204:INFO:Uploading results into container
2025-03-20 18:58:41,204:INFO:Uploading model into container now
2025-03-20 18:58:41,205:INFO:_master_model_container: 5
2025-03-20 18:58:41,205:INFO:_display_container: 2
2025-03-20 18:58:41,205:INFO:Lars(random_state=888)
2025-03-20 18:58:41,205:INFO:create_model() successfully completed......................................
2025-03-20 18:58:41,261:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:41,262:INFO:Creating metrics dataframe
2025-03-20 18:58:41,267:INFO:Initializing Lasso Least Angle Regression
2025-03-20 18:58:41,267:INFO:Total runtime is 0.18012300332387293 minutes
2025-03-20 18:58:41,268:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:41,268:INFO:Initializing create_model()
2025-03-20 18:58:41,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:41,268:INFO:Checking exceptions
2025-03-20 18:58:41,268:INFO:Importing libraries
2025-03-20 18:58:41,268:INFO:Copying training dataset
2025-03-20 18:58:41,270:INFO:Defining folds
2025-03-20 18:58:41,271:INFO:Declaring metric variables
2025-03-20 18:58:41,272:INFO:Importing untrained model
2025-03-20 18:58:41,273:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 18:58:41,276:INFO:Starting cross validation
2025-03-20 18:58:41,277:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:43,233:INFO:Calculating mean and std
2025-03-20 18:58:43,234:INFO:Creating metrics dataframe
2025-03-20 18:58:43,237:INFO:Uploading results into container
2025-03-20 18:58:43,237:INFO:Uploading model into container now
2025-03-20 18:58:43,238:INFO:_master_model_container: 6
2025-03-20 18:58:43,238:INFO:_display_container: 2
2025-03-20 18:58:43,238:INFO:LassoLars(random_state=888)
2025-03-20 18:58:43,238:INFO:create_model() successfully completed......................................
2025-03-20 18:58:43,298:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:43,298:INFO:Creating metrics dataframe
2025-03-20 18:58:43,303:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 18:58:43,303:INFO:Total runtime is 0.21405363877614345 minutes
2025-03-20 18:58:43,305:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:43,305:INFO:Initializing create_model()
2025-03-20 18:58:43,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:43,305:INFO:Checking exceptions
2025-03-20 18:58:43,305:INFO:Importing libraries
2025-03-20 18:58:43,305:INFO:Copying training dataset
2025-03-20 18:58:43,307:INFO:Defining folds
2025-03-20 18:58:43,307:INFO:Declaring metric variables
2025-03-20 18:58:43,309:INFO:Importing untrained model
2025-03-20 18:58:43,310:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 18:58:43,313:INFO:Starting cross validation
2025-03-20 18:58:43,314:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:45,019:INFO:Calculating mean and std
2025-03-20 18:58:45,020:INFO:Creating metrics dataframe
2025-03-20 18:58:45,022:INFO:Uploading results into container
2025-03-20 18:58:45,022:INFO:Uploading model into container now
2025-03-20 18:58:45,023:INFO:_master_model_container: 7
2025-03-20 18:58:45,023:INFO:_display_container: 2
2025-03-20 18:58:45,023:INFO:OrthogonalMatchingPursuit()
2025-03-20 18:58:45,023:INFO:create_model() successfully completed......................................
2025-03-20 18:58:45,075:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:45,075:INFO:Creating metrics dataframe
2025-03-20 18:58:45,080:INFO:Initializing Bayesian Ridge
2025-03-20 18:58:45,080:INFO:Total runtime is 0.24367970625559493 minutes
2025-03-20 18:58:45,082:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:45,082:INFO:Initializing create_model()
2025-03-20 18:58:45,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:45,083:INFO:Checking exceptions
2025-03-20 18:58:45,083:INFO:Importing libraries
2025-03-20 18:58:45,083:INFO:Copying training dataset
2025-03-20 18:58:45,084:INFO:Defining folds
2025-03-20 18:58:45,084:INFO:Declaring metric variables
2025-03-20 18:58:45,086:INFO:Importing untrained model
2025-03-20 18:58:45,088:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:58:45,091:INFO:Starting cross validation
2025-03-20 18:58:45,092:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:45,158:INFO:Calculating mean and std
2025-03-20 18:58:45,159:INFO:Creating metrics dataframe
2025-03-20 18:58:45,162:INFO:Uploading results into container
2025-03-20 18:58:45,162:INFO:Uploading model into container now
2025-03-20 18:58:45,162:INFO:_master_model_container: 8
2025-03-20 18:58:45,162:INFO:_display_container: 2
2025-03-20 18:58:45,162:INFO:BayesianRidge()
2025-03-20 18:58:45,162:INFO:create_model() successfully completed......................................
2025-03-20 18:58:45,214:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:45,214:INFO:Creating metrics dataframe
2025-03-20 18:58:45,219:INFO:Initializing Passive Aggressive Regressor
2025-03-20 18:58:45,219:INFO:Total runtime is 0.24599754412968958 minutes
2025-03-20 18:58:45,221:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:45,221:INFO:Initializing create_model()
2025-03-20 18:58:45,221:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:45,221:INFO:Checking exceptions
2025-03-20 18:58:45,221:INFO:Importing libraries
2025-03-20 18:58:45,221:INFO:Copying training dataset
2025-03-20 18:58:45,223:INFO:Defining folds
2025-03-20 18:58:45,223:INFO:Declaring metric variables
2025-03-20 18:58:45,225:INFO:Importing untrained model
2025-03-20 18:58:45,226:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 18:58:45,229:INFO:Starting cross validation
2025-03-20 18:58:45,230:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:45,297:INFO:Calculating mean and std
2025-03-20 18:58:45,298:INFO:Creating metrics dataframe
2025-03-20 18:58:45,300:INFO:Uploading results into container
2025-03-20 18:58:45,300:INFO:Uploading model into container now
2025-03-20 18:58:45,300:INFO:_master_model_container: 9
2025-03-20 18:58:45,300:INFO:_display_container: 2
2025-03-20 18:58:45,300:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 18:58:45,300:INFO:create_model() successfully completed......................................
2025-03-20 18:58:45,354:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:45,354:INFO:Creating metrics dataframe
2025-03-20 18:58:45,360:INFO:Initializing Huber Regressor
2025-03-20 18:58:45,360:INFO:Total runtime is 0.2483355522155762 minutes
2025-03-20 18:58:45,361:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:45,362:INFO:Initializing create_model()
2025-03-20 18:58:45,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:45,362:INFO:Checking exceptions
2025-03-20 18:58:45,362:INFO:Importing libraries
2025-03-20 18:58:45,362:INFO:Copying training dataset
2025-03-20 18:58:45,364:INFO:Defining folds
2025-03-20 18:58:45,364:INFO:Declaring metric variables
2025-03-20 18:58:45,365:INFO:Importing untrained model
2025-03-20 18:58:45,367:INFO:Huber Regressor Imported successfully
2025-03-20 18:58:45,371:INFO:Starting cross validation
2025-03-20 18:58:45,372:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:45,415:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:58:45,419:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:58:45,425:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:58:45,427:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:58:45,432:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 18:58:45,451:INFO:Calculating mean and std
2025-03-20 18:58:45,452:INFO:Creating metrics dataframe
2025-03-20 18:58:45,453:INFO:Uploading results into container
2025-03-20 18:58:45,454:INFO:Uploading model into container now
2025-03-20 18:58:45,454:INFO:_master_model_container: 10
2025-03-20 18:58:45,454:INFO:_display_container: 2
2025-03-20 18:58:45,454:INFO:HuberRegressor()
2025-03-20 18:58:45,454:INFO:create_model() successfully completed......................................
2025-03-20 18:58:45,507:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:45,507:INFO:Creating metrics dataframe
2025-03-20 18:58:45,513:INFO:Initializing K Neighbors Regressor
2025-03-20 18:58:45,513:INFO:Total runtime is 0.2508885542551677 minutes
2025-03-20 18:58:45,514:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:45,515:INFO:Initializing create_model()
2025-03-20 18:58:45,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:45,515:INFO:Checking exceptions
2025-03-20 18:58:45,515:INFO:Importing libraries
2025-03-20 18:58:45,515:INFO:Copying training dataset
2025-03-20 18:58:45,517:INFO:Defining folds
2025-03-20 18:58:45,517:INFO:Declaring metric variables
2025-03-20 18:58:45,518:INFO:Importing untrained model
2025-03-20 18:58:45,520:INFO:K Neighbors Regressor Imported successfully
2025-03-20 18:58:45,524:INFO:Starting cross validation
2025-03-20 18:58:45,525:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:45,620:INFO:Calculating mean and std
2025-03-20 18:58:45,621:INFO:Creating metrics dataframe
2025-03-20 18:58:45,623:INFO:Uploading results into container
2025-03-20 18:58:45,623:INFO:Uploading model into container now
2025-03-20 18:58:45,623:INFO:_master_model_container: 11
2025-03-20 18:58:45,623:INFO:_display_container: 2
2025-03-20 18:58:45,624:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 18:58:45,624:INFO:create_model() successfully completed......................................
2025-03-20 18:58:45,677:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:45,677:INFO:Creating metrics dataframe
2025-03-20 18:58:45,683:INFO:Initializing Decision Tree Regressor
2025-03-20 18:58:45,683:INFO:Total runtime is 0.2537278890609742 minutes
2025-03-20 18:58:45,685:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:45,685:INFO:Initializing create_model()
2025-03-20 18:58:45,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:45,685:INFO:Checking exceptions
2025-03-20 18:58:45,685:INFO:Importing libraries
2025-03-20 18:58:45,685:INFO:Copying training dataset
2025-03-20 18:58:45,687:INFO:Defining folds
2025-03-20 18:58:45,687:INFO:Declaring metric variables
2025-03-20 18:58:45,689:INFO:Importing untrained model
2025-03-20 18:58:45,691:INFO:Decision Tree Regressor Imported successfully
2025-03-20 18:58:45,694:INFO:Starting cross validation
2025-03-20 18:58:45,694:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:45,774:INFO:Calculating mean and std
2025-03-20 18:58:45,775:INFO:Creating metrics dataframe
2025-03-20 18:58:45,777:INFO:Uploading results into container
2025-03-20 18:58:45,777:INFO:Uploading model into container now
2025-03-20 18:58:45,777:INFO:_master_model_container: 12
2025-03-20 18:58:45,778:INFO:_display_container: 2
2025-03-20 18:58:45,778:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 18:58:45,778:INFO:create_model() successfully completed......................................
2025-03-20 18:58:45,830:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:45,830:INFO:Creating metrics dataframe
2025-03-20 18:58:45,836:INFO:Initializing Random Forest Regressor
2025-03-20 18:58:45,836:INFO:Total runtime is 0.2562759637832642 minutes
2025-03-20 18:58:45,838:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:45,838:INFO:Initializing create_model()
2025-03-20 18:58:45,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:45,838:INFO:Checking exceptions
2025-03-20 18:58:45,839:INFO:Importing libraries
2025-03-20 18:58:45,839:INFO:Copying training dataset
2025-03-20 18:58:45,840:INFO:Defining folds
2025-03-20 18:58:45,840:INFO:Declaring metric variables
2025-03-20 18:58:45,842:INFO:Importing untrained model
2025-03-20 18:58:45,843:INFO:Random Forest Regressor Imported successfully
2025-03-20 18:58:45,846:INFO:Starting cross validation
2025-03-20 18:58:45,847:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:46,190:INFO:Calculating mean and std
2025-03-20 18:58:46,191:INFO:Creating metrics dataframe
2025-03-20 18:58:46,192:INFO:Uploading results into container
2025-03-20 18:58:46,193:INFO:Uploading model into container now
2025-03-20 18:58:46,193:INFO:_master_model_container: 13
2025-03-20 18:58:46,193:INFO:_display_container: 2
2025-03-20 18:58:46,193:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:58:46,193:INFO:create_model() successfully completed......................................
2025-03-20 18:58:46,245:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:46,245:INFO:Creating metrics dataframe
2025-03-20 18:58:46,251:INFO:Initializing Extra Trees Regressor
2025-03-20 18:58:46,251:INFO:Total runtime is 0.2631909092267355 minutes
2025-03-20 18:58:46,253:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:46,253:INFO:Initializing create_model()
2025-03-20 18:58:46,253:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:46,253:INFO:Checking exceptions
2025-03-20 18:58:46,253:INFO:Importing libraries
2025-03-20 18:58:46,253:INFO:Copying training dataset
2025-03-20 18:58:46,255:INFO:Defining folds
2025-03-20 18:58:46,255:INFO:Declaring metric variables
2025-03-20 18:58:46,256:INFO:Importing untrained model
2025-03-20 18:58:46,258:INFO:Extra Trees Regressor Imported successfully
2025-03-20 18:58:46,261:INFO:Starting cross validation
2025-03-20 18:58:46,262:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:46,452:INFO:Calculating mean and std
2025-03-20 18:58:46,453:INFO:Creating metrics dataframe
2025-03-20 18:58:46,454:INFO:Uploading results into container
2025-03-20 18:58:46,455:INFO:Uploading model into container now
2025-03-20 18:58:46,455:INFO:_master_model_container: 14
2025-03-20 18:58:46,455:INFO:_display_container: 2
2025-03-20 18:58:46,455:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:58:46,455:INFO:create_model() successfully completed......................................
2025-03-20 18:58:46,506:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:46,506:INFO:Creating metrics dataframe
2025-03-20 18:58:46,516:INFO:Initializing AdaBoost Regressor
2025-03-20 18:58:46,516:INFO:Total runtime is 0.26761048237482715 minutes
2025-03-20 18:58:46,519:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:46,519:INFO:Initializing create_model()
2025-03-20 18:58:46,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:46,519:INFO:Checking exceptions
2025-03-20 18:58:46,519:INFO:Importing libraries
2025-03-20 18:58:46,519:INFO:Copying training dataset
2025-03-20 18:58:46,522:INFO:Defining folds
2025-03-20 18:58:46,523:INFO:Declaring metric variables
2025-03-20 18:58:46,525:INFO:Importing untrained model
2025-03-20 18:58:46,527:INFO:AdaBoost Regressor Imported successfully
2025-03-20 18:58:46,531:INFO:Starting cross validation
2025-03-20 18:58:46,532:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:46,729:INFO:Calculating mean and std
2025-03-20 18:58:46,730:INFO:Creating metrics dataframe
2025-03-20 18:58:46,731:INFO:Uploading results into container
2025-03-20 18:58:46,732:INFO:Uploading model into container now
2025-03-20 18:58:46,732:INFO:_master_model_container: 15
2025-03-20 18:58:46,732:INFO:_display_container: 2
2025-03-20 18:58:46,732:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 18:58:46,732:INFO:create_model() successfully completed......................................
2025-03-20 18:58:46,783:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:46,783:INFO:Creating metrics dataframe
2025-03-20 18:58:46,789:INFO:Initializing Gradient Boosting Regressor
2025-03-20 18:58:46,789:INFO:Total runtime is 0.27215497891108203 minutes
2025-03-20 18:58:46,791:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:46,791:INFO:Initializing create_model()
2025-03-20 18:58:46,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:46,791:INFO:Checking exceptions
2025-03-20 18:58:46,791:INFO:Importing libraries
2025-03-20 18:58:46,791:INFO:Copying training dataset
2025-03-20 18:58:46,793:INFO:Defining folds
2025-03-20 18:58:46,793:INFO:Declaring metric variables
2025-03-20 18:58:46,794:INFO:Importing untrained model
2025-03-20 18:58:46,796:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:58:46,799:INFO:Starting cross validation
2025-03-20 18:58:46,800:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:47,406:INFO:Calculating mean and std
2025-03-20 18:58:47,407:INFO:Creating metrics dataframe
2025-03-20 18:58:47,409:INFO:Uploading results into container
2025-03-20 18:58:47,409:INFO:Uploading model into container now
2025-03-20 18:58:47,410:INFO:_master_model_container: 16
2025-03-20 18:58:47,410:INFO:_display_container: 2
2025-03-20 18:58:47,410:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:58:47,410:INFO:create_model() successfully completed......................................
2025-03-20 18:58:47,463:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:47,464:INFO:Creating metrics dataframe
2025-03-20 18:58:47,470:INFO:Initializing Extreme Gradient Boosting
2025-03-20 18:58:47,470:INFO:Total runtime is 0.28351207574208587 minutes
2025-03-20 18:58:47,472:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:47,472:INFO:Initializing create_model()
2025-03-20 18:58:47,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:47,472:INFO:Checking exceptions
2025-03-20 18:58:47,472:INFO:Importing libraries
2025-03-20 18:58:47,472:INFO:Copying training dataset
2025-03-20 18:58:47,474:INFO:Defining folds
2025-03-20 18:58:47,474:INFO:Declaring metric variables
2025-03-20 18:58:47,476:INFO:Importing untrained model
2025-03-20 18:58:47,478:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 18:58:47,482:INFO:Starting cross validation
2025-03-20 18:58:47,483:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:47,961:INFO:Calculating mean and std
2025-03-20 18:58:47,962:INFO:Creating metrics dataframe
2025-03-20 18:58:47,963:INFO:Uploading results into container
2025-03-20 18:58:47,963:INFO:Uploading model into container now
2025-03-20 18:58:47,964:INFO:_master_model_container: 17
2025-03-20 18:58:47,964:INFO:_display_container: 2
2025-03-20 18:58:47,964:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 18:58:47,964:INFO:create_model() successfully completed......................................
2025-03-20 18:58:48,017:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:48,017:INFO:Creating metrics dataframe
2025-03-20 18:58:48,025:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 18:58:48,025:INFO:Total runtime is 0.2927507758140565 minutes
2025-03-20 18:58:48,028:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:48,028:INFO:Initializing create_model()
2025-03-20 18:58:48,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:48,028:INFO:Checking exceptions
2025-03-20 18:58:48,028:INFO:Importing libraries
2025-03-20 18:58:48,028:INFO:Copying training dataset
2025-03-20 18:58:48,032:INFO:Defining folds
2025-03-20 18:58:48,032:INFO:Declaring metric variables
2025-03-20 18:58:48,035:INFO:Importing untrained model
2025-03-20 18:58:48,038:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:58:48,043:INFO:Starting cross validation
2025-03-20 18:58:48,045:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:48,515:INFO:Calculating mean and std
2025-03-20 18:58:48,516:INFO:Creating metrics dataframe
2025-03-20 18:58:48,518:INFO:Uploading results into container
2025-03-20 18:58:48,518:INFO:Uploading model into container now
2025-03-20 18:58:48,519:INFO:_master_model_container: 18
2025-03-20 18:58:48,519:INFO:_display_container: 2
2025-03-20 18:58:48,519:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:58:48,519:INFO:create_model() successfully completed......................................
2025-03-20 18:58:48,575:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:48,575:INFO:Creating metrics dataframe
2025-03-20 18:58:48,584:INFO:Initializing CatBoost Regressor
2025-03-20 18:58:48,584:INFO:Total runtime is 0.30207980871200574 minutes
2025-03-20 18:58:48,586:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:48,587:INFO:Initializing create_model()
2025-03-20 18:58:48,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:48,587:INFO:Checking exceptions
2025-03-20 18:58:48,587:INFO:Importing libraries
2025-03-20 18:58:48,587:INFO:Copying training dataset
2025-03-20 18:58:48,589:INFO:Defining folds
2025-03-20 18:58:48,589:INFO:Declaring metric variables
2025-03-20 18:58:48,591:INFO:Importing untrained model
2025-03-20 18:58:48,593:INFO:CatBoost Regressor Imported successfully
2025-03-20 18:58:48,597:INFO:Starting cross validation
2025-03-20 18:58:48,598:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:50,932:INFO:Calculating mean and std
2025-03-20 18:58:50,933:INFO:Creating metrics dataframe
2025-03-20 18:58:50,934:INFO:Uploading results into container
2025-03-20 18:58:50,935:INFO:Uploading model into container now
2025-03-20 18:58:50,935:INFO:_master_model_container: 19
2025-03-20 18:58:50,935:INFO:_display_container: 2
2025-03-20 18:58:50,935:INFO:<catboost.core.CatBoostRegressor object at 0x0000022BF96E28E0>
2025-03-20 18:58:50,935:INFO:create_model() successfully completed......................................
2025-03-20 18:58:50,990:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:50,990:INFO:Creating metrics dataframe
2025-03-20 18:58:50,997:INFO:Initializing Dummy Regressor
2025-03-20 18:58:50,997:INFO:Total runtime is 0.3422908902168275 minutes
2025-03-20 18:58:50,999:INFO:SubProcess create_model() called ==================================
2025-03-20 18:58:50,999:INFO:Initializing create_model()
2025-03-20 18:58:50,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF2EA3AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:50,999:INFO:Checking exceptions
2025-03-20 18:58:50,999:INFO:Importing libraries
2025-03-20 18:58:50,999:INFO:Copying training dataset
2025-03-20 18:58:51,000:INFO:Defining folds
2025-03-20 18:58:51,001:INFO:Declaring metric variables
2025-03-20 18:58:51,002:INFO:Importing untrained model
2025-03-20 18:58:51,004:INFO:Dummy Regressor Imported successfully
2025-03-20 18:58:51,007:INFO:Starting cross validation
2025-03-20 18:58:51,007:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:58:51,071:INFO:Calculating mean and std
2025-03-20 18:58:51,072:INFO:Creating metrics dataframe
2025-03-20 18:58:51,073:INFO:Uploading results into container
2025-03-20 18:58:51,074:INFO:Uploading model into container now
2025-03-20 18:58:51,074:INFO:_master_model_container: 20
2025-03-20 18:58:51,074:INFO:_display_container: 2
2025-03-20 18:58:51,074:INFO:DummyRegressor()
2025-03-20 18:58:51,074:INFO:create_model() successfully completed......................................
2025-03-20 18:58:51,126:INFO:SubProcess create_model() end ==================================
2025-03-20 18:58:51,126:INFO:Creating metrics dataframe
2025-03-20 18:58:51,136:INFO:Initializing create_model()
2025-03-20 18:58:51,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:51,136:INFO:Checking exceptions
2025-03-20 18:58:51,137:INFO:Importing libraries
2025-03-20 18:58:51,137:INFO:Copying training dataset
2025-03-20 18:58:51,138:INFO:Defining folds
2025-03-20 18:58:51,138:INFO:Declaring metric variables
2025-03-20 18:58:51,139:INFO:Importing untrained model
2025-03-20 18:58:51,139:INFO:Declaring custom model
2025-03-20 18:58:51,139:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:58:51,139:INFO:Cross validation set to False
2025-03-20 18:58:51,139:INFO:Fitting Model
2025-03-20 18:58:51,178:INFO:BayesianRidge()
2025-03-20 18:58:51,178:INFO:create_model() successfully completed......................................
2025-03-20 18:58:51,228:INFO:Creating Dashboard logs
2025-03-20 18:58:51,230:INFO:Model: Bayesian Ridge
2025-03-20 18:58:51,246:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:58:51,276:INFO:Initializing predict_model()
2025-03-20 18:58:51,276:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BF7ECE160>)
2025-03-20 18:58:51,276:INFO:Checking exceptions
2025-03-20 18:58:51,276:INFO:Preloading libraries
2025-03-20 18:58:51,395:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 18:58:51,408:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:51,410:INFO:Initializing create_model()
2025-03-20 18:58:51,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:51,410:INFO:Checking exceptions
2025-03-20 18:58:51,411:INFO:Importing libraries
2025-03-20 18:58:51,411:INFO:Copying training dataset
2025-03-20 18:58:51,413:INFO:Defining folds
2025-03-20 18:58:51,413:INFO:Declaring metric variables
2025-03-20 18:58:51,413:INFO:Importing untrained model
2025-03-20 18:58:51,413:INFO:Declaring custom model
2025-03-20 18:58:51,413:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 18:58:51,414:INFO:Cross validation set to False
2025-03-20 18:58:51,414:INFO:Fitting Model
2025-03-20 18:58:52,061:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 18:58:52,061:INFO:create_model() successfully completed......................................
2025-03-20 18:58:52,111:INFO:Creating Dashboard logs
2025-03-20 18:58:52,113:INFO:Model: Gradient Boosting Regressor
2025-03-20 18:58:52,130:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:58:52,170:INFO:Initializing predict_model()
2025-03-20 18:58:52,171:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BF9725430>)
2025-03-20 18:58:52,171:INFO:Checking exceptions
2025-03-20 18:58:52,171:INFO:Preloading libraries
2025-03-20 18:58:52,321:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:52,324:INFO:Initializing create_model()
2025-03-20 18:58:52,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:52,324:INFO:Checking exceptions
2025-03-20 18:58:52,324:INFO:Importing libraries
2025-03-20 18:58:52,325:INFO:Copying training dataset
2025-03-20 18:58:52,326:INFO:Defining folds
2025-03-20 18:58:52,326:INFO:Declaring metric variables
2025-03-20 18:58:52,326:INFO:Importing untrained model
2025-03-20 18:58:52,326:INFO:Declaring custom model
2025-03-20 18:58:52,327:INFO:Ridge Regression Imported successfully
2025-03-20 18:58:52,327:INFO:Cross validation set to False
2025-03-20 18:58:52,327:INFO:Fitting Model
2025-03-20 18:58:52,356:INFO:Ridge(random_state=888)
2025-03-20 18:58:52,356:INFO:create_model() successfully completed......................................
2025-03-20 18:58:52,409:INFO:Creating Dashboard logs
2025-03-20 18:58:52,411:INFO:Model: Ridge Regression
2025-03-20 18:58:52,427:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 18:58:52,469:INFO:Initializing predict_model()
2025-03-20 18:58:52,469:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BF9720550>)
2025-03-20 18:58:52,469:INFO:Checking exceptions
2025-03-20 18:58:52,469:INFO:Preloading libraries
2025-03-20 18:58:52,596:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:52,598:INFO:Initializing create_model()
2025-03-20 18:58:52,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:58:52,598:INFO:Checking exceptions
2025-03-20 18:58:52,599:INFO:Importing libraries
2025-03-20 18:58:52,599:INFO:Copying training dataset
2025-03-20 18:58:52,601:INFO:Defining folds
2025-03-20 18:58:52,601:INFO:Declaring metric variables
2025-03-20 18:58:52,601:INFO:Importing untrained model
2025-03-20 18:58:52,601:INFO:Declaring custom model
2025-03-20 18:58:52,601:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 18:58:52,602:INFO:Cross validation set to False
2025-03-20 18:58:52,602:INFO:Fitting Model
2025-03-20 18:58:52,633:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 18:58:52,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.
2025-03-20 18:58:52,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 18:58:52,634:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 18:58:52,635:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 18:58:52,635:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 18:58:52,721:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 18:58:52,721:INFO:create_model() successfully completed......................................
2025-03-20 18:58:52,781:INFO:Creating Dashboard logs
2025-03-20 18:58:52,783:INFO:Model: Light Gradient Boosting Machine
2025-03-20 18:58:52,805:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 18:58:52,862:INFO:Initializing predict_model()
2025-03-20 18:58:52,862:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BF92E5700>)
2025-03-20 18:58:52,862:INFO:Checking exceptions
2025-03-20 18:58:52,862:INFO:Preloading libraries
2025-03-20 18:58:52,999:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,000:INFO:Creating Dashboard logs
2025-03-20 18:58:53,002:INFO:Model: Extreme Gradient Boosting
2025-03-20 18:58:53,027:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 18:58:53,123:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,123:INFO:Creating Dashboard logs
2025-03-20 18:58:53,125:INFO:Model: Random Forest Regressor
2025-03-20 18:58:53,144:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 18:58:53,220:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,220:INFO:Creating Dashboard logs
2025-03-20 18:58:53,222:INFO:Model: AdaBoost Regressor
2025-03-20 18:58:53,237:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 18:58:53,313:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,314:INFO:Creating Dashboard logs
2025-03-20 18:58:53,316:INFO:Model: CatBoost Regressor
2025-03-20 18:58:53,332:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 18:58:53,332:INFO:Logged params: {}
2025-03-20 18:58:53,410:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x0000022BF96E28E0> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,411:INFO:Creating Dashboard logs
2025-03-20 18:58:53,413:INFO:Model: Extra Trees Regressor
2025-03-20 18:58:53,428:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 18:58:53,521:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,522:INFO:Creating Dashboard logs
2025-03-20 18:58:53,523:INFO:Model: Decision Tree Regressor
2025-03-20 18:58:53,539:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 18:58:53,638:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,638:INFO:Creating Dashboard logs
2025-03-20 18:58:53,640:INFO:Model: Passive Aggressive Regressor
2025-03-20 18:58:53,655:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 18:58:53,762:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,763:INFO:Creating Dashboard logs
2025-03-20 18:58:53,765:INFO:Model: Huber Regressor
2025-03-20 18:58:53,781:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 18:58:53,891:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:53,891:INFO:Creating Dashboard logs
2025-03-20 18:58:53,893:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 18:58:53,908:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 18:58:54,023:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:54,024:INFO:Creating Dashboard logs
2025-03-20 18:58:54,026:INFO:Model: K Neighbors Regressor
2025-03-20 18:58:54,042:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 18:58:54,166:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:54,166:INFO:Creating Dashboard logs
2025-03-20 18:58:54,168:INFO:Model: Elastic Net
2025-03-20 18:58:54,184:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 18:58:54,309:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:54,309:INFO:Creating Dashboard logs
2025-03-20 18:58:54,311:INFO:Model: Lasso Regression
2025-03-20 18:58:54,327:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 18:58:54,460:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:54,460:INFO:Creating Dashboard logs
2025-03-20 18:58:54,462:INFO:Model: Lasso Least Angle Regression
2025-03-20 18:58:54,478:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 18:58:54,617:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:54,618:INFO:Creating Dashboard logs
2025-03-20 18:58:54,619:INFO:Model: Dummy Regressor
2025-03-20 18:58:54,636:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 18:58:54,779:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:54,779:INFO:Creating Dashboard logs
2025-03-20 18:58:54,781:INFO:Model: Linear Regression
2025-03-20 18:58:54,798:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 18:58:54,955:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:54,956:INFO:Creating Dashboard logs
2025-03-20 18:58:54,958:INFO:Model: Least Angle Regression
2025-03-20 18:58:54,974:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 18:58:55,129:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:58:55,138:INFO:_master_model_container: 20
2025-03-20 18:58:55,138:INFO:_display_container: 2
2025-03-20 18:58:55,139:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888)]
2025-03-20 18:58:55,139:INFO:compare_models() successfully completed......................................
2025-03-20 18:58:55,160:INFO:Initializing tune_model()
2025-03-20 18:58:55,160:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>)
2025-03-20 18:58:55,160:INFO:Checking exceptions
2025-03-20 18:58:55,160:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:58:55,205:INFO:Copying training dataset
2025-03-20 18:58:55,208:INFO:Checking base model
2025-03-20 18:58:55,208:INFO:Base model : Bayesian Ridge
2025-03-20 18:58:55,209:INFO:Declaring metric variables
2025-03-20 18:58:55,211:INFO:Defining Hyperparameters
2025-03-20 18:58:55,268:INFO:Tuning with n_jobs=-1
2025-03-20 18:58:55,268:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:58:55,268:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:58:55,268:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:58:55,273:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:58:55,273:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:58:55,274:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 18:59:20,443:INFO:best_params: {'actual_estimator__alpha_1': 2.7790528007118683e-05, 'actual_estimator__alpha_2': 1.2060302135926544e-08, 'actual_estimator__lambda_1': 0.985795119194573, 'actual_estimator__lambda_2': 1.8818387861796063e-09, 'actual_estimator__compute_score': True, 'actual_estimator__fit_intercept': True}
2025-03-20 18:59:20,447:INFO:Hyperparameter search completed
2025-03-20 18:59:20,447:INFO:SubProcess create_model() called ==================================
2025-03-20 18:59:20,447:INFO:Initializing create_model()
2025-03-20 18:59:20,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF7B082E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 2.7790528007118683e-05, 'alpha_2': 1.2060302135926544e-08, 'lambda_1': 0.985795119194573, 'lambda_2': 1.8818387861796063e-09, 'compute_score': True, 'fit_intercept': True})
2025-03-20 18:59:20,448:INFO:Checking exceptions
2025-03-20 18:59:20,448:INFO:Importing libraries
2025-03-20 18:59:20,448:INFO:Copying training dataset
2025-03-20 18:59:20,450:INFO:Defining folds
2025-03-20 18:59:20,450:INFO:Declaring metric variables
2025-03-20 18:59:20,452:INFO:Importing untrained model
2025-03-20 18:59:20,453:INFO:Declaring custom model
2025-03-20 18:59:20,455:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:59:20,458:INFO:Starting cross validation
2025-03-20 18:59:20,459:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:59:20,540:INFO:Calculating mean and std
2025-03-20 18:59:20,540:INFO:Creating metrics dataframe
2025-03-20 18:59:20,543:INFO:Finalizing model
2025-03-20 18:59:20,579:INFO:Uploading results into container
2025-03-20 18:59:20,579:INFO:Uploading model into container now
2025-03-20 18:59:20,580:INFO:_master_model_container: 21
2025-03-20 18:59:20,580:INFO:_display_container: 3
2025-03-20 18:59:20,580:INFO:BayesianRidge(alpha_1=2.7790528007118683e-05, alpha_2=1.2060302135926544e-08,
              compute_score=True, lambda_1=0.985795119194573,
              lambda_2=1.8818387861796063e-09)
2025-03-20 18:59:20,580:INFO:create_model() successfully completed......................................
2025-03-20 18:59:20,636:INFO:SubProcess create_model() end ==================================
2025-03-20 18:59:20,636:INFO:choose_better activated
2025-03-20 18:59:20,638:INFO:SubProcess create_model() called ==================================
2025-03-20 18:59:20,638:INFO:Initializing create_model()
2025-03-20 18:59:20,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 18:59:20,638:INFO:Checking exceptions
2025-03-20 18:59:20,639:INFO:Importing libraries
2025-03-20 18:59:20,639:INFO:Copying training dataset
2025-03-20 18:59:20,641:INFO:Defining folds
2025-03-20 18:59:20,641:INFO:Declaring metric variables
2025-03-20 18:59:20,641:INFO:Importing untrained model
2025-03-20 18:59:20,641:INFO:Declaring custom model
2025-03-20 18:59:20,641:INFO:Bayesian Ridge Imported successfully
2025-03-20 18:59:20,641:INFO:Starting cross validation
2025-03-20 18:59:20,642:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 18:59:20,710:INFO:Calculating mean and std
2025-03-20 18:59:20,710:INFO:Creating metrics dataframe
2025-03-20 18:59:20,711:INFO:Finalizing model
2025-03-20 18:59:20,745:INFO:Uploading results into container
2025-03-20 18:59:20,745:INFO:Uploading model into container now
2025-03-20 18:59:20,745:INFO:_master_model_container: 22
2025-03-20 18:59:20,745:INFO:_display_container: 4
2025-03-20 18:59:20,745:INFO:BayesianRidge()
2025-03-20 18:59:20,745:INFO:create_model() successfully completed......................................
2025-03-20 18:59:20,800:INFO:SubProcess create_model() end ==================================
2025-03-20 18:59:20,800:INFO:BayesianRidge() result for MAPE is 0.0211
2025-03-20 18:59:20,801:INFO:BayesianRidge(alpha_1=2.7790528007118683e-05, alpha_2=1.2060302135926544e-08,
              compute_score=True, lambda_1=0.985795119194573,
              lambda_2=1.8818387861796063e-09) result for MAPE is 0.0211
2025-03-20 18:59:20,801:INFO:BayesianRidge() is best model
2025-03-20 18:59:20,801:INFO:choose_better completed
2025-03-20 18:59:20,801:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 18:59:20,801:INFO:Creating Dashboard logs
2025-03-20 18:59:20,804:INFO:Model: Bayesian Ridge
2025-03-20 18:59:20,824:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 18:59:20,990:INFO:Initializing predict_model()
2025-03-20 18:59:20,990:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BFEA2D160>)
2025-03-20 18:59:20,990:INFO:Checking exceptions
2025-03-20 18:59:20,990:INFO:Preloading libraries
2025-03-20 18:59:21,132:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 18:59:21,137:INFO:_master_model_container: 22
2025-03-20 18:59:21,137:INFO:_display_container: 3
2025-03-20 18:59:21,137:INFO:BayesianRidge()
2025-03-20 18:59:21,137:INFO:tune_model() successfully completed......................................
2025-03-20 18:59:21,195:INFO:Initializing predict_model()
2025-03-20 18:59:21,195:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022B90182F70>)
2025-03-20 18:59:21,195:INFO:Checking exceptions
2025-03-20 18:59:21,195:INFO:Preloading libraries
2025-03-20 18:59:21,324:INFO:Initializing tune_model()
2025-03-20 18:59:21,324:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>)
2025-03-20 18:59:21,324:INFO:Checking exceptions
2025-03-20 18:59:21,325:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 18:59:21,335:INFO:Copying training dataset
2025-03-20 18:59:21,337:INFO:Checking base model
2025-03-20 18:59:21,337:INFO:Base model : Gradient Boosting Regressor
2025-03-20 18:59:21,339:INFO:Declaring metric variables
2025-03-20 18:59:21,341:INFO:Defining Hyperparameters
2025-03-20 18:59:21,398:INFO:Tuning with n_jobs=-1
2025-03-20 18:59:21,398:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:59:21,398:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 18:59:21,399:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 18:59:21,399:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 18:59:21,399:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 18:59:21,399:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:00:16,654:INFO:best_params: {'actual_estimator__n_estimators': 97, 'actual_estimator__learning_rate': 0.11406876138346284, 'actual_estimator__subsample': 0.8035599664827586, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 1, 'actual_estimator__max_features': 0.7353917996766489, 'actual_estimator__min_impurity_decrease': 1.7138164846715253e-06}
2025-03-20 19:00:16,658:INFO:Hyperparameter search completed
2025-03-20 19:00:16,658:INFO:SubProcess create_model() called ==================================
2025-03-20 19:00:16,659:INFO:Initializing create_model()
2025-03-20 19:00:16,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF7484430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 97, 'learning_rate': 0.11406876138346284, 'subsample': 0.8035599664827586, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 1, 'max_features': 0.7353917996766489, 'min_impurity_decrease': 1.7138164846715253e-06})
2025-03-20 19:00:16,659:INFO:Checking exceptions
2025-03-20 19:00:16,659:INFO:Importing libraries
2025-03-20 19:00:16,659:INFO:Copying training dataset
2025-03-20 19:00:16,660:INFO:Defining folds
2025-03-20 19:00:16,660:INFO:Declaring metric variables
2025-03-20 19:00:16,662:INFO:Importing untrained model
2025-03-20 19:00:16,662:INFO:Declaring custom model
2025-03-20 19:00:16,664:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:00:16,667:INFO:Starting cross validation
2025-03-20 19:00:16,667:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:00:16,861:INFO:Calculating mean and std
2025-03-20 19:00:16,862:INFO:Creating metrics dataframe
2025-03-20 19:00:16,865:INFO:Finalizing model
2025-03-20 19:00:17,033:INFO:Uploading results into container
2025-03-20 19:00:17,033:INFO:Uploading model into container now
2025-03-20 19:00:17,033:INFO:_master_model_container: 23
2025-03-20 19:00:17,033:INFO:_display_container: 5
2025-03-20 19:00:17,034:INFO:GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586)
2025-03-20 19:00:17,034:INFO:create_model() successfully completed......................................
2025-03-20 19:00:17,087:INFO:SubProcess create_model() end ==================================
2025-03-20 19:00:17,087:INFO:choose_better activated
2025-03-20 19:00:17,089:INFO:SubProcess create_model() called ==================================
2025-03-20 19:00:17,090:INFO:Initializing create_model()
2025-03-20 19:00:17,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:00:17,090:INFO:Checking exceptions
2025-03-20 19:00:17,091:INFO:Importing libraries
2025-03-20 19:00:17,091:INFO:Copying training dataset
2025-03-20 19:00:17,093:INFO:Defining folds
2025-03-20 19:00:17,093:INFO:Declaring metric variables
2025-03-20 19:00:17,093:INFO:Importing untrained model
2025-03-20 19:00:17,093:INFO:Declaring custom model
2025-03-20 19:00:17,093:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:00:17,093:INFO:Starting cross validation
2025-03-20 19:00:17,094:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:00:17,693:INFO:Calculating mean and std
2025-03-20 19:00:17,693:INFO:Creating metrics dataframe
2025-03-20 19:00:17,694:INFO:Finalizing model
2025-03-20 19:00:18,341:INFO:Uploading results into container
2025-03-20 19:00:18,341:INFO:Uploading model into container now
2025-03-20 19:00:18,342:INFO:_master_model_container: 24
2025-03-20 19:00:18,342:INFO:_display_container: 6
2025-03-20 19:00:18,342:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:00:18,342:INFO:create_model() successfully completed......................................
2025-03-20 19:00:18,394:INFO:SubProcess create_model() end ==================================
2025-03-20 19:00:18,394:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.0217
2025-03-20 19:00:18,395:INFO:GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586) result for MAPE is 0.0212
2025-03-20 19:00:18,395:INFO:GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586) is best model
2025-03-20 19:00:18,395:INFO:choose_better completed
2025-03-20 19:00:18,395:INFO:Creating Dashboard logs
2025-03-20 19:00:18,397:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:00:18,415:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.11406876138346284, 'loss': 'squared_error', 'max_depth': 1, 'max_features': 0.7353917996766489, 'max_leaf_nodes': None, 'min_impurity_decrease': 1.7138164846715253e-06, 'min_samples_leaf': 1, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 97, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.8035599664827586, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:00:18,593:INFO:Initializing predict_model()
2025-03-20 19:00:18,593:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BFEAE1160>)
2025-03-20 19:00:18,593:INFO:Checking exceptions
2025-03-20 19:00:18,593:INFO:Preloading libraries
2025-03-20 19:00:18,731:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:00:18,736:INFO:_master_model_container: 24
2025-03-20 19:00:18,736:INFO:_display_container: 5
2025-03-20 19:00:18,736:INFO:GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586)
2025-03-20 19:00:18,736:INFO:tune_model() successfully completed......................................
2025-03-20 19:00:18,791:INFO:Initializing predict_model()
2025-03-20 19:00:18,791:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BF91C8C10>)
2025-03-20 19:00:18,791:INFO:Checking exceptions
2025-03-20 19:00:18,791:INFO:Preloading libraries
2025-03-20 19:00:18,912:INFO:Initializing tune_model()
2025-03-20 19:00:18,913:INFO:tune_model(estimator=Ridge(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>)
2025-03-20 19:00:18,913:INFO:Checking exceptions
2025-03-20 19:00:18,913:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:00:18,921:INFO:Copying training dataset
2025-03-20 19:00:18,923:INFO:Checking base model
2025-03-20 19:00:18,923:INFO:Base model : Ridge Regression
2025-03-20 19:00:18,926:INFO:Declaring metric variables
2025-03-20 19:00:18,928:INFO:Defining Hyperparameters
2025-03-20 19:00:18,994:INFO:Tuning with n_jobs=-1
2025-03-20 19:00:18,995:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:00:18,995:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:00:18,995:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:00:18,995:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:00:18,995:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:00:18,995:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:00:41,388:INFO:best_params: {'actual_estimator__alpha': 0.14659564883826065, 'actual_estimator__fit_intercept': True}
2025-03-20 19:00:41,392:INFO:Hyperparameter search completed
2025-03-20 19:00:41,392:INFO:SubProcess create_model() called ==================================
2025-03-20 19:00:41,393:INFO:Initializing create_model()
2025-03-20 19:00:41,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF91BE220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 0.14659564883826065, 'fit_intercept': True})
2025-03-20 19:00:41,393:INFO:Checking exceptions
2025-03-20 19:00:41,393:INFO:Importing libraries
2025-03-20 19:00:41,393:INFO:Copying training dataset
2025-03-20 19:00:41,395:INFO:Defining folds
2025-03-20 19:00:41,395:INFO:Declaring metric variables
2025-03-20 19:00:41,396:INFO:Importing untrained model
2025-03-20 19:00:41,396:INFO:Declaring custom model
2025-03-20 19:00:41,398:INFO:Ridge Regression Imported successfully
2025-03-20 19:00:41,401:INFO:Starting cross validation
2025-03-20 19:00:41,401:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:00:41,465:INFO:Calculating mean and std
2025-03-20 19:00:41,466:INFO:Creating metrics dataframe
2025-03-20 19:00:41,468:INFO:Finalizing model
2025-03-20 19:00:41,499:INFO:Uploading results into container
2025-03-20 19:00:41,500:INFO:Uploading model into container now
2025-03-20 19:00:41,500:INFO:_master_model_container: 25
2025-03-20 19:00:41,500:INFO:_display_container: 7
2025-03-20 19:00:41,500:INFO:Ridge(alpha=0.14659564883826065, random_state=888)
2025-03-20 19:00:41,500:INFO:create_model() successfully completed......................................
2025-03-20 19:00:41,556:INFO:SubProcess create_model() end ==================================
2025-03-20 19:00:41,556:INFO:choose_better activated
2025-03-20 19:00:41,558:INFO:SubProcess create_model() called ==================================
2025-03-20 19:00:41,559:INFO:Initializing create_model()
2025-03-20 19:00:41,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:00:41,559:INFO:Checking exceptions
2025-03-20 19:00:41,560:INFO:Importing libraries
2025-03-20 19:00:41,560:INFO:Copying training dataset
2025-03-20 19:00:41,562:INFO:Defining folds
2025-03-20 19:00:41,562:INFO:Declaring metric variables
2025-03-20 19:00:41,562:INFO:Importing untrained model
2025-03-20 19:00:41,562:INFO:Declaring custom model
2025-03-20 19:00:41,562:INFO:Ridge Regression Imported successfully
2025-03-20 19:00:41,562:INFO:Starting cross validation
2025-03-20 19:00:41,563:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:00:41,634:INFO:Calculating mean and std
2025-03-20 19:00:41,635:INFO:Creating metrics dataframe
2025-03-20 19:00:41,636:INFO:Finalizing model
2025-03-20 19:00:41,664:INFO:Uploading results into container
2025-03-20 19:00:41,664:INFO:Uploading model into container now
2025-03-20 19:00:41,664:INFO:_master_model_container: 26
2025-03-20 19:00:41,664:INFO:_display_container: 8
2025-03-20 19:00:41,664:INFO:Ridge(random_state=888)
2025-03-20 19:00:41,664:INFO:create_model() successfully completed......................................
2025-03-20 19:00:41,717:INFO:SubProcess create_model() end ==================================
2025-03-20 19:00:41,717:INFO:Ridge(random_state=888) result for MAPE is 0.0222
2025-03-20 19:00:41,717:INFO:Ridge(alpha=0.14659564883826065, random_state=888) result for MAPE is 0.0205
2025-03-20 19:00:41,717:INFO:Ridge(alpha=0.14659564883826065, random_state=888) is best model
2025-03-20 19:00:41,717:INFO:choose_better completed
2025-03-20 19:00:41,717:INFO:Creating Dashboard logs
2025-03-20 19:00:41,720:INFO:Model: Ridge Regression
2025-03-20 19:00:41,738:INFO:Logged params: {'alpha': 0.14659564883826065, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:00:41,905:INFO:Initializing predict_model()
2025-03-20 19:00:41,905:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(alpha=0.14659564883826065, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BFD9D1B80>)
2025-03-20 19:00:41,905:INFO:Checking exceptions
2025-03-20 19:00:41,905:INFO:Preloading libraries
2025-03-20 19:00:42,039:ERROR:_log_model() for Ridge(alpha=0.14659564883826065, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:00:42,043:INFO:_master_model_container: 26
2025-03-20 19:00:42,043:INFO:_display_container: 7
2025-03-20 19:00:42,044:INFO:Ridge(alpha=0.14659564883826065, random_state=888)
2025-03-20 19:00:42,044:INFO:tune_model() successfully completed......................................
2025-03-20 19:00:42,097:INFO:Initializing predict_model()
2025-03-20 19:00:42,098:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(alpha=0.14659564883826065, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BF94A3AF0>)
2025-03-20 19:00:42,098:INFO:Checking exceptions
2025-03-20 19:00:42,098:INFO:Preloading libraries
2025-03-20 19:00:42,221:INFO:Initializing tune_model()
2025-03-20 19:00:42,221:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>)
2025-03-20 19:00:42,221:INFO:Checking exceptions
2025-03-20 19:00:42,221:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:00:42,231:INFO:Copying training dataset
2025-03-20 19:00:42,233:INFO:Checking base model
2025-03-20 19:00:42,233:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 19:00:42,235:INFO:Declaring metric variables
2025-03-20 19:00:42,237:INFO:Defining Hyperparameters
2025-03-20 19:00:42,292:INFO:Tuning with n_jobs=-1
2025-03-20 19:00:42,293:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:00:42,293:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:00:42,293:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:00:42,293:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:00:42,293:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:00:42,293:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:01:27,802:INFO:best_params: {'actual_estimator__num_leaves': 53, 'actual_estimator__learning_rate': 0.19137594112085554, 'actual_estimator__n_estimators': 242, 'actual_estimator__min_split_gain': 0.6540838986559412, 'actual_estimator__reg_alpha': 1.3631156336007196e-06, 'actual_estimator__reg_lambda': 2.6400581173536615e-07, 'actual_estimator__feature_fraction': 0.5345141250872596, 'actual_estimator__bagging_fraction': 0.8008005013254366, 'actual_estimator__bagging_freq': 5, 'actual_estimator__min_child_samples': 10}
2025-03-20 19:01:27,809:INFO:Hyperparameter search completed
2025-03-20 19:01:27,809:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:27,809:INFO:Initializing create_model()
2025-03-20 19:01:27,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF92D5BB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 53, 'learning_rate': 0.19137594112085554, 'n_estimators': 242, 'min_split_gain': 0.6540838986559412, 'reg_alpha': 1.3631156336007196e-06, 'reg_lambda': 2.6400581173536615e-07, 'feature_fraction': 0.5345141250872596, 'bagging_fraction': 0.8008005013254366, 'bagging_freq': 5, 'min_child_samples': 10})
2025-03-20 19:01:27,809:INFO:Checking exceptions
2025-03-20 19:01:27,809:INFO:Importing libraries
2025-03-20 19:01:27,809:INFO:Copying training dataset
2025-03-20 19:01:27,813:INFO:Defining folds
2025-03-20 19:01:27,813:INFO:Declaring metric variables
2025-03-20 19:01:27,816:INFO:Importing untrained model
2025-03-20 19:01:27,816:INFO:Declaring custom model
2025-03-20 19:01:27,819:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:01:27,823:INFO:Starting cross validation
2025-03-20 19:01:27,824:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:27,994:INFO:Calculating mean and std
2025-03-20 19:01:27,995:INFO:Creating metrics dataframe
2025-03-20 19:01:27,999:INFO:Finalizing model
2025-03-20 19:01:28,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.5345141250872596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5345141250872596
2025-03-20 19:01:28,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8008005013254366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8008005013254366
2025-03-20 19:01:28,040:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 19:01:28,044:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:01:28,044:INFO:[LightGBM] [Warning] feature_fraction is set=0.5345141250872596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5345141250872596
2025-03-20 19:01:28,044:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8008005013254366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8008005013254366
2025-03-20 19:01:28,044:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 19:01:28,045:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000580 seconds.
2025-03-20 19:01:28,045:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:01:28,045:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:01:28,046:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:01:28,046:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:01:28,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:28,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:28,119:INFO:Uploading results into container
2025-03-20 19:01:28,119:INFO:Uploading model into container now
2025-03-20 19:01:28,120:INFO:_master_model_container: 27
2025-03-20 19:01:28,120:INFO:_display_container: 9
2025-03-20 19:01:28,120:INFO:LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07)
2025-03-20 19:01:28,121:INFO:create_model() successfully completed......................................
2025-03-20 19:01:28,187:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:28,187:INFO:choose_better activated
2025-03-20 19:01:28,189:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:28,190:INFO:Initializing create_model()
2025-03-20 19:01:28,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:28,190:INFO:Checking exceptions
2025-03-20 19:01:28,191:INFO:Importing libraries
2025-03-20 19:01:28,191:INFO:Copying training dataset
2025-03-20 19:01:28,194:INFO:Defining folds
2025-03-20 19:01:28,194:INFO:Declaring metric variables
2025-03-20 19:01:28,194:INFO:Importing untrained model
2025-03-20 19:01:28,194:INFO:Declaring custom model
2025-03-20 19:01:28,195:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:01:28,195:INFO:Starting cross validation
2025-03-20 19:01:28,196:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:28,687:INFO:Calculating mean and std
2025-03-20 19:01:28,687:INFO:Creating metrics dataframe
2025-03-20 19:01:28,688:INFO:Finalizing model
2025-03-20 19:01:28,730:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:01:28,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.
2025-03-20 19:01:28,731:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:01:28,731:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:01:28,732:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:01:28,732:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:01:28,869:INFO:Uploading results into container
2025-03-20 19:01:28,869:INFO:Uploading model into container now
2025-03-20 19:01:28,870:INFO:_master_model_container: 28
2025-03-20 19:01:28,870:INFO:_display_container: 10
2025-03-20 19:01:28,870:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:01:28,870:INFO:create_model() successfully completed......................................
2025-03-20 19:01:28,929:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:28,930:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0233
2025-03-20 19:01:28,930:INFO:LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07) result for MAPE is 0.0217
2025-03-20 19:01:28,931:INFO:LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07) is best model
2025-03-20 19:01:28,931:INFO:choose_better completed
2025-03-20 19:01:28,931:INFO:Creating Dashboard logs
2025-03-20 19:01:28,934:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:01:28,957:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.19137594112085554, 'max_depth': -1, 'min_child_samples': 10, 'min_child_weight': 0.001, 'min_split_gain': 0.6540838986559412, 'n_estimators': 242, 'n_jobs': -1, 'num_leaves': 53, 'objective': None, 'random_state': 888, 'reg_alpha': 1.3631156336007196e-06, 'reg_lambda': 2.6400581173536615e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5345141250872596, 'bagging_fraction': 0.8008005013254366, 'bagging_freq': 5}
2025-03-20 19:01:29,157:INFO:Initializing predict_model()
2025-03-20 19:01:29,157:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BFEA2DD30>)
2025-03-20 19:01:29,157:INFO:Checking exceptions
2025-03-20 19:01:29,157:INFO:Preloading libraries
2025-03-20 19:01:29,312:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:29,319:INFO:_master_model_container: 28
2025-03-20 19:01:29,319:INFO:_display_container: 9
2025-03-20 19:01:29,319:INFO:LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07)
2025-03-20 19:01:29,319:INFO:tune_model() successfully completed......................................
2025-03-20 19:01:29,380:INFO:Initializing predict_model()
2025-03-20 19:01:29,380:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022B90182F70>)
2025-03-20 19:01:29,380:INFO:Checking exceptions
2025-03-20 19:01:29,380:INFO:Preloading libraries
2025-03-20 19:01:29,525:INFO:Initializing blend_models()
2025-03-20 19:01:29,525:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator_list=[BayesianRidge(), GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), Ridge(alpha=0.14659564883826065, random_state=888), LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 19:01:29,525:INFO:Checking exceptions
2025-03-20 19:01:29,536:INFO:Importing libraries
2025-03-20 19:01:29,536:INFO:Copying training dataset
2025-03-20 19:01:29,538:INFO:Getting model names
2025-03-20 19:01:29,541:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:29,547:INFO:Initializing create_model()
2025-03-20 19:01:29,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BFD933F70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:29,547:INFO:Checking exceptions
2025-03-20 19:01:29,547:INFO:Importing libraries
2025-03-20 19:01:29,547:INFO:Copying training dataset
2025-03-20 19:01:29,554:INFO:Defining folds
2025-03-20 19:01:29,554:INFO:Declaring metric variables
2025-03-20 19:01:29,557:INFO:Importing untrained model
2025-03-20 19:01:29,557:INFO:Declaring custom model
2025-03-20 19:01:29,561:INFO:Voting Regressor Imported successfully
2025-03-20 19:01:29,566:INFO:Starting cross validation
2025-03-20 19:01:29,567:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:30,041:INFO:Calculating mean and std
2025-03-20 19:01:30,041:INFO:Creating metrics dataframe
2025-03-20 19:01:30,045:INFO:Finalizing model
2025-03-20 19:01:30,291:INFO:Uploading results into container
2025-03-20 19:01:30,291:INFO:Uploading model into container now
2025-03-20 19:01:30,292:INFO:_master_model_container: 29
2025-03-20 19:01:30,292:INFO:_display_container: 11
2025-03-20 19:01:30,295:INFO:VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)
2025-03-20 19:01:30,295:INFO:create_model() successfully completed......................................
2025-03-20 19:01:30,350:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:30,350:INFO:Creating Dashboard logs
2025-03-20 19:01:30,352:INFO:Model: Voting Regressor
2025-03-20 19:01:30,370:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(), 'Ridge Regression': Ridge(alpha=0.14659564883826065, random_state=888), 'Bayesian Ridge__alpha_1': 1e-06, 'Bayesian Ridge__alpha_2': 1e-06, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 1e-06, 'Bayesian Ridge__lambda_2': 1e-06, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.11406876138346284, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 1, 'Gradient Boosting Regressor__max_features': 0.7353917996766489, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 1.7138164846715253e-06, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 97, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.8035599664827586, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.14659564883826065, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.19137594112085554, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 10, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.6540838986559412, 'Light Gradient Boosting Machine__n_estimators': 242, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 53, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 1.3631156336007196e-06, 'Light Gradient Boosting Machine__reg_lambda': 2.6400581173536615e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.5345141250872596, 'Light Gradient Boosting Machine__bagging_fraction': 0.8008005013254366, 'Light Gradient Boosting Machine__bagging_freq': 5}
2025-03-20 19:01:30,601:INFO:Initializing predict_model()
2025-03-20 19:01:30,601:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BFEA2DB80>)
2025-03-20 19:01:30,601:INFO:Checking exceptions
2025-03-20 19:01:30,601:INFO:Preloading libraries
2025-03-20 19:01:30,747:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:30,752:INFO:_master_model_container: 29
2025-03-20 19:01:30,752:INFO:_display_container: 11
2025-03-20 19:01:30,757:INFO:VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)
2025-03-20 19:01:30,757:INFO:blend_models() successfully completed......................................
2025-03-20 19:01:30,827:INFO:Initializing compare_models()
2025-03-20 19:01:30,827:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, include=[BayesianRidge(), GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), Ridge(alpha=0.14659564883826065, random_state=888), LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07), VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, 'include': [BayesianRidge(), GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), Ridge(alpha=0.14659564883826065, random_state=888), LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07), VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 19:01:30,827:INFO:Checking exceptions
2025-03-20 19:01:30,829:INFO:Preparing display monitor
2025-03-20 19:01:30,841:INFO:Initializing custom model Bayesian Ridge
2025-03-20 19:01:30,842:INFO:Total runtime is 8.277098337809245e-06 minutes
2025-03-20 19:01:30,843:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:30,843:INFO:Initializing create_model()
2025-03-20 19:01:30,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BFD8DDD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:30,844:INFO:Checking exceptions
2025-03-20 19:01:30,844:INFO:Importing libraries
2025-03-20 19:01:30,844:INFO:Copying training dataset
2025-03-20 19:01:30,847:INFO:Defining folds
2025-03-20 19:01:30,847:INFO:Declaring metric variables
2025-03-20 19:01:30,849:INFO:Importing untrained model
2025-03-20 19:01:30,849:INFO:Declaring custom model
2025-03-20 19:01:30,851:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:01:30,855:INFO:Starting cross validation
2025-03-20 19:01:30,856:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:30,918:INFO:Calculating mean and std
2025-03-20 19:01:30,918:INFO:Creating metrics dataframe
2025-03-20 19:01:30,920:INFO:Uploading results into container
2025-03-20 19:01:30,920:INFO:Uploading model into container now
2025-03-20 19:01:30,920:INFO:_master_model_container: 30
2025-03-20 19:01:30,920:INFO:_display_container: 12
2025-03-20 19:01:30,921:INFO:BayesianRidge()
2025-03-20 19:01:30,921:INFO:create_model() successfully completed......................................
2025-03-20 19:01:30,974:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:30,974:INFO:Creating metrics dataframe
2025-03-20 19:01:30,979:INFO:Initializing custom model Gradient Boosting Regressor
2025-03-20 19:01:30,979:INFO:Total runtime is 0.002292931079864502 minutes
2025-03-20 19:01:30,981:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:30,981:INFO:Initializing create_model()
2025-03-20 19:01:30,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BFD8DDD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:30,981:INFO:Checking exceptions
2025-03-20 19:01:30,981:INFO:Importing libraries
2025-03-20 19:01:30,981:INFO:Copying training dataset
2025-03-20 19:01:30,984:INFO:Defining folds
2025-03-20 19:01:30,984:INFO:Declaring metric variables
2025-03-20 19:01:30,986:INFO:Importing untrained model
2025-03-20 19:01:30,986:INFO:Declaring custom model
2025-03-20 19:01:30,988:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:01:30,992:INFO:Starting cross validation
2025-03-20 19:01:30,992:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:31,180:INFO:Calculating mean and std
2025-03-20 19:01:31,181:INFO:Creating metrics dataframe
2025-03-20 19:01:31,182:INFO:Uploading results into container
2025-03-20 19:01:31,182:INFO:Uploading model into container now
2025-03-20 19:01:31,183:INFO:_master_model_container: 31
2025-03-20 19:01:31,183:INFO:_display_container: 12
2025-03-20 19:01:31,183:INFO:GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586)
2025-03-20 19:01:31,183:INFO:create_model() successfully completed......................................
2025-03-20 19:01:31,238:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:31,238:INFO:Creating metrics dataframe
2025-03-20 19:01:31,242:INFO:Initializing custom model Ridge Regression
2025-03-20 19:01:31,242:INFO:Total runtime is 0.006680436929066976 minutes
2025-03-20 19:01:31,244:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:31,245:INFO:Initializing create_model()
2025-03-20 19:01:31,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(alpha=0.14659564883826065, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BFD8DDD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:31,245:INFO:Checking exceptions
2025-03-20 19:01:31,245:INFO:Importing libraries
2025-03-20 19:01:31,245:INFO:Copying training dataset
2025-03-20 19:01:31,247:INFO:Defining folds
2025-03-20 19:01:31,247:INFO:Declaring metric variables
2025-03-20 19:01:31,249:INFO:Importing untrained model
2025-03-20 19:01:31,249:INFO:Declaring custom model
2025-03-20 19:01:31,251:INFO:Ridge Regression Imported successfully
2025-03-20 19:01:31,255:INFO:Starting cross validation
2025-03-20 19:01:31,255:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:31,334:INFO:Calculating mean and std
2025-03-20 19:01:31,334:INFO:Creating metrics dataframe
2025-03-20 19:01:31,336:INFO:Uploading results into container
2025-03-20 19:01:31,336:INFO:Uploading model into container now
2025-03-20 19:01:31,336:INFO:_master_model_container: 32
2025-03-20 19:01:31,336:INFO:_display_container: 12
2025-03-20 19:01:31,336:INFO:Ridge(alpha=0.14659564883826065, random_state=888)
2025-03-20 19:01:31,336:INFO:create_model() successfully completed......................................
2025-03-20 19:01:31,393:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:31,393:INFO:Creating metrics dataframe
2025-03-20 19:01:31,398:INFO:Initializing custom model Light Gradient Boosting Machine
2025-03-20 19:01:31,399:INFO:Total runtime is 0.009286252657572429 minutes
2025-03-20 19:01:31,400:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:31,401:INFO:Initializing create_model()
2025-03-20 19:01:31,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BFD8DDD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:31,401:INFO:Checking exceptions
2025-03-20 19:01:31,401:INFO:Importing libraries
2025-03-20 19:01:31,401:INFO:Copying training dataset
2025-03-20 19:01:31,403:INFO:Defining folds
2025-03-20 19:01:31,403:INFO:Declaring metric variables
2025-03-20 19:01:31,405:INFO:Importing untrained model
2025-03-20 19:01:31,405:INFO:Declaring custom model
2025-03-20 19:01:31,408:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:01:31,411:INFO:Starting cross validation
2025-03-20 19:01:31,412:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:31,550:INFO:Calculating mean and std
2025-03-20 19:01:31,550:INFO:Creating metrics dataframe
2025-03-20 19:01:31,552:INFO:Uploading results into container
2025-03-20 19:01:31,552:INFO:Uploading model into container now
2025-03-20 19:01:31,552:INFO:_master_model_container: 33
2025-03-20 19:01:31,553:INFO:_display_container: 12
2025-03-20 19:01:31,553:INFO:LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07)
2025-03-20 19:01:31,553:INFO:create_model() successfully completed......................................
2025-03-20 19:01:31,611:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:31,612:INFO:Creating metrics dataframe
2025-03-20 19:01:31,618:INFO:Initializing custom model Voting Regressor
2025-03-20 19:01:31,618:INFO:Total runtime is 0.012945024172465007 minutes
2025-03-20 19:01:31,621:INFO:SubProcess create_model() called ==================================
2025-03-20 19:01:31,625:INFO:Initializing create_model()
2025-03-20 19:01:31,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BFD8DDD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:31,626:INFO:Checking exceptions
2025-03-20 19:01:31,626:INFO:Importing libraries
2025-03-20 19:01:31,626:INFO:Copying training dataset
2025-03-20 19:01:31,628:INFO:Defining folds
2025-03-20 19:01:31,628:INFO:Declaring metric variables
2025-03-20 19:01:31,631:INFO:Importing untrained model
2025-03-20 19:01:31,631:INFO:Declaring custom model
2025-03-20 19:01:31,634:INFO:Voting Regressor Imported successfully
2025-03-20 19:01:31,638:INFO:Starting cross validation
2025-03-20 19:01:31,639:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:01:32,073:INFO:Calculating mean and std
2025-03-20 19:01:32,075:INFO:Creating metrics dataframe
2025-03-20 19:01:32,077:INFO:Uploading results into container
2025-03-20 19:01:32,077:INFO:Uploading model into container now
2025-03-20 19:01:32,078:INFO:_master_model_container: 34
2025-03-20 19:01:32,078:INFO:_display_container: 12
2025-03-20 19:01:32,082:INFO:VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)
2025-03-20 19:01:32,082:INFO:create_model() successfully completed......................................
2025-03-20 19:01:32,142:INFO:SubProcess create_model() end ==================================
2025-03-20 19:01:32,142:INFO:Creating metrics dataframe
2025-03-20 19:01:32,158:INFO:Initializing create_model()
2025-03-20 19:01:32,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:32,158:INFO:Checking exceptions
2025-03-20 19:01:32,159:INFO:Importing libraries
2025-03-20 19:01:32,160:INFO:Copying training dataset
2025-03-20 19:01:32,162:INFO:Defining folds
2025-03-20 19:01:32,162:INFO:Declaring metric variables
2025-03-20 19:01:32,162:INFO:Importing untrained model
2025-03-20 19:01:32,162:INFO:Declaring custom model
2025-03-20 19:01:32,164:INFO:Voting Regressor Imported successfully
2025-03-20 19:01:32,164:INFO:Cross validation set to False
2025-03-20 19:01:32,164:INFO:Fitting Model
2025-03-20 19:01:32,385:INFO:VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)
2025-03-20 19:01:32,385:INFO:create_model() successfully completed......................................
2025-03-20 19:01:32,441:INFO:Creating Dashboard logs
2025-03-20 19:01:32,444:INFO:Model: Voting Regressor
2025-03-20 19:01:32,465:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(), 'Ridge Regression': Ridge(alpha=0.14659564883826065, random_state=888), 'Bayesian Ridge__alpha_1': 1e-06, 'Bayesian Ridge__alpha_2': 1e-06, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 1e-06, 'Bayesian Ridge__lambda_2': 1e-06, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.11406876138346284, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 1, 'Gradient Boosting Regressor__max_features': 0.7353917996766489, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 1.7138164846715253e-06, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 97, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.8035599664827586, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.14659564883826065, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.19137594112085554, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 10, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.6540838986559412, 'Light Gradient Boosting Machine__n_estimators': 242, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 53, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 1.3631156336007196e-06, 'Light Gradient Boosting Machine__reg_lambda': 2.6400581173536615e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.5345141250872596, 'Light Gradient Boosting Machine__bagging_fraction': 0.8008005013254366, 'Light Gradient Boosting Machine__bagging_freq': 5}
2025-03-20 19:01:32,715:INFO:Initializing predict_model()
2025-03-20 19:01:32,716:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BFDA1EB80>)
2025-03-20 19:01:32,716:INFO:Checking exceptions
2025-03-20 19:01:32,716:INFO:Preloading libraries
2025-03-20 19:01:32,864:ERROR:_log_model() for VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:32,865:INFO:Creating Dashboard logs
2025-03-20 19:01:32,867:INFO:Model: Bayesian Ridge
2025-03-20 19:01:32,891:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:01:33,131:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:33,131:INFO:Creating Dashboard logs
2025-03-20 19:01:33,133:INFO:Model: Ridge Regression
2025-03-20 19:01:33,150:INFO:Logged params: {'alpha': 0.14659564883826065, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:01:33,369:ERROR:_log_model() for Ridge(alpha=0.14659564883826065, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:33,369:INFO:Creating Dashboard logs
2025-03-20 19:01:33,371:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:01:33,387:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.19137594112085554, 'max_depth': -1, 'min_child_samples': 10, 'min_child_weight': 0.001, 'min_split_gain': 0.6540838986559412, 'n_estimators': 242, 'n_jobs': -1, 'num_leaves': 53, 'objective': None, 'random_state': 888, 'reg_alpha': 1.3631156336007196e-06, 'reg_lambda': 2.6400581173536615e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5345141250872596, 'bagging_fraction': 0.8008005013254366, 'bagging_freq': 5}
2025-03-20 19:01:33,617:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:33,618:INFO:Creating Dashboard logs
2025-03-20 19:01:33,620:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:01:33,636:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.11406876138346284, 'loss': 'squared_error', 'max_depth': 1, 'max_features': 0.7353917996766489, 'max_leaf_nodes': None, 'min_impurity_decrease': 1.7138164846715253e-06, 'min_samples_leaf': 1, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 97, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.8035599664827586, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:01:33,882:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:33,888:INFO:_master_model_container: 34
2025-03-20 19:01:33,888:INFO:_display_container: 12
2025-03-20 19:01:33,892:INFO:VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)
2025-03-20 19:01:33,892:INFO:compare_models() successfully completed......................................
2025-03-20 19:01:33,980:INFO:Initializing finalize_model()
2025-03-20 19:01:33,980:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:01:33,980:INFO:Finalizing BayesianRidge()
2025-03-20 19:01:33,982:INFO:Initializing create_model()
2025-03-20 19:01:33,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=BayesianRidge(), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:33,982:INFO:Checking exceptions
2025-03-20 19:01:33,983:INFO:Importing libraries
2025-03-20 19:01:33,983:INFO:Copying training dataset
2025-03-20 19:01:33,983:INFO:Defining folds
2025-03-20 19:01:33,983:INFO:Declaring metric variables
2025-03-20 19:01:33,984:INFO:Importing untrained model
2025-03-20 19:01:33,984:INFO:Declaring custom model
2025-03-20 19:01:33,984:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:01:33,984:INFO:Cross validation set to False
2025-03-20 19:01:33,984:INFO:Fitting Model
2025-03-20 19:01:34,028:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', BayesianRidge())])
2025-03-20 19:01:34,028:INFO:create_model() successfully completed......................................
2025-03-20 19:01:34,084:INFO:Creating Dashboard logs
2025-03-20 19:01:34,085:INFO:Model: Bayesian Ridge
2025-03-20 19:01:34,102:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:01:34,358:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', BayesianRidge())]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:34,359:INFO:_master_model_container: 34
2025-03-20 19:01:34,359:INFO:_display_container: 12
2025-03-20 19:01:34,363:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', BayesianRidge())])
2025-03-20 19:01:34,363:INFO:finalize_model() successfully completed......................................
2025-03-20 19:01:34,426:INFO:Initializing save_model()
2025-03-20 19:01:34,426:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', BayesianRidge())]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_190133, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:01:34,426:INFO:Adding model into prep_pipe
2025-03-20 19:01:34,426:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:01:34,430:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\br_250320_190133.pkl saved in current working directory
2025-03-20 19:01:34,435:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', BayesianRidge())])
2025-03-20 19:01:34,435:INFO:save_model() successfully completed......................................
2025-03-20 19:01:34,490:INFO:Initializing finalize_model()
2025-03-20 19:01:34,490:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:01:34,490:INFO:Finalizing GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586)
2025-03-20 19:01:34,492:INFO:Initializing create_model()
2025-03-20 19:01:34,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=GradientBoostingRegressor(learning_rate=0.11406876138346284, max_depth=1,
                          max_features=0.7353917996766489,
                          min_impurity_decrease=1.7138164846715253e-06,
                          min_samples_split=3, n_estimators=97,
                          random_state=888, subsample=0.8035599664827586), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:34,493:INFO:Checking exceptions
2025-03-20 19:01:34,493:INFO:Importing libraries
2025-03-20 19:01:34,493:INFO:Copying training dataset
2025-03-20 19:01:34,494:INFO:Defining folds
2025-03-20 19:01:34,494:INFO:Declaring metric variables
2025-03-20 19:01:34,494:INFO:Importing untrained model
2025-03-20 19:01:34,494:INFO:Declaring custom model
2025-03-20 19:01:34,494:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:01:34,495:INFO:Cross validation set to False
2025-03-20 19:01:34,495:INFO:Fitting Model
2025-03-20 19:01:34,718:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                           max_depth=1,
                                           max_features=0.7353917996766489,
                                           min_impurity_decrease=1.7138164846715253e-06,
                                           min_samples_split=3, n_estimators=97,
                                           random_state=888,
                                           subsample=0.8035599664827586))])
2025-03-20 19:01:34,718:INFO:create_model() successfully completed......................................
2025-03-20 19:01:34,779:INFO:Creating Dashboard logs
2025-03-20 19:01:34,779:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:01:34,797:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.11406876138346284, 'loss': 'squared_error', 'max_depth': 1, 'max_features': 0.7353917996766489, 'max_leaf_nodes': None, 'min_impurity_decrease': 1.7138164846715253e-06, 'min_samples_leaf': 1, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 97, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.8035599664827586, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:01:35,055:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                           max_depth=1,
                                           max_features=0.7353917996766489,
                                           min_impurity_decrease=1.7138164846715253e-06,
                                           min_samples_split=3, n_estimators=97,
                                           random_state=888,
                                           subsample=0.8035599664827586))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:35,056:INFO:_master_model_container: 34
2025-03-20 19:01:35,056:INFO:_display_container: 12
2025-03-20 19:01:35,061:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                           max_depth=1,
                                           max_features=0.7353917996766489,
                                           min_impurity_decrease=1.7138164846715253e-06,
                                           min_samples_split=3, n_estimators=97,
                                           random_state=888,
                                           subsample=0.8035599664827586))])
2025-03-20 19:01:35,061:INFO:finalize_model() successfully completed......................................
2025-03-20 19:01:35,130:INFO:Initializing save_model()
2025-03-20 19:01:35,130:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                           max_depth=1,
                                           max_features=0.7353917996766489,
                                           min_impurity_decrease=1.7138164846715253e-06,
                                           min_samples_split=3, n_estimators=97,
                                           random_state=888,
                                           subsample=0.8035599664827586))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_190134, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:01:35,130:INFO:Adding model into prep_pipe
2025-03-20 19:01:35,130:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:01:35,136:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_190134.pkl saved in current working directory
2025-03-20 19:01:35,141:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                           max_depth=1,
                                           max_features=0.7353917996766489,
                                           min_impurity_decrease=1.7138164846715253e-06,
                                           min_samples_split=3, n_estimators=97,
                                           random_state=888,
                                           subsample=0.8035599664827586))])
2025-03-20 19:01:35,141:INFO:save_model() successfully completed......................................
2025-03-20 19:01:35,204:INFO:Initializing finalize_model()
2025-03-20 19:01:35,204:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(alpha=0.14659564883826065, random_state=888), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:01:35,204:INFO:Finalizing Ridge(alpha=0.14659564883826065, random_state=888)
2025-03-20 19:01:35,206:INFO:Initializing create_model()
2025-03-20 19:01:35,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=Ridge(alpha=0.14659564883826065, random_state=888), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:35,206:INFO:Checking exceptions
2025-03-20 19:01:35,207:INFO:Importing libraries
2025-03-20 19:01:35,207:INFO:Copying training dataset
2025-03-20 19:01:35,207:INFO:Defining folds
2025-03-20 19:01:35,207:INFO:Declaring metric variables
2025-03-20 19:01:35,208:INFO:Importing untrained model
2025-03-20 19:01:35,208:INFO:Declaring custom model
2025-03-20 19:01:35,208:INFO:Ridge Regression Imported successfully
2025-03-20 19:01:35,208:INFO:Cross validation set to False
2025-03-20 19:01:35,208:INFO:Fitting Model
2025-03-20 19:01:35,248:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.14659564883826065, random_state=888))])
2025-03-20 19:01:35,248:INFO:create_model() successfully completed......................................
2025-03-20 19:01:35,314:INFO:Creating Dashboard logs
2025-03-20 19:01:35,314:INFO:Model: Ridge Regression
2025-03-20 19:01:35,334:INFO:Logged params: {'alpha': 0.14659564883826065, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:01:35,607:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.14659564883826065, random_state=888))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:35,607:INFO:_master_model_container: 34
2025-03-20 19:01:35,607:INFO:_display_container: 12
2025-03-20 19:01:35,611:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.14659564883826065, random_state=888))])
2025-03-20 19:01:35,611:INFO:finalize_model() successfully completed......................................
2025-03-20 19:01:35,677:INFO:Initializing save_model()
2025-03-20 19:01:35,677:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.14659564883826065, random_state=888))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\ridge_250320_190135, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:01:35,677:INFO:Adding model into prep_pipe
2025-03-20 19:01:35,677:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:01:35,681:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\ridge_250320_190135.pkl saved in current working directory
2025-03-20 19:01:35,686:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 Ridge(alpha=0.14659564883826065, random_state=888))])
2025-03-20 19:01:35,686:INFO:save_model() successfully completed......................................
2025-03-20 19:01:35,741:INFO:Initializing finalize_model()
2025-03-20 19:01:35,741:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:01:35,741:INFO:Finalizing LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07)
2025-03-20 19:01:35,743:INFO:Initializing create_model()
2025-03-20 19:01:35,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=LGBMRegressor(bagging_fraction=0.8008005013254366, bagging_freq=5,
              feature_fraction=0.5345141250872596,
              learning_rate=0.19137594112085554, min_child_samples=10,
              min_split_gain=0.6540838986559412, n_estimators=242, n_jobs=-1,
              num_leaves=53, random_state=888, reg_alpha=1.3631156336007196e-06,
              reg_lambda=2.6400581173536615e-07), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:35,743:INFO:Checking exceptions
2025-03-20 19:01:35,744:INFO:Importing libraries
2025-03-20 19:01:35,744:INFO:Copying training dataset
2025-03-20 19:01:35,744:INFO:Defining folds
2025-03-20 19:01:35,744:INFO:Declaring metric variables
2025-03-20 19:01:35,744:INFO:Importing untrained model
2025-03-20 19:01:35,744:INFO:Declaring custom model
2025-03-20 19:01:35,745:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:01:35,745:INFO:Cross validation set to False
2025-03-20 19:01:35,745:INFO:Fitting Model
2025-03-20 19:01:35,778:INFO:[LightGBM] [Warning] feature_fraction is set=0.5345141250872596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5345141250872596
2025-03-20 19:01:35,778:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8008005013254366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8008005013254366
2025-03-20 19:01:35,778:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 19:01:35,779:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:01:35,779:INFO:[LightGBM] [Warning] feature_fraction is set=0.5345141250872596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5345141250872596
2025-03-20 19:01:35,779:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8008005013254366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8008005013254366
2025-03-20 19:01:35,780:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 19:01:35,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
2025-03-20 19:01:35,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:01:35,780:INFO:[LightGBM] [Info] Total Bins 4616
2025-03-20 19:01:35,782:INFO:[LightGBM] [Info] Number of data points in the train set: 1769, number of used features: 37
2025-03-20 19:01:35,782:INFO:[LightGBM] [Info] Start training from score 15.920889
2025-03-20 19:01:35,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:01:35,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:01:35,843:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8008005013254366,
                               bagging_freq=5,
                               feature_fraction=0.5345141250872596,
                               learning_rate=0.19137594112085554,
                               min_child_samples=10,
                               min_split_gain=0.6540838986559412,
                               n_estimators=242, n_jobs=-1, num_leaves=53,
                               random_state=888,
                               reg_alpha=1.3631156336007196e-06,
                               reg_lambda=2.6400581173536615e-07))])
2025-03-20 19:01:35,843:INFO:create_model() successfully completed......................................
2025-03-20 19:01:35,908:INFO:Creating Dashboard logs
2025-03-20 19:01:35,908:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:01:35,932:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.19137594112085554, 'max_depth': -1, 'min_child_samples': 10, 'min_child_weight': 0.001, 'min_split_gain': 0.6540838986559412, 'n_estimators': 242, 'n_jobs': -1, 'num_leaves': 53, 'objective': None, 'random_state': 888, 'reg_alpha': 1.3631156336007196e-06, 'reg_lambda': 2.6400581173536615e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5345141250872596, 'bagging_fraction': 0.8008005013254366, 'bagging_freq': 5}
2025-03-20 19:01:36,220:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8008005013254366,
                               bagging_freq=5,
                               feature_fraction=0.5345141250872596,
                               learning_rate=0.19137594112085554,
                               min_child_samples=10,
                               min_split_gain=0.6540838986559412,
                               n_estimators=242, n_jobs=-1, num_leaves=53,
                               random_state=888,
                               reg_alpha=1.3631156336007196e-06,
                               reg_lambda=2.6400581173536615e-07))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:36,220:INFO:_master_model_container: 34
2025-03-20 19:01:36,220:INFO:_display_container: 12
2025-03-20 19:01:36,225:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8008005013254366,
                               bagging_freq=5,
                               feature_fraction=0.5345141250872596,
                               learning_rate=0.19137594112085554,
                               min_child_samples=10,
                               min_split_gain=0.6540838986559412,
                               n_estimators=242, n_jobs=-1, num_leaves=53,
                               random_state=888,
                               reg_alpha=1.3631156336007196e-06,
                               reg_lambda=2.6400581173536615e-07))])
2025-03-20 19:01:36,225:INFO:finalize_model() successfully completed......................................
2025-03-20 19:01:36,299:INFO:Initializing save_model()
2025-03-20 19:01:36,299:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8008005013254366,
                               bagging_freq=5,
                               feature_fraction=0.5345141250872596,
                               learning_rate=0.19137594112085554,
                               min_child_samples=10,
                               min_split_gain=0.6540838986559412,
                               n_estimators=242, n_jobs=-1, num_leaves=53,
                               random_state=888,
                               reg_alpha=1.3631156336007196e-06,
                               reg_lambda=2.6400581173536615e-07))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_190135, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:01:36,299:INFO:Adding model into prep_pipe
2025-03-20 19:01:36,299:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:01:36,305:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_190135.pkl saved in current working directory
2025-03-20 19:01:36,312:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.8008005013254366,
                               bagging_freq=5,
                               feature_fraction=0.5345141250872596,
                               learning_rate=0.19137594112085554,
                               min_child_samples=10,
                               min_split_gain=0.6540838986559412,
                               n_estimators=242, n_jobs=-1, num_leaves=53,
                               random_state=888,
                               reg_alpha=1.3631156336007196e-06,
                               reg_lambda=2.6400581173536615e-07))])
2025-03-20 19:01:36,312:INFO:save_model() successfully completed......................................
2025-03-20 19:01:36,386:INFO:Initializing finalize_model()
2025-03-20 19:01:36,386:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:01:36,390:INFO:Finalizing VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1)
2025-03-20 19:01:36,396:INFO:Initializing create_model()
2025-03-20 19:01:36,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BF4649C40>, estimator=VotingRegressor(estimators=[('Bayesian Ridge', BayesianRidge()),
                            ('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.11406876138346284,
                                                       max_depth=1,
                                                       max_features=0.7353917996766489,
                                                       min_impurity_decrease=1.7138164846715253e-06,
                                                       min_samples_split=3,
                                                       n_estimators=97,
                                                       random_state=888,
                                                       subsample=0.8035599664827586)),
                            ('Ridge Regression',
                             Ridge(a...
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction=0.8008005013254366,
                                           bagging_freq=5,
                                           feature_fraction=0.5345141250872596,
                                           learning_rate=0.19137594112085554,
                                           min_child_samples=10,
                                           min_split_gain=0.6540838986559412,
                                           n_estimators=242, n_jobs=-1,
                                           num_leaves=53, random_state=888,
                                           reg_alpha=1.3631156336007196e-06,
                                           reg_lambda=2.6400581173536615e-07))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:01:36,396:INFO:Checking exceptions
2025-03-20 19:01:36,398:INFO:Importing libraries
2025-03-20 19:01:36,398:INFO:Copying training dataset
2025-03-20 19:01:36,398:INFO:Defining folds
2025-03-20 19:01:36,398:INFO:Declaring metric variables
2025-03-20 19:01:36,398:INFO:Importing untrained model
2025-03-20 19:01:36,398:INFO:Declaring custom model
2025-03-20 19:01:36,399:INFO:Voting Regressor Imported successfully
2025-03-20 19:01:36,400:INFO:Cross validation set to False
2025-03-20 19:01:36,400:INFO:Fitting Model
2025-03-20 19:01:36,689:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8008005013254366,
                                                            bagging_freq=5,
                                                            feature_fraction=0.5345141250872596,
                                                            learning_rate=0.19137594112085554,
                                                            min_child_samples=10,
                                                            min_split_gain=0.6540838986559412,
                                                            n_estimators=242,
                                                            n_jobs=-1,
                                                            num_leaves=53,
                                                            random_state=888,
                                                            reg_alpha=1.3631156336007196e-06,
                                                            reg_lambda=2.6400581173536615e-07))],
                                 n_jobs=-1))])
2025-03-20 19:01:36,690:INFO:create_model() successfully completed......................................
2025-03-20 19:01:36,755:INFO:Creating Dashboard logs
2025-03-20 19:01:36,755:INFO:Model: Voting Regressor
2025-03-20 19:01:36,775:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Bayesian Ridge': BayesianRidge(), 'Ridge Regression': Ridge(alpha=0.14659564883826065, random_state=888), 'Bayesian Ridge__alpha_1': 1e-06, 'Bayesian Ridge__alpha_2': 1e-06, 'Bayesian Ridge__alpha_init': None, 'Bayesian Ridge__compute_score': False, 'Bayesian Ridge__copy_X': True, 'Bayesian Ridge__fit_intercept': True, 'Bayesian Ridge__lambda_1': 1e-06, 'Bayesian Ridge__lambda_2': 1e-06, 'Bayesian Ridge__lambda_init': None, 'Bayesian Ridge__n_iter': 300, 'Bayesian Ridge__tol': 0.001, 'Bayesian Ridge__verbose': False, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.11406876138346284, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 1, 'Gradient Boosting Regressor__max_features': 0.7353917996766489, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 1.7138164846715253e-06, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 97, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.8035599664827586, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Ridge Regression__alpha': 0.14659564883826065, 'Ridge Regression__copy_X': True, 'Ridge Regression__fit_intercept': True, 'Ridge Regression__max_iter': None, 'Ridge Regression__positive': False, 'Ridge Regression__random_state': 888, 'Ridge Regression__solver': 'auto', 'Ridge Regression__tol': 0.0001, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.19137594112085554, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 10, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.6540838986559412, 'Light Gradient Boosting Machine__n_estimators': 242, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 53, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 1.3631156336007196e-06, 'Light Gradient Boosting Machine__reg_lambda': 2.6400581173536615e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.5345141250872596, 'Light Gradient Boosting Machine__bagging_fraction': 0.8008005013254366, 'Light Gradient Boosting Machine__bagging_freq': 5}
2025-03-20 19:01:37,108:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8008005013254366,
                                                            bagging_freq=5,
                                                            feature_fraction=0.5345141250872596,
                                                            learning_rate=0.19137594112085554,
                                                            min_child_samples=10,
                                                            min_split_gain=0.6540838986559412,
                                                            n_estimators=242,
                                                            n_jobs=-1,
                                                            num_leaves=53,
                                                            random_state=888,
                                                            reg_alpha=1.3631156336007196e-06,
                                                            reg_lambda=2.6400581173536615e-07))],
                                 n_jobs=-1))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:01:37,108:INFO:_master_model_container: 34
2025-03-20 19:01:37,108:INFO:_display_container: 12
2025-03-20 19:01:37,125:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8008005013254366,
                                                            bagging_freq=5,
                                                            feature_fraction=0.5345141250872596,
                                                            learning_rate=0.19137594112085554,
                                                            min_child_samples=10,
                                                            min_split_gain=0.6540838986559412,
                                                            n_estimators=242,
                                                            n_jobs=-1,
                                                            num_leaves=53,
                                                            random_state=888,
                                                            reg_alpha=1.3631156336007196e-06,
                                                            reg_lambda=2.6400581173536615e-07))],
                                 n_jobs=-1))])
2025-03-20 19:01:37,125:INFO:finalize_model() successfully completed......................................
2025-03-20 19:01:37,212:INFO:Initializing save_model()
2025-03-20 19:01:37,212:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8008005013254366,
                                                            bagging_freq=5,
                                                            feature_fraction=0.5345141250872596,
                                                            learning_rate=0.19137594112085554,
                                                            min_child_samples=10,
                                                            min_split_gain=0.6540838986559412,
                                                            n_estimators=242,
                                                            n_jobs=-1,
                                                            num_leaves=53,
                                                            random_state=888,
                                                            reg_alpha=1.3631156336007196e-06,
                                                            reg_lambda=2.6400581173536615e-07))],
                                 n_jobs=-1))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_190136, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:01:37,212:INFO:Adding model into prep_pipe
2025-03-20 19:01:37,212:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:01:37,221:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_190136.pkl saved in current working directory
2025-03-20 19:01:37,242:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8008005013254366,
                                                            bagging_freq=5,
                                                            feature_fraction=0.5345141250872596,
                                                            learning_rate=0.19137594112085554,
                                                            min_child_samples=10,
                                                            min_split_gain=0.6540838986559412,
                                                            n_estimators=242,
                                                            n_jobs=-1,
                                                            num_leaves=53,
                                                            random_state=888,
                                                            reg_alpha=1.3631156336007196e-06,
                                                            reg_lambda=2.6400581173536615e-07))],
                                 n_jobs=-1))])
2025-03-20 19:01:37,242:INFO:save_model() successfully completed......................................
2025-03-20 19:04:35,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:04:35,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:04:35,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:04:35,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:04:35,191:INFO:Initializing load_model()
2025-03-20 19:04:35,191:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_190136, platform=None, authentication=None, verbose=True)
2025-03-20 19:04:35,718:INFO:Initializing predict_model()
2025-03-20 19:04:35,718:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002738AEFE850>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8008005013254366,
                                                            bagging_freq=5,
                                                            feature_fraction=0.5345141250872596,
                                                            learning_rate=0.19137594112085554,
                                                            min_child_samples=10,
                                                            min_split_gain=0.6540838986559412,
                                                            n_estimators=242,
                                                            n_jobs=-1,
                                                            num_leaves=53,
                                                            random_state=888,
                                                            reg_alpha=1.3631156336007196e-06,
                                                            reg_lambda=2.6400581173536615e-07))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000273F146E8B0>)
2025-03-20 19:04:35,718:INFO:Checking exceptions
2025-03-20 19:04:35,718:INFO:Preloading libraries
2025-03-20 19:04:35,718:INFO:Set up data.
2025-03-20 19:04:35,724:INFO:Set up index.
2025-03-20 19:04:35,795:INFO:Initializing load_model()
2025-03-20 19:04:35,795:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_190136, platform=None, authentication=None, verbose=True)
2025-03-20 19:04:35,819:INFO:Initializing predict_model()
2025-03-20 19:04:35,819:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002738C019B20>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             ('Light Gradient Boosting Machine',
                                              LGBMRegressor(bagging_fraction=0.8008005013254366,
                                                            bagging_freq=5,
                                                            feature_fraction=0.5345141250872596,
                                                            learning_rate=0.19137594112085554,
                                                            min_child_samples=10,
                                                            min_split_gain=0.6540838986559412,
                                                            n_estimators=242,
                                                            n_jobs=-1,
                                                            num_leaves=53,
                                                            random_state=888,
                                                            reg_alpha=1.3631156336007196e-06,
                                                            reg_lambda=2.6400581173536615e-07))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000273F09EC1F0>)
2025-03-20 19:04:35,819:INFO:Checking exceptions
2025-03-20 19:04:35,819:INFO:Preloading libraries
2025-03-20 19:04:35,820:INFO:Set up data.
2025-03-20 19:04:35,826:INFO:Set up index.
2025-03-20 19:04:39,171:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 19:04:41,248:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 19:14:53,733:INFO:PyCaret RegressionExperiment
2025-03-20 19:14:53,733:INFO:Logging name: reg-default-name
2025-03-20 19:14:53,733:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 19:14:53,733:INFO:version 3.2.0
2025-03-20 19:14:53,733:INFO:Initializing setup()
2025-03-20 19:14:53,733:INFO:self.USI: 74fe
2025-03-20 19:14:53,733:INFO:self._variable_keys: {'_ml_usecase', 'exp_name_log', 'logging_param', 'seed', 'data', 'X_train', 'y', 'transform_target_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X_test', '_available_plots', 'exp_id', 'idx', 'gpu_param', 'memory', 'target_param', 'log_plots_param', 'y_train', 'gpu_n_jobs_param', 'X', 'USI', 'n_jobs_param', 'pipeline', 'html_param', 'y_test'}
2025-03-20 19:14:53,733:INFO:Checking environment
2025-03-20 19:14:53,733:INFO:python_version: 3.8.20
2025-03-20 19:14:53,733:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 19:14:53,733:INFO:machine: AMD64
2025-03-20 19:14:53,733:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 19:14:53,740:INFO:Memory: svmem(total=68447973376, available=39517536256, percent=42.3, used=28930437120, free=39517536256)
2025-03-20 19:14:53,740:INFO:Physical Core: 24
2025-03-20 19:14:53,740:INFO:Logical Core: 32
2025-03-20 19:14:53,740:INFO:Checking libraries
2025-03-20 19:14:53,740:INFO:System:
2025-03-20 19:14:53,740:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 19:14:53,740:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 19:14:53,740:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 19:14:53,740:INFO:PyCaret required dependencies:
2025-03-20 19:14:53,740:INFO:                 pip: 24.2
2025-03-20 19:14:53,740:INFO:          setuptools: 75.1.0
2025-03-20 19:14:53,740:INFO:             pycaret: 3.2.0
2025-03-20 19:14:53,740:INFO:             IPython: 8.12.3
2025-03-20 19:14:53,740:INFO:          ipywidgets: 8.1.5
2025-03-20 19:14:53,740:INFO:                tqdm: 4.67.1
2025-03-20 19:14:53,740:INFO:               numpy: 1.24.4
2025-03-20 19:14:53,740:INFO:              pandas: 1.5.3
2025-03-20 19:14:53,740:INFO:              jinja2: 3.1.4
2025-03-20 19:14:53,740:INFO:               scipy: 1.10.1
2025-03-20 19:14:53,740:INFO:              joblib: 1.3.2
2025-03-20 19:14:53,740:INFO:             sklearn: 1.2.2
2025-03-20 19:14:53,740:INFO:                pyod: 2.0.2
2025-03-20 19:14:53,740:INFO:            imblearn: 0.12.4
2025-03-20 19:14:53,740:INFO:   category_encoders: 2.6.4
2025-03-20 19:14:53,740:INFO:            lightgbm: 4.5.0
2025-03-20 19:14:53,740:INFO:               numba: 0.58.1
2025-03-20 19:14:53,740:INFO:            requests: 2.32.3
2025-03-20 19:14:53,740:INFO:          matplotlib: 3.6.0
2025-03-20 19:14:53,740:INFO:          scikitplot: 0.3.7
2025-03-20 19:14:53,740:INFO:         yellowbrick: 1.5
2025-03-20 19:14:53,740:INFO:              plotly: 5.24.1
2025-03-20 19:14:53,740:INFO:    plotly-resampler: Not installed
2025-03-20 19:14:53,740:INFO:             kaleido: 0.2.1
2025-03-20 19:14:53,740:INFO:           schemdraw: 0.15
2025-03-20 19:14:53,740:INFO:         statsmodels: 0.14.1
2025-03-20 19:14:53,740:INFO:              sktime: 0.21.1
2025-03-20 19:14:53,740:INFO:               tbats: 1.1.3
2025-03-20 19:14:53,740:INFO:            pmdarima: 2.0.4
2025-03-20 19:14:53,740:INFO:              psutil: 6.1.0
2025-03-20 19:14:53,740:INFO:          markupsafe: 2.1.5
2025-03-20 19:14:53,740:INFO:             pickle5: Not installed
2025-03-20 19:14:53,740:INFO:         cloudpickle: 2.2.1
2025-03-20 19:14:53,740:INFO:         deprecation: 2.1.0
2025-03-20 19:14:53,740:INFO:              xxhash: 3.5.0
2025-03-20 19:14:53,740:INFO:           wurlitzer: Not installed
2025-03-20 19:14:53,741:INFO:PyCaret optional dependencies:
2025-03-20 19:14:53,741:INFO:                shap: 0.44.1
2025-03-20 19:14:53,741:INFO:           interpret: 0.6.6
2025-03-20 19:14:53,741:INFO:                umap: 0.5.7
2025-03-20 19:14:53,741:INFO:     ydata_profiling: 4.6.0
2025-03-20 19:14:53,741:INFO:  explainerdashboard: 0.4.7
2025-03-20 19:14:53,741:INFO:             autoviz: Not installed
2025-03-20 19:14:53,741:INFO:           fairlearn: 0.7.0
2025-03-20 19:14:53,741:INFO:          deepchecks: Not installed
2025-03-20 19:14:53,741:INFO:             xgboost: 2.1.3
2025-03-20 19:14:53,741:INFO:            catboost: 1.2.7
2025-03-20 19:14:53,741:INFO:              kmodes: 0.12.2
2025-03-20 19:14:53,741:INFO:             mlxtend: 0.23.1
2025-03-20 19:14:53,741:INFO:       statsforecast: 1.5.0
2025-03-20 19:14:53,741:INFO:        tune_sklearn: 0.5.0
2025-03-20 19:14:53,741:INFO:                 ray: 2.10.0
2025-03-20 19:14:53,741:INFO:            hyperopt: 0.2.7
2025-03-20 19:14:53,741:INFO:              optuna: 4.1.0
2025-03-20 19:14:53,741:INFO:               skopt: 0.10.2
2025-03-20 19:14:53,741:INFO:              mlflow: 1.30.1
2025-03-20 19:14:53,741:INFO:              gradio: 3.50.2
2025-03-20 19:14:53,741:INFO:             fastapi: 0.115.5
2025-03-20 19:14:53,741:INFO:             uvicorn: 0.32.1
2025-03-20 19:14:53,741:INFO:              m2cgen: 0.10.0
2025-03-20 19:14:53,741:INFO:           evidently: 0.2.8
2025-03-20 19:14:53,741:INFO:               fugue: 0.8.6
2025-03-20 19:14:53,741:INFO:           streamlit: Not installed
2025-03-20 19:14:53,741:INFO:             prophet: Not installed
2025-03-20 19:14:53,741:INFO:None
2025-03-20 19:14:53,741:INFO:Set up data.
2025-03-20 19:14:53,746:INFO:Set up folding strategy.
2025-03-20 19:14:53,746:INFO:Set up train/test split.
2025-03-20 19:14:53,746:INFO:Set up data.
2025-03-20 19:14:53,751:INFO:Set up index.
2025-03-20 19:14:53,751:INFO:Assigning column types.
2025-03-20 19:14:53,753:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 19:14:53,753:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,755:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,757:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,803:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:53,804:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:53,805:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,807:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,855:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:53,856:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:53,856:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 19:14:53,858:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,860:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,907:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:53,908:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:53,910:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,912:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,958:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:53,959:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:53,960:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 19:14:53,964:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:14:53,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,009:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,010:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,014:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,059:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,060:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,060:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 19:14:54,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,114:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,115:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,144:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,164:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,165:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,165:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 19:14:54,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,212:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,213:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:14:54,261:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,262:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,263:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 19:14:54,312:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,313:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,362:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,363:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,364:INFO:Preparing preprocessing pipeline...
2025-03-20 19:14:54,364:INFO:Set up simple imputation.
2025-03-20 19:14:54,365:INFO:Set up encoding of categorical features.
2025-03-20 19:14:54,365:INFO:Set up feature normalization.
2025-03-20 19:14:54,366:INFO:Set up column name cleaning.
2025-03-20 19:14:54,416:INFO:Finished creating preprocessing pipeline.
2025-03-20 19:14:54,420:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:14:54,420:INFO:Creating final display dataframe.
2025-03-20 19:14:54,552:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              74fe
2025-03-20 19:14:54,618:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,619:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,671:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:14:54,672:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:14:54,672:INFO:Logging experiment in loggers
2025-03-20 19:14:54,707:INFO:SubProcess save_model() called ==================================
2025-03-20 19:14:54,714:INFO:Initializing save_model()
2025-03-20 19:14:54,715:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpo37wbs6i\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:14:54,715:INFO:Adding model into prep_pipe
2025-03-20 19:14:54,715:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:14:54,718:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpo37wbs6i\Transformation Pipeline.pkl saved in current working directory
2025-03-20 19:14:54,722:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:14:54,722:INFO:save_model() successfully completed......................................
2025-03-20 19:14:54,784:INFO:SubProcess save_model() end ==================================
2025-03-20 19:14:54,789:INFO:setup() successfully completed in 0.94s...............
2025-03-20 19:14:54,789:INFO:Initializing compare_models()
2025-03-20 19:14:54,789:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 19:14:54,789:INFO:Checking exceptions
2025-03-20 19:14:54,791:INFO:Preparing display monitor
2025-03-20 19:14:54,804:INFO:Initializing Linear Regression
2025-03-20 19:14:54,804:INFO:Total runtime is 0.0 minutes
2025-03-20 19:14:54,807:INFO:SubProcess create_model() called ==================================
2025-03-20 19:14:54,807:INFO:Initializing create_model()
2025-03-20 19:14:54,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:14:54,807:INFO:Checking exceptions
2025-03-20 19:14:54,807:INFO:Importing libraries
2025-03-20 19:14:54,807:INFO:Copying training dataset
2025-03-20 19:14:54,810:INFO:Defining folds
2025-03-20 19:14:54,810:INFO:Declaring metric variables
2025-03-20 19:14:54,812:INFO:Importing untrained model
2025-03-20 19:14:54,813:INFO:Linear Regression Imported successfully
2025-03-20 19:14:54,818:INFO:Starting cross validation
2025-03-20 19:14:54,819:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:14:57,308:INFO:Calculating mean and std
2025-03-20 19:14:57,310:INFO:Creating metrics dataframe
2025-03-20 19:14:57,311:INFO:Uploading results into container
2025-03-20 19:14:57,312:INFO:Uploading model into container now
2025-03-20 19:14:57,313:INFO:_master_model_container: 1
2025-03-20 19:14:57,313:INFO:_display_container: 2
2025-03-20 19:14:57,313:INFO:LinearRegression(n_jobs=-1)
2025-03-20 19:14:57,313:INFO:create_model() successfully completed......................................
2025-03-20 19:14:57,379:INFO:SubProcess create_model() end ==================================
2025-03-20 19:14:57,379:INFO:Creating metrics dataframe
2025-03-20 19:14:57,383:INFO:Initializing Lasso Regression
2025-03-20 19:14:57,383:INFO:Total runtime is 0.04297816356023153 minutes
2025-03-20 19:14:57,386:INFO:SubProcess create_model() called ==================================
2025-03-20 19:14:57,386:INFO:Initializing create_model()
2025-03-20 19:14:57,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:14:57,386:INFO:Checking exceptions
2025-03-20 19:14:57,386:INFO:Importing libraries
2025-03-20 19:14:57,386:INFO:Copying training dataset
2025-03-20 19:14:57,388:INFO:Defining folds
2025-03-20 19:14:57,388:INFO:Declaring metric variables
2025-03-20 19:14:57,390:INFO:Importing untrained model
2025-03-20 19:14:57,392:INFO:Lasso Regression Imported successfully
2025-03-20 19:14:57,395:INFO:Starting cross validation
2025-03-20 19:14:57,396:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:14:59,387:INFO:Calculating mean and std
2025-03-20 19:14:59,388:INFO:Creating metrics dataframe
2025-03-20 19:14:59,390:INFO:Uploading results into container
2025-03-20 19:14:59,390:INFO:Uploading model into container now
2025-03-20 19:14:59,390:INFO:_master_model_container: 2
2025-03-20 19:14:59,391:INFO:_display_container: 2
2025-03-20 19:14:59,391:INFO:Lasso(random_state=888)
2025-03-20 19:14:59,391:INFO:create_model() successfully completed......................................
2025-03-20 19:14:59,457:INFO:SubProcess create_model() end ==================================
2025-03-20 19:14:59,457:INFO:Creating metrics dataframe
2025-03-20 19:14:59,462:INFO:Initializing Ridge Regression
2025-03-20 19:14:59,462:INFO:Total runtime is 0.07762890259424846 minutes
2025-03-20 19:14:59,464:INFO:SubProcess create_model() called ==================================
2025-03-20 19:14:59,464:INFO:Initializing create_model()
2025-03-20 19:14:59,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:14:59,464:INFO:Checking exceptions
2025-03-20 19:14:59,465:INFO:Importing libraries
2025-03-20 19:14:59,465:INFO:Copying training dataset
2025-03-20 19:14:59,467:INFO:Defining folds
2025-03-20 19:14:59,467:INFO:Declaring metric variables
2025-03-20 19:14:59,468:INFO:Importing untrained model
2025-03-20 19:14:59,470:INFO:Ridge Regression Imported successfully
2025-03-20 19:14:59,473:INFO:Starting cross validation
2025-03-20 19:14:59,474:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:01,496:INFO:Calculating mean and std
2025-03-20 19:15:01,497:INFO:Creating metrics dataframe
2025-03-20 19:15:01,500:INFO:Uploading results into container
2025-03-20 19:15:01,500:INFO:Uploading model into container now
2025-03-20 19:15:01,500:INFO:_master_model_container: 3
2025-03-20 19:15:01,500:INFO:_display_container: 2
2025-03-20 19:15:01,500:INFO:Ridge(random_state=888)
2025-03-20 19:15:01,501:INFO:create_model() successfully completed......................................
2025-03-20 19:15:01,568:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:01,568:INFO:Creating metrics dataframe
2025-03-20 19:15:01,574:INFO:Initializing Elastic Net
2025-03-20 19:15:01,574:INFO:Total runtime is 0.11282596985499065 minutes
2025-03-20 19:15:01,577:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:01,577:INFO:Initializing create_model()
2025-03-20 19:15:01,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:01,577:INFO:Checking exceptions
2025-03-20 19:15:01,577:INFO:Importing libraries
2025-03-20 19:15:01,577:INFO:Copying training dataset
2025-03-20 19:15:01,579:INFO:Defining folds
2025-03-20 19:15:01,579:INFO:Declaring metric variables
2025-03-20 19:15:01,581:INFO:Importing untrained model
2025-03-20 19:15:01,583:INFO:Elastic Net Imported successfully
2025-03-20 19:15:01,587:INFO:Starting cross validation
2025-03-20 19:15:01,588:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:03,605:INFO:Calculating mean and std
2025-03-20 19:15:03,606:INFO:Creating metrics dataframe
2025-03-20 19:15:03,609:INFO:Uploading results into container
2025-03-20 19:15:03,610:INFO:Uploading model into container now
2025-03-20 19:15:03,610:INFO:_master_model_container: 4
2025-03-20 19:15:03,610:INFO:_display_container: 2
2025-03-20 19:15:03,611:INFO:ElasticNet(random_state=888)
2025-03-20 19:15:03,611:INFO:create_model() successfully completed......................................
2025-03-20 19:15:03,670:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:03,671:INFO:Creating metrics dataframe
2025-03-20 19:15:03,675:INFO:Initializing Least Angle Regression
2025-03-20 19:15:03,675:INFO:Total runtime is 0.1478492061297099 minutes
2025-03-20 19:15:03,678:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:03,678:INFO:Initializing create_model()
2025-03-20 19:15:03,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:03,678:INFO:Checking exceptions
2025-03-20 19:15:03,678:INFO:Importing libraries
2025-03-20 19:15:03,678:INFO:Copying training dataset
2025-03-20 19:15:03,680:INFO:Defining folds
2025-03-20 19:15:03,680:INFO:Declaring metric variables
2025-03-20 19:15:03,682:INFO:Importing untrained model
2025-03-20 19:15:03,684:INFO:Least Angle Regression Imported successfully
2025-03-20 19:15:03,687:INFO:Starting cross validation
2025-03-20 19:15:03,688:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:05,611:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,611:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,612:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,612:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,612:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.010e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,612:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.349e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,612:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,612:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,612:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.688e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,613:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.707e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,613:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.503e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,613:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.186e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,614:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.114e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,614:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.912e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,614:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.216e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,614:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.848e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,614:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.737e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:05,638:INFO:Calculating mean and std
2025-03-20 19:15:05,639:INFO:Creating metrics dataframe
2025-03-20 19:15:05,640:INFO:Uploading results into container
2025-03-20 19:15:05,641:INFO:Uploading model into container now
2025-03-20 19:15:05,641:INFO:_master_model_container: 5
2025-03-20 19:15:05,641:INFO:_display_container: 2
2025-03-20 19:15:05,641:INFO:Lars(random_state=888)
2025-03-20 19:15:05,641:INFO:create_model() successfully completed......................................
2025-03-20 19:15:05,706:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:05,706:INFO:Creating metrics dataframe
2025-03-20 19:15:05,711:INFO:Initializing Lasso Least Angle Regression
2025-03-20 19:15:05,711:INFO:Total runtime is 0.18177978197733563 minutes
2025-03-20 19:15:05,713:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:05,713:INFO:Initializing create_model()
2025-03-20 19:15:05,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:05,714:INFO:Checking exceptions
2025-03-20 19:15:05,714:INFO:Importing libraries
2025-03-20 19:15:05,714:INFO:Copying training dataset
2025-03-20 19:15:05,716:INFO:Defining folds
2025-03-20 19:15:05,716:INFO:Declaring metric variables
2025-03-20 19:15:05,718:INFO:Importing untrained model
2025-03-20 19:15:05,720:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 19:15:05,723:INFO:Starting cross validation
2025-03-20 19:15:05,724:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:07,701:INFO:Calculating mean and std
2025-03-20 19:15:07,702:INFO:Creating metrics dataframe
2025-03-20 19:15:07,704:INFO:Uploading results into container
2025-03-20 19:15:07,704:INFO:Uploading model into container now
2025-03-20 19:15:07,705:INFO:_master_model_container: 6
2025-03-20 19:15:07,705:INFO:_display_container: 2
2025-03-20 19:15:07,705:INFO:LassoLars(random_state=888)
2025-03-20 19:15:07,705:INFO:create_model() successfully completed......................................
2025-03-20 19:15:07,768:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:07,768:INFO:Creating metrics dataframe
2025-03-20 19:15:07,774:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 19:15:07,774:INFO:Total runtime is 0.21615734895070396 minutes
2025-03-20 19:15:07,775:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:07,775:INFO:Initializing create_model()
2025-03-20 19:15:07,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:07,776:INFO:Checking exceptions
2025-03-20 19:15:07,776:INFO:Importing libraries
2025-03-20 19:15:07,776:INFO:Copying training dataset
2025-03-20 19:15:07,778:INFO:Defining folds
2025-03-20 19:15:07,778:INFO:Declaring metric variables
2025-03-20 19:15:07,780:INFO:Importing untrained model
2025-03-20 19:15:07,782:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 19:15:07,785:INFO:Starting cross validation
2025-03-20 19:15:07,787:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:09,503:INFO:Calculating mean and std
2025-03-20 19:15:09,504:INFO:Creating metrics dataframe
2025-03-20 19:15:09,505:INFO:Uploading results into container
2025-03-20 19:15:09,505:INFO:Uploading model into container now
2025-03-20 19:15:09,506:INFO:_master_model_container: 7
2025-03-20 19:15:09,506:INFO:_display_container: 2
2025-03-20 19:15:09,506:INFO:OrthogonalMatchingPursuit()
2025-03-20 19:15:09,506:INFO:create_model() successfully completed......................................
2025-03-20 19:15:09,565:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:09,565:INFO:Creating metrics dataframe
2025-03-20 19:15:09,570:INFO:Initializing Bayesian Ridge
2025-03-20 19:15:09,570:INFO:Total runtime is 0.2460980335871379 minutes
2025-03-20 19:15:09,572:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:09,572:INFO:Initializing create_model()
2025-03-20 19:15:09,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:09,572:INFO:Checking exceptions
2025-03-20 19:15:09,572:INFO:Importing libraries
2025-03-20 19:15:09,572:INFO:Copying training dataset
2025-03-20 19:15:09,574:INFO:Defining folds
2025-03-20 19:15:09,574:INFO:Declaring metric variables
2025-03-20 19:15:09,576:INFO:Importing untrained model
2025-03-20 19:15:09,577:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:15:09,581:INFO:Starting cross validation
2025-03-20 19:15:09,582:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:09,656:INFO:Calculating mean and std
2025-03-20 19:15:09,657:INFO:Creating metrics dataframe
2025-03-20 19:15:09,659:INFO:Uploading results into container
2025-03-20 19:15:09,660:INFO:Uploading model into container now
2025-03-20 19:15:09,660:INFO:_master_model_container: 8
2025-03-20 19:15:09,660:INFO:_display_container: 2
2025-03-20 19:15:09,660:INFO:BayesianRidge()
2025-03-20 19:15:09,660:INFO:create_model() successfully completed......................................
2025-03-20 19:15:09,719:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:09,719:INFO:Creating metrics dataframe
2025-03-20 19:15:09,724:INFO:Initializing Passive Aggressive Regressor
2025-03-20 19:15:09,724:INFO:Total runtime is 0.24866433938344323 minutes
2025-03-20 19:15:09,726:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:09,726:INFO:Initializing create_model()
2025-03-20 19:15:09,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:09,726:INFO:Checking exceptions
2025-03-20 19:15:09,727:INFO:Importing libraries
2025-03-20 19:15:09,727:INFO:Copying training dataset
2025-03-20 19:15:09,729:INFO:Defining folds
2025-03-20 19:15:09,729:INFO:Declaring metric variables
2025-03-20 19:15:09,731:INFO:Importing untrained model
2025-03-20 19:15:09,732:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 19:15:09,736:INFO:Starting cross validation
2025-03-20 19:15:09,737:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:09,810:INFO:Calculating mean and std
2025-03-20 19:15:09,811:INFO:Creating metrics dataframe
2025-03-20 19:15:09,812:INFO:Uploading results into container
2025-03-20 19:15:09,813:INFO:Uploading model into container now
2025-03-20 19:15:09,813:INFO:_master_model_container: 9
2025-03-20 19:15:09,813:INFO:_display_container: 2
2025-03-20 19:15:09,813:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 19:15:09,813:INFO:create_model() successfully completed......................................
2025-03-20 19:15:09,874:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:09,874:INFO:Creating metrics dataframe
2025-03-20 19:15:09,879:INFO:Initializing Huber Regressor
2025-03-20 19:15:09,879:INFO:Total runtime is 0.2512429356575013 minutes
2025-03-20 19:15:09,881:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:09,881:INFO:Initializing create_model()
2025-03-20 19:15:09,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:09,881:INFO:Checking exceptions
2025-03-20 19:15:09,881:INFO:Importing libraries
2025-03-20 19:15:09,882:INFO:Copying training dataset
2025-03-20 19:15:09,884:INFO:Defining folds
2025-03-20 19:15:09,884:INFO:Declaring metric variables
2025-03-20 19:15:09,885:INFO:Importing untrained model
2025-03-20 19:15:09,887:INFO:Huber Regressor Imported successfully
2025-03-20 19:15:09,890:INFO:Starting cross validation
2025-03-20 19:15:09,891:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:09,932:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:09,937:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:09,940:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:09,946:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:09,948:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:09,964:INFO:Calculating mean and std
2025-03-20 19:15:09,965:INFO:Creating metrics dataframe
2025-03-20 19:15:09,966:INFO:Uploading results into container
2025-03-20 19:15:09,966:INFO:Uploading model into container now
2025-03-20 19:15:09,967:INFO:_master_model_container: 10
2025-03-20 19:15:09,967:INFO:_display_container: 2
2025-03-20 19:15:09,967:INFO:HuberRegressor()
2025-03-20 19:15:09,967:INFO:create_model() successfully completed......................................
2025-03-20 19:15:10,027:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:10,027:INFO:Creating metrics dataframe
2025-03-20 19:15:10,033:INFO:Initializing K Neighbors Regressor
2025-03-20 19:15:10,033:INFO:Total runtime is 0.2538007616996766 minutes
2025-03-20 19:15:10,034:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:10,035:INFO:Initializing create_model()
2025-03-20 19:15:10,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:10,035:INFO:Checking exceptions
2025-03-20 19:15:10,035:INFO:Importing libraries
2025-03-20 19:15:10,035:INFO:Copying training dataset
2025-03-20 19:15:10,037:INFO:Defining folds
2025-03-20 19:15:10,037:INFO:Declaring metric variables
2025-03-20 19:15:10,039:INFO:Importing untrained model
2025-03-20 19:15:10,041:INFO:K Neighbors Regressor Imported successfully
2025-03-20 19:15:10,044:INFO:Starting cross validation
2025-03-20 19:15:10,045:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:10,149:INFO:Calculating mean and std
2025-03-20 19:15:10,150:INFO:Creating metrics dataframe
2025-03-20 19:15:10,151:INFO:Uploading results into container
2025-03-20 19:15:10,152:INFO:Uploading model into container now
2025-03-20 19:15:10,152:INFO:_master_model_container: 11
2025-03-20 19:15:10,152:INFO:_display_container: 2
2025-03-20 19:15:10,152:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 19:15:10,152:INFO:create_model() successfully completed......................................
2025-03-20 19:15:10,213:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:10,213:INFO:Creating metrics dataframe
2025-03-20 19:15:10,219:INFO:Initializing Decision Tree Regressor
2025-03-20 19:15:10,219:INFO:Total runtime is 0.25690493186314906 minutes
2025-03-20 19:15:10,220:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:10,220:INFO:Initializing create_model()
2025-03-20 19:15:10,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:10,221:INFO:Checking exceptions
2025-03-20 19:15:10,221:INFO:Importing libraries
2025-03-20 19:15:10,221:INFO:Copying training dataset
2025-03-20 19:15:10,223:INFO:Defining folds
2025-03-20 19:15:10,223:INFO:Declaring metric variables
2025-03-20 19:15:10,225:INFO:Importing untrained model
2025-03-20 19:15:10,227:INFO:Decision Tree Regressor Imported successfully
2025-03-20 19:15:10,230:INFO:Starting cross validation
2025-03-20 19:15:10,230:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:10,318:INFO:Calculating mean and std
2025-03-20 19:15:10,319:INFO:Creating metrics dataframe
2025-03-20 19:15:10,321:INFO:Uploading results into container
2025-03-20 19:15:10,321:INFO:Uploading model into container now
2025-03-20 19:15:10,321:INFO:_master_model_container: 12
2025-03-20 19:15:10,321:INFO:_display_container: 2
2025-03-20 19:15:10,321:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 19:15:10,321:INFO:create_model() successfully completed......................................
2025-03-20 19:15:10,381:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:10,381:INFO:Creating metrics dataframe
2025-03-20 19:15:10,388:INFO:Initializing Random Forest Regressor
2025-03-20 19:15:10,388:INFO:Total runtime is 0.2597263375918071 minutes
2025-03-20 19:15:10,390:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:10,390:INFO:Initializing create_model()
2025-03-20 19:15:10,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:10,391:INFO:Checking exceptions
2025-03-20 19:15:10,391:INFO:Importing libraries
2025-03-20 19:15:10,391:INFO:Copying training dataset
2025-03-20 19:15:10,393:INFO:Defining folds
2025-03-20 19:15:10,393:INFO:Declaring metric variables
2025-03-20 19:15:10,395:INFO:Importing untrained model
2025-03-20 19:15:10,397:INFO:Random Forest Regressor Imported successfully
2025-03-20 19:15:10,400:INFO:Starting cross validation
2025-03-20 19:15:10,402:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:10,780:INFO:Calculating mean and std
2025-03-20 19:15:10,781:INFO:Creating metrics dataframe
2025-03-20 19:15:10,782:INFO:Uploading results into container
2025-03-20 19:15:10,783:INFO:Uploading model into container now
2025-03-20 19:15:10,783:INFO:_master_model_container: 13
2025-03-20 19:15:10,783:INFO:_display_container: 2
2025-03-20 19:15:10,783:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:15:10,783:INFO:create_model() successfully completed......................................
2025-03-20 19:15:10,845:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:10,845:INFO:Creating metrics dataframe
2025-03-20 19:15:10,850:INFO:Initializing Extra Trees Regressor
2025-03-20 19:15:10,850:INFO:Total runtime is 0.2674336632092794 minutes
2025-03-20 19:15:10,852:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:10,852:INFO:Initializing create_model()
2025-03-20 19:15:10,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:10,852:INFO:Checking exceptions
2025-03-20 19:15:10,852:INFO:Importing libraries
2025-03-20 19:15:10,852:INFO:Copying training dataset
2025-03-20 19:15:10,855:INFO:Defining folds
2025-03-20 19:15:10,855:INFO:Declaring metric variables
2025-03-20 19:15:10,856:INFO:Importing untrained model
2025-03-20 19:15:10,858:INFO:Extra Trees Regressor Imported successfully
2025-03-20 19:15:10,862:INFO:Starting cross validation
2025-03-20 19:15:10,863:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:11,057:INFO:Calculating mean and std
2025-03-20 19:15:11,058:INFO:Creating metrics dataframe
2025-03-20 19:15:11,060:INFO:Uploading results into container
2025-03-20 19:15:11,060:INFO:Uploading model into container now
2025-03-20 19:15:11,061:INFO:_master_model_container: 14
2025-03-20 19:15:11,061:INFO:_display_container: 2
2025-03-20 19:15:11,061:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:15:11,061:INFO:create_model() successfully completed......................................
2025-03-20 19:15:11,121:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:11,121:INFO:Creating metrics dataframe
2025-03-20 19:15:11,127:INFO:Initializing AdaBoost Regressor
2025-03-20 19:15:11,127:INFO:Total runtime is 0.2720353205998739 minutes
2025-03-20 19:15:11,129:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:11,129:INFO:Initializing create_model()
2025-03-20 19:15:11,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:11,129:INFO:Checking exceptions
2025-03-20 19:15:11,129:INFO:Importing libraries
2025-03-20 19:15:11,129:INFO:Copying training dataset
2025-03-20 19:15:11,131:INFO:Defining folds
2025-03-20 19:15:11,131:INFO:Declaring metric variables
2025-03-20 19:15:11,133:INFO:Importing untrained model
2025-03-20 19:15:11,135:INFO:AdaBoost Regressor Imported successfully
2025-03-20 19:15:11,139:INFO:Starting cross validation
2025-03-20 19:15:11,140:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:11,350:INFO:Calculating mean and std
2025-03-20 19:15:11,351:INFO:Creating metrics dataframe
2025-03-20 19:15:11,353:INFO:Uploading results into container
2025-03-20 19:15:11,353:INFO:Uploading model into container now
2025-03-20 19:15:11,353:INFO:_master_model_container: 15
2025-03-20 19:15:11,353:INFO:_display_container: 2
2025-03-20 19:15:11,353:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 19:15:11,354:INFO:create_model() successfully completed......................................
2025-03-20 19:15:11,415:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:11,415:INFO:Creating metrics dataframe
2025-03-20 19:15:11,421:INFO:Initializing Gradient Boosting Regressor
2025-03-20 19:15:11,421:INFO:Total runtime is 0.2769357562065125 minutes
2025-03-20 19:15:11,423:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:11,423:INFO:Initializing create_model()
2025-03-20 19:15:11,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:11,423:INFO:Checking exceptions
2025-03-20 19:15:11,423:INFO:Importing libraries
2025-03-20 19:15:11,423:INFO:Copying training dataset
2025-03-20 19:15:11,425:INFO:Defining folds
2025-03-20 19:15:11,426:INFO:Declaring metric variables
2025-03-20 19:15:11,427:INFO:Importing untrained model
2025-03-20 19:15:11,429:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:15:11,433:INFO:Starting cross validation
2025-03-20 19:15:11,434:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:12,043:INFO:Calculating mean and std
2025-03-20 19:15:12,044:INFO:Creating metrics dataframe
2025-03-20 19:15:12,045:INFO:Uploading results into container
2025-03-20 19:15:12,046:INFO:Uploading model into container now
2025-03-20 19:15:12,046:INFO:_master_model_container: 16
2025-03-20 19:15:12,046:INFO:_display_container: 2
2025-03-20 19:15:12,047:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:15:12,047:INFO:create_model() successfully completed......................................
2025-03-20 19:15:12,106:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:12,106:INFO:Creating metrics dataframe
2025-03-20 19:15:12,112:INFO:Initializing Extreme Gradient Boosting
2025-03-20 19:15:12,112:INFO:Total runtime is 0.2884592453638713 minutes
2025-03-20 19:15:12,114:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:12,115:INFO:Initializing create_model()
2025-03-20 19:15:12,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:12,115:INFO:Checking exceptions
2025-03-20 19:15:12,115:INFO:Importing libraries
2025-03-20 19:15:12,115:INFO:Copying training dataset
2025-03-20 19:15:12,116:INFO:Defining folds
2025-03-20 19:15:12,116:INFO:Declaring metric variables
2025-03-20 19:15:12,118:INFO:Importing untrained model
2025-03-20 19:15:12,120:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:15:12,124:INFO:Starting cross validation
2025-03-20 19:15:12,125:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:12,581:INFO:Calculating mean and std
2025-03-20 19:15:12,582:INFO:Creating metrics dataframe
2025-03-20 19:15:12,583:INFO:Uploading results into container
2025-03-20 19:15:12,584:INFO:Uploading model into container now
2025-03-20 19:15:12,584:INFO:_master_model_container: 17
2025-03-20 19:15:12,584:INFO:_display_container: 2
2025-03-20 19:15:12,584:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:15:12,585:INFO:create_model() successfully completed......................................
2025-03-20 19:15:12,644:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:12,644:INFO:Creating metrics dataframe
2025-03-20 19:15:12,651:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 19:15:12,651:INFO:Total runtime is 0.2974405686060588 minutes
2025-03-20 19:15:12,653:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:12,653:INFO:Initializing create_model()
2025-03-20 19:15:12,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:12,653:INFO:Checking exceptions
2025-03-20 19:15:12,653:INFO:Importing libraries
2025-03-20 19:15:12,653:INFO:Copying training dataset
2025-03-20 19:15:12,656:INFO:Defining folds
2025-03-20 19:15:12,656:INFO:Declaring metric variables
2025-03-20 19:15:12,657:INFO:Importing untrained model
2025-03-20 19:15:12,659:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:15:12,663:INFO:Starting cross validation
2025-03-20 19:15:12,664:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:13,135:INFO:Calculating mean and std
2025-03-20 19:15:13,136:INFO:Creating metrics dataframe
2025-03-20 19:15:13,139:INFO:Uploading results into container
2025-03-20 19:15:13,139:INFO:Uploading model into container now
2025-03-20 19:15:13,139:INFO:_master_model_container: 18
2025-03-20 19:15:13,139:INFO:_display_container: 2
2025-03-20 19:15:13,140:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:15:13,140:INFO:create_model() successfully completed......................................
2025-03-20 19:15:13,204:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:13,204:INFO:Creating metrics dataframe
2025-03-20 19:15:13,213:INFO:Initializing CatBoost Regressor
2025-03-20 19:15:13,213:INFO:Total runtime is 0.30681092739105226 minutes
2025-03-20 19:15:13,216:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:13,216:INFO:Initializing create_model()
2025-03-20 19:15:13,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:13,216:INFO:Checking exceptions
2025-03-20 19:15:13,216:INFO:Importing libraries
2025-03-20 19:15:13,216:INFO:Copying training dataset
2025-03-20 19:15:13,219:INFO:Defining folds
2025-03-20 19:15:13,219:INFO:Declaring metric variables
2025-03-20 19:15:13,221:INFO:Importing untrained model
2025-03-20 19:15:13,224:INFO:CatBoost Regressor Imported successfully
2025-03-20 19:15:13,228:INFO:Starting cross validation
2025-03-20 19:15:13,229:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:15,645:INFO:Calculating mean and std
2025-03-20 19:15:15,646:INFO:Creating metrics dataframe
2025-03-20 19:15:15,648:INFO:Uploading results into container
2025-03-20 19:15:15,648:INFO:Uploading model into container now
2025-03-20 19:15:15,648:INFO:_master_model_container: 19
2025-03-20 19:15:15,648:INFO:_display_container: 2
2025-03-20 19:15:15,648:INFO:<catboost.core.CatBoostRegressor object at 0x0000022C14238760>
2025-03-20 19:15:15,648:INFO:create_model() successfully completed......................................
2025-03-20 19:15:15,710:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:15,710:INFO:Creating metrics dataframe
2025-03-20 19:15:15,717:INFO:Initializing Dummy Regressor
2025-03-20 19:15:15,717:INFO:Total runtime is 0.348534901936849 minutes
2025-03-20 19:15:15,719:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:15,719:INFO:Initializing create_model()
2025-03-20 19:15:15,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C13F37040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:15,719:INFO:Checking exceptions
2025-03-20 19:15:15,719:INFO:Importing libraries
2025-03-20 19:15:15,719:INFO:Copying training dataset
2025-03-20 19:15:15,721:INFO:Defining folds
2025-03-20 19:15:15,721:INFO:Declaring metric variables
2025-03-20 19:15:15,723:INFO:Importing untrained model
2025-03-20 19:15:15,725:INFO:Dummy Regressor Imported successfully
2025-03-20 19:15:15,728:INFO:Starting cross validation
2025-03-20 19:15:15,729:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:15,799:INFO:Calculating mean and std
2025-03-20 19:15:15,800:INFO:Creating metrics dataframe
2025-03-20 19:15:15,801:INFO:Uploading results into container
2025-03-20 19:15:15,802:INFO:Uploading model into container now
2025-03-20 19:15:15,802:INFO:_master_model_container: 20
2025-03-20 19:15:15,802:INFO:_display_container: 2
2025-03-20 19:15:15,802:INFO:DummyRegressor()
2025-03-20 19:15:15,802:INFO:create_model() successfully completed......................................
2025-03-20 19:15:15,863:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:15,863:INFO:Creating metrics dataframe
2025-03-20 19:15:15,875:INFO:Initializing create_model()
2025-03-20 19:15:15,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:15,875:INFO:Checking exceptions
2025-03-20 19:15:15,875:INFO:Importing libraries
2025-03-20 19:15:15,875:INFO:Copying training dataset
2025-03-20 19:15:15,877:INFO:Defining folds
2025-03-20 19:15:15,877:INFO:Declaring metric variables
2025-03-20 19:15:15,877:INFO:Importing untrained model
2025-03-20 19:15:15,877:INFO:Declaring custom model
2025-03-20 19:15:15,878:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:15:15,878:INFO:Cross validation set to False
2025-03-20 19:15:15,878:INFO:Fitting Model
2025-03-20 19:15:15,916:INFO:BayesianRidge()
2025-03-20 19:15:15,916:INFO:create_model() successfully completed......................................
2025-03-20 19:15:15,976:INFO:Creating Dashboard logs
2025-03-20 19:15:15,979:INFO:Model: Bayesian Ridge
2025-03-20 19:15:15,998:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:15:16,033:INFO:Initializing predict_model()
2025-03-20 19:15:16,034:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BFFEE4940>)
2025-03-20 19:15:16,034:INFO:Checking exceptions
2025-03-20 19:15:16,034:INFO:Preloading libraries
2025-03-20 19:15:16,179:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:16,182:INFO:Initializing create_model()
2025-03-20 19:15:16,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:16,182:INFO:Checking exceptions
2025-03-20 19:15:16,183:INFO:Importing libraries
2025-03-20 19:15:16,183:INFO:Copying training dataset
2025-03-20 19:15:16,186:INFO:Defining folds
2025-03-20 19:15:16,186:INFO:Declaring metric variables
2025-03-20 19:15:16,186:INFO:Importing untrained model
2025-03-20 19:15:16,186:INFO:Declaring custom model
2025-03-20 19:15:16,187:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:15:16,187:INFO:Cross validation set to False
2025-03-20 19:15:16,187:INFO:Fitting Model
2025-03-20 19:15:16,868:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:15:16,868:INFO:create_model() successfully completed......................................
2025-03-20 19:15:16,928:INFO:Creating Dashboard logs
2025-03-20 19:15:16,930:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:15:16,950:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:15:16,995:INFO:Initializing predict_model()
2025-03-20 19:15:16,995:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022C13F8EAF0>)
2025-03-20 19:15:16,995:INFO:Checking exceptions
2025-03-20 19:15:16,996:INFO:Preloading libraries
2025-03-20 19:15:17,140:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:17,143:INFO:Initializing create_model()
2025-03-20 19:15:17,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:17,143:INFO:Checking exceptions
2025-03-20 19:15:17,144:INFO:Importing libraries
2025-03-20 19:15:17,144:INFO:Copying training dataset
2025-03-20 19:15:17,146:INFO:Defining folds
2025-03-20 19:15:17,146:INFO:Declaring metric variables
2025-03-20 19:15:17,146:INFO:Importing untrained model
2025-03-20 19:15:17,146:INFO:Declaring custom model
2025-03-20 19:15:17,146:INFO:Ridge Regression Imported successfully
2025-03-20 19:15:17,147:INFO:Cross validation set to False
2025-03-20 19:15:17,147:INFO:Fitting Model
2025-03-20 19:15:17,180:INFO:Ridge(random_state=888)
2025-03-20 19:15:17,180:INFO:create_model() successfully completed......................................
2025-03-20 19:15:17,240:INFO:Creating Dashboard logs
2025-03-20 19:15:17,242:INFO:Model: Ridge Regression
2025-03-20 19:15:17,261:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:15:17,308:INFO:Initializing predict_model()
2025-03-20 19:15:17,308:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022C13F8EDC0>)
2025-03-20 19:15:17,308:INFO:Checking exceptions
2025-03-20 19:15:17,308:INFO:Preloading libraries
2025-03-20 19:15:17,453:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:17,456:INFO:Initializing create_model()
2025-03-20 19:15:17,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:17,456:INFO:Checking exceptions
2025-03-20 19:15:17,457:INFO:Importing libraries
2025-03-20 19:15:17,457:INFO:Copying training dataset
2025-03-20 19:15:17,459:INFO:Defining folds
2025-03-20 19:15:17,459:INFO:Declaring metric variables
2025-03-20 19:15:17,459:INFO:Importing untrained model
2025-03-20 19:15:17,459:INFO:Declaring custom model
2025-03-20 19:15:17,460:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:15:17,460:INFO:Cross validation set to False
2025-03-20 19:15:17,460:INFO:Fitting Model
2025-03-20 19:15:17,495:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:15:17,496:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.
2025-03-20 19:15:17,496:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:15:17,496:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:15:17,497:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:15:17,498:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:15:17,574:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:15:17,574:INFO:create_model() successfully completed......................................
2025-03-20 19:15:17,674:INFO:Creating Dashboard logs
2025-03-20 19:15:17,676:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:15:17,694:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:15:17,753:INFO:Initializing predict_model()
2025-03-20 19:15:17,753:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022BFEAD7460>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022C13F8E8B0>)
2025-03-20 19:15:17,753:INFO:Checking exceptions
2025-03-20 19:15:17,753:INFO:Preloading libraries
2025-03-20 19:15:17,912:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:17,912:INFO:Creating Dashboard logs
2025-03-20 19:15:17,915:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:15:17,939:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:15:18,039:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,039:INFO:Creating Dashboard logs
2025-03-20 19:15:18,041:INFO:Model: Random Forest Regressor
2025-03-20 19:15:18,060:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:15:18,156:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,156:INFO:Creating Dashboard logs
2025-03-20 19:15:18,158:INFO:Model: AdaBoost Regressor
2025-03-20 19:15:18,176:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 19:15:18,260:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,261:INFO:Creating Dashboard logs
2025-03-20 19:15:18,263:INFO:Model: CatBoost Regressor
2025-03-20 19:15:18,280:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 19:15:18,280:INFO:Logged params: {}
2025-03-20 19:15:18,363:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x0000022C14238760> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,363:INFO:Creating Dashboard logs
2025-03-20 19:15:18,365:INFO:Model: Extra Trees Regressor
2025-03-20 19:15:18,382:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:15:18,480:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,480:INFO:Creating Dashboard logs
2025-03-20 19:15:18,482:INFO:Model: Decision Tree Regressor
2025-03-20 19:15:18,499:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 19:15:18,603:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,604:INFO:Creating Dashboard logs
2025-03-20 19:15:18,606:INFO:Model: Passive Aggressive Regressor
2025-03-20 19:15:18,624:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:15:18,736:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,737:INFO:Creating Dashboard logs
2025-03-20 19:15:18,739:INFO:Model: Huber Regressor
2025-03-20 19:15:18,757:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 19:15:18,870:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:18,871:INFO:Creating Dashboard logs
2025-03-20 19:15:18,873:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 19:15:18,890:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 19:15:19,011:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:19,012:INFO:Creating Dashboard logs
2025-03-20 19:15:19,014:INFO:Model: K Neighbors Regressor
2025-03-20 19:15:19,033:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 19:15:19,168:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:19,169:INFO:Creating Dashboard logs
2025-03-20 19:15:19,171:INFO:Model: Elastic Net
2025-03-20 19:15:19,191:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:15:19,326:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:19,327:INFO:Creating Dashboard logs
2025-03-20 19:15:19,329:INFO:Model: Lasso Regression
2025-03-20 19:15:19,347:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:15:19,487:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:19,487:INFO:Creating Dashboard logs
2025-03-20 19:15:19,489:INFO:Model: Lasso Least Angle Regression
2025-03-20 19:15:19,508:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:15:19,659:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:19,660:INFO:Creating Dashboard logs
2025-03-20 19:15:19,663:INFO:Model: Dummy Regressor
2025-03-20 19:15:19,681:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 19:15:19,831:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:19,832:INFO:Creating Dashboard logs
2025-03-20 19:15:19,834:INFO:Model: Linear Regression
2025-03-20 19:15:19,853:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 19:15:20,007:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:20,007:INFO:Creating Dashboard logs
2025-03-20 19:15:20,009:INFO:Model: Least Angle Regression
2025-03-20 19:15:20,027:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:15:20,192:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:15:20,200:INFO:_master_model_container: 20
2025-03-20 19:15:20,200:INFO:_display_container: 2
2025-03-20 19:15:20,201:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888)]
2025-03-20 19:15:20,201:INFO:compare_models() successfully completed......................................
2025-03-20 19:15:37,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:15:37,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:15:37,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:15:37,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:15:37,370:INFO:PyCaret RegressionExperiment
2025-03-20 19:15:37,370:INFO:Logging name: reg-default-name
2025-03-20 19:15:37,370:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 19:15:37,370:INFO:version 3.2.0
2025-03-20 19:15:37,371:INFO:Initializing setup()
2025-03-20 19:15:37,371:INFO:self.USI: ab17
2025-03-20 19:15:37,371:INFO:self._variable_keys: {'USI', 'y_train', '_ml_usecase', 'y', 'exp_id', 'X_train', 'target_param', 'memory', 'gpu_param', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'logging_param', 'pipeline', '_available_plots', 'n_jobs_param', 'fold_generator', 'html_param', 'fold_shuffle_param', 'y_test', 'seed', 'X_test', 'idx', 'X', 'fold_groups_param', 'exp_name_log', 'data'}
2025-03-20 19:15:37,371:INFO:Checking environment
2025-03-20 19:15:37,371:INFO:python_version: 3.8.20
2025-03-20 19:15:37,371:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 19:15:37,371:INFO:machine: AMD64
2025-03-20 19:15:37,371:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 19:15:37,377:INFO:Memory: svmem(total=68447973376, available=39711412224, percent=42.0, used=28736561152, free=39711412224)
2025-03-20 19:15:37,377:INFO:Physical Core: 24
2025-03-20 19:15:37,377:INFO:Logical Core: 32
2025-03-20 19:15:37,377:INFO:Checking libraries
2025-03-20 19:15:37,378:INFO:System:
2025-03-20 19:15:37,378:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 19:15:37,378:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 19:15:37,378:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 19:15:37,378:INFO:PyCaret required dependencies:
2025-03-20 19:15:37,869:INFO:                 pip: 24.2
2025-03-20 19:15:37,869:INFO:          setuptools: 75.1.0
2025-03-20 19:15:37,869:INFO:             pycaret: 3.2.0
2025-03-20 19:15:37,869:INFO:             IPython: 8.12.3
2025-03-20 19:15:37,869:INFO:          ipywidgets: 8.1.5
2025-03-20 19:15:37,869:INFO:                tqdm: 4.67.1
2025-03-20 19:15:37,869:INFO:               numpy: 1.24.4
2025-03-20 19:15:37,869:INFO:              pandas: 1.5.3
2025-03-20 19:15:37,869:INFO:              jinja2: 3.1.4
2025-03-20 19:15:37,869:INFO:               scipy: 1.10.1
2025-03-20 19:15:37,869:INFO:              joblib: 1.3.2
2025-03-20 19:15:37,869:INFO:             sklearn: 1.2.2
2025-03-20 19:15:37,869:INFO:                pyod: 2.0.2
2025-03-20 19:15:37,869:INFO:            imblearn: 0.12.4
2025-03-20 19:15:37,869:INFO:   category_encoders: 2.6.4
2025-03-20 19:15:37,869:INFO:            lightgbm: 4.5.0
2025-03-20 19:15:37,869:INFO:               numba: 0.58.1
2025-03-20 19:15:37,869:INFO:            requests: 2.32.3
2025-03-20 19:15:37,869:INFO:          matplotlib: 3.6.0
2025-03-20 19:15:37,869:INFO:          scikitplot: 0.3.7
2025-03-20 19:15:37,869:INFO:         yellowbrick: 1.5
2025-03-20 19:15:37,870:INFO:              plotly: 5.24.1
2025-03-20 19:15:37,870:INFO:    plotly-resampler: Not installed
2025-03-20 19:15:37,870:INFO:             kaleido: 0.2.1
2025-03-20 19:15:37,870:INFO:           schemdraw: 0.15
2025-03-20 19:15:37,870:INFO:         statsmodels: 0.14.1
2025-03-20 19:15:37,870:INFO:              sktime: 0.21.1
2025-03-20 19:15:37,870:INFO:               tbats: 1.1.3
2025-03-20 19:15:37,870:INFO:            pmdarima: 2.0.4
2025-03-20 19:15:37,870:INFO:              psutil: 6.1.0
2025-03-20 19:15:37,870:INFO:          markupsafe: 2.1.5
2025-03-20 19:15:37,870:INFO:             pickle5: Not installed
2025-03-20 19:15:37,870:INFO:         cloudpickle: 2.2.1
2025-03-20 19:15:37,870:INFO:         deprecation: 2.1.0
2025-03-20 19:15:37,870:INFO:              xxhash: 3.5.0
2025-03-20 19:15:37,870:INFO:           wurlitzer: Not installed
2025-03-20 19:15:37,870:INFO:PyCaret optional dependencies:
2025-03-20 19:15:39,140:INFO:                shap: 0.44.1
2025-03-20 19:15:39,140:INFO:           interpret: 0.6.6
2025-03-20 19:15:39,140:INFO:                umap: 0.5.7
2025-03-20 19:15:39,140:INFO:     ydata_profiling: 4.6.0
2025-03-20 19:15:39,140:INFO:  explainerdashboard: 0.4.7
2025-03-20 19:15:39,140:INFO:             autoviz: Not installed
2025-03-20 19:15:39,140:INFO:           fairlearn: 0.7.0
2025-03-20 19:15:39,140:INFO:          deepchecks: Not installed
2025-03-20 19:15:39,140:INFO:             xgboost: 2.1.3
2025-03-20 19:15:39,140:INFO:            catboost: 1.2.7
2025-03-20 19:15:39,140:INFO:              kmodes: 0.12.2
2025-03-20 19:15:39,140:INFO:             mlxtend: 0.23.1
2025-03-20 19:15:39,140:INFO:       statsforecast: 1.5.0
2025-03-20 19:15:39,140:INFO:        tune_sklearn: 0.5.0
2025-03-20 19:15:39,140:INFO:                 ray: 2.10.0
2025-03-20 19:15:39,140:INFO:            hyperopt: 0.2.7
2025-03-20 19:15:39,140:INFO:              optuna: 4.1.0
2025-03-20 19:15:39,140:INFO:               skopt: 0.10.2
2025-03-20 19:15:39,140:INFO:              mlflow: 1.30.1
2025-03-20 19:15:39,140:INFO:              gradio: 3.50.2
2025-03-20 19:15:39,140:INFO:             fastapi: 0.115.5
2025-03-20 19:15:39,140:INFO:             uvicorn: 0.32.1
2025-03-20 19:15:39,140:INFO:              m2cgen: 0.10.0
2025-03-20 19:15:39,140:INFO:           evidently: 0.2.8
2025-03-20 19:15:39,140:INFO:               fugue: 0.8.6
2025-03-20 19:15:39,140:INFO:           streamlit: Not installed
2025-03-20 19:15:39,141:INFO:             prophet: Not installed
2025-03-20 19:15:39,141:INFO:None
2025-03-20 19:15:39,141:INFO:Set up data.
2025-03-20 19:15:39,146:INFO:Set up folding strategy.
2025-03-20 19:15:39,146:INFO:Set up train/test split.
2025-03-20 19:15:39,146:INFO:Set up data.
2025-03-20 19:15:39,150:INFO:Set up index.
2025-03-20 19:15:39,150:INFO:Assigning column types.
2025-03-20 19:15:39,152:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 19:15:39,152:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,154:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,200:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,201:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,212:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,214:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,216:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,260:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,261:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,261:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 19:15:39,263:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,265:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,289:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,308:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,309:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,311:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,313:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,357:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,358:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,358:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 19:15:39,362:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,406:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,406:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,407:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,412:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,436:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,455:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,457:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,457:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 19:15:39,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,505:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,505:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,506:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,554:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,555:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,555:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 19:15:39,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,605:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,606:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:15:39,655:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,657:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,657:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 19:15:39,705:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,706:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,754:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:39,756:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:39,757:INFO:Preparing preprocessing pipeline...
2025-03-20 19:15:39,757:INFO:Set up simple imputation.
2025-03-20 19:15:39,758:INFO:Set up encoding of categorical features.
2025-03-20 19:15:39,758:INFO:Set up feature normalization.
2025-03-20 19:15:39,759:INFO:Set up column name cleaning.
2025-03-20 19:15:39,808:INFO:Finished creating preprocessing pipeline.
2025-03-20 19:15:39,813:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:15:39,813:INFO:Creating final display dataframe.
2025-03-20 19:15:39,946:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              ab17
2025-03-20 19:15:40,000:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:40,001:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:40,050:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:15:40,051:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:15:40,052:INFO:Logging experiment in loggers
2025-03-20 19:15:40,197:INFO:SubProcess save_model() called ==================================
2025-03-20 19:15:40,204:INFO:Initializing save_model()
2025-03-20 19:15:40,204:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpkx7g_kvg\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:15:40,204:INFO:Adding model into prep_pipe
2025-03-20 19:15:40,204:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:15:40,208:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpkx7g_kvg\Transformation Pipeline.pkl saved in current working directory
2025-03-20 19:15:40,212:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:15:40,212:INFO:save_model() successfully completed......................................
2025-03-20 19:15:40,265:INFO:SubProcess save_model() end ==================================
2025-03-20 19:15:40,271:INFO:setup() successfully completed in 2.68s...............
2025-03-20 19:15:40,271:INFO:Initializing compare_models()
2025-03-20 19:15:40,271:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 19:15:40,271:INFO:Checking exceptions
2025-03-20 19:15:40,272:INFO:Preparing display monitor
2025-03-20 19:15:40,285:INFO:Initializing Linear Regression
2025-03-20 19:15:40,285:INFO:Total runtime is 0.0 minutes
2025-03-20 19:15:40,287:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:40,288:INFO:Initializing create_model()
2025-03-20 19:15:40,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:40,288:INFO:Checking exceptions
2025-03-20 19:15:40,288:INFO:Importing libraries
2025-03-20 19:15:40,288:INFO:Copying training dataset
2025-03-20 19:15:40,290:INFO:Defining folds
2025-03-20 19:15:40,290:INFO:Declaring metric variables
2025-03-20 19:15:40,292:INFO:Importing untrained model
2025-03-20 19:15:40,293:INFO:Linear Regression Imported successfully
2025-03-20 19:15:40,297:INFO:Starting cross validation
2025-03-20 19:15:40,300:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:42,858:INFO:Calculating mean and std
2025-03-20 19:15:42,858:INFO:Creating metrics dataframe
2025-03-20 19:15:42,860:INFO:Uploading results into container
2025-03-20 19:15:42,860:INFO:Uploading model into container now
2025-03-20 19:15:42,861:INFO:_master_model_container: 1
2025-03-20 19:15:42,861:INFO:_display_container: 2
2025-03-20 19:15:42,861:INFO:LinearRegression(n_jobs=-1)
2025-03-20 19:15:42,861:INFO:create_model() successfully completed......................................
2025-03-20 19:15:42,918:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:42,918:INFO:Creating metrics dataframe
2025-03-20 19:15:42,922:INFO:Initializing Lasso Regression
2025-03-20 19:15:42,922:INFO:Total runtime is 0.043946675459543866 minutes
2025-03-20 19:15:42,924:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:42,924:INFO:Initializing create_model()
2025-03-20 19:15:42,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:42,924:INFO:Checking exceptions
2025-03-20 19:15:42,924:INFO:Importing libraries
2025-03-20 19:15:42,924:INFO:Copying training dataset
2025-03-20 19:15:42,926:INFO:Defining folds
2025-03-20 19:15:42,926:INFO:Declaring metric variables
2025-03-20 19:15:42,928:INFO:Importing untrained model
2025-03-20 19:15:42,929:INFO:Lasso Regression Imported successfully
2025-03-20 19:15:42,932:INFO:Starting cross validation
2025-03-20 19:15:42,933:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:44,951:INFO:Calculating mean and std
2025-03-20 19:15:44,952:INFO:Creating metrics dataframe
2025-03-20 19:15:44,954:INFO:Uploading results into container
2025-03-20 19:15:44,954:INFO:Uploading model into container now
2025-03-20 19:15:44,955:INFO:_master_model_container: 2
2025-03-20 19:15:44,955:INFO:_display_container: 2
2025-03-20 19:15:44,955:INFO:Lasso(random_state=888)
2025-03-20 19:15:44,955:INFO:create_model() successfully completed......................................
2025-03-20 19:15:45,011:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:45,011:INFO:Creating metrics dataframe
2025-03-20 19:15:45,016:INFO:Initializing Ridge Regression
2025-03-20 19:15:45,016:INFO:Total runtime is 0.07883747418721518 minutes
2025-03-20 19:15:45,017:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:45,018:INFO:Initializing create_model()
2025-03-20 19:15:45,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:45,018:INFO:Checking exceptions
2025-03-20 19:15:45,018:INFO:Importing libraries
2025-03-20 19:15:45,018:INFO:Copying training dataset
2025-03-20 19:15:45,019:INFO:Defining folds
2025-03-20 19:15:45,020:INFO:Declaring metric variables
2025-03-20 19:15:45,021:INFO:Importing untrained model
2025-03-20 19:15:45,023:INFO:Ridge Regression Imported successfully
2025-03-20 19:15:45,026:INFO:Starting cross validation
2025-03-20 19:15:45,027:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:47,014:INFO:Calculating mean and std
2025-03-20 19:15:47,015:INFO:Creating metrics dataframe
2025-03-20 19:15:47,017:INFO:Uploading results into container
2025-03-20 19:15:47,017:INFO:Uploading model into container now
2025-03-20 19:15:47,018:INFO:_master_model_container: 3
2025-03-20 19:15:47,018:INFO:_display_container: 2
2025-03-20 19:15:47,018:INFO:Ridge(random_state=888)
2025-03-20 19:15:47,018:INFO:create_model() successfully completed......................................
2025-03-20 19:15:47,080:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:47,080:INFO:Creating metrics dataframe
2025-03-20 19:15:47,084:INFO:Initializing Elastic Net
2025-03-20 19:15:47,085:INFO:Total runtime is 0.11332264741261801 minutes
2025-03-20 19:15:47,086:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:47,086:INFO:Initializing create_model()
2025-03-20 19:15:47,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:47,086:INFO:Checking exceptions
2025-03-20 19:15:47,086:INFO:Importing libraries
2025-03-20 19:15:47,086:INFO:Copying training dataset
2025-03-20 19:15:47,088:INFO:Defining folds
2025-03-20 19:15:47,088:INFO:Declaring metric variables
2025-03-20 19:15:47,090:INFO:Importing untrained model
2025-03-20 19:15:47,092:INFO:Elastic Net Imported successfully
2025-03-20 19:15:47,095:INFO:Starting cross validation
2025-03-20 19:15:47,096:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:49,108:INFO:Calculating mean and std
2025-03-20 19:15:49,109:INFO:Creating metrics dataframe
2025-03-20 19:15:49,111:INFO:Uploading results into container
2025-03-20 19:15:49,112:INFO:Uploading model into container now
2025-03-20 19:15:49,112:INFO:_master_model_container: 4
2025-03-20 19:15:49,112:INFO:_display_container: 2
2025-03-20 19:15:49,112:INFO:ElasticNet(random_state=888)
2025-03-20 19:15:49,112:INFO:create_model() successfully completed......................................
2025-03-20 19:15:49,168:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:49,168:INFO:Creating metrics dataframe
2025-03-20 19:15:49,174:INFO:Initializing Least Angle Regression
2025-03-20 19:15:49,174:INFO:Total runtime is 0.1481389363606771 minutes
2025-03-20 19:15:49,176:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:49,176:INFO:Initializing create_model()
2025-03-20 19:15:49,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:49,176:INFO:Checking exceptions
2025-03-20 19:15:49,176:INFO:Importing libraries
2025-03-20 19:15:49,176:INFO:Copying training dataset
2025-03-20 19:15:49,178:INFO:Defining folds
2025-03-20 19:15:49,178:INFO:Declaring metric variables
2025-03-20 19:15:49,180:INFO:Importing untrained model
2025-03-20 19:15:49,181:INFO:Least Angle Regression Imported successfully
2025-03-20 19:15:49,184:INFO:Starting cross validation
2025-03-20 19:15:49,185:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:51,198:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,198:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.010e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,199:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,199:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.349e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,199:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,199:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,200:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,200:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,200:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.114e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,200:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.912e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,200:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.216e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,200:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.688e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,201:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.848e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,201:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.737e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,201:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.707e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,201:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.503e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,201:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.186e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:15:51,217:INFO:Calculating mean and std
2025-03-20 19:15:51,218:INFO:Creating metrics dataframe
2025-03-20 19:15:51,220:INFO:Uploading results into container
2025-03-20 19:15:51,221:INFO:Uploading model into container now
2025-03-20 19:15:51,221:INFO:_master_model_container: 5
2025-03-20 19:15:51,221:INFO:_display_container: 2
2025-03-20 19:15:51,221:INFO:Lars(random_state=888)
2025-03-20 19:15:51,221:INFO:create_model() successfully completed......................................
2025-03-20 19:15:51,284:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:51,285:INFO:Creating metrics dataframe
2025-03-20 19:15:51,290:INFO:Initializing Lasso Least Angle Regression
2025-03-20 19:15:51,290:INFO:Total runtime is 0.1834105094273885 minutes
2025-03-20 19:15:51,292:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:51,292:INFO:Initializing create_model()
2025-03-20 19:15:51,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:51,292:INFO:Checking exceptions
2025-03-20 19:15:51,292:INFO:Importing libraries
2025-03-20 19:15:51,292:INFO:Copying training dataset
2025-03-20 19:15:51,294:INFO:Defining folds
2025-03-20 19:15:51,294:INFO:Declaring metric variables
2025-03-20 19:15:51,295:INFO:Importing untrained model
2025-03-20 19:15:51,297:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 19:15:51,300:INFO:Starting cross validation
2025-03-20 19:15:51,300:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:53,296:INFO:Calculating mean and std
2025-03-20 19:15:53,297:INFO:Creating metrics dataframe
2025-03-20 19:15:53,299:INFO:Uploading results into container
2025-03-20 19:15:53,299:INFO:Uploading model into container now
2025-03-20 19:15:53,299:INFO:_master_model_container: 6
2025-03-20 19:15:53,299:INFO:_display_container: 2
2025-03-20 19:15:53,299:INFO:LassoLars(random_state=888)
2025-03-20 19:15:53,299:INFO:create_model() successfully completed......................................
2025-03-20 19:15:53,358:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:53,359:INFO:Creating metrics dataframe
2025-03-20 19:15:53,364:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 19:15:53,364:INFO:Total runtime is 0.2179701805114746 minutes
2025-03-20 19:15:53,366:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:53,366:INFO:Initializing create_model()
2025-03-20 19:15:53,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:53,366:INFO:Checking exceptions
2025-03-20 19:15:53,366:INFO:Importing libraries
2025-03-20 19:15:53,366:INFO:Copying training dataset
2025-03-20 19:15:53,368:INFO:Defining folds
2025-03-20 19:15:53,368:INFO:Declaring metric variables
2025-03-20 19:15:53,369:INFO:Importing untrained model
2025-03-20 19:15:53,370:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 19:15:53,374:INFO:Starting cross validation
2025-03-20 19:15:53,374:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:55,097:INFO:Calculating mean and std
2025-03-20 19:15:55,098:INFO:Creating metrics dataframe
2025-03-20 19:15:55,100:INFO:Uploading results into container
2025-03-20 19:15:55,100:INFO:Uploading model into container now
2025-03-20 19:15:55,100:INFO:_master_model_container: 7
2025-03-20 19:15:55,100:INFO:_display_container: 2
2025-03-20 19:15:55,101:INFO:OrthogonalMatchingPursuit()
2025-03-20 19:15:55,101:INFO:create_model() successfully completed......................................
2025-03-20 19:15:55,158:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:55,158:INFO:Creating metrics dataframe
2025-03-20 19:15:55,164:INFO:Initializing Bayesian Ridge
2025-03-20 19:15:55,164:INFO:Total runtime is 0.24797710180282592 minutes
2025-03-20 19:15:55,166:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:55,166:INFO:Initializing create_model()
2025-03-20 19:15:55,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:55,166:INFO:Checking exceptions
2025-03-20 19:15:55,166:INFO:Importing libraries
2025-03-20 19:15:55,166:INFO:Copying training dataset
2025-03-20 19:15:55,168:INFO:Defining folds
2025-03-20 19:15:55,168:INFO:Declaring metric variables
2025-03-20 19:15:55,169:INFO:Importing untrained model
2025-03-20 19:15:55,171:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:15:55,174:INFO:Starting cross validation
2025-03-20 19:15:55,175:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:55,236:INFO:Calculating mean and std
2025-03-20 19:15:55,237:INFO:Creating metrics dataframe
2025-03-20 19:15:55,238:INFO:Uploading results into container
2025-03-20 19:15:55,239:INFO:Uploading model into container now
2025-03-20 19:15:55,239:INFO:_master_model_container: 8
2025-03-20 19:15:55,239:INFO:_display_container: 2
2025-03-20 19:15:55,239:INFO:BayesianRidge()
2025-03-20 19:15:55,239:INFO:create_model() successfully completed......................................
2025-03-20 19:15:55,294:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:55,294:INFO:Creating metrics dataframe
2025-03-20 19:15:55,300:INFO:Initializing Passive Aggressive Regressor
2025-03-20 19:15:55,300:INFO:Total runtime is 0.25023710330327353 minutes
2025-03-20 19:15:55,302:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:55,302:INFO:Initializing create_model()
2025-03-20 19:15:55,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:55,302:INFO:Checking exceptions
2025-03-20 19:15:55,302:INFO:Importing libraries
2025-03-20 19:15:55,302:INFO:Copying training dataset
2025-03-20 19:15:55,304:INFO:Defining folds
2025-03-20 19:15:55,304:INFO:Declaring metric variables
2025-03-20 19:15:55,306:INFO:Importing untrained model
2025-03-20 19:15:55,307:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 19:15:55,310:INFO:Starting cross validation
2025-03-20 19:15:55,311:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:55,375:INFO:Calculating mean and std
2025-03-20 19:15:55,376:INFO:Creating metrics dataframe
2025-03-20 19:15:55,377:INFO:Uploading results into container
2025-03-20 19:15:55,378:INFO:Uploading model into container now
2025-03-20 19:15:55,378:INFO:_master_model_container: 9
2025-03-20 19:15:55,378:INFO:_display_container: 2
2025-03-20 19:15:55,378:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 19:15:55,378:INFO:create_model() successfully completed......................................
2025-03-20 19:15:55,433:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:55,433:INFO:Creating metrics dataframe
2025-03-20 19:15:55,439:INFO:Initializing Huber Regressor
2025-03-20 19:15:55,439:INFO:Total runtime is 0.25255487362543744 minutes
2025-03-20 19:15:55,441:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:55,441:INFO:Initializing create_model()
2025-03-20 19:15:55,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:55,441:INFO:Checking exceptions
2025-03-20 19:15:55,441:INFO:Importing libraries
2025-03-20 19:15:55,441:INFO:Copying training dataset
2025-03-20 19:15:55,443:INFO:Defining folds
2025-03-20 19:15:55,443:INFO:Declaring metric variables
2025-03-20 19:15:55,445:INFO:Importing untrained model
2025-03-20 19:15:55,447:INFO:Huber Regressor Imported successfully
2025-03-20 19:15:55,450:INFO:Starting cross validation
2025-03-20 19:15:55,451:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:55,491:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:55,494:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:55,498:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:55,502:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:55,505:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:15:55,529:INFO:Calculating mean and std
2025-03-20 19:15:55,530:INFO:Creating metrics dataframe
2025-03-20 19:15:55,531:INFO:Uploading results into container
2025-03-20 19:15:55,532:INFO:Uploading model into container now
2025-03-20 19:15:55,532:INFO:_master_model_container: 10
2025-03-20 19:15:55,532:INFO:_display_container: 2
2025-03-20 19:15:55,532:INFO:HuberRegressor()
2025-03-20 19:15:55,532:INFO:create_model() successfully completed......................................
2025-03-20 19:15:55,586:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:55,586:INFO:Creating metrics dataframe
2025-03-20 19:15:55,591:INFO:Initializing K Neighbors Regressor
2025-03-20 19:15:55,591:INFO:Total runtime is 0.25509910980860395 minutes
2025-03-20 19:15:55,593:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:55,593:INFO:Initializing create_model()
2025-03-20 19:15:55,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:55,593:INFO:Checking exceptions
2025-03-20 19:15:55,593:INFO:Importing libraries
2025-03-20 19:15:55,593:INFO:Copying training dataset
2025-03-20 19:15:55,595:INFO:Defining folds
2025-03-20 19:15:55,595:INFO:Declaring metric variables
2025-03-20 19:15:55,597:INFO:Importing untrained model
2025-03-20 19:15:55,599:INFO:K Neighbors Regressor Imported successfully
2025-03-20 19:15:55,602:INFO:Starting cross validation
2025-03-20 19:15:55,603:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:55,698:INFO:Calculating mean and std
2025-03-20 19:15:55,699:INFO:Creating metrics dataframe
2025-03-20 19:15:55,701:INFO:Uploading results into container
2025-03-20 19:15:55,701:INFO:Uploading model into container now
2025-03-20 19:15:55,701:INFO:_master_model_container: 11
2025-03-20 19:15:55,701:INFO:_display_container: 2
2025-03-20 19:15:55,701:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 19:15:55,701:INFO:create_model() successfully completed......................................
2025-03-20 19:15:55,756:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:55,756:INFO:Creating metrics dataframe
2025-03-20 19:15:55,761:INFO:Initializing Decision Tree Regressor
2025-03-20 19:15:55,762:INFO:Total runtime is 0.25793838103612265 minutes
2025-03-20 19:15:55,763:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:55,764:INFO:Initializing create_model()
2025-03-20 19:15:55,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:55,764:INFO:Checking exceptions
2025-03-20 19:15:55,764:INFO:Importing libraries
2025-03-20 19:15:55,764:INFO:Copying training dataset
2025-03-20 19:15:55,766:INFO:Defining folds
2025-03-20 19:15:55,766:INFO:Declaring metric variables
2025-03-20 19:15:55,767:INFO:Importing untrained model
2025-03-20 19:15:55,769:INFO:Decision Tree Regressor Imported successfully
2025-03-20 19:15:55,772:INFO:Starting cross validation
2025-03-20 19:15:55,773:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:55,852:INFO:Calculating mean and std
2025-03-20 19:15:55,853:INFO:Creating metrics dataframe
2025-03-20 19:15:55,855:INFO:Uploading results into container
2025-03-20 19:15:55,855:INFO:Uploading model into container now
2025-03-20 19:15:55,855:INFO:_master_model_container: 12
2025-03-20 19:15:55,855:INFO:_display_container: 2
2025-03-20 19:15:55,856:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 19:15:55,856:INFO:create_model() successfully completed......................................
2025-03-20 19:15:55,909:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:55,910:INFO:Creating metrics dataframe
2025-03-20 19:15:55,915:INFO:Initializing Random Forest Regressor
2025-03-20 19:15:55,915:INFO:Total runtime is 0.2604966719945272 minutes
2025-03-20 19:15:55,918:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:55,918:INFO:Initializing create_model()
2025-03-20 19:15:55,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:55,919:INFO:Checking exceptions
2025-03-20 19:15:55,919:INFO:Importing libraries
2025-03-20 19:15:55,919:INFO:Copying training dataset
2025-03-20 19:15:55,920:INFO:Defining folds
2025-03-20 19:15:55,921:INFO:Declaring metric variables
2025-03-20 19:15:55,922:INFO:Importing untrained model
2025-03-20 19:15:55,924:INFO:Random Forest Regressor Imported successfully
2025-03-20 19:15:55,927:INFO:Starting cross validation
2025-03-20 19:15:55,928:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:56,284:INFO:Calculating mean and std
2025-03-20 19:15:56,284:INFO:Creating metrics dataframe
2025-03-20 19:15:56,286:INFO:Uploading results into container
2025-03-20 19:15:56,286:INFO:Uploading model into container now
2025-03-20 19:15:56,287:INFO:_master_model_container: 13
2025-03-20 19:15:56,287:INFO:_display_container: 2
2025-03-20 19:15:56,287:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:15:56,287:INFO:create_model() successfully completed......................................
2025-03-20 19:15:56,343:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:56,343:INFO:Creating metrics dataframe
2025-03-20 19:15:56,352:INFO:Initializing Extra Trees Regressor
2025-03-20 19:15:56,352:INFO:Total runtime is 0.26777125597000123 minutes
2025-03-20 19:15:56,355:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:56,355:INFO:Initializing create_model()
2025-03-20 19:15:56,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:56,356:INFO:Checking exceptions
2025-03-20 19:15:56,356:INFO:Importing libraries
2025-03-20 19:15:56,356:INFO:Copying training dataset
2025-03-20 19:15:56,360:INFO:Defining folds
2025-03-20 19:15:56,360:INFO:Declaring metric variables
2025-03-20 19:15:56,362:INFO:Importing untrained model
2025-03-20 19:15:56,365:INFO:Extra Trees Regressor Imported successfully
2025-03-20 19:15:56,371:INFO:Starting cross validation
2025-03-20 19:15:56,373:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:56,576:INFO:Calculating mean and std
2025-03-20 19:15:56,577:INFO:Creating metrics dataframe
2025-03-20 19:15:56,579:INFO:Uploading results into container
2025-03-20 19:15:56,579:INFO:Uploading model into container now
2025-03-20 19:15:56,579:INFO:_master_model_container: 14
2025-03-20 19:15:56,579:INFO:_display_container: 2
2025-03-20 19:15:56,579:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:15:56,580:INFO:create_model() successfully completed......................................
2025-03-20 19:15:56,634:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:56,634:INFO:Creating metrics dataframe
2025-03-20 19:15:56,640:INFO:Initializing AdaBoost Regressor
2025-03-20 19:15:56,641:INFO:Total runtime is 0.2725886623064677 minutes
2025-03-20 19:15:56,642:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:56,643:INFO:Initializing create_model()
2025-03-20 19:15:56,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:56,643:INFO:Checking exceptions
2025-03-20 19:15:56,643:INFO:Importing libraries
2025-03-20 19:15:56,643:INFO:Copying training dataset
2025-03-20 19:15:56,645:INFO:Defining folds
2025-03-20 19:15:56,645:INFO:Declaring metric variables
2025-03-20 19:15:56,647:INFO:Importing untrained model
2025-03-20 19:15:56,648:INFO:AdaBoost Regressor Imported successfully
2025-03-20 19:15:56,652:INFO:Starting cross validation
2025-03-20 19:15:56,653:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:56,853:INFO:Calculating mean and std
2025-03-20 19:15:56,854:INFO:Creating metrics dataframe
2025-03-20 19:15:56,855:INFO:Uploading results into container
2025-03-20 19:15:56,855:INFO:Uploading model into container now
2025-03-20 19:15:56,856:INFO:_master_model_container: 15
2025-03-20 19:15:56,856:INFO:_display_container: 2
2025-03-20 19:15:56,856:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 19:15:56,856:INFO:create_model() successfully completed......................................
2025-03-20 19:15:56,909:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:56,909:INFO:Creating metrics dataframe
2025-03-20 19:15:56,916:INFO:Initializing Gradient Boosting Regressor
2025-03-20 19:15:56,916:INFO:Total runtime is 0.2771751403808594 minutes
2025-03-20 19:15:56,917:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:56,918:INFO:Initializing create_model()
2025-03-20 19:15:56,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:56,918:INFO:Checking exceptions
2025-03-20 19:15:56,918:INFO:Importing libraries
2025-03-20 19:15:56,918:INFO:Copying training dataset
2025-03-20 19:15:56,920:INFO:Defining folds
2025-03-20 19:15:56,920:INFO:Declaring metric variables
2025-03-20 19:15:56,922:INFO:Importing untrained model
2025-03-20 19:15:56,924:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:15:56,927:INFO:Starting cross validation
2025-03-20 19:15:56,929:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:57,546:INFO:Calculating mean and std
2025-03-20 19:15:57,546:INFO:Creating metrics dataframe
2025-03-20 19:15:57,548:INFO:Uploading results into container
2025-03-20 19:15:57,548:INFO:Uploading model into container now
2025-03-20 19:15:57,549:INFO:_master_model_container: 16
2025-03-20 19:15:57,549:INFO:_display_container: 2
2025-03-20 19:15:57,549:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:15:57,549:INFO:create_model() successfully completed......................................
2025-03-20 19:15:57,599:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:57,599:INFO:Creating metrics dataframe
2025-03-20 19:15:57,605:INFO:Initializing Extreme Gradient Boosting
2025-03-20 19:15:57,605:INFO:Total runtime is 0.28866491715113324 minutes
2025-03-20 19:15:57,607:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:57,607:INFO:Initializing create_model()
2025-03-20 19:15:57,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:57,608:INFO:Checking exceptions
2025-03-20 19:15:57,608:INFO:Importing libraries
2025-03-20 19:15:57,608:INFO:Copying training dataset
2025-03-20 19:15:57,610:INFO:Defining folds
2025-03-20 19:15:57,610:INFO:Declaring metric variables
2025-03-20 19:15:57,611:INFO:Importing untrained model
2025-03-20 19:15:57,613:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:15:57,616:INFO:Starting cross validation
2025-03-20 19:15:57,617:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:58,100:INFO:Calculating mean and std
2025-03-20 19:15:58,101:INFO:Creating metrics dataframe
2025-03-20 19:15:58,102:INFO:Uploading results into container
2025-03-20 19:15:58,103:INFO:Uploading model into container now
2025-03-20 19:15:58,103:INFO:_master_model_container: 17
2025-03-20 19:15:58,103:INFO:_display_container: 2
2025-03-20 19:15:58,103:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:15:58,103:INFO:create_model() successfully completed......................................
2025-03-20 19:15:58,157:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:58,157:INFO:Creating metrics dataframe
2025-03-20 19:15:58,164:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 19:15:58,164:INFO:Total runtime is 0.29797083934148155 minutes
2025-03-20 19:15:58,166:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:58,166:INFO:Initializing create_model()
2025-03-20 19:15:58,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:58,166:INFO:Checking exceptions
2025-03-20 19:15:58,166:INFO:Importing libraries
2025-03-20 19:15:58,166:INFO:Copying training dataset
2025-03-20 19:15:58,168:INFO:Defining folds
2025-03-20 19:15:58,168:INFO:Declaring metric variables
2025-03-20 19:15:58,169:INFO:Importing untrained model
2025-03-20 19:15:58,172:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:15:58,175:INFO:Starting cross validation
2025-03-20 19:15:58,175:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:15:58,639:INFO:Calculating mean and std
2025-03-20 19:15:58,640:INFO:Creating metrics dataframe
2025-03-20 19:15:58,642:INFO:Uploading results into container
2025-03-20 19:15:58,642:INFO:Uploading model into container now
2025-03-20 19:15:58,643:INFO:_master_model_container: 18
2025-03-20 19:15:58,643:INFO:_display_container: 2
2025-03-20 19:15:58,643:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:15:58,643:INFO:create_model() successfully completed......................................
2025-03-20 19:15:58,701:INFO:SubProcess create_model() end ==================================
2025-03-20 19:15:58,701:INFO:Creating metrics dataframe
2025-03-20 19:15:58,710:INFO:Initializing CatBoost Regressor
2025-03-20 19:15:58,710:INFO:Total runtime is 0.30707638661066694 minutes
2025-03-20 19:15:58,712:INFO:SubProcess create_model() called ==================================
2025-03-20 19:15:58,712:INFO:Initializing create_model()
2025-03-20 19:15:58,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:15:58,712:INFO:Checking exceptions
2025-03-20 19:15:58,713:INFO:Importing libraries
2025-03-20 19:15:58,713:INFO:Copying training dataset
2025-03-20 19:15:58,715:INFO:Defining folds
2025-03-20 19:15:58,715:INFO:Declaring metric variables
2025-03-20 19:15:58,717:INFO:Importing untrained model
2025-03-20 19:15:58,719:INFO:CatBoost Regressor Imported successfully
2025-03-20 19:15:58,723:INFO:Starting cross validation
2025-03-20 19:15:58,725:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:01,149:INFO:Calculating mean and std
2025-03-20 19:16:01,150:INFO:Creating metrics dataframe
2025-03-20 19:16:01,151:INFO:Uploading results into container
2025-03-20 19:16:01,152:INFO:Uploading model into container now
2025-03-20 19:16:01,152:INFO:_master_model_container: 19
2025-03-20 19:16:01,152:INFO:_display_container: 2
2025-03-20 19:16:01,152:INFO:<catboost.core.CatBoostRegressor object at 0x000001F3D5A63C10>
2025-03-20 19:16:01,152:INFO:create_model() successfully completed......................................
2025-03-20 19:16:01,207:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:01,207:INFO:Creating metrics dataframe
2025-03-20 19:16:01,214:INFO:Initializing Dummy Regressor
2025-03-20 19:16:01,214:INFO:Total runtime is 0.3488056778907776 minutes
2025-03-20 19:16:01,215:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:01,216:INFO:Initializing create_model()
2025-03-20 19:16:01,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3D5831B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:01,216:INFO:Checking exceptions
2025-03-20 19:16:01,216:INFO:Importing libraries
2025-03-20 19:16:01,216:INFO:Copying training dataset
2025-03-20 19:16:01,218:INFO:Defining folds
2025-03-20 19:16:01,218:INFO:Declaring metric variables
2025-03-20 19:16:01,220:INFO:Importing untrained model
2025-03-20 19:16:01,221:INFO:Dummy Regressor Imported successfully
2025-03-20 19:16:01,225:INFO:Starting cross validation
2025-03-20 19:16:01,226:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:01,303:INFO:Calculating mean and std
2025-03-20 19:16:01,304:INFO:Creating metrics dataframe
2025-03-20 19:16:01,305:INFO:Uploading results into container
2025-03-20 19:16:01,306:INFO:Uploading model into container now
2025-03-20 19:16:01,306:INFO:_master_model_container: 20
2025-03-20 19:16:01,306:INFO:_display_container: 2
2025-03-20 19:16:01,306:INFO:DummyRegressor()
2025-03-20 19:16:01,306:INFO:create_model() successfully completed......................................
2025-03-20 19:16:01,359:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:01,359:INFO:Creating metrics dataframe
2025-03-20 19:16:01,370:INFO:Initializing create_model()
2025-03-20 19:16:01,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:01,370:INFO:Checking exceptions
2025-03-20 19:16:01,371:INFO:Importing libraries
2025-03-20 19:16:01,371:INFO:Copying training dataset
2025-03-20 19:16:01,373:INFO:Defining folds
2025-03-20 19:16:01,373:INFO:Declaring metric variables
2025-03-20 19:16:01,373:INFO:Importing untrained model
2025-03-20 19:16:01,373:INFO:Declaring custom model
2025-03-20 19:16:01,373:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:16:01,374:INFO:Cross validation set to False
2025-03-20 19:16:01,374:INFO:Fitting Model
2025-03-20 19:16:01,409:INFO:BayesianRidge()
2025-03-20 19:16:01,409:INFO:create_model() successfully completed......................................
2025-03-20 19:16:01,464:INFO:Creating Dashboard logs
2025-03-20 19:16:01,466:INFO:Model: Bayesian Ridge
2025-03-20 19:16:01,483:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:16:01,517:INFO:Initializing predict_model()
2025-03-20 19:16:01,517:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F3D46B4280>)
2025-03-20 19:16:01,517:INFO:Checking exceptions
2025-03-20 19:16:01,517:INFO:Preloading libraries
2025-03-20 19:16:01,645:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 19:16:01,660:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:01,663:INFO:Initializing create_model()
2025-03-20 19:16:01,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:01,663:INFO:Checking exceptions
2025-03-20 19:16:01,664:INFO:Importing libraries
2025-03-20 19:16:01,664:INFO:Copying training dataset
2025-03-20 19:16:01,666:INFO:Defining folds
2025-03-20 19:16:01,666:INFO:Declaring metric variables
2025-03-20 19:16:01,666:INFO:Importing untrained model
2025-03-20 19:16:01,667:INFO:Declaring custom model
2025-03-20 19:16:01,667:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:16:01,668:INFO:Cross validation set to False
2025-03-20 19:16:01,668:INFO:Fitting Model
2025-03-20 19:16:02,339:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:16:02,339:INFO:create_model() successfully completed......................................
2025-03-20 19:16:02,390:INFO:Creating Dashboard logs
2025-03-20 19:16:02,393:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:16:02,412:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:02,457:INFO:Initializing predict_model()
2025-03-20 19:16:02,457:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F3D5888550>)
2025-03-20 19:16:02,457:INFO:Checking exceptions
2025-03-20 19:16:02,457:INFO:Preloading libraries
2025-03-20 19:16:02,595:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:02,598:INFO:Initializing create_model()
2025-03-20 19:16:02,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:02,598:INFO:Checking exceptions
2025-03-20 19:16:02,599:INFO:Importing libraries
2025-03-20 19:16:02,599:INFO:Copying training dataset
2025-03-20 19:16:02,601:INFO:Defining folds
2025-03-20 19:16:02,601:INFO:Declaring metric variables
2025-03-20 19:16:02,601:INFO:Importing untrained model
2025-03-20 19:16:02,601:INFO:Declaring custom model
2025-03-20 19:16:02,601:INFO:Ridge Regression Imported successfully
2025-03-20 19:16:02,602:INFO:Cross validation set to False
2025-03-20 19:16:02,602:INFO:Fitting Model
2025-03-20 19:16:02,632:INFO:Ridge(random_state=888)
2025-03-20 19:16:02,632:INFO:create_model() successfully completed......................................
2025-03-20 19:16:02,686:INFO:Creating Dashboard logs
2025-03-20 19:16:02,689:INFO:Model: Ridge Regression
2025-03-20 19:16:02,707:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:16:02,753:INFO:Initializing predict_model()
2025-03-20 19:16:02,754:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F3D5708670>)
2025-03-20 19:16:02,754:INFO:Checking exceptions
2025-03-20 19:16:02,754:INFO:Preloading libraries
2025-03-20 19:16:02,890:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:02,892:INFO:Initializing create_model()
2025-03-20 19:16:02,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:02,893:INFO:Checking exceptions
2025-03-20 19:16:02,893:INFO:Importing libraries
2025-03-20 19:16:02,893:INFO:Copying training dataset
2025-03-20 19:16:02,895:INFO:Defining folds
2025-03-20 19:16:02,896:INFO:Declaring metric variables
2025-03-20 19:16:02,896:INFO:Importing untrained model
2025-03-20 19:16:02,896:INFO:Declaring custom model
2025-03-20 19:16:02,896:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:16:02,897:INFO:Cross validation set to False
2025-03-20 19:16:02,897:INFO:Fitting Model
2025-03-20 19:16:02,930:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:16:02,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.
2025-03-20 19:16:02,931:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:16:02,932:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:16:02,932:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:16:02,932:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:16:03,014:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:16:03,014:INFO:create_model() successfully completed......................................
2025-03-20 19:16:03,077:INFO:Creating Dashboard logs
2025-03-20 19:16:03,079:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:16:03,102:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:16:03,163:INFO:Initializing predict_model()
2025-03-20 19:16:03,163:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F3EC439910>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F3D5893820>)
2025-03-20 19:16:03,163:INFO:Checking exceptions
2025-03-20 19:16:03,163:INFO:Preloading libraries
2025-03-20 19:16:03,307:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:03,308:INFO:Creating Dashboard logs
2025-03-20 19:16:03,311:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:16:03,335:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:16:03,436:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:03,437:INFO:Creating Dashboard logs
2025-03-20 19:16:03,439:INFO:Model: Random Forest Regressor
2025-03-20 19:16:03,457:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:03,542:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:03,543:INFO:Creating Dashboard logs
2025-03-20 19:16:03,545:INFO:Model: AdaBoost Regressor
2025-03-20 19:16:03,565:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 19:16:03,655:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:03,655:INFO:Creating Dashboard logs
2025-03-20 19:16:03,657:INFO:Model: CatBoost Regressor
2025-03-20 19:16:03,676:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 19:16:03,676:INFO:Logged params: {}
2025-03-20 19:16:03,767:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x000001F3D5A63C10> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:03,768:INFO:Creating Dashboard logs
2025-03-20 19:16:03,770:INFO:Model: Extra Trees Regressor
2025-03-20 19:16:03,787:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:03,890:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:03,891:INFO:Creating Dashboard logs
2025-03-20 19:16:03,893:INFO:Model: Decision Tree Regressor
2025-03-20 19:16:03,911:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 19:16:04,017:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:04,018:INFO:Creating Dashboard logs
2025-03-20 19:16:04,019:INFO:Model: Passive Aggressive Regressor
2025-03-20 19:16:04,036:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:04,151:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:04,152:INFO:Creating Dashboard logs
2025-03-20 19:16:04,153:INFO:Model: Huber Regressor
2025-03-20 19:16:04,171:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 19:16:04,292:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:04,292:INFO:Creating Dashboard logs
2025-03-20 19:16:04,294:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 19:16:04,313:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 19:16:04,435:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:04,436:INFO:Creating Dashboard logs
2025-03-20 19:16:04,438:INFO:Model: K Neighbors Regressor
2025-03-20 19:16:04,456:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 19:16:04,586:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:04,586:INFO:Creating Dashboard logs
2025-03-20 19:16:04,588:INFO:Model: Elastic Net
2025-03-20 19:16:04,605:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:16:04,744:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:04,745:INFO:Creating Dashboard logs
2025-03-20 19:16:04,747:INFO:Model: Lasso Regression
2025-03-20 19:16:04,765:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:16:04,910:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:04,911:INFO:Creating Dashboard logs
2025-03-20 19:16:04,913:INFO:Model: Lasso Least Angle Regression
2025-03-20 19:16:04,932:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:16:05,082:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:05,083:INFO:Creating Dashboard logs
2025-03-20 19:16:05,085:INFO:Model: Dummy Regressor
2025-03-20 19:16:05,103:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 19:16:05,253:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:05,253:INFO:Creating Dashboard logs
2025-03-20 19:16:05,255:INFO:Model: Linear Regression
2025-03-20 19:16:05,273:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 19:16:05,428:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:05,429:INFO:Creating Dashboard logs
2025-03-20 19:16:05,431:INFO:Model: Least Angle Regression
2025-03-20 19:16:05,449:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:16:05,613:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:05,621:INFO:_master_model_container: 20
2025-03-20 19:16:05,622:INFO:_display_container: 2
2025-03-20 19:16:05,622:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888)]
2025-03-20 19:16:05,622:INFO:compare_models() successfully completed......................................
2025-03-20 19:16:27,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:16:27,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:16:27,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:16:27,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:16:27,269:INFO:PyCaret RegressionExperiment
2025-03-20 19:16:27,269:INFO:Logging name: reg-default-name
2025-03-20 19:16:27,269:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 19:16:27,269:INFO:version 3.2.0
2025-03-20 19:16:27,269:INFO:Initializing setup()
2025-03-20 19:16:27,269:INFO:self.USI: 23bc
2025-03-20 19:16:27,269:INFO:self._variable_keys: {'y_train', 'html_param', 'X_test', 'y', 'exp_name_log', 'seed', 'idx', 'gpu_n_jobs_param', 'pipeline', 'fold_generator', 'memory', 'transform_target_param', 'data', '_available_plots', 'y_test', 'X_train', '_ml_usecase', 'logging_param', 'gpu_param', 'target_param', 'log_plots_param', 'USI', 'n_jobs_param', 'exp_id', 'fold_shuffle_param', 'X', 'fold_groups_param'}
2025-03-20 19:16:27,269:INFO:Checking environment
2025-03-20 19:16:27,269:INFO:python_version: 3.8.20
2025-03-20 19:16:27,269:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 19:16:27,270:INFO:machine: AMD64
2025-03-20 19:16:27,270:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 19:16:27,276:INFO:Memory: svmem(total=68447973376, available=39676243968, percent=42.0, used=28771729408, free=39676243968)
2025-03-20 19:16:27,277:INFO:Physical Core: 24
2025-03-20 19:16:27,277:INFO:Logical Core: 32
2025-03-20 19:16:27,277:INFO:Checking libraries
2025-03-20 19:16:27,277:INFO:System:
2025-03-20 19:16:27,277:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 19:16:27,277:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 19:16:27,277:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 19:16:27,277:INFO:PyCaret required dependencies:
2025-03-20 19:16:27,783:INFO:                 pip: 24.2
2025-03-20 19:16:27,783:INFO:          setuptools: 75.1.0
2025-03-20 19:16:27,783:INFO:             pycaret: 3.2.0
2025-03-20 19:16:27,783:INFO:             IPython: 8.12.3
2025-03-20 19:16:27,783:INFO:          ipywidgets: 8.1.5
2025-03-20 19:16:27,783:INFO:                tqdm: 4.67.1
2025-03-20 19:16:27,783:INFO:               numpy: 1.24.4
2025-03-20 19:16:27,783:INFO:              pandas: 1.5.3
2025-03-20 19:16:27,783:INFO:              jinja2: 3.1.4
2025-03-20 19:16:27,783:INFO:               scipy: 1.10.1
2025-03-20 19:16:27,783:INFO:              joblib: 1.3.2
2025-03-20 19:16:27,783:INFO:             sklearn: 1.2.2
2025-03-20 19:16:27,783:INFO:                pyod: 2.0.2
2025-03-20 19:16:27,783:INFO:            imblearn: 0.12.4
2025-03-20 19:16:27,783:INFO:   category_encoders: 2.6.4
2025-03-20 19:16:27,783:INFO:            lightgbm: 4.5.0
2025-03-20 19:16:27,783:INFO:               numba: 0.58.1
2025-03-20 19:16:27,783:INFO:            requests: 2.32.3
2025-03-20 19:16:27,783:INFO:          matplotlib: 3.6.0
2025-03-20 19:16:27,783:INFO:          scikitplot: 0.3.7
2025-03-20 19:16:27,783:INFO:         yellowbrick: 1.5
2025-03-20 19:16:27,783:INFO:              plotly: 5.24.1
2025-03-20 19:16:27,783:INFO:    plotly-resampler: Not installed
2025-03-20 19:16:27,783:INFO:             kaleido: 0.2.1
2025-03-20 19:16:27,783:INFO:           schemdraw: 0.15
2025-03-20 19:16:27,783:INFO:         statsmodels: 0.14.1
2025-03-20 19:16:27,783:INFO:              sktime: 0.21.1
2025-03-20 19:16:27,783:INFO:               tbats: 1.1.3
2025-03-20 19:16:27,783:INFO:            pmdarima: 2.0.4
2025-03-20 19:16:27,783:INFO:              psutil: 6.1.0
2025-03-20 19:16:27,783:INFO:          markupsafe: 2.1.5
2025-03-20 19:16:27,783:INFO:             pickle5: Not installed
2025-03-20 19:16:27,783:INFO:         cloudpickle: 2.2.1
2025-03-20 19:16:27,783:INFO:         deprecation: 2.1.0
2025-03-20 19:16:27,783:INFO:              xxhash: 3.5.0
2025-03-20 19:16:27,783:INFO:           wurlitzer: Not installed
2025-03-20 19:16:27,783:INFO:PyCaret optional dependencies:
2025-03-20 19:16:29,066:INFO:                shap: 0.44.1
2025-03-20 19:16:29,066:INFO:           interpret: 0.6.6
2025-03-20 19:16:29,066:INFO:                umap: 0.5.7
2025-03-20 19:16:29,066:INFO:     ydata_profiling: 4.6.0
2025-03-20 19:16:29,066:INFO:  explainerdashboard: 0.4.7
2025-03-20 19:16:29,066:INFO:             autoviz: Not installed
2025-03-20 19:16:29,066:INFO:           fairlearn: 0.7.0
2025-03-20 19:16:29,066:INFO:          deepchecks: Not installed
2025-03-20 19:16:29,066:INFO:             xgboost: 2.1.3
2025-03-20 19:16:29,066:INFO:            catboost: 1.2.7
2025-03-20 19:16:29,066:INFO:              kmodes: 0.12.2
2025-03-20 19:16:29,066:INFO:             mlxtend: 0.23.1
2025-03-20 19:16:29,066:INFO:       statsforecast: 1.5.0
2025-03-20 19:16:29,066:INFO:        tune_sklearn: 0.5.0
2025-03-20 19:16:29,066:INFO:                 ray: 2.10.0
2025-03-20 19:16:29,067:INFO:            hyperopt: 0.2.7
2025-03-20 19:16:29,067:INFO:              optuna: 4.1.0
2025-03-20 19:16:29,067:INFO:               skopt: 0.10.2
2025-03-20 19:16:29,067:INFO:              mlflow: 1.30.1
2025-03-20 19:16:29,067:INFO:              gradio: 3.50.2
2025-03-20 19:16:29,067:INFO:             fastapi: 0.115.5
2025-03-20 19:16:29,067:INFO:             uvicorn: 0.32.1
2025-03-20 19:16:29,067:INFO:              m2cgen: 0.10.0
2025-03-20 19:16:29,067:INFO:           evidently: 0.2.8
2025-03-20 19:16:29,067:INFO:               fugue: 0.8.6
2025-03-20 19:16:29,067:INFO:           streamlit: Not installed
2025-03-20 19:16:29,067:INFO:             prophet: Not installed
2025-03-20 19:16:29,067:INFO:None
2025-03-20 19:16:29,067:INFO:Set up data.
2025-03-20 19:16:29,072:INFO:Set up folding strategy.
2025-03-20 19:16:29,072:INFO:Set up train/test split.
2025-03-20 19:16:29,072:INFO:Set up data.
2025-03-20 19:16:29,077:INFO:Set up index.
2025-03-20 19:16:29,077:INFO:Assigning column types.
2025-03-20 19:16:29,079:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 19:16:29,079:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,107:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,127:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,128:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,139:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,141:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,186:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,187:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,187:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 19:16:29,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,216:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,235:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,236:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,238:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,240:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,283:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,284:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,285:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,285:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 19:16:29,289:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,331:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,332:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,333:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,337:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,381:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,382:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,382:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 19:16:29,410:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,429:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,430:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,431:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,478:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,479:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,479:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 19:16:29,509:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,528:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,529:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:16:29,577:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,578:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,579:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 19:16:29,625:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,627:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,674:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,675:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,677:INFO:Preparing preprocessing pipeline...
2025-03-20 19:16:29,677:INFO:Set up simple imputation.
2025-03-20 19:16:29,678:INFO:Set up encoding of categorical features.
2025-03-20 19:16:29,678:INFO:Set up feature normalization.
2025-03-20 19:16:29,679:INFO:Set up column name cleaning.
2025-03-20 19:16:29,726:INFO:Finished creating preprocessing pipeline.
2025-03-20 19:16:29,730:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:16:29,730:INFO:Creating final display dataframe.
2025-03-20 19:16:29,854:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              23bc
2025-03-20 19:16:29,906:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,908:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,955:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:16:29,956:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:16:29,956:INFO:Logging experiment in loggers
2025-03-20 19:16:30,101:INFO:SubProcess save_model() called ==================================
2025-03-20 19:16:30,109:INFO:Initializing save_model()
2025-03-20 19:16:30,109:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmphveu0gz2\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:16:30,109:INFO:Adding model into prep_pipe
2025-03-20 19:16:30,109:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:16:30,113:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmphveu0gz2\Transformation Pipeline.pkl saved in current working directory
2025-03-20 19:16:30,116:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:16:30,116:INFO:save_model() successfully completed......................................
2025-03-20 19:16:30,171:INFO:SubProcess save_model() end ==================================
2025-03-20 19:16:30,176:INFO:setup() successfully completed in 2.69s...............
2025-03-20 19:16:30,177:INFO:Initializing compare_models()
2025-03-20 19:16:30,177:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 19:16:30,177:INFO:Checking exceptions
2025-03-20 19:16:30,178:INFO:Preparing display monitor
2025-03-20 19:16:30,190:INFO:Initializing Linear Regression
2025-03-20 19:16:30,190:INFO:Total runtime is 0.0 minutes
2025-03-20 19:16:30,192:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:30,193:INFO:Initializing create_model()
2025-03-20 19:16:30,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:30,193:INFO:Checking exceptions
2025-03-20 19:16:30,193:INFO:Importing libraries
2025-03-20 19:16:30,193:INFO:Copying training dataset
2025-03-20 19:16:30,196:INFO:Defining folds
2025-03-20 19:16:30,196:INFO:Declaring metric variables
2025-03-20 19:16:30,198:INFO:Importing untrained model
2025-03-20 19:16:30,200:INFO:Linear Regression Imported successfully
2025-03-20 19:16:30,204:INFO:Starting cross validation
2025-03-20 19:16:30,208:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:32,678:INFO:Calculating mean and std
2025-03-20 19:16:32,679:INFO:Creating metrics dataframe
2025-03-20 19:16:32,680:INFO:Uploading results into container
2025-03-20 19:16:32,681:INFO:Uploading model into container now
2025-03-20 19:16:32,681:INFO:_master_model_container: 1
2025-03-20 19:16:32,681:INFO:_display_container: 2
2025-03-20 19:16:32,681:INFO:LinearRegression(n_jobs=-1)
2025-03-20 19:16:32,681:INFO:create_model() successfully completed......................................
2025-03-20 19:16:32,742:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:32,742:INFO:Creating metrics dataframe
2025-03-20 19:16:32,746:INFO:Initializing Lasso Regression
2025-03-20 19:16:32,747:INFO:Total runtime is 0.04261395533879598 minutes
2025-03-20 19:16:32,748:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:32,748:INFO:Initializing create_model()
2025-03-20 19:16:32,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:32,748:INFO:Checking exceptions
2025-03-20 19:16:32,748:INFO:Importing libraries
2025-03-20 19:16:32,749:INFO:Copying training dataset
2025-03-20 19:16:32,750:INFO:Defining folds
2025-03-20 19:16:32,751:INFO:Declaring metric variables
2025-03-20 19:16:32,752:INFO:Importing untrained model
2025-03-20 19:16:32,753:INFO:Lasso Regression Imported successfully
2025-03-20 19:16:32,756:INFO:Starting cross validation
2025-03-20 19:16:32,757:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:34,725:INFO:Calculating mean and std
2025-03-20 19:16:34,726:INFO:Creating metrics dataframe
2025-03-20 19:16:34,729:INFO:Uploading results into container
2025-03-20 19:16:34,729:INFO:Uploading model into container now
2025-03-20 19:16:34,729:INFO:_master_model_container: 2
2025-03-20 19:16:34,730:INFO:_display_container: 2
2025-03-20 19:16:34,730:INFO:Lasso(random_state=888)
2025-03-20 19:16:34,730:INFO:create_model() successfully completed......................................
2025-03-20 19:16:34,786:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:34,786:INFO:Creating metrics dataframe
2025-03-20 19:16:34,791:INFO:Initializing Ridge Regression
2025-03-20 19:16:34,791:INFO:Total runtime is 0.076695716381073 minutes
2025-03-20 19:16:34,793:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:34,793:INFO:Initializing create_model()
2025-03-20 19:16:34,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:34,793:INFO:Checking exceptions
2025-03-20 19:16:34,793:INFO:Importing libraries
2025-03-20 19:16:34,793:INFO:Copying training dataset
2025-03-20 19:16:34,795:INFO:Defining folds
2025-03-20 19:16:34,795:INFO:Declaring metric variables
2025-03-20 19:16:34,797:INFO:Importing untrained model
2025-03-20 19:16:34,799:INFO:Ridge Regression Imported successfully
2025-03-20 19:16:34,802:INFO:Starting cross validation
2025-03-20 19:16:34,803:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:36,789:INFO:Calculating mean and std
2025-03-20 19:16:36,790:INFO:Creating metrics dataframe
2025-03-20 19:16:36,792:INFO:Uploading results into container
2025-03-20 19:16:36,792:INFO:Uploading model into container now
2025-03-20 19:16:36,793:INFO:_master_model_container: 3
2025-03-20 19:16:36,793:INFO:_display_container: 2
2025-03-20 19:16:36,793:INFO:Ridge(random_state=888)
2025-03-20 19:16:36,793:INFO:create_model() successfully completed......................................
2025-03-20 19:16:36,849:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:36,849:INFO:Creating metrics dataframe
2025-03-20 19:16:36,854:INFO:Initializing Elastic Net
2025-03-20 19:16:36,854:INFO:Total runtime is 0.1110649347305298 minutes
2025-03-20 19:16:36,856:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:36,856:INFO:Initializing create_model()
2025-03-20 19:16:36,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:36,856:INFO:Checking exceptions
2025-03-20 19:16:36,856:INFO:Importing libraries
2025-03-20 19:16:36,856:INFO:Copying training dataset
2025-03-20 19:16:36,858:INFO:Defining folds
2025-03-20 19:16:36,858:INFO:Declaring metric variables
2025-03-20 19:16:36,859:INFO:Importing untrained model
2025-03-20 19:16:36,861:INFO:Elastic Net Imported successfully
2025-03-20 19:16:36,863:INFO:Starting cross validation
2025-03-20 19:16:36,864:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:38,852:INFO:Calculating mean and std
2025-03-20 19:16:38,853:INFO:Creating metrics dataframe
2025-03-20 19:16:38,854:INFO:Uploading results into container
2025-03-20 19:16:38,855:INFO:Uploading model into container now
2025-03-20 19:16:38,855:INFO:_master_model_container: 4
2025-03-20 19:16:38,855:INFO:_display_container: 2
2025-03-20 19:16:38,856:INFO:ElasticNet(random_state=888)
2025-03-20 19:16:38,856:INFO:create_model() successfully completed......................................
2025-03-20 19:16:38,910:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:38,910:INFO:Creating metrics dataframe
2025-03-20 19:16:38,915:INFO:Initializing Least Angle Regression
2025-03-20 19:16:38,915:INFO:Total runtime is 0.1454180955886841 minutes
2025-03-20 19:16:38,917:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:38,917:INFO:Initializing create_model()
2025-03-20 19:16:38,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:38,917:INFO:Checking exceptions
2025-03-20 19:16:38,917:INFO:Importing libraries
2025-03-20 19:16:38,917:INFO:Copying training dataset
2025-03-20 19:16:38,919:INFO:Defining folds
2025-03-20 19:16:38,919:INFO:Declaring metric variables
2025-03-20 19:16:38,920:INFO:Importing untrained model
2025-03-20 19:16:38,922:INFO:Least Angle Regression Imported successfully
2025-03-20 19:16:38,925:INFO:Starting cross validation
2025-03-20 19:16:38,925:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:40,896:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,896:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,896:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,896:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,896:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,897:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,897:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.010e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,897:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.349e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,897:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.688e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.114e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.912e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.216e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.848e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.737e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.707e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.503e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,898:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.186e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:16:40,915:INFO:Calculating mean and std
2025-03-20 19:16:40,916:INFO:Creating metrics dataframe
2025-03-20 19:16:40,917:INFO:Uploading results into container
2025-03-20 19:16:40,918:INFO:Uploading model into container now
2025-03-20 19:16:40,918:INFO:_master_model_container: 5
2025-03-20 19:16:40,918:INFO:_display_container: 2
2025-03-20 19:16:40,918:INFO:Lars(random_state=888)
2025-03-20 19:16:40,918:INFO:create_model() successfully completed......................................
2025-03-20 19:16:40,980:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:40,980:INFO:Creating metrics dataframe
2025-03-20 19:16:40,985:INFO:Initializing Lasso Least Angle Regression
2025-03-20 19:16:40,985:INFO:Total runtime is 0.17991983890533447 minutes
2025-03-20 19:16:40,986:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:40,986:INFO:Initializing create_model()
2025-03-20 19:16:40,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:40,987:INFO:Checking exceptions
2025-03-20 19:16:40,987:INFO:Importing libraries
2025-03-20 19:16:40,987:INFO:Copying training dataset
2025-03-20 19:16:40,988:INFO:Defining folds
2025-03-20 19:16:40,988:INFO:Declaring metric variables
2025-03-20 19:16:40,990:INFO:Importing untrained model
2025-03-20 19:16:40,992:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 19:16:40,995:INFO:Starting cross validation
2025-03-20 19:16:40,996:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:43,009:INFO:Calculating mean and std
2025-03-20 19:16:43,010:INFO:Creating metrics dataframe
2025-03-20 19:16:43,012:INFO:Uploading results into container
2025-03-20 19:16:43,012:INFO:Uploading model into container now
2025-03-20 19:16:43,013:INFO:_master_model_container: 6
2025-03-20 19:16:43,013:INFO:_display_container: 2
2025-03-20 19:16:43,013:INFO:LassoLars(random_state=888)
2025-03-20 19:16:43,013:INFO:create_model() successfully completed......................................
2025-03-20 19:16:43,071:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:43,071:INFO:Creating metrics dataframe
2025-03-20 19:16:43,076:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 19:16:43,076:INFO:Total runtime is 0.21477592786153157 minutes
2025-03-20 19:16:43,077:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:43,078:INFO:Initializing create_model()
2025-03-20 19:16:43,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:43,078:INFO:Checking exceptions
2025-03-20 19:16:43,078:INFO:Importing libraries
2025-03-20 19:16:43,078:INFO:Copying training dataset
2025-03-20 19:16:43,080:INFO:Defining folds
2025-03-20 19:16:43,080:INFO:Declaring metric variables
2025-03-20 19:16:43,081:INFO:Importing untrained model
2025-03-20 19:16:43,083:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 19:16:43,086:INFO:Starting cross validation
2025-03-20 19:16:43,087:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:44,779:INFO:Calculating mean and std
2025-03-20 19:16:44,780:INFO:Creating metrics dataframe
2025-03-20 19:16:44,782:INFO:Uploading results into container
2025-03-20 19:16:44,782:INFO:Uploading model into container now
2025-03-20 19:16:44,782:INFO:_master_model_container: 7
2025-03-20 19:16:44,783:INFO:_display_container: 2
2025-03-20 19:16:44,783:INFO:OrthogonalMatchingPursuit()
2025-03-20 19:16:44,783:INFO:create_model() successfully completed......................................
2025-03-20 19:16:44,836:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:44,836:INFO:Creating metrics dataframe
2025-03-20 19:16:44,842:INFO:Initializing Bayesian Ridge
2025-03-20 19:16:44,842:INFO:Total runtime is 0.24421226183573405 minutes
2025-03-20 19:16:44,844:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:44,844:INFO:Initializing create_model()
2025-03-20 19:16:44,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:44,844:INFO:Checking exceptions
2025-03-20 19:16:44,844:INFO:Importing libraries
2025-03-20 19:16:44,844:INFO:Copying training dataset
2025-03-20 19:16:44,846:INFO:Defining folds
2025-03-20 19:16:44,846:INFO:Declaring metric variables
2025-03-20 19:16:44,848:INFO:Importing untrained model
2025-03-20 19:16:44,849:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:16:44,852:INFO:Starting cross validation
2025-03-20 19:16:44,853:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:44,918:INFO:Calculating mean and std
2025-03-20 19:16:44,919:INFO:Creating metrics dataframe
2025-03-20 19:16:44,920:INFO:Uploading results into container
2025-03-20 19:16:44,921:INFO:Uploading model into container now
2025-03-20 19:16:44,921:INFO:_master_model_container: 8
2025-03-20 19:16:44,921:INFO:_display_container: 2
2025-03-20 19:16:44,921:INFO:BayesianRidge()
2025-03-20 19:16:44,921:INFO:create_model() successfully completed......................................
2025-03-20 19:16:44,974:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:44,974:INFO:Creating metrics dataframe
2025-03-20 19:16:44,980:INFO:Initializing Passive Aggressive Regressor
2025-03-20 19:16:44,980:INFO:Total runtime is 0.2464973012606303 minutes
2025-03-20 19:16:44,982:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:44,982:INFO:Initializing create_model()
2025-03-20 19:16:44,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:44,982:INFO:Checking exceptions
2025-03-20 19:16:44,982:INFO:Importing libraries
2025-03-20 19:16:44,982:INFO:Copying training dataset
2025-03-20 19:16:44,984:INFO:Defining folds
2025-03-20 19:16:44,984:INFO:Declaring metric variables
2025-03-20 19:16:44,985:INFO:Importing untrained model
2025-03-20 19:16:44,986:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 19:16:44,990:INFO:Starting cross validation
2025-03-20 19:16:44,991:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:45,057:INFO:Calculating mean and std
2025-03-20 19:16:45,058:INFO:Creating metrics dataframe
2025-03-20 19:16:45,059:INFO:Uploading results into container
2025-03-20 19:16:45,060:INFO:Uploading model into container now
2025-03-20 19:16:45,060:INFO:_master_model_container: 9
2025-03-20 19:16:45,060:INFO:_display_container: 2
2025-03-20 19:16:45,060:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 19:16:45,060:INFO:create_model() successfully completed......................................
2025-03-20 19:16:45,114:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:45,114:INFO:Creating metrics dataframe
2025-03-20 19:16:45,120:INFO:Initializing Huber Regressor
2025-03-20 19:16:45,120:INFO:Total runtime is 0.24883226156234742 minutes
2025-03-20 19:16:45,121:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:45,121:INFO:Initializing create_model()
2025-03-20 19:16:45,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:45,122:INFO:Checking exceptions
2025-03-20 19:16:45,122:INFO:Importing libraries
2025-03-20 19:16:45,122:INFO:Copying training dataset
2025-03-20 19:16:45,123:INFO:Defining folds
2025-03-20 19:16:45,123:INFO:Declaring metric variables
2025-03-20 19:16:45,125:INFO:Importing untrained model
2025-03-20 19:16:45,127:INFO:Huber Regressor Imported successfully
2025-03-20 19:16:45,130:INFO:Starting cross validation
2025-03-20 19:16:45,131:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:45,171:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:16:45,173:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:16:45,178:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:16:45,181:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:16:45,184:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:16:45,211:INFO:Calculating mean and std
2025-03-20 19:16:45,212:INFO:Creating metrics dataframe
2025-03-20 19:16:45,213:INFO:Uploading results into container
2025-03-20 19:16:45,214:INFO:Uploading model into container now
2025-03-20 19:16:45,214:INFO:_master_model_container: 10
2025-03-20 19:16:45,214:INFO:_display_container: 2
2025-03-20 19:16:45,214:INFO:HuberRegressor()
2025-03-20 19:16:45,214:INFO:create_model() successfully completed......................................
2025-03-20 19:16:45,267:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:45,267:INFO:Creating metrics dataframe
2025-03-20 19:16:45,273:INFO:Initializing K Neighbors Regressor
2025-03-20 19:16:45,273:INFO:Total runtime is 0.2513835986455282 minutes
2025-03-20 19:16:45,274:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:45,274:INFO:Initializing create_model()
2025-03-20 19:16:45,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:45,275:INFO:Checking exceptions
2025-03-20 19:16:45,275:INFO:Importing libraries
2025-03-20 19:16:45,275:INFO:Copying training dataset
2025-03-20 19:16:45,277:INFO:Defining folds
2025-03-20 19:16:45,277:INFO:Declaring metric variables
2025-03-20 19:16:45,278:INFO:Importing untrained model
2025-03-20 19:16:45,280:INFO:K Neighbors Regressor Imported successfully
2025-03-20 19:16:45,283:INFO:Starting cross validation
2025-03-20 19:16:45,284:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:45,380:INFO:Calculating mean and std
2025-03-20 19:16:45,381:INFO:Creating metrics dataframe
2025-03-20 19:16:45,382:INFO:Uploading results into container
2025-03-20 19:16:45,382:INFO:Uploading model into container now
2025-03-20 19:16:45,383:INFO:_master_model_container: 11
2025-03-20 19:16:45,383:INFO:_display_container: 2
2025-03-20 19:16:45,383:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 19:16:45,383:INFO:create_model() successfully completed......................................
2025-03-20 19:16:45,437:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:45,437:INFO:Creating metrics dataframe
2025-03-20 19:16:45,442:INFO:Initializing Decision Tree Regressor
2025-03-20 19:16:45,442:INFO:Total runtime is 0.2542063275973002 minutes
2025-03-20 19:16:45,444:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:45,444:INFO:Initializing create_model()
2025-03-20 19:16:45,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:45,444:INFO:Checking exceptions
2025-03-20 19:16:45,444:INFO:Importing libraries
2025-03-20 19:16:45,444:INFO:Copying training dataset
2025-03-20 19:16:45,446:INFO:Defining folds
2025-03-20 19:16:45,446:INFO:Declaring metric variables
2025-03-20 19:16:45,448:INFO:Importing untrained model
2025-03-20 19:16:45,449:INFO:Decision Tree Regressor Imported successfully
2025-03-20 19:16:45,452:INFO:Starting cross validation
2025-03-20 19:16:45,453:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:45,519:INFO:Calculating mean and std
2025-03-20 19:16:45,519:INFO:Creating metrics dataframe
2025-03-20 19:16:45,521:INFO:Uploading results into container
2025-03-20 19:16:45,522:INFO:Uploading model into container now
2025-03-20 19:16:45,522:INFO:_master_model_container: 12
2025-03-20 19:16:45,522:INFO:_display_container: 2
2025-03-20 19:16:45,522:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 19:16:45,522:INFO:create_model() successfully completed......................................
2025-03-20 19:16:45,577:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:45,577:INFO:Creating metrics dataframe
2025-03-20 19:16:45,583:INFO:Initializing Random Forest Regressor
2025-03-20 19:16:45,583:INFO:Total runtime is 0.25654892921447753 minutes
2025-03-20 19:16:45,584:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:45,584:INFO:Initializing create_model()
2025-03-20 19:16:45,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:45,584:INFO:Checking exceptions
2025-03-20 19:16:45,585:INFO:Importing libraries
2025-03-20 19:16:45,585:INFO:Copying training dataset
2025-03-20 19:16:45,587:INFO:Defining folds
2025-03-20 19:16:45,587:INFO:Declaring metric variables
2025-03-20 19:16:45,588:INFO:Importing untrained model
2025-03-20 19:16:45,590:INFO:Random Forest Regressor Imported successfully
2025-03-20 19:16:45,593:INFO:Starting cross validation
2025-03-20 19:16:45,594:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:45,950:INFO:Calculating mean and std
2025-03-20 19:16:45,951:INFO:Creating metrics dataframe
2025-03-20 19:16:45,952:INFO:Uploading results into container
2025-03-20 19:16:45,953:INFO:Uploading model into container now
2025-03-20 19:16:45,953:INFO:_master_model_container: 13
2025-03-20 19:16:45,953:INFO:_display_container: 2
2025-03-20 19:16:45,953:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:16:45,953:INFO:create_model() successfully completed......................................
2025-03-20 19:16:46,006:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:46,006:INFO:Creating metrics dataframe
2025-03-20 19:16:46,012:INFO:Initializing Extra Trees Regressor
2025-03-20 19:16:46,012:INFO:Total runtime is 0.26369889577229816 minutes
2025-03-20 19:16:46,014:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:46,014:INFO:Initializing create_model()
2025-03-20 19:16:46,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:46,014:INFO:Checking exceptions
2025-03-20 19:16:46,014:INFO:Importing libraries
2025-03-20 19:16:46,014:INFO:Copying training dataset
2025-03-20 19:16:46,016:INFO:Defining folds
2025-03-20 19:16:46,016:INFO:Declaring metric variables
2025-03-20 19:16:46,017:INFO:Importing untrained model
2025-03-20 19:16:46,019:INFO:Extra Trees Regressor Imported successfully
2025-03-20 19:16:46,022:INFO:Starting cross validation
2025-03-20 19:16:46,023:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:46,211:INFO:Calculating mean and std
2025-03-20 19:16:46,212:INFO:Creating metrics dataframe
2025-03-20 19:16:46,214:INFO:Uploading results into container
2025-03-20 19:16:46,214:INFO:Uploading model into container now
2025-03-20 19:16:46,214:INFO:_master_model_container: 14
2025-03-20 19:16:46,214:INFO:_display_container: 2
2025-03-20 19:16:46,214:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:16:46,215:INFO:create_model() successfully completed......................................
2025-03-20 19:16:46,268:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:46,268:INFO:Creating metrics dataframe
2025-03-20 19:16:46,274:INFO:Initializing AdaBoost Regressor
2025-03-20 19:16:46,274:INFO:Total runtime is 0.26807916164398193 minutes
2025-03-20 19:16:46,276:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:46,276:INFO:Initializing create_model()
2025-03-20 19:16:46,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:46,276:INFO:Checking exceptions
2025-03-20 19:16:46,276:INFO:Importing libraries
2025-03-20 19:16:46,276:INFO:Copying training dataset
2025-03-20 19:16:46,278:INFO:Defining folds
2025-03-20 19:16:46,278:INFO:Declaring metric variables
2025-03-20 19:16:46,280:INFO:Importing untrained model
2025-03-20 19:16:46,281:INFO:AdaBoost Regressor Imported successfully
2025-03-20 19:16:46,285:INFO:Starting cross validation
2025-03-20 19:16:46,285:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:46,473:INFO:Calculating mean and std
2025-03-20 19:16:46,474:INFO:Creating metrics dataframe
2025-03-20 19:16:46,475:INFO:Uploading results into container
2025-03-20 19:16:46,475:INFO:Uploading model into container now
2025-03-20 19:16:46,476:INFO:_master_model_container: 15
2025-03-20 19:16:46,476:INFO:_display_container: 2
2025-03-20 19:16:46,476:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 19:16:46,476:INFO:create_model() successfully completed......................................
2025-03-20 19:16:46,530:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:46,530:INFO:Creating metrics dataframe
2025-03-20 19:16:46,537:INFO:Initializing Gradient Boosting Regressor
2025-03-20 19:16:46,537:INFO:Total runtime is 0.27244798342386883 minutes
2025-03-20 19:16:46,539:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:46,539:INFO:Initializing create_model()
2025-03-20 19:16:46,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:46,539:INFO:Checking exceptions
2025-03-20 19:16:46,539:INFO:Importing libraries
2025-03-20 19:16:46,539:INFO:Copying training dataset
2025-03-20 19:16:46,541:INFO:Defining folds
2025-03-20 19:16:46,541:INFO:Declaring metric variables
2025-03-20 19:16:46,542:INFO:Importing untrained model
2025-03-20 19:16:46,544:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:16:46,547:INFO:Starting cross validation
2025-03-20 19:16:46,547:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:47,151:INFO:Calculating mean and std
2025-03-20 19:16:47,152:INFO:Creating metrics dataframe
2025-03-20 19:16:47,153:INFO:Uploading results into container
2025-03-20 19:16:47,153:INFO:Uploading model into container now
2025-03-20 19:16:47,154:INFO:_master_model_container: 16
2025-03-20 19:16:47,154:INFO:_display_container: 2
2025-03-20 19:16:47,154:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:16:47,154:INFO:create_model() successfully completed......................................
2025-03-20 19:16:47,206:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:47,207:INFO:Creating metrics dataframe
2025-03-20 19:16:47,213:INFO:Initializing Extreme Gradient Boosting
2025-03-20 19:16:47,213:INFO:Total runtime is 0.28371745347976685 minutes
2025-03-20 19:16:47,215:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:47,215:INFO:Initializing create_model()
2025-03-20 19:16:47,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:47,215:INFO:Checking exceptions
2025-03-20 19:16:47,215:INFO:Importing libraries
2025-03-20 19:16:47,215:INFO:Copying training dataset
2025-03-20 19:16:47,217:INFO:Defining folds
2025-03-20 19:16:47,217:INFO:Declaring metric variables
2025-03-20 19:16:47,219:INFO:Importing untrained model
2025-03-20 19:16:47,220:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:16:47,223:INFO:Starting cross validation
2025-03-20 19:16:47,224:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:47,690:INFO:Calculating mean and std
2025-03-20 19:16:47,691:INFO:Creating metrics dataframe
2025-03-20 19:16:47,692:INFO:Uploading results into container
2025-03-20 19:16:47,693:INFO:Uploading model into container now
2025-03-20 19:16:47,693:INFO:_master_model_container: 17
2025-03-20 19:16:47,693:INFO:_display_container: 2
2025-03-20 19:16:47,693:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:16:47,693:INFO:create_model() successfully completed......................................
2025-03-20 19:16:47,746:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:47,746:INFO:Creating metrics dataframe
2025-03-20 19:16:47,752:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 19:16:47,752:INFO:Total runtime is 0.29270782868067424 minutes
2025-03-20 19:16:47,754:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:47,754:INFO:Initializing create_model()
2025-03-20 19:16:47,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:47,754:INFO:Checking exceptions
2025-03-20 19:16:47,754:INFO:Importing libraries
2025-03-20 19:16:47,754:INFO:Copying training dataset
2025-03-20 19:16:47,756:INFO:Defining folds
2025-03-20 19:16:47,756:INFO:Declaring metric variables
2025-03-20 19:16:47,758:INFO:Importing untrained model
2025-03-20 19:16:47,759:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:16:47,765:INFO:Starting cross validation
2025-03-20 19:16:47,766:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:48,259:INFO:Calculating mean and std
2025-03-20 19:16:48,260:INFO:Creating metrics dataframe
2025-03-20 19:16:48,262:INFO:Uploading results into container
2025-03-20 19:16:48,263:INFO:Uploading model into container now
2025-03-20 19:16:48,263:INFO:_master_model_container: 18
2025-03-20 19:16:48,263:INFO:_display_container: 2
2025-03-20 19:16:48,264:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:16:48,264:INFO:create_model() successfully completed......................................
2025-03-20 19:16:48,322:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:48,322:INFO:Creating metrics dataframe
2025-03-20 19:16:48,331:INFO:Initializing CatBoost Regressor
2025-03-20 19:16:48,331:INFO:Total runtime is 0.3023514191309611 minutes
2025-03-20 19:16:48,333:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:48,333:INFO:Initializing create_model()
2025-03-20 19:16:48,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:48,333:INFO:Checking exceptions
2025-03-20 19:16:48,333:INFO:Importing libraries
2025-03-20 19:16:48,334:INFO:Copying training dataset
2025-03-20 19:16:48,336:INFO:Defining folds
2025-03-20 19:16:48,336:INFO:Declaring metric variables
2025-03-20 19:16:48,338:INFO:Importing untrained model
2025-03-20 19:16:48,340:INFO:CatBoost Regressor Imported successfully
2025-03-20 19:16:48,344:INFO:Starting cross validation
2025-03-20 19:16:48,346:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:50,708:INFO:Calculating mean and std
2025-03-20 19:16:50,709:INFO:Creating metrics dataframe
2025-03-20 19:16:50,711:INFO:Uploading results into container
2025-03-20 19:16:50,712:INFO:Uploading model into container now
2025-03-20 19:16:50,712:INFO:_master_model_container: 19
2025-03-20 19:16:50,712:INFO:_display_container: 2
2025-03-20 19:16:50,712:INFO:<catboost.core.CatBoostRegressor object at 0x000001FA01EC44C0>
2025-03-20 19:16:50,712:INFO:create_model() successfully completed......................................
2025-03-20 19:16:50,764:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:50,764:INFO:Creating metrics dataframe
2025-03-20 19:16:50,770:INFO:Initializing Dummy Regressor
2025-03-20 19:16:50,770:INFO:Total runtime is 0.34300729036331173 minutes
2025-03-20 19:16:50,772:INFO:SubProcess create_model() called ==================================
2025-03-20 19:16:50,772:INFO:Initializing create_model()
2025-03-20 19:16:50,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01BFCD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:50,772:INFO:Checking exceptions
2025-03-20 19:16:50,772:INFO:Importing libraries
2025-03-20 19:16:50,772:INFO:Copying training dataset
2025-03-20 19:16:50,774:INFO:Defining folds
2025-03-20 19:16:50,774:INFO:Declaring metric variables
2025-03-20 19:16:50,776:INFO:Importing untrained model
2025-03-20 19:16:50,777:INFO:Dummy Regressor Imported successfully
2025-03-20 19:16:50,780:INFO:Starting cross validation
2025-03-20 19:16:50,781:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:16:50,847:INFO:Calculating mean and std
2025-03-20 19:16:50,848:INFO:Creating metrics dataframe
2025-03-20 19:16:50,849:INFO:Uploading results into container
2025-03-20 19:16:50,850:INFO:Uploading model into container now
2025-03-20 19:16:50,850:INFO:_master_model_container: 20
2025-03-20 19:16:50,850:INFO:_display_container: 2
2025-03-20 19:16:50,850:INFO:DummyRegressor()
2025-03-20 19:16:50,850:INFO:create_model() successfully completed......................................
2025-03-20 19:16:50,904:INFO:SubProcess create_model() end ==================================
2025-03-20 19:16:50,904:INFO:Creating metrics dataframe
2025-03-20 19:16:50,915:INFO:Initializing create_model()
2025-03-20 19:16:50,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:50,915:INFO:Checking exceptions
2025-03-20 19:16:50,916:INFO:Importing libraries
2025-03-20 19:16:50,916:INFO:Copying training dataset
2025-03-20 19:16:50,918:INFO:Defining folds
2025-03-20 19:16:50,918:INFO:Declaring metric variables
2025-03-20 19:16:50,918:INFO:Importing untrained model
2025-03-20 19:16:50,918:INFO:Declaring custom model
2025-03-20 19:16:50,918:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:16:50,919:INFO:Cross validation set to False
2025-03-20 19:16:50,919:INFO:Fitting Model
2025-03-20 19:16:50,953:INFO:BayesianRidge()
2025-03-20 19:16:50,953:INFO:create_model() successfully completed......................................
2025-03-20 19:16:51,007:INFO:Creating Dashboard logs
2025-03-20 19:16:51,009:INFO:Model: Bayesian Ridge
2025-03-20 19:16:51,027:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:16:51,060:INFO:Initializing predict_model()
2025-03-20 19:16:51,060:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA00946280>)
2025-03-20 19:16:51,061:INFO:Checking exceptions
2025-03-20 19:16:51,061:INFO:Preloading libraries
2025-03-20 19:16:51,186:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 19:16:51,198:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:51,201:INFO:Initializing create_model()
2025-03-20 19:16:51,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:51,201:INFO:Checking exceptions
2025-03-20 19:16:51,202:INFO:Importing libraries
2025-03-20 19:16:51,202:INFO:Copying training dataset
2025-03-20 19:16:51,205:INFO:Defining folds
2025-03-20 19:16:51,205:INFO:Declaring metric variables
2025-03-20 19:16:51,205:INFO:Importing untrained model
2025-03-20 19:16:51,205:INFO:Declaring custom model
2025-03-20 19:16:51,205:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:16:51,206:INFO:Cross validation set to False
2025-03-20 19:16:51,206:INFO:Fitting Model
2025-03-20 19:16:51,878:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:16:51,878:INFO:create_model() successfully completed......................................
2025-03-20 19:16:51,930:INFO:Creating Dashboard logs
2025-03-20 19:16:51,931:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:16:51,951:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:51,997:INFO:Initializing predict_model()
2025-03-20 19:16:51,997:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA019D2550>)
2025-03-20 19:16:51,997:INFO:Checking exceptions
2025-03-20 19:16:51,997:INFO:Preloading libraries
2025-03-20 19:16:52,135:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:52,138:INFO:Initializing create_model()
2025-03-20 19:16:52,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:52,138:INFO:Checking exceptions
2025-03-20 19:16:52,139:INFO:Importing libraries
2025-03-20 19:16:52,139:INFO:Copying training dataset
2025-03-20 19:16:52,141:INFO:Defining folds
2025-03-20 19:16:52,141:INFO:Declaring metric variables
2025-03-20 19:16:52,141:INFO:Importing untrained model
2025-03-20 19:16:52,141:INFO:Declaring custom model
2025-03-20 19:16:52,141:INFO:Ridge Regression Imported successfully
2025-03-20 19:16:52,142:INFO:Cross validation set to False
2025-03-20 19:16:52,142:INFO:Fitting Model
2025-03-20 19:16:52,171:INFO:Ridge(random_state=888)
2025-03-20 19:16:52,171:INFO:create_model() successfully completed......................................
2025-03-20 19:16:52,225:INFO:Creating Dashboard logs
2025-03-20 19:16:52,227:INFO:Model: Ridge Regression
2025-03-20 19:16:52,245:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:16:52,294:INFO:Initializing predict_model()
2025-03-20 19:16:52,294:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA019DD670>)
2025-03-20 19:16:52,294:INFO:Checking exceptions
2025-03-20 19:16:52,294:INFO:Preloading libraries
2025-03-20 19:16:52,428:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:52,430:INFO:Initializing create_model()
2025-03-20 19:16:52,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:52,430:INFO:Checking exceptions
2025-03-20 19:16:52,431:INFO:Importing libraries
2025-03-20 19:16:52,431:INFO:Copying training dataset
2025-03-20 19:16:52,433:INFO:Defining folds
2025-03-20 19:16:52,433:INFO:Declaring metric variables
2025-03-20 19:16:52,433:INFO:Importing untrained model
2025-03-20 19:16:52,433:INFO:Declaring custom model
2025-03-20 19:16:52,434:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:16:52,434:INFO:Cross validation set to False
2025-03-20 19:16:52,434:INFO:Fitting Model
2025-03-20 19:16:52,468:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:16:52,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.
2025-03-20 19:16:52,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:16:52,470:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:16:52,470:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:16:52,470:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:16:52,546:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:16:52,546:INFO:create_model() successfully completed......................................
2025-03-20 19:16:52,607:INFO:Creating Dashboard logs
2025-03-20 19:16:52,610:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:16:52,635:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:16:52,699:INFO:Initializing predict_model()
2025-03-20 19:16:52,699:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA019DE820>)
2025-03-20 19:16:52,699:INFO:Checking exceptions
2025-03-20 19:16:52,699:INFO:Preloading libraries
2025-03-20 19:16:52,841:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:52,845:INFO:Initializing create_model()
2025-03-20 19:16:52,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:16:52,845:INFO:Checking exceptions
2025-03-20 19:16:52,846:INFO:Importing libraries
2025-03-20 19:16:52,846:INFO:Copying training dataset
2025-03-20 19:16:52,848:INFO:Defining folds
2025-03-20 19:16:52,849:INFO:Declaring metric variables
2025-03-20 19:16:52,849:INFO:Importing untrained model
2025-03-20 19:16:52,849:INFO:Declaring custom model
2025-03-20 19:16:52,849:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:16:52,850:INFO:Cross validation set to False
2025-03-20 19:16:52,850:INFO:Fitting Model
2025-03-20 19:16:53,045:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:16:53,045:INFO:create_model() successfully completed......................................
2025-03-20 19:16:53,106:INFO:Creating Dashboard logs
2025-03-20 19:16:53,109:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:16:53,134:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:16:53,218:INFO:Initializing predict_model()
2025-03-20 19:16:53,218:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA01E6B940>)
2025-03-20 19:16:53,218:INFO:Checking exceptions
2025-03-20 19:16:53,218:INFO:Preloading libraries
2025-03-20 19:16:53,398:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:53,399:INFO:Creating Dashboard logs
2025-03-20 19:16:53,401:INFO:Model: Random Forest Regressor
2025-03-20 19:16:53,425:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:53,524:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:53,525:INFO:Creating Dashboard logs
2025-03-20 19:16:53,526:INFO:Model: AdaBoost Regressor
2025-03-20 19:16:53,544:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 19:16:53,627:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:53,628:INFO:Creating Dashboard logs
2025-03-20 19:16:53,630:INFO:Model: CatBoost Regressor
2025-03-20 19:16:53,649:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 19:16:53,649:INFO:Logged params: {}
2025-03-20 19:16:53,736:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x000001FA01EC44C0> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:53,736:INFO:Creating Dashboard logs
2025-03-20 19:16:53,738:INFO:Model: Extra Trees Regressor
2025-03-20 19:16:53,756:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:53,858:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:53,858:INFO:Creating Dashboard logs
2025-03-20 19:16:53,861:INFO:Model: Decision Tree Regressor
2025-03-20 19:16:53,879:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 19:16:53,985:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:53,985:INFO:Creating Dashboard logs
2025-03-20 19:16:53,987:INFO:Model: Passive Aggressive Regressor
2025-03-20 19:16:54,005:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:16:54,118:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:54,118:INFO:Creating Dashboard logs
2025-03-20 19:16:54,120:INFO:Model: Huber Regressor
2025-03-20 19:16:54,137:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 19:16:54,254:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:54,254:INFO:Creating Dashboard logs
2025-03-20 19:16:54,257:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 19:16:54,274:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 19:16:54,398:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:54,398:INFO:Creating Dashboard logs
2025-03-20 19:16:54,400:INFO:Model: K Neighbors Regressor
2025-03-20 19:16:54,419:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 19:16:54,549:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:54,550:INFO:Creating Dashboard logs
2025-03-20 19:16:54,552:INFO:Model: Elastic Net
2025-03-20 19:16:54,570:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:16:54,711:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:54,711:INFO:Creating Dashboard logs
2025-03-20 19:16:54,713:INFO:Model: Lasso Regression
2025-03-20 19:16:54,731:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:16:54,878:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:54,879:INFO:Creating Dashboard logs
2025-03-20 19:16:54,880:INFO:Model: Lasso Least Angle Regression
2025-03-20 19:16:54,899:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:16:55,050:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:55,050:INFO:Creating Dashboard logs
2025-03-20 19:16:55,053:INFO:Model: Dummy Regressor
2025-03-20 19:16:55,072:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 19:16:55,230:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:55,231:INFO:Creating Dashboard logs
2025-03-20 19:16:55,233:INFO:Model: Linear Regression
2025-03-20 19:16:55,252:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 19:16:55,413:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:55,413:INFO:Creating Dashboard logs
2025-03-20 19:16:55,415:INFO:Model: Least Angle Regression
2025-03-20 19:16:55,434:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:16:55,618:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:16:55,628:INFO:_master_model_container: 20
2025-03-20 19:16:55,628:INFO:_display_container: 2
2025-03-20 19:16:55,630:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)]
2025-03-20 19:16:55,630:INFO:compare_models() successfully completed......................................
2025-03-20 19:20:54,646:INFO:Initializing tune_model()
2025-03-20 19:20:54,647:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>)
2025-03-20 19:20:54,647:INFO:Checking exceptions
2025-03-20 19:20:54,647:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:20:54,688:INFO:Copying training dataset
2025-03-20 19:20:54,690:INFO:Checking base model
2025-03-20 19:20:54,690:INFO:Base model : Bayesian Ridge
2025-03-20 19:20:54,691:INFO:Declaring metric variables
2025-03-20 19:20:54,693:INFO:Defining Hyperparameters
2025-03-20 19:20:54,751:INFO:Tuning with n_jobs=-1
2025-03-20 19:20:54,752:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:20:54,752:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:20:54,752:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:20:54,757:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:20:54,757:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:20:54,757:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:21:19,405:INFO:best_params: {'actual_estimator__alpha_1': 0.15236276711294466, 'actual_estimator__alpha_2': 5.185274577395409e-06, 'actual_estimator__lambda_1': 0.9719005034871095, 'actual_estimator__lambda_2': 0.00014680388223384992, 'actual_estimator__compute_score': True, 'actual_estimator__fit_intercept': True}
2025-03-20 19:21:19,409:INFO:Hyperparameter search completed
2025-03-20 19:21:19,409:INFO:SubProcess create_model() called ==================================
2025-03-20 19:21:19,409:INFO:Initializing create_model()
2025-03-20 19:21:19,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01E4F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 0.15236276711294466, 'alpha_2': 5.185274577395409e-06, 'lambda_1': 0.9719005034871095, 'lambda_2': 0.00014680388223384992, 'compute_score': True, 'fit_intercept': True})
2025-03-20 19:21:19,409:INFO:Checking exceptions
2025-03-20 19:21:19,409:INFO:Importing libraries
2025-03-20 19:21:19,409:INFO:Copying training dataset
2025-03-20 19:21:19,412:INFO:Defining folds
2025-03-20 19:21:19,412:INFO:Declaring metric variables
2025-03-20 19:21:19,414:INFO:Importing untrained model
2025-03-20 19:21:19,414:INFO:Declaring custom model
2025-03-20 19:21:19,416:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:21:19,419:INFO:Starting cross validation
2025-03-20 19:21:19,420:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:21:19,486:INFO:Calculating mean and std
2025-03-20 19:21:19,487:INFO:Creating metrics dataframe
2025-03-20 19:21:19,489:INFO:Finalizing model
2025-03-20 19:21:19,525:INFO:Uploading results into container
2025-03-20 19:21:19,525:INFO:Uploading model into container now
2025-03-20 19:21:19,526:INFO:_master_model_container: 21
2025-03-20 19:21:19,526:INFO:_display_container: 3
2025-03-20 19:21:19,526:INFO:BayesianRidge(alpha_1=0.15236276711294466, alpha_2=5.185274577395409e-06,
              compute_score=True, lambda_1=0.9719005034871095,
              lambda_2=0.00014680388223384992)
2025-03-20 19:21:19,526:INFO:create_model() successfully completed......................................
2025-03-20 19:21:19,583:INFO:SubProcess create_model() end ==================================
2025-03-20 19:21:19,583:INFO:choose_better activated
2025-03-20 19:21:19,585:INFO:SubProcess create_model() called ==================================
2025-03-20 19:21:19,586:INFO:Initializing create_model()
2025-03-20 19:21:19,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:21:19,586:INFO:Checking exceptions
2025-03-20 19:21:19,587:INFO:Importing libraries
2025-03-20 19:21:19,587:INFO:Copying training dataset
2025-03-20 19:21:19,589:INFO:Defining folds
2025-03-20 19:21:19,589:INFO:Declaring metric variables
2025-03-20 19:21:19,589:INFO:Importing untrained model
2025-03-20 19:21:19,589:INFO:Declaring custom model
2025-03-20 19:21:19,589:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:21:19,589:INFO:Starting cross validation
2025-03-20 19:21:19,590:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:21:19,655:INFO:Calculating mean and std
2025-03-20 19:21:19,656:INFO:Creating metrics dataframe
2025-03-20 19:21:19,657:INFO:Finalizing model
2025-03-20 19:21:19,691:INFO:Uploading results into container
2025-03-20 19:21:19,691:INFO:Uploading model into container now
2025-03-20 19:21:19,691:INFO:_master_model_container: 22
2025-03-20 19:21:19,692:INFO:_display_container: 4
2025-03-20 19:21:19,692:INFO:BayesianRidge()
2025-03-20 19:21:19,692:INFO:create_model() successfully completed......................................
2025-03-20 19:21:19,750:INFO:SubProcess create_model() end ==================================
2025-03-20 19:21:19,750:INFO:BayesianRidge() result for MAPE is 0.0211
2025-03-20 19:21:19,750:INFO:BayesianRidge(alpha_1=0.15236276711294466, alpha_2=5.185274577395409e-06,
              compute_score=True, lambda_1=0.9719005034871095,
              lambda_2=0.00014680388223384992) result for MAPE is 0.0211
2025-03-20 19:21:19,750:INFO:BayesianRidge() is best model
2025-03-20 19:21:19,750:INFO:choose_better completed
2025-03-20 19:21:19,750:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 19:21:19,751:INFO:Creating Dashboard logs
2025-03-20 19:21:19,753:INFO:Model: Bayesian Ridge
2025-03-20 19:21:19,772:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:21:19,944:INFO:Initializing predict_model()
2025-03-20 19:21:19,944:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA95997EE0>)
2025-03-20 19:21:19,944:INFO:Checking exceptions
2025-03-20 19:21:19,944:INFO:Preloading libraries
2025-03-20 19:21:20,088:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:21:20,093:INFO:_master_model_container: 22
2025-03-20 19:21:20,093:INFO:_display_container: 3
2025-03-20 19:21:20,093:INFO:BayesianRidge()
2025-03-20 19:21:20,093:INFO:tune_model() successfully completed......................................
2025-03-20 19:21:20,152:INFO:Initializing predict_model()
2025-03-20 19:21:20,152:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA006BC430>)
2025-03-20 19:21:20,152:INFO:Checking exceptions
2025-03-20 19:21:20,152:INFO:Preloading libraries
2025-03-20 19:21:20,283:INFO:Initializing tune_model()
2025-03-20 19:21:20,283:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>)
2025-03-20 19:21:20,283:INFO:Checking exceptions
2025-03-20 19:21:20,283:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:21:20,292:INFO:Copying training dataset
2025-03-20 19:21:20,295:INFO:Checking base model
2025-03-20 19:21:20,295:INFO:Base model : Gradient Boosting Regressor
2025-03-20 19:21:20,298:INFO:Declaring metric variables
2025-03-20 19:21:20,300:INFO:Defining Hyperparameters
2025-03-20 19:21:20,369:INFO:Tuning with n_jobs=-1
2025-03-20 19:21:20,370:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:21:20,370:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:21:20,370:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:21:20,371:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:21:20,371:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:21:20,371:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:22:14,104:INFO:best_params: {'actual_estimator__n_estimators': 185, 'actual_estimator__learning_rate': 0.032338564871734976, 'actual_estimator__subsample': 0.29223267821766347, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_depth': 4, 'actual_estimator__max_features': 0.7930794141442938, 'actual_estimator__min_impurity_decrease': 2.885315648069339e-09}
2025-03-20 19:22:14,109:INFO:Hyperparameter search completed
2025-03-20 19:22:14,109:INFO:SubProcess create_model() called ==================================
2025-03-20 19:22:14,109:INFO:Initializing create_model()
2025-03-20 19:22:14,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA9AAED070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 185, 'learning_rate': 0.032338564871734976, 'subsample': 0.29223267821766347, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 0.7930794141442938, 'min_impurity_decrease': 2.885315648069339e-09})
2025-03-20 19:22:14,109:INFO:Checking exceptions
2025-03-20 19:22:14,109:INFO:Importing libraries
2025-03-20 19:22:14,109:INFO:Copying training dataset
2025-03-20 19:22:14,111:INFO:Defining folds
2025-03-20 19:22:14,111:INFO:Declaring metric variables
2025-03-20 19:22:14,113:INFO:Importing untrained model
2025-03-20 19:22:14,113:INFO:Declaring custom model
2025-03-20 19:22:14,116:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:22:14,119:INFO:Starting cross validation
2025-03-20 19:22:14,120:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:22:14,714:INFO:Calculating mean and std
2025-03-20 19:22:14,715:INFO:Creating metrics dataframe
2025-03-20 19:22:14,717:INFO:Finalizing model
2025-03-20 19:22:15,133:INFO:Uploading results into container
2025-03-20 19:22:15,134:INFO:Uploading model into container now
2025-03-20 19:22:15,134:INFO:_master_model_container: 23
2025-03-20 19:22:15,134:INFO:_display_container: 5
2025-03-20 19:22:15,134:INFO:GradientBoostingRegressor(learning_rate=0.032338564871734976, max_depth=4,
                          max_features=0.7930794141442938,
                          min_impurity_decrease=2.885315648069339e-09,
                          min_samples_leaf=2, min_samples_split=7,
                          n_estimators=185, random_state=888,
                          subsample=0.29223267821766347)
2025-03-20 19:22:15,134:INFO:create_model() successfully completed......................................
2025-03-20 19:22:15,193:INFO:SubProcess create_model() end ==================================
2025-03-20 19:22:15,193:INFO:choose_better activated
2025-03-20 19:22:15,195:INFO:SubProcess create_model() called ==================================
2025-03-20 19:22:15,195:INFO:Initializing create_model()
2025-03-20 19:22:15,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:22:15,195:INFO:Checking exceptions
2025-03-20 19:22:15,196:INFO:Importing libraries
2025-03-20 19:22:15,196:INFO:Copying training dataset
2025-03-20 19:22:15,198:INFO:Defining folds
2025-03-20 19:22:15,198:INFO:Declaring metric variables
2025-03-20 19:22:15,198:INFO:Importing untrained model
2025-03-20 19:22:15,198:INFO:Declaring custom model
2025-03-20 19:22:15,198:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:22:15,199:INFO:Starting cross validation
2025-03-20 19:22:15,199:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:22:15,807:INFO:Calculating mean and std
2025-03-20 19:22:15,807:INFO:Creating metrics dataframe
2025-03-20 19:22:15,808:INFO:Finalizing model
2025-03-20 19:22:16,487:INFO:Uploading results into container
2025-03-20 19:22:16,487:INFO:Uploading model into container now
2025-03-20 19:22:16,487:INFO:_master_model_container: 24
2025-03-20 19:22:16,487:INFO:_display_container: 6
2025-03-20 19:22:16,487:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:22:16,487:INFO:create_model() successfully completed......................................
2025-03-20 19:22:16,547:INFO:SubProcess create_model() end ==================================
2025-03-20 19:22:16,547:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.0217
2025-03-20 19:22:16,548:INFO:GradientBoostingRegressor(learning_rate=0.032338564871734976, max_depth=4,
                          max_features=0.7930794141442938,
                          min_impurity_decrease=2.885315648069339e-09,
                          min_samples_leaf=2, min_samples_split=7,
                          n_estimators=185, random_state=888,
                          subsample=0.29223267821766347) result for MAPE is 0.0203
2025-03-20 19:22:16,548:INFO:GradientBoostingRegressor(learning_rate=0.032338564871734976, max_depth=4,
                          max_features=0.7930794141442938,
                          min_impurity_decrease=2.885315648069339e-09,
                          min_samples_leaf=2, min_samples_split=7,
                          n_estimators=185, random_state=888,
                          subsample=0.29223267821766347) is best model
2025-03-20 19:22:16,548:INFO:choose_better completed
2025-03-20 19:22:16,548:INFO:Creating Dashboard logs
2025-03-20 19:22:16,550:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:22:16,568:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.032338564871734976, 'loss': 'squared_error', 'max_depth': 4, 'max_features': 0.7930794141442938, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.885315648069339e-09, 'min_samples_leaf': 2, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 185, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.29223267821766347, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:22:16,754:INFO:Initializing predict_model()
2025-03-20 19:22:16,754:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=GradientBoostingRegressor(learning_rate=0.032338564871734976, max_depth=4,
                          max_features=0.7930794141442938,
                          min_impurity_decrease=2.885315648069339e-09,
                          min_samples_leaf=2, min_samples_split=7,
                          n_estimators=185, random_state=888,
                          subsample=0.29223267821766347), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA9486A040>)
2025-03-20 19:22:16,754:INFO:Checking exceptions
2025-03-20 19:22:16,754:INFO:Preloading libraries
2025-03-20 19:22:16,899:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.032338564871734976, max_depth=4,
                          max_features=0.7930794141442938,
                          min_impurity_decrease=2.885315648069339e-09,
                          min_samples_leaf=2, min_samples_split=7,
                          n_estimators=185, random_state=888,
                          subsample=0.29223267821766347) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:22:16,904:INFO:_master_model_container: 24
2025-03-20 19:22:16,904:INFO:_display_container: 5
2025-03-20 19:22:16,904:INFO:GradientBoostingRegressor(learning_rate=0.032338564871734976, max_depth=4,
                          max_features=0.7930794141442938,
                          min_impurity_decrease=2.885315648069339e-09,
                          min_samples_leaf=2, min_samples_split=7,
                          n_estimators=185, random_state=888,
                          subsample=0.29223267821766347)
2025-03-20 19:22:16,904:INFO:tune_model() successfully completed......................................
2025-03-20 19:22:16,965:INFO:Initializing predict_model()
2025-03-20 19:22:16,965:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=GradientBoostingRegressor(learning_rate=0.032338564871734976, max_depth=4,
                          max_features=0.7930794141442938,
                          min_impurity_decrease=2.885315648069339e-09,
                          min_samples_leaf=2, min_samples_split=7,
                          n_estimators=185, random_state=888,
                          subsample=0.29223267821766347), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA006BC430>)
2025-03-20 19:22:16,965:INFO:Checking exceptions
2025-03-20 19:22:16,965:INFO:Preloading libraries
2025-03-20 19:22:17,099:INFO:Initializing tune_model()
2025-03-20 19:22:17,099:INFO:tune_model(estimator=Ridge(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>)
2025-03-20 19:22:17,099:INFO:Checking exceptions
2025-03-20 19:22:17,099:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:22:17,107:INFO:Copying training dataset
2025-03-20 19:22:17,109:INFO:Checking base model
2025-03-20 19:22:17,109:INFO:Base model : Ridge Regression
2025-03-20 19:22:17,112:INFO:Declaring metric variables
2025-03-20 19:22:17,114:INFO:Defining Hyperparameters
2025-03-20 19:22:17,173:INFO:Tuning with n_jobs=-1
2025-03-20 19:22:17,174:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:22:17,174:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:22:17,174:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:22:17,174:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:22:17,174:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:22:17,174:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:22:40,476:INFO:best_params: {'actual_estimator__alpha': 0.1745461976392001, 'actual_estimator__fit_intercept': True}
2025-03-20 19:22:40,480:INFO:Hyperparameter search completed
2025-03-20 19:22:40,480:INFO:SubProcess create_model() called ==================================
2025-03-20 19:22:40,480:INFO:Initializing create_model()
2025-03-20 19:22:40,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA01CE6EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 0.1745461976392001, 'fit_intercept': True})
2025-03-20 19:22:40,481:INFO:Checking exceptions
2025-03-20 19:22:40,481:INFO:Importing libraries
2025-03-20 19:22:40,481:INFO:Copying training dataset
2025-03-20 19:22:40,483:INFO:Defining folds
2025-03-20 19:22:40,483:INFO:Declaring metric variables
2025-03-20 19:22:40,484:INFO:Importing untrained model
2025-03-20 19:22:40,484:INFO:Declaring custom model
2025-03-20 19:22:40,486:INFO:Ridge Regression Imported successfully
2025-03-20 19:22:40,489:INFO:Starting cross validation
2025-03-20 19:22:40,490:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:22:42,367:INFO:Calculating mean and std
2025-03-20 19:22:42,368:INFO:Creating metrics dataframe
2025-03-20 19:22:42,371:INFO:Finalizing model
2025-03-20 19:22:42,405:INFO:Uploading results into container
2025-03-20 19:22:42,405:INFO:Uploading model into container now
2025-03-20 19:22:42,406:INFO:_master_model_container: 25
2025-03-20 19:22:42,406:INFO:_display_container: 7
2025-03-20 19:22:42,406:INFO:Ridge(alpha=0.1745461976392001, random_state=888)
2025-03-20 19:22:42,406:INFO:create_model() successfully completed......................................
2025-03-20 19:22:42,464:INFO:SubProcess create_model() end ==================================
2025-03-20 19:22:42,464:INFO:choose_better activated
2025-03-20 19:22:42,466:INFO:SubProcess create_model() called ==================================
2025-03-20 19:22:42,467:INFO:Initializing create_model()
2025-03-20 19:22:42,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:22:42,467:INFO:Checking exceptions
2025-03-20 19:22:42,467:INFO:Importing libraries
2025-03-20 19:22:42,467:INFO:Copying training dataset
2025-03-20 19:22:42,469:INFO:Defining folds
2025-03-20 19:22:42,469:INFO:Declaring metric variables
2025-03-20 19:22:42,469:INFO:Importing untrained model
2025-03-20 19:22:42,469:INFO:Declaring custom model
2025-03-20 19:22:42,470:INFO:Ridge Regression Imported successfully
2025-03-20 19:22:42,470:INFO:Starting cross validation
2025-03-20 19:22:42,470:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:22:44,476:INFO:Calculating mean and std
2025-03-20 19:22:44,477:INFO:Creating metrics dataframe
2025-03-20 19:22:44,478:INFO:Finalizing model
2025-03-20 19:22:44,509:INFO:Uploading results into container
2025-03-20 19:22:44,509:INFO:Uploading model into container now
2025-03-20 19:22:44,509:INFO:_master_model_container: 26
2025-03-20 19:22:44,509:INFO:_display_container: 8
2025-03-20 19:22:44,509:INFO:Ridge(random_state=888)
2025-03-20 19:22:44,509:INFO:create_model() successfully completed......................................
2025-03-20 19:22:44,567:INFO:SubProcess create_model() end ==================================
2025-03-20 19:22:44,567:INFO:Ridge(random_state=888) result for MAPE is 0.0222
2025-03-20 19:22:44,567:INFO:Ridge(alpha=0.1745461976392001, random_state=888) result for MAPE is 0.0206
2025-03-20 19:22:44,567:INFO:Ridge(alpha=0.1745461976392001, random_state=888) is best model
2025-03-20 19:22:44,567:INFO:choose_better completed
2025-03-20 19:22:44,567:INFO:Creating Dashboard logs
2025-03-20 19:22:44,569:INFO:Model: Ridge Regression
2025-03-20 19:22:44,590:INFO:Logged params: {'alpha': 0.1745461976392001, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:22:44,773:INFO:Initializing predict_model()
2025-03-20 19:22:44,773:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=Ridge(alpha=0.1745461976392001, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA95AB7B80>)
2025-03-20 19:22:44,773:INFO:Checking exceptions
2025-03-20 19:22:44,773:INFO:Preloading libraries
2025-03-20 19:22:44,914:ERROR:_log_model() for Ridge(alpha=0.1745461976392001, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:22:44,918:INFO:_master_model_container: 26
2025-03-20 19:22:44,918:INFO:_display_container: 7
2025-03-20 19:22:44,919:INFO:Ridge(alpha=0.1745461976392001, random_state=888)
2025-03-20 19:22:44,919:INFO:tune_model() successfully completed......................................
2025-03-20 19:22:44,979:INFO:Initializing predict_model()
2025-03-20 19:22:44,979:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=Ridge(alpha=0.1745461976392001, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA006BC430>)
2025-03-20 19:22:44,979:INFO:Checking exceptions
2025-03-20 19:22:44,979:INFO:Preloading libraries
2025-03-20 19:22:45,116:INFO:Initializing tune_model()
2025-03-20 19:22:45,117:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>)
2025-03-20 19:22:45,117:INFO:Checking exceptions
2025-03-20 19:22:45,117:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:22:45,125:INFO:Copying training dataset
2025-03-20 19:22:45,126:INFO:Checking base model
2025-03-20 19:22:45,126:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 19:22:45,128:INFO:Declaring metric variables
2025-03-20 19:22:45,130:INFO:Defining Hyperparameters
2025-03-20 19:22:45,193:INFO:Tuning with n_jobs=-1
2025-03-20 19:22:45,193:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:22:45,193:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:22:45,193:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:22:45,193:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:22:45,193:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:22:45,194:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:23:29,067:INFO:best_params: {'actual_estimator__num_leaves': 39, 'actual_estimator__learning_rate': 0.026556667500443686, 'actual_estimator__n_estimators': 282, 'actual_estimator__min_split_gain': 0.528296219805712, 'actual_estimator__reg_alpha': 0.00017819515267429795, 'actual_estimator__reg_lambda': 1.3235400440085592e-07, 'actual_estimator__feature_fraction': 0.6023486179502875, 'actual_estimator__bagging_fraction': 0.5203463906975803, 'actual_estimator__bagging_freq': 5, 'actual_estimator__min_child_samples': 12}
2025-03-20 19:23:29,073:INFO:Hyperparameter search completed
2025-03-20 19:23:29,074:INFO:SubProcess create_model() called ==================================
2025-03-20 19:23:29,074:INFO:Initializing create_model()
2025-03-20 19:23:29,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA006FE910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 39, 'learning_rate': 0.026556667500443686, 'n_estimators': 282, 'min_split_gain': 0.528296219805712, 'reg_alpha': 0.00017819515267429795, 'reg_lambda': 1.3235400440085592e-07, 'feature_fraction': 0.6023486179502875, 'bagging_fraction': 0.5203463906975803, 'bagging_freq': 5, 'min_child_samples': 12})
2025-03-20 19:23:29,074:INFO:Checking exceptions
2025-03-20 19:23:29,074:INFO:Importing libraries
2025-03-20 19:23:29,074:INFO:Copying training dataset
2025-03-20 19:23:29,078:INFO:Defining folds
2025-03-20 19:23:29,078:INFO:Declaring metric variables
2025-03-20 19:23:29,080:INFO:Importing untrained model
2025-03-20 19:23:29,080:INFO:Declaring custom model
2025-03-20 19:23:29,083:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:23:29,087:INFO:Starting cross validation
2025-03-20 19:23:29,089:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:23:31,282:INFO:Calculating mean and std
2025-03-20 19:23:31,284:INFO:Creating metrics dataframe
2025-03-20 19:23:31,287:INFO:Finalizing model
2025-03-20 19:23:31,330:INFO:[LightGBM] [Warning] feature_fraction is set=0.6023486179502875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6023486179502875
2025-03-20 19:23:31,330:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5203463906975803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5203463906975803
2025-03-20 19:23:31,330:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 19:23:31,335:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:23:31,335:INFO:[LightGBM] [Warning] feature_fraction is set=0.6023486179502875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6023486179502875
2025-03-20 19:23:31,335:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5203463906975803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5203463906975803
2025-03-20 19:23:31,335:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-03-20 19:23:31,336:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-03-20 19:23:31,336:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:23:31,336:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:23:31,337:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:23:31,337:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:23:31,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:23:31,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:23:31,412:INFO:Uploading results into container
2025-03-20 19:23:31,412:INFO:Uploading model into container now
2025-03-20 19:23:31,413:INFO:_master_model_container: 27
2025-03-20 19:23:31,413:INFO:_display_container: 9
2025-03-20 19:23:31,414:INFO:LGBMRegressor(bagging_fraction=0.5203463906975803, bagging_freq=5,
              feature_fraction=0.6023486179502875,
              learning_rate=0.026556667500443686, min_child_samples=12,
              min_split_gain=0.528296219805712, n_estimators=282, n_jobs=-1,
              num_leaves=39, random_state=888, reg_alpha=0.00017819515267429795,
              reg_lambda=1.3235400440085592e-07)
2025-03-20 19:23:31,414:INFO:create_model() successfully completed......................................
2025-03-20 19:23:31,482:INFO:SubProcess create_model() end ==================================
2025-03-20 19:23:31,482:INFO:choose_better activated
2025-03-20 19:23:31,485:INFO:SubProcess create_model() called ==================================
2025-03-20 19:23:31,485:INFO:Initializing create_model()
2025-03-20 19:23:31,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:23:31,485:INFO:Checking exceptions
2025-03-20 19:23:31,486:INFO:Importing libraries
2025-03-20 19:23:31,487:INFO:Copying training dataset
2025-03-20 19:23:31,489:INFO:Defining folds
2025-03-20 19:23:31,489:INFO:Declaring metric variables
2025-03-20 19:23:31,490:INFO:Importing untrained model
2025-03-20 19:23:31,490:INFO:Declaring custom model
2025-03-20 19:23:31,490:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:23:31,490:INFO:Starting cross validation
2025-03-20 19:23:31,491:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:23:33,853:INFO:Calculating mean and std
2025-03-20 19:23:33,854:INFO:Creating metrics dataframe
2025-03-20 19:23:33,855:INFO:Finalizing model
2025-03-20 19:23:33,899:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:23:33,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2025-03-20 19:23:33,900:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:23:33,900:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:23:33,900:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:23:33,901:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:23:34,005:INFO:Uploading results into container
2025-03-20 19:23:34,005:INFO:Uploading model into container now
2025-03-20 19:23:34,005:INFO:_master_model_container: 28
2025-03-20 19:23:34,005:INFO:_display_container: 10
2025-03-20 19:23:34,006:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:23:34,006:INFO:create_model() successfully completed......................................
2025-03-20 19:23:34,108:INFO:SubProcess create_model() end ==================================
2025-03-20 19:23:34,108:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0233
2025-03-20 19:23:34,109:INFO:LGBMRegressor(bagging_fraction=0.5203463906975803, bagging_freq=5,
              feature_fraction=0.6023486179502875,
              learning_rate=0.026556667500443686, min_child_samples=12,
              min_split_gain=0.528296219805712, n_estimators=282, n_jobs=-1,
              num_leaves=39, random_state=888, reg_alpha=0.00017819515267429795,
              reg_lambda=1.3235400440085592e-07) result for MAPE is 0.0218
2025-03-20 19:23:34,109:INFO:LGBMRegressor(bagging_fraction=0.5203463906975803, bagging_freq=5,
              feature_fraction=0.6023486179502875,
              learning_rate=0.026556667500443686, min_child_samples=12,
              min_split_gain=0.528296219805712, n_estimators=282, n_jobs=-1,
              num_leaves=39, random_state=888, reg_alpha=0.00017819515267429795,
              reg_lambda=1.3235400440085592e-07) is best model
2025-03-20 19:23:34,109:INFO:choose_better completed
2025-03-20 19:23:34,110:INFO:Creating Dashboard logs
2025-03-20 19:23:34,113:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:23:34,131:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.026556667500443686, 'max_depth': -1, 'min_child_samples': 12, 'min_child_weight': 0.001, 'min_split_gain': 0.528296219805712, 'n_estimators': 282, 'n_jobs': -1, 'num_leaves': 39, 'objective': None, 'random_state': 888, 'reg_alpha': 0.00017819515267429795, 'reg_lambda': 1.3235400440085592e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6023486179502875, 'bagging_fraction': 0.5203463906975803, 'bagging_freq': 5}
2025-03-20 19:23:34,346:INFO:Initializing predict_model()
2025-03-20 19:23:34,346:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=LGBMRegressor(bagging_fraction=0.5203463906975803, bagging_freq=5,
              feature_fraction=0.6023486179502875,
              learning_rate=0.026556667500443686, min_child_samples=12,
              min_split_gain=0.528296219805712, n_estimators=282, n_jobs=-1,
              num_leaves=39, random_state=888, reg_alpha=0.00017819515267429795,
              reg_lambda=1.3235400440085592e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA95997670>)
2025-03-20 19:23:34,346:INFO:Checking exceptions
2025-03-20 19:23:34,346:INFO:Preloading libraries
2025-03-20 19:23:34,506:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.5203463906975803, bagging_freq=5,
              feature_fraction=0.6023486179502875,
              learning_rate=0.026556667500443686, min_child_samples=12,
              min_split_gain=0.528296219805712, n_estimators=282, n_jobs=-1,
              num_leaves=39, random_state=888, reg_alpha=0.00017819515267429795,
              reg_lambda=1.3235400440085592e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:23:34,512:INFO:_master_model_container: 28
2025-03-20 19:23:34,512:INFO:_display_container: 9
2025-03-20 19:23:34,512:INFO:LGBMRegressor(bagging_fraction=0.5203463906975803, bagging_freq=5,
              feature_fraction=0.6023486179502875,
              learning_rate=0.026556667500443686, min_child_samples=12,
              min_split_gain=0.528296219805712, n_estimators=282, n_jobs=-1,
              num_leaves=39, random_state=888, reg_alpha=0.00017819515267429795,
              reg_lambda=1.3235400440085592e-07)
2025-03-20 19:23:34,512:INFO:tune_model() successfully completed......................................
2025-03-20 19:23:34,580:INFO:Initializing predict_model()
2025-03-20 19:23:34,580:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=LGBMRegressor(bagging_fraction=0.5203463906975803, bagging_freq=5,
              feature_fraction=0.6023486179502875,
              learning_rate=0.026556667500443686, min_child_samples=12,
              min_split_gain=0.528296219805712, n_estimators=282, n_jobs=-1,
              num_leaves=39, random_state=888, reg_alpha=0.00017819515267429795,
              reg_lambda=1.3235400440085592e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA01D93550>)
2025-03-20 19:23:34,580:INFO:Checking exceptions
2025-03-20 19:23:34,581:INFO:Preloading libraries
2025-03-20 19:23:34,760:INFO:Initializing tune_model()
2025-03-20 19:23:34,761:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>)
2025-03-20 19:23:34,761:INFO:Checking exceptions
2025-03-20 19:23:34,761:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:23:34,769:INFO:Copying training dataset
2025-03-20 19:23:34,772:INFO:Checking base model
2025-03-20 19:23:34,772:INFO:Base model : Extreme Gradient Boosting
2025-03-20 19:23:34,774:INFO:Declaring metric variables
2025-03-20 19:23:34,776:INFO:Defining Hyperparameters
2025-03-20 19:23:34,836:INFO:Tuning with n_jobs=-1
2025-03-20 19:23:34,836:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:23:34,836:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:23:34,836:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:23:34,836:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:23:34,836:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:23:34,836:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:24:42,792:INFO:best_params: {'actual_estimator__learning_rate': 0.06008921545685394, 'actual_estimator__n_estimators': 105, 'actual_estimator__subsample': 0.7161711166916122, 'actual_estimator__max_depth': 4, 'actual_estimator__colsample_bytree': 0.9942604698622604, 'actual_estimator__min_child_weight': 3, 'actual_estimator__reg_alpha': 0.010878750238145473, 'actual_estimator__reg_lambda': 0.00032561461882170254, 'actual_estimator__scale_pos_weight': 46.98310393973665}
2025-03-20 19:24:42,799:INFO:Hyperparameter search completed
2025-03-20 19:24:42,799:INFO:SubProcess create_model() called ==================================
2025-03-20 19:24:42,800:INFO:Initializing create_model()
2025-03-20 19:24:42,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA946D4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.06008921545685394, 'n_estimators': 105, 'subsample': 0.7161711166916122, 'max_depth': 4, 'colsample_bytree': 0.9942604698622604, 'min_child_weight': 3, 'reg_alpha': 0.010878750238145473, 'reg_lambda': 0.00032561461882170254, 'scale_pos_weight': 46.98310393973665})
2025-03-20 19:24:42,800:INFO:Checking exceptions
2025-03-20 19:24:42,800:INFO:Importing libraries
2025-03-20 19:24:42,800:INFO:Copying training dataset
2025-03-20 19:24:42,804:INFO:Defining folds
2025-03-20 19:24:42,804:INFO:Declaring metric variables
2025-03-20 19:24:42,806:INFO:Importing untrained model
2025-03-20 19:24:42,807:INFO:Declaring custom model
2025-03-20 19:24:42,810:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:24:42,813:INFO:Starting cross validation
2025-03-20 19:24:42,815:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:24:44,971:INFO:Calculating mean and std
2025-03-20 19:24:44,972:INFO:Creating metrics dataframe
2025-03-20 19:24:44,975:INFO:Finalizing model
2025-03-20 19:24:45,097:INFO:Uploading results into container
2025-03-20 19:24:45,097:INFO:Uploading model into container now
2025-03-20 19:24:45,098:INFO:_master_model_container: 29
2025-03-20 19:24:45,098:INFO:_display_container: 11
2025-03-20 19:24:45,099:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9942604698622604, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.06008921545685394, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=105, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:24:45,099:INFO:create_model() successfully completed......................................
2025-03-20 19:24:45,173:INFO:SubProcess create_model() end ==================================
2025-03-20 19:24:45,173:INFO:choose_better activated
2025-03-20 19:24:45,176:INFO:SubProcess create_model() called ==================================
2025-03-20 19:24:45,176:INFO:Initializing create_model()
2025-03-20 19:24:45,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:24:45,176:INFO:Checking exceptions
2025-03-20 19:24:45,178:INFO:Importing libraries
2025-03-20 19:24:45,178:INFO:Copying training dataset
2025-03-20 19:24:45,181:INFO:Defining folds
2025-03-20 19:24:45,181:INFO:Declaring metric variables
2025-03-20 19:24:45,181:INFO:Importing untrained model
2025-03-20 19:24:45,181:INFO:Declaring custom model
2025-03-20 19:24:45,182:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:24:45,182:INFO:Starting cross validation
2025-03-20 19:24:45,183:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:24:45,602:INFO:Calculating mean and std
2025-03-20 19:24:45,602:INFO:Creating metrics dataframe
2025-03-20 19:24:45,603:INFO:Finalizing model
2025-03-20 19:24:45,796:INFO:Uploading results into container
2025-03-20 19:24:45,796:INFO:Uploading model into container now
2025-03-20 19:24:45,796:INFO:_master_model_container: 30
2025-03-20 19:24:45,796:INFO:_display_container: 12
2025-03-20 19:24:45,797:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:24:45,797:INFO:create_model() successfully completed......................................
2025-03-20 19:24:45,859:INFO:SubProcess create_model() end ==================================
2025-03-20 19:24:45,860:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.0235
2025-03-20 19:24:45,860:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9942604698622604, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.06008921545685394, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=105, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.0216
2025-03-20 19:24:45,861:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9942604698622604, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.06008921545685394, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=105, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) is best model
2025-03-20 19:24:45,861:INFO:choose_better completed
2025-03-20 19:24:45,861:INFO:Creating Dashboard logs
2025-03-20 19:24:45,864:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:24:45,892:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.9942604698622604, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.06008921545685394, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 4, 'max_leaves': None, 'min_child_weight': 3, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 105, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': 0.010878750238145473, 'reg_lambda': 0.00032561461882170254, 'sampling_method': None, 'scale_pos_weight': 46.98310393973665, 'subsample': 0.7161711166916122, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:24:46,109:INFO:Initializing predict_model()
2025-03-20 19:24:46,109:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9942604698622604, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.06008921545685394, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=105, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA95A8DD30>)
2025-03-20 19:24:46,109:INFO:Checking exceptions
2025-03-20 19:24:46,109:INFO:Preloading libraries
2025-03-20 19:24:46,261:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9942604698622604, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.06008921545685394, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=105, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:24:46,267:INFO:_master_model_container: 30
2025-03-20 19:24:46,267:INFO:_display_container: 11
2025-03-20 19:24:46,268:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9942604698622604, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.06008921545685394, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=105, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:24:46,268:INFO:tune_model() successfully completed......................................
2025-03-20 19:24:46,334:INFO:Initializing predict_model()
2025-03-20 19:24:46,334:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FA1783E640>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9942604698622604, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.06008921545685394, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=105, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA006F34C0>)
2025-03-20 19:24:46,334:INFO:Checking exceptions
2025-03-20 19:24:46,335:INFO:Preloading libraries
2025-03-20 19:28:54,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:28:54,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:28:54,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:28:54,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:28:55,036:INFO:PyCaret RegressionExperiment
2025-03-20 19:28:55,036:INFO:Logging name: reg-default-name
2025-03-20 19:28:55,036:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 19:28:55,036:INFO:version 3.2.0
2025-03-20 19:28:55,036:INFO:Initializing setup()
2025-03-20 19:28:55,036:INFO:self.USI: 95d3
2025-03-20 19:28:55,036:INFO:self._variable_keys: {'USI', 'pipeline', 'exp_id', 'seed', 'log_plots_param', 'html_param', 'exp_name_log', '_available_plots', 'X_test', 'y_train', 'logging_param', 'fold_shuffle_param', 'fold_generator', 'y_test', 'X', 'gpu_param', 'idx', 'X_train', 'memory', 'y', '_ml_usecase', 'fold_groups_param', 'transform_target_param', 'data', 'n_jobs_param', 'target_param', 'gpu_n_jobs_param'}
2025-03-20 19:28:55,036:INFO:Checking environment
2025-03-20 19:28:55,036:INFO:python_version: 3.8.20
2025-03-20 19:28:55,036:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 19:28:55,036:INFO:machine: AMD64
2025-03-20 19:28:55,036:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 19:28:55,044:INFO:Memory: svmem(total=68447973376, available=41449594880, percent=39.4, used=26998378496, free=41449594880)
2025-03-20 19:28:55,044:INFO:Physical Core: 24
2025-03-20 19:28:55,044:INFO:Logical Core: 32
2025-03-20 19:28:55,044:INFO:Checking libraries
2025-03-20 19:28:55,044:INFO:System:
2025-03-20 19:28:55,044:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 19:28:55,044:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 19:28:55,044:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 19:28:55,044:INFO:PyCaret required dependencies:
2025-03-20 19:28:55,564:INFO:                 pip: 24.2
2025-03-20 19:28:55,564:INFO:          setuptools: 75.1.0
2025-03-20 19:28:55,564:INFO:             pycaret: 3.2.0
2025-03-20 19:28:55,564:INFO:             IPython: 8.12.3
2025-03-20 19:28:55,564:INFO:          ipywidgets: 8.1.5
2025-03-20 19:28:55,564:INFO:                tqdm: 4.67.1
2025-03-20 19:28:55,565:INFO:               numpy: 1.24.4
2025-03-20 19:28:55,565:INFO:              pandas: 1.5.3
2025-03-20 19:28:55,565:INFO:              jinja2: 3.1.4
2025-03-20 19:28:55,565:INFO:               scipy: 1.10.1
2025-03-20 19:28:55,565:INFO:              joblib: 1.3.2
2025-03-20 19:28:55,565:INFO:             sklearn: 1.2.2
2025-03-20 19:28:55,565:INFO:                pyod: 2.0.2
2025-03-20 19:28:55,565:INFO:            imblearn: 0.12.4
2025-03-20 19:28:55,565:INFO:   category_encoders: 2.6.4
2025-03-20 19:28:55,565:INFO:            lightgbm: 4.5.0
2025-03-20 19:28:55,565:INFO:               numba: 0.58.1
2025-03-20 19:28:55,565:INFO:            requests: 2.32.3
2025-03-20 19:28:55,565:INFO:          matplotlib: 3.6.0
2025-03-20 19:28:55,565:INFO:          scikitplot: 0.3.7
2025-03-20 19:28:55,565:INFO:         yellowbrick: 1.5
2025-03-20 19:28:55,565:INFO:              plotly: 5.24.1
2025-03-20 19:28:55,565:INFO:    plotly-resampler: Not installed
2025-03-20 19:28:55,565:INFO:             kaleido: 0.2.1
2025-03-20 19:28:55,565:INFO:           schemdraw: 0.15
2025-03-20 19:28:55,565:INFO:         statsmodels: 0.14.1
2025-03-20 19:28:55,565:INFO:              sktime: 0.21.1
2025-03-20 19:28:55,565:INFO:               tbats: 1.1.3
2025-03-20 19:28:55,565:INFO:            pmdarima: 2.0.4
2025-03-20 19:28:55,565:INFO:              psutil: 6.1.0
2025-03-20 19:28:55,565:INFO:          markupsafe: 2.1.5
2025-03-20 19:28:55,565:INFO:             pickle5: Not installed
2025-03-20 19:28:55,565:INFO:         cloudpickle: 2.2.1
2025-03-20 19:28:55,565:INFO:         deprecation: 2.1.0
2025-03-20 19:28:55,565:INFO:              xxhash: 3.5.0
2025-03-20 19:28:55,565:INFO:           wurlitzer: Not installed
2025-03-20 19:28:55,565:INFO:PyCaret optional dependencies:
2025-03-20 19:28:56,914:INFO:                shap: 0.44.1
2025-03-20 19:28:56,914:INFO:           interpret: 0.6.6
2025-03-20 19:28:56,914:INFO:                umap: 0.5.7
2025-03-20 19:28:56,914:INFO:     ydata_profiling: 4.6.0
2025-03-20 19:28:56,914:INFO:  explainerdashboard: 0.4.7
2025-03-20 19:28:56,915:INFO:             autoviz: Not installed
2025-03-20 19:28:56,915:INFO:           fairlearn: 0.7.0
2025-03-20 19:28:56,915:INFO:          deepchecks: Not installed
2025-03-20 19:28:56,915:INFO:             xgboost: 2.1.3
2025-03-20 19:28:56,915:INFO:            catboost: 1.2.7
2025-03-20 19:28:56,915:INFO:              kmodes: 0.12.2
2025-03-20 19:28:56,915:INFO:             mlxtend: 0.23.1
2025-03-20 19:28:56,915:INFO:       statsforecast: 1.5.0
2025-03-20 19:28:56,915:INFO:        tune_sklearn: 0.5.0
2025-03-20 19:28:56,915:INFO:                 ray: 2.10.0
2025-03-20 19:28:56,915:INFO:            hyperopt: 0.2.7
2025-03-20 19:28:56,915:INFO:              optuna: 4.1.0
2025-03-20 19:28:56,915:INFO:               skopt: 0.10.2
2025-03-20 19:28:56,915:INFO:              mlflow: 1.30.1
2025-03-20 19:28:56,915:INFO:              gradio: 3.50.2
2025-03-20 19:28:56,915:INFO:             fastapi: 0.115.5
2025-03-20 19:28:56,915:INFO:             uvicorn: 0.32.1
2025-03-20 19:28:56,915:INFO:              m2cgen: 0.10.0
2025-03-20 19:28:56,915:INFO:           evidently: 0.2.8
2025-03-20 19:28:56,915:INFO:               fugue: 0.8.6
2025-03-20 19:28:56,915:INFO:           streamlit: Not installed
2025-03-20 19:28:56,915:INFO:             prophet: Not installed
2025-03-20 19:28:56,915:INFO:None
2025-03-20 19:28:56,915:INFO:Set up data.
2025-03-20 19:28:56,920:INFO:Set up folding strategy.
2025-03-20 19:28:56,920:INFO:Set up train/test split.
2025-03-20 19:28:56,920:INFO:Set up data.
2025-03-20 19:28:56,925:INFO:Set up index.
2025-03-20 19:28:56,925:INFO:Assigning column types.
2025-03-20 19:28:56,927:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 19:28:56,927:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:28:56,929:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:28:56,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:28:56,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:56,976:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:56,976:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:56,977:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:56,988:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:28:56,990:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:28:56,992:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,036:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,037:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,037:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 19:28:57,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,041:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,066:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,086:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,087:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,089:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,091:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,116:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,136:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,137:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,137:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 19:28:57,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,185:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,186:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,187:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,216:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,236:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,237:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,237:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 19:28:57,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,286:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,287:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,317:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,337:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,338:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,338:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 19:28:57,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,390:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,391:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,421:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:28:57,440:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,441:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,442:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 19:28:57,493:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,494:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,542:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,543:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,545:INFO:Preparing preprocessing pipeline...
2025-03-20 19:28:57,545:INFO:Set up simple imputation.
2025-03-20 19:28:57,547:INFO:Set up encoding of categorical features.
2025-03-20 19:28:57,547:INFO:Set up feature normalization.
2025-03-20 19:28:57,547:INFO:Set up column name cleaning.
2025-03-20 19:28:57,595:INFO:Finished creating preprocessing pipeline.
2025-03-20 19:28:57,599:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:28:57,599:INFO:Creating final display dataframe.
2025-03-20 19:28:57,725:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              95d3
2025-03-20 19:28:57,780:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,782:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,831:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:28:57,832:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:28:57,833:INFO:Logging experiment in loggers
2025-03-20 19:28:57,978:INFO:SubProcess save_model() called ==================================
2025-03-20 19:28:57,986:INFO:Initializing save_model()
2025-03-20 19:28:57,986:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpasymg7r6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:28:57,986:INFO:Adding model into prep_pipe
2025-03-20 19:28:57,986:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:28:57,990:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpasymg7r6\Transformation Pipeline.pkl saved in current working directory
2025-03-20 19:28:57,994:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:28:57,994:INFO:save_model() successfully completed......................................
2025-03-20 19:28:58,050:INFO:SubProcess save_model() end ==================================
2025-03-20 19:28:58,055:INFO:setup() successfully completed in 2.8s...............
2025-03-20 19:28:58,055:INFO:Initializing compare_models()
2025-03-20 19:28:58,055:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 19:28:58,055:INFO:Checking exceptions
2025-03-20 19:28:58,056:INFO:Preparing display monitor
2025-03-20 19:28:58,068:INFO:Initializing Linear Regression
2025-03-20 19:28:58,068:INFO:Total runtime is 0.0 minutes
2025-03-20 19:28:58,070:INFO:SubProcess create_model() called ==================================
2025-03-20 19:28:58,070:INFO:Initializing create_model()
2025-03-20 19:28:58,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:28:58,071:INFO:Checking exceptions
2025-03-20 19:28:58,071:INFO:Importing libraries
2025-03-20 19:28:58,071:INFO:Copying training dataset
2025-03-20 19:28:58,073:INFO:Defining folds
2025-03-20 19:28:58,073:INFO:Declaring metric variables
2025-03-20 19:28:58,075:INFO:Importing untrained model
2025-03-20 19:28:58,077:INFO:Linear Regression Imported successfully
2025-03-20 19:28:58,080:INFO:Starting cross validation
2025-03-20 19:28:58,083:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:00,618:INFO:Calculating mean and std
2025-03-20 19:29:00,619:INFO:Creating metrics dataframe
2025-03-20 19:29:00,620:INFO:Uploading results into container
2025-03-20 19:29:00,621:INFO:Uploading model into container now
2025-03-20 19:29:00,621:INFO:_master_model_container: 1
2025-03-20 19:29:00,621:INFO:_display_container: 2
2025-03-20 19:29:00,621:INFO:LinearRegression(n_jobs=-1)
2025-03-20 19:29:00,621:INFO:create_model() successfully completed......................................
2025-03-20 19:29:00,677:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:00,677:INFO:Creating metrics dataframe
2025-03-20 19:29:00,681:INFO:Initializing Lasso Regression
2025-03-20 19:29:00,681:INFO:Total runtime is 0.04354936679204305 minutes
2025-03-20 19:29:00,683:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:00,683:INFO:Initializing create_model()
2025-03-20 19:29:00,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:00,683:INFO:Checking exceptions
2025-03-20 19:29:00,683:INFO:Importing libraries
2025-03-20 19:29:00,683:INFO:Copying training dataset
2025-03-20 19:29:00,685:INFO:Defining folds
2025-03-20 19:29:00,685:INFO:Declaring metric variables
2025-03-20 19:29:00,687:INFO:Importing untrained model
2025-03-20 19:29:00,689:INFO:Lasso Regression Imported successfully
2025-03-20 19:29:00,692:INFO:Starting cross validation
2025-03-20 19:29:00,693:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:02,804:INFO:Calculating mean and std
2025-03-20 19:29:02,805:INFO:Creating metrics dataframe
2025-03-20 19:29:02,806:INFO:Uploading results into container
2025-03-20 19:29:02,807:INFO:Uploading model into container now
2025-03-20 19:29:02,807:INFO:_master_model_container: 2
2025-03-20 19:29:02,808:INFO:_display_container: 2
2025-03-20 19:29:02,808:INFO:Lasso(random_state=888)
2025-03-20 19:29:02,808:INFO:create_model() successfully completed......................................
2025-03-20 19:29:02,864:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:02,864:INFO:Creating metrics dataframe
2025-03-20 19:29:02,869:INFO:Initializing Ridge Regression
2025-03-20 19:29:02,869:INFO:Total runtime is 0.08000462849934896 minutes
2025-03-20 19:29:02,870:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:02,870:INFO:Initializing create_model()
2025-03-20 19:29:02,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:02,870:INFO:Checking exceptions
2025-03-20 19:29:02,870:INFO:Importing libraries
2025-03-20 19:29:02,870:INFO:Copying training dataset
2025-03-20 19:29:02,872:INFO:Defining folds
2025-03-20 19:29:02,872:INFO:Declaring metric variables
2025-03-20 19:29:02,874:INFO:Importing untrained model
2025-03-20 19:29:02,875:INFO:Ridge Regression Imported successfully
2025-03-20 19:29:02,878:INFO:Starting cross validation
2025-03-20 19:29:02,879:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:05,144:INFO:Calculating mean and std
2025-03-20 19:29:05,146:INFO:Creating metrics dataframe
2025-03-20 19:29:05,148:INFO:Uploading results into container
2025-03-20 19:29:05,148:INFO:Uploading model into container now
2025-03-20 19:29:05,149:INFO:_master_model_container: 3
2025-03-20 19:29:05,149:INFO:_display_container: 2
2025-03-20 19:29:05,149:INFO:Ridge(random_state=888)
2025-03-20 19:29:05,149:INFO:create_model() successfully completed......................................
2025-03-20 19:29:05,208:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:05,208:INFO:Creating metrics dataframe
2025-03-20 19:29:05,212:INFO:Initializing Elastic Net
2025-03-20 19:29:05,213:INFO:Total runtime is 0.1190756916999817 minutes
2025-03-20 19:29:05,214:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:05,214:INFO:Initializing create_model()
2025-03-20 19:29:05,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:05,215:INFO:Checking exceptions
2025-03-20 19:29:05,215:INFO:Importing libraries
2025-03-20 19:29:05,215:INFO:Copying training dataset
2025-03-20 19:29:05,216:INFO:Defining folds
2025-03-20 19:29:05,217:INFO:Declaring metric variables
2025-03-20 19:29:05,218:INFO:Importing untrained model
2025-03-20 19:29:05,220:INFO:Elastic Net Imported successfully
2025-03-20 19:29:05,223:INFO:Starting cross validation
2025-03-20 19:29:05,224:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:07,393:INFO:Calculating mean and std
2025-03-20 19:29:07,394:INFO:Creating metrics dataframe
2025-03-20 19:29:07,396:INFO:Uploading results into container
2025-03-20 19:29:07,397:INFO:Uploading model into container now
2025-03-20 19:29:07,397:INFO:_master_model_container: 4
2025-03-20 19:29:07,397:INFO:_display_container: 2
2025-03-20 19:29:07,398:INFO:ElasticNet(random_state=888)
2025-03-20 19:29:07,398:INFO:create_model() successfully completed......................................
2025-03-20 19:29:07,450:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:07,450:INFO:Creating metrics dataframe
2025-03-20 19:29:07,455:INFO:Initializing Least Angle Regression
2025-03-20 19:29:07,455:INFO:Total runtime is 0.1564415454864502 minutes
2025-03-20 19:29:07,456:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:07,456:INFO:Initializing create_model()
2025-03-20 19:29:07,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:07,456:INFO:Checking exceptions
2025-03-20 19:29:07,457:INFO:Importing libraries
2025-03-20 19:29:07,457:INFO:Copying training dataset
2025-03-20 19:29:07,458:INFO:Defining folds
2025-03-20 19:29:07,459:INFO:Declaring metric variables
2025-03-20 19:29:07,460:INFO:Importing untrained model
2025-03-20 19:29:07,462:INFO:Least Angle Regression Imported successfully
2025-03-20 19:29:07,465:INFO:Starting cross validation
2025-03-20 19:29:07,466:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:09,678:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.010e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,678:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.349e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,679:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,679:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,680:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,680:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.688e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,681:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.707e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,681:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.503e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,681:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.186e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,682:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,683:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,683:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,685:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.114e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,685:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.912e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,685:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.216e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,685:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.848e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,685:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.737e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:29:09,717:INFO:Calculating mean and std
2025-03-20 19:29:09,718:INFO:Creating metrics dataframe
2025-03-20 19:29:09,721:INFO:Uploading results into container
2025-03-20 19:29:09,722:INFO:Uploading model into container now
2025-03-20 19:29:09,722:INFO:_master_model_container: 5
2025-03-20 19:29:09,722:INFO:_display_container: 2
2025-03-20 19:29:09,723:INFO:Lars(random_state=888)
2025-03-20 19:29:09,723:INFO:create_model() successfully completed......................................
2025-03-20 19:29:09,780:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:09,780:INFO:Creating metrics dataframe
2025-03-20 19:29:09,785:INFO:Initializing Lasso Least Angle Regression
2025-03-20 19:29:09,785:INFO:Total runtime is 0.19527254899342855 minutes
2025-03-20 19:29:09,787:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:09,787:INFO:Initializing create_model()
2025-03-20 19:29:09,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:09,787:INFO:Checking exceptions
2025-03-20 19:29:09,787:INFO:Importing libraries
2025-03-20 19:29:09,787:INFO:Copying training dataset
2025-03-20 19:29:09,789:INFO:Defining folds
2025-03-20 19:29:09,789:INFO:Declaring metric variables
2025-03-20 19:29:09,791:INFO:Importing untrained model
2025-03-20 19:29:09,792:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 19:29:09,796:INFO:Starting cross validation
2025-03-20 19:29:09,797:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:11,842:INFO:Calculating mean and std
2025-03-20 19:29:11,843:INFO:Creating metrics dataframe
2025-03-20 19:29:11,844:INFO:Uploading results into container
2025-03-20 19:29:11,845:INFO:Uploading model into container now
2025-03-20 19:29:11,845:INFO:_master_model_container: 6
2025-03-20 19:29:11,845:INFO:_display_container: 2
2025-03-20 19:29:11,845:INFO:LassoLars(random_state=888)
2025-03-20 19:29:11,845:INFO:create_model() successfully completed......................................
2025-03-20 19:29:11,905:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:11,905:INFO:Creating metrics dataframe
2025-03-20 19:29:11,910:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 19:29:11,910:INFO:Total runtime is 0.23070139090220135 minutes
2025-03-20 19:29:11,912:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:11,912:INFO:Initializing create_model()
2025-03-20 19:29:11,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:11,912:INFO:Checking exceptions
2025-03-20 19:29:11,912:INFO:Importing libraries
2025-03-20 19:29:11,912:INFO:Copying training dataset
2025-03-20 19:29:11,914:INFO:Defining folds
2025-03-20 19:29:11,914:INFO:Declaring metric variables
2025-03-20 19:29:11,916:INFO:Importing untrained model
2025-03-20 19:29:11,918:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 19:29:11,922:INFO:Starting cross validation
2025-03-20 19:29:11,923:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:13,797:INFO:Calculating mean and std
2025-03-20 19:29:13,798:INFO:Creating metrics dataframe
2025-03-20 19:29:13,800:INFO:Uploading results into container
2025-03-20 19:29:13,800:INFO:Uploading model into container now
2025-03-20 19:29:13,800:INFO:_master_model_container: 7
2025-03-20 19:29:13,800:INFO:_display_container: 2
2025-03-20 19:29:13,801:INFO:OrthogonalMatchingPursuit()
2025-03-20 19:29:13,801:INFO:create_model() successfully completed......................................
2025-03-20 19:29:13,859:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:13,859:INFO:Creating metrics dataframe
2025-03-20 19:29:13,864:INFO:Initializing Bayesian Ridge
2025-03-20 19:29:13,864:INFO:Total runtime is 0.26326614220937095 minutes
2025-03-20 19:29:13,866:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:13,866:INFO:Initializing create_model()
2025-03-20 19:29:13,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:13,866:INFO:Checking exceptions
2025-03-20 19:29:13,866:INFO:Importing libraries
2025-03-20 19:29:13,866:INFO:Copying training dataset
2025-03-20 19:29:13,868:INFO:Defining folds
2025-03-20 19:29:13,868:INFO:Declaring metric variables
2025-03-20 19:29:13,870:INFO:Importing untrained model
2025-03-20 19:29:13,871:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:29:13,875:INFO:Starting cross validation
2025-03-20 19:29:13,876:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:13,951:INFO:Calculating mean and std
2025-03-20 19:29:13,952:INFO:Creating metrics dataframe
2025-03-20 19:29:13,954:INFO:Uploading results into container
2025-03-20 19:29:13,954:INFO:Uploading model into container now
2025-03-20 19:29:13,954:INFO:_master_model_container: 8
2025-03-20 19:29:13,954:INFO:_display_container: 2
2025-03-20 19:29:13,955:INFO:BayesianRidge()
2025-03-20 19:29:13,955:INFO:create_model() successfully completed......................................
2025-03-20 19:29:14,005:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:14,005:INFO:Creating metrics dataframe
2025-03-20 19:29:14,010:INFO:Initializing Passive Aggressive Regressor
2025-03-20 19:29:14,010:INFO:Total runtime is 0.2656915108362834 minutes
2025-03-20 19:29:14,012:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:14,012:INFO:Initializing create_model()
2025-03-20 19:29:14,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:14,012:INFO:Checking exceptions
2025-03-20 19:29:14,012:INFO:Importing libraries
2025-03-20 19:29:14,012:INFO:Copying training dataset
2025-03-20 19:29:14,014:INFO:Defining folds
2025-03-20 19:29:14,014:INFO:Declaring metric variables
2025-03-20 19:29:14,016:INFO:Importing untrained model
2025-03-20 19:29:14,018:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 19:29:14,022:INFO:Starting cross validation
2025-03-20 19:29:14,023:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:14,105:INFO:Calculating mean and std
2025-03-20 19:29:14,106:INFO:Creating metrics dataframe
2025-03-20 19:29:14,108:INFO:Uploading results into container
2025-03-20 19:29:14,108:INFO:Uploading model into container now
2025-03-20 19:29:14,108:INFO:_master_model_container: 9
2025-03-20 19:29:14,108:INFO:_display_container: 2
2025-03-20 19:29:14,108:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 19:29:14,108:INFO:create_model() successfully completed......................................
2025-03-20 19:29:14,160:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:14,160:INFO:Creating metrics dataframe
2025-03-20 19:29:14,166:INFO:Initializing Huber Regressor
2025-03-20 19:29:14,166:INFO:Total runtime is 0.2682907263437907 minutes
2025-03-20 19:29:14,168:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:14,168:INFO:Initializing create_model()
2025-03-20 19:29:14,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:14,168:INFO:Checking exceptions
2025-03-20 19:29:14,168:INFO:Importing libraries
2025-03-20 19:29:14,168:INFO:Copying training dataset
2025-03-20 19:29:14,170:INFO:Defining folds
2025-03-20 19:29:14,170:INFO:Declaring metric variables
2025-03-20 19:29:14,171:INFO:Importing untrained model
2025-03-20 19:29:14,173:INFO:Huber Regressor Imported successfully
2025-03-20 19:29:14,176:INFO:Starting cross validation
2025-03-20 19:29:14,177:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:14,216:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:29:14,220:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:29:14,223:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:29:14,239:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:29:14,246:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:29:14,274:INFO:Calculating mean and std
2025-03-20 19:29:14,275:INFO:Creating metrics dataframe
2025-03-20 19:29:14,277:INFO:Uploading results into container
2025-03-20 19:29:14,277:INFO:Uploading model into container now
2025-03-20 19:29:14,278:INFO:_master_model_container: 10
2025-03-20 19:29:14,278:INFO:_display_container: 2
2025-03-20 19:29:14,278:INFO:HuberRegressor()
2025-03-20 19:29:14,278:INFO:create_model() successfully completed......................................
2025-03-20 19:29:14,332:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:14,332:INFO:Creating metrics dataframe
2025-03-20 19:29:14,337:INFO:Initializing K Neighbors Regressor
2025-03-20 19:29:14,337:INFO:Total runtime is 0.271146555741628 minutes
2025-03-20 19:29:14,339:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:14,339:INFO:Initializing create_model()
2025-03-20 19:29:14,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:14,339:INFO:Checking exceptions
2025-03-20 19:29:14,339:INFO:Importing libraries
2025-03-20 19:29:14,340:INFO:Copying training dataset
2025-03-20 19:29:14,341:INFO:Defining folds
2025-03-20 19:29:14,341:INFO:Declaring metric variables
2025-03-20 19:29:14,343:INFO:Importing untrained model
2025-03-20 19:29:14,344:INFO:K Neighbors Regressor Imported successfully
2025-03-20 19:29:14,347:INFO:Starting cross validation
2025-03-20 19:29:14,348:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:14,459:INFO:Calculating mean and std
2025-03-20 19:29:14,460:INFO:Creating metrics dataframe
2025-03-20 19:29:14,462:INFO:Uploading results into container
2025-03-20 19:29:14,462:INFO:Uploading model into container now
2025-03-20 19:29:14,463:INFO:_master_model_container: 11
2025-03-20 19:29:14,463:INFO:_display_container: 2
2025-03-20 19:29:14,463:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 19:29:14,463:INFO:create_model() successfully completed......................................
2025-03-20 19:29:14,518:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:14,518:INFO:Creating metrics dataframe
2025-03-20 19:29:14,524:INFO:Initializing Decision Tree Regressor
2025-03-20 19:29:14,524:INFO:Total runtime is 0.2742590030034383 minutes
2025-03-20 19:29:14,526:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:14,526:INFO:Initializing create_model()
2025-03-20 19:29:14,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:14,526:INFO:Checking exceptions
2025-03-20 19:29:14,526:INFO:Importing libraries
2025-03-20 19:29:14,526:INFO:Copying training dataset
2025-03-20 19:29:14,528:INFO:Defining folds
2025-03-20 19:29:14,528:INFO:Declaring metric variables
2025-03-20 19:29:14,529:INFO:Importing untrained model
2025-03-20 19:29:14,531:INFO:Decision Tree Regressor Imported successfully
2025-03-20 19:29:14,534:INFO:Starting cross validation
2025-03-20 19:29:14,535:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:14,613:INFO:Calculating mean and std
2025-03-20 19:29:14,614:INFO:Creating metrics dataframe
2025-03-20 19:29:14,616:INFO:Uploading results into container
2025-03-20 19:29:14,616:INFO:Uploading model into container now
2025-03-20 19:29:14,616:INFO:_master_model_container: 12
2025-03-20 19:29:14,616:INFO:_display_container: 2
2025-03-20 19:29:14,616:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 19:29:14,616:INFO:create_model() successfully completed......................................
2025-03-20 19:29:14,671:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:14,671:INFO:Creating metrics dataframe
2025-03-20 19:29:14,677:INFO:Initializing Random Forest Regressor
2025-03-20 19:29:14,677:INFO:Total runtime is 0.2768168290456136 minutes
2025-03-20 19:29:14,679:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:14,680:INFO:Initializing create_model()
2025-03-20 19:29:14,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:14,680:INFO:Checking exceptions
2025-03-20 19:29:14,680:INFO:Importing libraries
2025-03-20 19:29:14,680:INFO:Copying training dataset
2025-03-20 19:29:14,681:INFO:Defining folds
2025-03-20 19:29:14,682:INFO:Declaring metric variables
2025-03-20 19:29:14,683:INFO:Importing untrained model
2025-03-20 19:29:14,685:INFO:Random Forest Regressor Imported successfully
2025-03-20 19:29:14,688:INFO:Starting cross validation
2025-03-20 19:29:14,688:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:15,044:INFO:Calculating mean and std
2025-03-20 19:29:15,045:INFO:Creating metrics dataframe
2025-03-20 19:29:15,047:INFO:Uploading results into container
2025-03-20 19:29:15,047:INFO:Uploading model into container now
2025-03-20 19:29:15,047:INFO:_master_model_container: 13
2025-03-20 19:29:15,047:INFO:_display_container: 2
2025-03-20 19:29:15,048:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:29:15,048:INFO:create_model() successfully completed......................................
2025-03-20 19:29:15,098:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:15,098:INFO:Creating metrics dataframe
2025-03-20 19:29:15,104:INFO:Initializing Extra Trees Regressor
2025-03-20 19:29:15,104:INFO:Total runtime is 0.2839357097943624 minutes
2025-03-20 19:29:15,106:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:15,106:INFO:Initializing create_model()
2025-03-20 19:29:15,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:15,106:INFO:Checking exceptions
2025-03-20 19:29:15,106:INFO:Importing libraries
2025-03-20 19:29:15,107:INFO:Copying training dataset
2025-03-20 19:29:15,109:INFO:Defining folds
2025-03-20 19:29:15,109:INFO:Declaring metric variables
2025-03-20 19:29:15,111:INFO:Importing untrained model
2025-03-20 19:29:15,113:INFO:Extra Trees Regressor Imported successfully
2025-03-20 19:29:15,116:INFO:Starting cross validation
2025-03-20 19:29:15,117:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:15,321:INFO:Calculating mean and std
2025-03-20 19:29:15,322:INFO:Creating metrics dataframe
2025-03-20 19:29:15,325:INFO:Uploading results into container
2025-03-20 19:29:15,326:INFO:Uploading model into container now
2025-03-20 19:29:15,326:INFO:_master_model_container: 14
2025-03-20 19:29:15,326:INFO:_display_container: 2
2025-03-20 19:29:15,326:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:29:15,326:INFO:create_model() successfully completed......................................
2025-03-20 19:29:15,382:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:15,382:INFO:Creating metrics dataframe
2025-03-20 19:29:15,389:INFO:Initializing AdaBoost Regressor
2025-03-20 19:29:15,389:INFO:Total runtime is 0.28867887655893965 minutes
2025-03-20 19:29:15,391:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:15,391:INFO:Initializing create_model()
2025-03-20 19:29:15,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:15,391:INFO:Checking exceptions
2025-03-20 19:29:15,392:INFO:Importing libraries
2025-03-20 19:29:15,392:INFO:Copying training dataset
2025-03-20 19:29:15,394:INFO:Defining folds
2025-03-20 19:29:15,394:INFO:Declaring metric variables
2025-03-20 19:29:15,395:INFO:Importing untrained model
2025-03-20 19:29:15,397:INFO:AdaBoost Regressor Imported successfully
2025-03-20 19:29:15,402:INFO:Starting cross validation
2025-03-20 19:29:15,403:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:15,599:INFO:Calculating mean and std
2025-03-20 19:29:15,600:INFO:Creating metrics dataframe
2025-03-20 19:29:15,601:INFO:Uploading results into container
2025-03-20 19:29:15,601:INFO:Uploading model into container now
2025-03-20 19:29:15,602:INFO:_master_model_container: 15
2025-03-20 19:29:15,602:INFO:_display_container: 2
2025-03-20 19:29:15,602:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 19:29:15,602:INFO:create_model() successfully completed......................................
2025-03-20 19:29:15,655:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:15,655:INFO:Creating metrics dataframe
2025-03-20 19:29:15,662:INFO:Initializing Gradient Boosting Regressor
2025-03-20 19:29:15,662:INFO:Total runtime is 0.29322336912155156 minutes
2025-03-20 19:29:15,664:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:15,664:INFO:Initializing create_model()
2025-03-20 19:29:15,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:15,664:INFO:Checking exceptions
2025-03-20 19:29:15,664:INFO:Importing libraries
2025-03-20 19:29:15,664:INFO:Copying training dataset
2025-03-20 19:29:15,666:INFO:Defining folds
2025-03-20 19:29:15,666:INFO:Declaring metric variables
2025-03-20 19:29:15,668:INFO:Importing untrained model
2025-03-20 19:29:15,669:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:29:15,673:INFO:Starting cross validation
2025-03-20 19:29:15,674:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:16,291:INFO:Calculating mean and std
2025-03-20 19:29:16,292:INFO:Creating metrics dataframe
2025-03-20 19:29:16,294:INFO:Uploading results into container
2025-03-20 19:29:16,294:INFO:Uploading model into container now
2025-03-20 19:29:16,294:INFO:_master_model_container: 16
2025-03-20 19:29:16,294:INFO:_display_container: 2
2025-03-20 19:29:16,295:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:29:16,295:INFO:create_model() successfully completed......................................
2025-03-20 19:29:16,349:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:16,349:INFO:Creating metrics dataframe
2025-03-20 19:29:16,355:INFO:Initializing Extreme Gradient Boosting
2025-03-20 19:29:16,355:INFO:Total runtime is 0.3047796487808228 minutes
2025-03-20 19:29:16,357:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:16,357:INFO:Initializing create_model()
2025-03-20 19:29:16,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:16,357:INFO:Checking exceptions
2025-03-20 19:29:16,357:INFO:Importing libraries
2025-03-20 19:29:16,357:INFO:Copying training dataset
2025-03-20 19:29:16,359:INFO:Defining folds
2025-03-20 19:29:16,359:INFO:Declaring metric variables
2025-03-20 19:29:16,360:INFO:Importing untrained model
2025-03-20 19:29:16,362:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:29:16,365:INFO:Starting cross validation
2025-03-20 19:29:16,366:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:16,846:INFO:Calculating mean and std
2025-03-20 19:29:16,847:INFO:Creating metrics dataframe
2025-03-20 19:29:16,849:INFO:Uploading results into container
2025-03-20 19:29:16,849:INFO:Uploading model into container now
2025-03-20 19:29:16,850:INFO:_master_model_container: 17
2025-03-20 19:29:16,850:INFO:_display_container: 2
2025-03-20 19:29:16,851:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:29:16,851:INFO:create_model() successfully completed......................................
2025-03-20 19:29:16,907:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:16,907:INFO:Creating metrics dataframe
2025-03-20 19:29:16,914:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 19:29:16,914:INFO:Total runtime is 0.31409472227096563 minutes
2025-03-20 19:29:16,915:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:16,916:INFO:Initializing create_model()
2025-03-20 19:29:16,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:16,916:INFO:Checking exceptions
2025-03-20 19:29:16,916:INFO:Importing libraries
2025-03-20 19:29:16,916:INFO:Copying training dataset
2025-03-20 19:29:16,918:INFO:Defining folds
2025-03-20 19:29:16,918:INFO:Declaring metric variables
2025-03-20 19:29:16,919:INFO:Importing untrained model
2025-03-20 19:29:16,921:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:29:16,924:INFO:Starting cross validation
2025-03-20 19:29:16,925:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:17,385:INFO:Calculating mean and std
2025-03-20 19:29:17,386:INFO:Creating metrics dataframe
2025-03-20 19:29:17,388:INFO:Uploading results into container
2025-03-20 19:29:17,388:INFO:Uploading model into container now
2025-03-20 19:29:17,389:INFO:_master_model_container: 18
2025-03-20 19:29:17,389:INFO:_display_container: 2
2025-03-20 19:29:17,389:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:29:17,389:INFO:create_model() successfully completed......................................
2025-03-20 19:29:17,450:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:17,450:INFO:Creating metrics dataframe
2025-03-20 19:29:17,459:INFO:Initializing CatBoost Regressor
2025-03-20 19:29:17,459:INFO:Total runtime is 0.3231754342714946 minutes
2025-03-20 19:29:17,461:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:17,461:INFO:Initializing create_model()
2025-03-20 19:29:17,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:17,461:INFO:Checking exceptions
2025-03-20 19:29:17,461:INFO:Importing libraries
2025-03-20 19:29:17,462:INFO:Copying training dataset
2025-03-20 19:29:17,464:INFO:Defining folds
2025-03-20 19:29:17,464:INFO:Declaring metric variables
2025-03-20 19:29:17,466:INFO:Importing untrained model
2025-03-20 19:29:17,468:INFO:CatBoost Regressor Imported successfully
2025-03-20 19:29:17,473:INFO:Starting cross validation
2025-03-20 19:29:17,474:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:20,033:INFO:Calculating mean and std
2025-03-20 19:29:20,034:INFO:Creating metrics dataframe
2025-03-20 19:29:20,036:INFO:Uploading results into container
2025-03-20 19:29:20,036:INFO:Uploading model into container now
2025-03-20 19:29:20,036:INFO:_master_model_container: 19
2025-03-20 19:29:20,036:INFO:_display_container: 2
2025-03-20 19:29:20,036:INFO:<catboost.core.CatBoostRegressor object at 0x000001DD6A2FB1C0>
2025-03-20 19:29:20,036:INFO:create_model() successfully completed......................................
2025-03-20 19:29:20,090:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:20,090:INFO:Creating metrics dataframe
2025-03-20 19:29:20,097:INFO:Initializing Dummy Regressor
2025-03-20 19:29:20,097:INFO:Total runtime is 0.3671386599540711 minutes
2025-03-20 19:29:20,098:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:20,098:INFO:Initializing create_model()
2025-03-20 19:29:20,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD691BE9A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:20,099:INFO:Checking exceptions
2025-03-20 19:29:20,099:INFO:Importing libraries
2025-03-20 19:29:20,099:INFO:Copying training dataset
2025-03-20 19:29:20,101:INFO:Defining folds
2025-03-20 19:29:20,101:INFO:Declaring metric variables
2025-03-20 19:29:20,102:INFO:Importing untrained model
2025-03-20 19:29:20,104:INFO:Dummy Regressor Imported successfully
2025-03-20 19:29:20,107:INFO:Starting cross validation
2025-03-20 19:29:20,108:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:20,172:INFO:Calculating mean and std
2025-03-20 19:29:20,173:INFO:Creating metrics dataframe
2025-03-20 19:29:20,175:INFO:Uploading results into container
2025-03-20 19:29:20,175:INFO:Uploading model into container now
2025-03-20 19:29:20,176:INFO:_master_model_container: 20
2025-03-20 19:29:20,176:INFO:_display_container: 2
2025-03-20 19:29:20,176:INFO:DummyRegressor()
2025-03-20 19:29:20,176:INFO:create_model() successfully completed......................................
2025-03-20 19:29:20,230:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:20,230:INFO:Creating metrics dataframe
2025-03-20 19:29:20,242:INFO:Initializing create_model()
2025-03-20 19:29:20,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:20,242:INFO:Checking exceptions
2025-03-20 19:29:20,243:INFO:Importing libraries
2025-03-20 19:29:20,243:INFO:Copying training dataset
2025-03-20 19:29:20,245:INFO:Defining folds
2025-03-20 19:29:20,245:INFO:Declaring metric variables
2025-03-20 19:29:20,245:INFO:Importing untrained model
2025-03-20 19:29:20,245:INFO:Declaring custom model
2025-03-20 19:29:20,245:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:29:20,246:INFO:Cross validation set to False
2025-03-20 19:29:20,246:INFO:Fitting Model
2025-03-20 19:29:20,286:INFO:BayesianRidge()
2025-03-20 19:29:20,286:INFO:create_model() successfully completed......................................
2025-03-20 19:29:20,337:INFO:Creating Dashboard logs
2025-03-20 19:29:20,339:INFO:Model: Bayesian Ridge
2025-03-20 19:29:20,358:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:29:20,395:INFO:Initializing predict_model()
2025-03-20 19:29:20,395:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A2D5310>)
2025-03-20 19:29:20,395:INFO:Checking exceptions
2025-03-20 19:29:20,395:INFO:Preloading libraries
2025-03-20 19:29:20,521:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 19:29:20,536:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:20,539:INFO:Initializing create_model()
2025-03-20 19:29:20,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:20,539:INFO:Checking exceptions
2025-03-20 19:29:20,540:INFO:Importing libraries
2025-03-20 19:29:20,540:INFO:Copying training dataset
2025-03-20 19:29:20,542:INFO:Defining folds
2025-03-20 19:29:20,542:INFO:Declaring metric variables
2025-03-20 19:29:20,542:INFO:Importing untrained model
2025-03-20 19:29:20,542:INFO:Declaring custom model
2025-03-20 19:29:20,542:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:29:20,543:INFO:Cross validation set to False
2025-03-20 19:29:20,543:INFO:Fitting Model
2025-03-20 19:29:21,219:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:29:21,219:INFO:create_model() successfully completed......................................
2025-03-20 19:29:21,271:INFO:Creating Dashboard logs
2025-03-20 19:29:21,273:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:29:21,291:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:29:21,340:INFO:Initializing predict_model()
2025-03-20 19:29:21,340:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A8195E0>)
2025-03-20 19:29:21,340:INFO:Checking exceptions
2025-03-20 19:29:21,340:INFO:Preloading libraries
2025-03-20 19:29:21,475:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:21,478:INFO:Initializing create_model()
2025-03-20 19:29:21,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:21,478:INFO:Checking exceptions
2025-03-20 19:29:21,479:INFO:Importing libraries
2025-03-20 19:29:21,479:INFO:Copying training dataset
2025-03-20 19:29:21,481:INFO:Defining folds
2025-03-20 19:29:21,481:INFO:Declaring metric variables
2025-03-20 19:29:21,481:INFO:Importing untrained model
2025-03-20 19:29:21,481:INFO:Declaring custom model
2025-03-20 19:29:21,481:INFO:Ridge Regression Imported successfully
2025-03-20 19:29:21,482:INFO:Cross validation set to False
2025-03-20 19:29:21,482:INFO:Fitting Model
2025-03-20 19:29:21,512:INFO:Ridge(random_state=888)
2025-03-20 19:29:21,512:INFO:create_model() successfully completed......................................
2025-03-20 19:29:21,565:INFO:Creating Dashboard logs
2025-03-20 19:29:21,567:INFO:Model: Ridge Regression
2025-03-20 19:29:21,586:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:29:21,633:INFO:Initializing predict_model()
2025-03-20 19:29:21,633:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A896700>)
2025-03-20 19:29:21,633:INFO:Checking exceptions
2025-03-20 19:29:21,633:INFO:Preloading libraries
2025-03-20 19:29:21,766:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:21,769:INFO:Initializing create_model()
2025-03-20 19:29:21,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:21,769:INFO:Checking exceptions
2025-03-20 19:29:21,770:INFO:Importing libraries
2025-03-20 19:29:21,770:INFO:Copying training dataset
2025-03-20 19:29:21,772:INFO:Defining folds
2025-03-20 19:29:21,772:INFO:Declaring metric variables
2025-03-20 19:29:21,772:INFO:Importing untrained model
2025-03-20 19:29:21,772:INFO:Declaring custom model
2025-03-20 19:29:21,773:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:29:21,773:INFO:Cross validation set to False
2025-03-20 19:29:21,773:INFO:Fitting Model
2025-03-20 19:29:21,807:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:29:21,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.
2025-03-20 19:29:21,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:29:21,808:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:29:21,809:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:29:21,809:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:29:21,883:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:29:21,883:INFO:create_model() successfully completed......................................
2025-03-20 19:29:21,941:INFO:Creating Dashboard logs
2025-03-20 19:29:21,943:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:29:21,967:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:29:22,034:INFO:Initializing predict_model()
2025-03-20 19:29:22,034:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A82D8B0>)
2025-03-20 19:29:22,035:INFO:Checking exceptions
2025-03-20 19:29:22,035:INFO:Preloading libraries
2025-03-20 19:29:22,224:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:22,228:INFO:Initializing create_model()
2025-03-20 19:29:22,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:22,229:INFO:Checking exceptions
2025-03-20 19:29:22,230:INFO:Importing libraries
2025-03-20 19:29:22,230:INFO:Copying training dataset
2025-03-20 19:29:22,232:INFO:Defining folds
2025-03-20 19:29:22,232:INFO:Declaring metric variables
2025-03-20 19:29:22,232:INFO:Importing untrained model
2025-03-20 19:29:22,232:INFO:Declaring custom model
2025-03-20 19:29:22,233:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:29:22,234:INFO:Cross validation set to False
2025-03-20 19:29:22,234:INFO:Fitting Model
2025-03-20 19:29:22,441:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:29:22,441:INFO:create_model() successfully completed......................................
2025-03-20 19:29:22,510:INFO:Creating Dashboard logs
2025-03-20 19:29:22,512:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:29:22,544:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:29:22,627:INFO:Initializing predict_model()
2025-03-20 19:29:22,627:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A84C9D0>)
2025-03-20 19:29:22,627:INFO:Checking exceptions
2025-03-20 19:29:22,627:INFO:Preloading libraries
2025-03-20 19:29:22,818:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:22,819:INFO:Creating Dashboard logs
2025-03-20 19:29:22,821:INFO:Model: Random Forest Regressor
2025-03-20 19:29:22,847:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:29:22,963:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:22,964:INFO:Creating Dashboard logs
2025-03-20 19:29:22,966:INFO:Model: AdaBoost Regressor
2025-03-20 19:29:22,987:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 19:29:23,096:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:23,097:INFO:Creating Dashboard logs
2025-03-20 19:29:23,099:INFO:Model: CatBoost Regressor
2025-03-20 19:29:23,120:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 19:29:23,120:INFO:Logged params: {}
2025-03-20 19:29:23,213:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x000001DD6A2FB1C0> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:23,214:INFO:Creating Dashboard logs
2025-03-20 19:29:23,216:INFO:Model: Extra Trees Regressor
2025-03-20 19:29:23,235:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:29:23,358:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:23,359:INFO:Creating Dashboard logs
2025-03-20 19:29:23,360:INFO:Model: Decision Tree Regressor
2025-03-20 19:29:23,381:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 19:29:23,496:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:23,497:INFO:Creating Dashboard logs
2025-03-20 19:29:23,499:INFO:Model: Passive Aggressive Regressor
2025-03-20 19:29:23,518:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:29:23,640:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:23,641:INFO:Creating Dashboard logs
2025-03-20 19:29:23,642:INFO:Model: Huber Regressor
2025-03-20 19:29:23,661:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 19:29:23,796:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:23,797:INFO:Creating Dashboard logs
2025-03-20 19:29:23,798:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 19:29:23,819:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 19:29:23,958:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:23,959:INFO:Creating Dashboard logs
2025-03-20 19:29:23,961:INFO:Model: K Neighbors Regressor
2025-03-20 19:29:23,982:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 19:29:24,125:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:24,126:INFO:Creating Dashboard logs
2025-03-20 19:29:24,128:INFO:Model: Elastic Net
2025-03-20 19:29:24,148:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:29:24,292:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:24,292:INFO:Creating Dashboard logs
2025-03-20 19:29:24,294:INFO:Model: Lasso Regression
2025-03-20 19:29:24,315:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:29:24,468:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:24,469:INFO:Creating Dashboard logs
2025-03-20 19:29:24,471:INFO:Model: Lasso Least Angle Regression
2025-03-20 19:29:24,491:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:29:24,667:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:24,668:INFO:Creating Dashboard logs
2025-03-20 19:29:24,670:INFO:Model: Dummy Regressor
2025-03-20 19:29:24,690:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 19:29:24,872:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:24,872:INFO:Creating Dashboard logs
2025-03-20 19:29:24,874:INFO:Model: Linear Regression
2025-03-20 19:29:24,893:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 19:29:25,061:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:25,062:INFO:Creating Dashboard logs
2025-03-20 19:29:25,063:INFO:Model: Least Angle Regression
2025-03-20 19:29:25,082:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:29:25,267:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:25,276:INFO:_master_model_container: 20
2025-03-20 19:29:25,276:INFO:_display_container: 2
2025-03-20 19:29:25,277:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)]
2025-03-20 19:29:25,277:INFO:compare_models() successfully completed......................................
2025-03-20 19:29:25,318:INFO:Initializing tune_model()
2025-03-20 19:29:25,318:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>)
2025-03-20 19:29:25,318:INFO:Checking exceptions
2025-03-20 19:29:25,318:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:29:25,361:INFO:Copying training dataset
2025-03-20 19:29:25,363:INFO:Checking base model
2025-03-20 19:29:25,363:INFO:Base model : Bayesian Ridge
2025-03-20 19:29:25,365:INFO:Declaring metric variables
2025-03-20 19:29:25,366:INFO:Defining Hyperparameters
2025-03-20 19:29:25,424:INFO:Tuning with n_jobs=-1
2025-03-20 19:29:25,425:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:29:25,425:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:29:25,425:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:29:25,430:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:29:25,430:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:29:25,431:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:29:51,954:INFO:best_params: {'actual_estimator__alpha_1': 1.566833864581418e-05, 'actual_estimator__alpha_2': 7.41401418324027e-06, 'actual_estimator__lambda_1': 0.8695137088370402, 'actual_estimator__lambda_2': 0.00809086590419075, 'actual_estimator__compute_score': False, 'actual_estimator__fit_intercept': True}
2025-03-20 19:29:51,958:INFO:Hyperparameter search completed
2025-03-20 19:29:51,959:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:51,959:INFO:Initializing create_model()
2025-03-20 19:29:51,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD6A90F340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 1.566833864581418e-05, 'alpha_2': 7.41401418324027e-06, 'lambda_1': 0.8695137088370402, 'lambda_2': 0.00809086590419075, 'compute_score': False, 'fit_intercept': True})
2025-03-20 19:29:51,959:INFO:Checking exceptions
2025-03-20 19:29:51,959:INFO:Importing libraries
2025-03-20 19:29:51,959:INFO:Copying training dataset
2025-03-20 19:29:51,962:INFO:Defining folds
2025-03-20 19:29:51,962:INFO:Declaring metric variables
2025-03-20 19:29:51,964:INFO:Importing untrained model
2025-03-20 19:29:51,964:INFO:Declaring custom model
2025-03-20 19:29:51,966:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:29:51,973:INFO:Starting cross validation
2025-03-20 19:29:51,974:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:52,043:INFO:Calculating mean and std
2025-03-20 19:29:52,043:INFO:Creating metrics dataframe
2025-03-20 19:29:52,046:INFO:Finalizing model
2025-03-20 19:29:52,086:INFO:Uploading results into container
2025-03-20 19:29:52,087:INFO:Uploading model into container now
2025-03-20 19:29:52,087:INFO:_master_model_container: 21
2025-03-20 19:29:52,087:INFO:_display_container: 3
2025-03-20 19:29:52,088:INFO:BayesianRidge(alpha_1=1.566833864581418e-05, alpha_2=7.41401418324027e-06,
              lambda_1=0.8695137088370402, lambda_2=0.00809086590419075)
2025-03-20 19:29:52,088:INFO:create_model() successfully completed......................................
2025-03-20 19:29:52,142:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:52,142:INFO:choose_better activated
2025-03-20 19:29:52,145:INFO:SubProcess create_model() called ==================================
2025-03-20 19:29:52,145:INFO:Initializing create_model()
2025-03-20 19:29:52,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:29:52,145:INFO:Checking exceptions
2025-03-20 19:29:52,146:INFO:Importing libraries
2025-03-20 19:29:52,146:INFO:Copying training dataset
2025-03-20 19:29:52,148:INFO:Defining folds
2025-03-20 19:29:52,148:INFO:Declaring metric variables
2025-03-20 19:29:52,148:INFO:Importing untrained model
2025-03-20 19:29:52,148:INFO:Declaring custom model
2025-03-20 19:29:52,148:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:29:52,148:INFO:Starting cross validation
2025-03-20 19:29:52,149:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:29:52,212:INFO:Calculating mean and std
2025-03-20 19:29:52,213:INFO:Creating metrics dataframe
2025-03-20 19:29:52,213:INFO:Finalizing model
2025-03-20 19:29:52,248:INFO:Uploading results into container
2025-03-20 19:29:52,249:INFO:Uploading model into container now
2025-03-20 19:29:52,249:INFO:_master_model_container: 22
2025-03-20 19:29:52,249:INFO:_display_container: 4
2025-03-20 19:29:52,249:INFO:BayesianRidge()
2025-03-20 19:29:52,249:INFO:create_model() successfully completed......................................
2025-03-20 19:29:52,304:INFO:SubProcess create_model() end ==================================
2025-03-20 19:29:52,305:INFO:BayesianRidge() result for MAPE is 0.0211
2025-03-20 19:29:52,305:INFO:BayesianRidge(alpha_1=1.566833864581418e-05, alpha_2=7.41401418324027e-06,
              lambda_1=0.8695137088370402, lambda_2=0.00809086590419075) result for MAPE is 0.0211
2025-03-20 19:29:52,305:INFO:BayesianRidge() is best model
2025-03-20 19:29:52,305:INFO:choose_better completed
2025-03-20 19:29:52,306:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 19:29:52,306:INFO:Creating Dashboard logs
2025-03-20 19:29:52,308:INFO:Model: Bayesian Ridge
2025-03-20 19:29:52,326:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:29:52,505:INFO:Initializing predict_model()
2025-03-20 19:29:52,505:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6EB6A5E0>)
2025-03-20 19:29:52,505:INFO:Checking exceptions
2025-03-20 19:29:52,505:INFO:Preloading libraries
2025-03-20 19:29:52,643:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:29:52,648:INFO:_master_model_container: 22
2025-03-20 19:29:52,648:INFO:_display_container: 3
2025-03-20 19:29:52,648:INFO:BayesianRidge()
2025-03-20 19:29:52,648:INFO:tune_model() successfully completed......................................
2025-03-20 19:29:52,705:INFO:Initializing predict_model()
2025-03-20 19:29:52,705:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD010A2F70>)
2025-03-20 19:29:52,705:INFO:Checking exceptions
2025-03-20 19:29:52,705:INFO:Preloading libraries
2025-03-20 19:29:52,833:INFO:Initializing tune_model()
2025-03-20 19:29:52,833:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>)
2025-03-20 19:29:52,833:INFO:Checking exceptions
2025-03-20 19:29:52,833:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:29:52,841:INFO:Copying training dataset
2025-03-20 19:29:52,842:INFO:Checking base model
2025-03-20 19:29:52,843:INFO:Base model : Gradient Boosting Regressor
2025-03-20 19:29:52,845:INFO:Declaring metric variables
2025-03-20 19:29:52,847:INFO:Defining Hyperparameters
2025-03-20 19:29:52,905:INFO:Tuning with n_jobs=-1
2025-03-20 19:29:52,905:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:29:52,905:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:29:52,905:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:29:52,905:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:29:52,906:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:29:52,906:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:30:50,916:INFO:best_params: {'actual_estimator__n_estimators': 104, 'actual_estimator__learning_rate': 0.06590961269907711, 'actual_estimator__subsample': 0.5133438772875569, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__max_depth': 3, 'actual_estimator__max_features': 0.7202572740441111, 'actual_estimator__min_impurity_decrease': 0.00015133586537456308}
2025-03-20 19:30:50,921:INFO:Hyperparameter search completed
2025-03-20 19:30:50,921:INFO:SubProcess create_model() called ==================================
2025-03-20 19:30:50,922:INFO:Initializing create_model()
2025-03-20 19:30:50,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD6EA03F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 104, 'learning_rate': 0.06590961269907711, 'subsample': 0.5133438772875569, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 0.7202572740441111, 'min_impurity_decrease': 0.00015133586537456308})
2025-03-20 19:30:50,922:INFO:Checking exceptions
2025-03-20 19:30:50,922:INFO:Importing libraries
2025-03-20 19:30:50,922:INFO:Copying training dataset
2025-03-20 19:30:50,924:INFO:Defining folds
2025-03-20 19:30:50,924:INFO:Declaring metric variables
2025-03-20 19:30:50,926:INFO:Importing untrained model
2025-03-20 19:30:50,926:INFO:Declaring custom model
2025-03-20 19:30:50,928:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:30:50,931:INFO:Starting cross validation
2025-03-20 19:30:50,932:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:30:51,212:INFO:Calculating mean and std
2025-03-20 19:30:51,213:INFO:Creating metrics dataframe
2025-03-20 19:30:51,216:INFO:Finalizing model
2025-03-20 19:30:51,500:INFO:Uploading results into container
2025-03-20 19:30:51,500:INFO:Uploading model into container now
2025-03-20 19:30:51,500:INFO:_master_model_container: 23
2025-03-20 19:30:51,500:INFO:_display_container: 5
2025-03-20 19:30:51,501:INFO:GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569)
2025-03-20 19:30:51,501:INFO:create_model() successfully completed......................................
2025-03-20 19:30:51,555:INFO:SubProcess create_model() end ==================================
2025-03-20 19:30:51,555:INFO:choose_better activated
2025-03-20 19:30:51,557:INFO:SubProcess create_model() called ==================================
2025-03-20 19:30:51,558:INFO:Initializing create_model()
2025-03-20 19:30:51,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:30:51,558:INFO:Checking exceptions
2025-03-20 19:30:51,559:INFO:Importing libraries
2025-03-20 19:30:51,559:INFO:Copying training dataset
2025-03-20 19:30:51,560:INFO:Defining folds
2025-03-20 19:30:51,560:INFO:Declaring metric variables
2025-03-20 19:30:51,561:INFO:Importing untrained model
2025-03-20 19:30:51,561:INFO:Declaring custom model
2025-03-20 19:30:51,561:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:30:51,561:INFO:Starting cross validation
2025-03-20 19:30:51,562:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:30:52,166:INFO:Calculating mean and std
2025-03-20 19:30:52,167:INFO:Creating metrics dataframe
2025-03-20 19:30:52,167:INFO:Finalizing model
2025-03-20 19:30:52,843:INFO:Uploading results into container
2025-03-20 19:30:52,844:INFO:Uploading model into container now
2025-03-20 19:30:52,844:INFO:_master_model_container: 24
2025-03-20 19:30:52,844:INFO:_display_container: 6
2025-03-20 19:30:52,844:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:30:52,844:INFO:create_model() successfully completed......................................
2025-03-20 19:30:52,899:INFO:SubProcess create_model() end ==================================
2025-03-20 19:30:52,900:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.0217
2025-03-20 19:30:52,900:INFO:GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569) result for MAPE is 0.0208
2025-03-20 19:30:52,900:INFO:GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569) is best model
2025-03-20 19:30:52,900:INFO:choose_better completed
2025-03-20 19:30:52,900:INFO:Creating Dashboard logs
2025-03-20 19:30:52,902:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:30:52,922:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.06590961269907711, 'loss': 'squared_error', 'max_depth': 3, 'max_features': 0.7202572740441111, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.00015133586537456308, 'min_samples_leaf': 4, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 104, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.5133438772875569, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:30:53,123:INFO:Initializing predict_model()
2025-03-20 19:30:53,123:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD7E5A6E50>)
2025-03-20 19:30:53,123:INFO:Checking exceptions
2025-03-20 19:30:53,123:INFO:Preloading libraries
2025-03-20 19:30:53,265:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:30:53,270:INFO:_master_model_container: 24
2025-03-20 19:30:53,270:INFO:_display_container: 5
2025-03-20 19:30:53,270:INFO:GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569)
2025-03-20 19:30:53,270:INFO:tune_model() successfully completed......................................
2025-03-20 19:30:53,329:INFO:Initializing predict_model()
2025-03-20 19:30:53,329:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A575550>)
2025-03-20 19:30:53,329:INFO:Checking exceptions
2025-03-20 19:30:53,329:INFO:Preloading libraries
2025-03-20 19:30:53,461:INFO:Initializing tune_model()
2025-03-20 19:30:53,461:INFO:tune_model(estimator=Ridge(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>)
2025-03-20 19:30:53,461:INFO:Checking exceptions
2025-03-20 19:30:53,461:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:30:53,470:INFO:Copying training dataset
2025-03-20 19:30:53,473:INFO:Checking base model
2025-03-20 19:30:53,473:INFO:Base model : Ridge Regression
2025-03-20 19:30:53,475:INFO:Declaring metric variables
2025-03-20 19:30:53,477:INFO:Defining Hyperparameters
2025-03-20 19:30:53,534:INFO:Tuning with n_jobs=-1
2025-03-20 19:30:53,534:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:30:53,534:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:30:53,535:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:30:53,535:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:30:53,535:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:30:53,535:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:31:17,719:INFO:best_params: {'actual_estimator__alpha': 0.13169927710971985, 'actual_estimator__fit_intercept': True}
2025-03-20 19:31:17,779:INFO:Hyperparameter search completed
2025-03-20 19:31:17,779:INFO:SubProcess create_model() called ==================================
2025-03-20 19:31:17,779:INFO:Initializing create_model()
2025-03-20 19:31:17,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD9F5DDAC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 0.13169927710971985, 'fit_intercept': True})
2025-03-20 19:31:17,779:INFO:Checking exceptions
2025-03-20 19:31:17,779:INFO:Importing libraries
2025-03-20 19:31:17,779:INFO:Copying training dataset
2025-03-20 19:31:17,781:INFO:Defining folds
2025-03-20 19:31:17,781:INFO:Declaring metric variables
2025-03-20 19:31:17,783:INFO:Importing untrained model
2025-03-20 19:31:17,783:INFO:Declaring custom model
2025-03-20 19:31:17,785:INFO:Ridge Regression Imported successfully
2025-03-20 19:31:17,788:INFO:Starting cross validation
2025-03-20 19:31:17,789:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:31:17,863:INFO:Calculating mean and std
2025-03-20 19:31:17,864:INFO:Creating metrics dataframe
2025-03-20 19:31:17,866:INFO:Finalizing model
2025-03-20 19:31:17,900:INFO:Uploading results into container
2025-03-20 19:31:17,900:INFO:Uploading model into container now
2025-03-20 19:31:17,901:INFO:_master_model_container: 25
2025-03-20 19:31:17,901:INFO:_display_container: 7
2025-03-20 19:31:17,901:INFO:Ridge(alpha=0.13169927710971985, random_state=888)
2025-03-20 19:31:17,901:INFO:create_model() successfully completed......................................
2025-03-20 19:31:17,956:INFO:SubProcess create_model() end ==================================
2025-03-20 19:31:17,956:INFO:choose_better activated
2025-03-20 19:31:17,958:INFO:SubProcess create_model() called ==================================
2025-03-20 19:31:17,958:INFO:Initializing create_model()
2025-03-20 19:31:17,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:31:17,958:INFO:Checking exceptions
2025-03-20 19:31:17,959:INFO:Importing libraries
2025-03-20 19:31:17,959:INFO:Copying training dataset
2025-03-20 19:31:17,961:INFO:Defining folds
2025-03-20 19:31:17,961:INFO:Declaring metric variables
2025-03-20 19:31:17,961:INFO:Importing untrained model
2025-03-20 19:31:17,961:INFO:Declaring custom model
2025-03-20 19:31:17,961:INFO:Ridge Regression Imported successfully
2025-03-20 19:31:17,961:INFO:Starting cross validation
2025-03-20 19:31:17,962:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:31:18,033:INFO:Calculating mean and std
2025-03-20 19:31:18,033:INFO:Creating metrics dataframe
2025-03-20 19:31:18,034:INFO:Finalizing model
2025-03-20 19:31:18,063:INFO:Uploading results into container
2025-03-20 19:31:18,063:INFO:Uploading model into container now
2025-03-20 19:31:18,064:INFO:_master_model_container: 26
2025-03-20 19:31:18,064:INFO:_display_container: 8
2025-03-20 19:31:18,064:INFO:Ridge(random_state=888)
2025-03-20 19:31:18,064:INFO:create_model() successfully completed......................................
2025-03-20 19:31:18,118:INFO:SubProcess create_model() end ==================================
2025-03-20 19:31:18,118:INFO:Ridge(random_state=888) result for MAPE is 0.0222
2025-03-20 19:31:18,118:INFO:Ridge(alpha=0.13169927710971985, random_state=888) result for MAPE is 0.0205
2025-03-20 19:31:18,118:INFO:Ridge(alpha=0.13169927710971985, random_state=888) is best model
2025-03-20 19:31:18,118:INFO:choose_better completed
2025-03-20 19:31:18,118:INFO:Creating Dashboard logs
2025-03-20 19:31:18,120:INFO:Model: Ridge Regression
2025-03-20 19:31:18,140:INFO:Logged params: {'alpha': 0.13169927710971985, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:31:18,332:INFO:Initializing predict_model()
2025-03-20 19:31:18,333:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=Ridge(alpha=0.13169927710971985, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD955B49D0>)
2025-03-20 19:31:18,333:INFO:Checking exceptions
2025-03-20 19:31:18,333:INFO:Preloading libraries
2025-03-20 19:31:18,477:ERROR:_log_model() for Ridge(alpha=0.13169927710971985, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:31:18,482:INFO:_master_model_container: 26
2025-03-20 19:31:18,482:INFO:_display_container: 7
2025-03-20 19:31:18,482:INFO:Ridge(alpha=0.13169927710971985, random_state=888)
2025-03-20 19:31:18,482:INFO:tune_model() successfully completed......................................
2025-03-20 19:31:18,539:INFO:Initializing predict_model()
2025-03-20 19:31:18,539:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=Ridge(alpha=0.13169927710971985, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A575550>)
2025-03-20 19:31:18,539:INFO:Checking exceptions
2025-03-20 19:31:18,539:INFO:Preloading libraries
2025-03-20 19:31:18,671:INFO:Initializing tune_model()
2025-03-20 19:31:18,671:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>)
2025-03-20 19:31:18,672:INFO:Checking exceptions
2025-03-20 19:31:18,672:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:31:18,680:INFO:Copying training dataset
2025-03-20 19:31:18,682:INFO:Checking base model
2025-03-20 19:31:18,682:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 19:31:18,684:INFO:Declaring metric variables
2025-03-20 19:31:18,686:INFO:Defining Hyperparameters
2025-03-20 19:31:18,741:INFO:Tuning with n_jobs=-1
2025-03-20 19:31:18,742:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:31:18,742:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:31:18,742:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:31:18,742:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:31:18,742:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:31:18,743:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:32:04,008:INFO:best_params: {'actual_estimator__num_leaves': 17, 'actual_estimator__learning_rate': 0.1529461355569285, 'actual_estimator__n_estimators': 62, 'actual_estimator__min_split_gain': 0.9404501687571057, 'actual_estimator__reg_alpha': 4.582936528169156e-06, 'actual_estimator__reg_lambda': 5.288031134612004e-07, 'actual_estimator__feature_fraction': 0.5153652354600231, 'actual_estimator__bagging_fraction': 0.7023764860621651, 'actual_estimator__bagging_freq': 6, 'actual_estimator__min_child_samples': 3}
2025-03-20 19:32:04,015:INFO:Hyperparameter search completed
2025-03-20 19:32:04,015:INFO:SubProcess create_model() called ==================================
2025-03-20 19:32:04,015:INFO:Initializing create_model()
2025-03-20 19:32:04,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD68B903D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 17, 'learning_rate': 0.1529461355569285, 'n_estimators': 62, 'min_split_gain': 0.9404501687571057, 'reg_alpha': 4.582936528169156e-06, 'reg_lambda': 5.288031134612004e-07, 'feature_fraction': 0.5153652354600231, 'bagging_fraction': 0.7023764860621651, 'bagging_freq': 6, 'min_child_samples': 3})
2025-03-20 19:32:04,015:INFO:Checking exceptions
2025-03-20 19:32:04,015:INFO:Importing libraries
2025-03-20 19:32:04,016:INFO:Copying training dataset
2025-03-20 19:32:04,019:INFO:Defining folds
2025-03-20 19:32:04,019:INFO:Declaring metric variables
2025-03-20 19:32:04,021:INFO:Importing untrained model
2025-03-20 19:32:04,021:INFO:Declaring custom model
2025-03-20 19:32:04,024:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:32:04,028:INFO:Starting cross validation
2025-03-20 19:32:04,029:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:32:04,177:INFO:Calculating mean and std
2025-03-20 19:32:04,178:INFO:Creating metrics dataframe
2025-03-20 19:32:04,182:INFO:Finalizing model
2025-03-20 19:32:04,232:INFO:[LightGBM] [Warning] feature_fraction is set=0.5153652354600231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5153652354600231
2025-03-20 19:32:04,233:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7023764860621651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7023764860621651
2025-03-20 19:32:04,233:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 19:32:04,235:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:32:04,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.5153652354600231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5153652354600231
2025-03-20 19:32:04,235:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7023764860621651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7023764860621651
2025-03-20 19:32:04,235:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 19:32:04,236:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000669 seconds.
2025-03-20 19:32:04,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:32:04,237:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:32:04,237:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:32:04,237:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:32:04,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:32:04,272:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 19:32:04,278:INFO:Uploading results into container
2025-03-20 19:32:04,278:INFO:Uploading model into container now
2025-03-20 19:32:04,279:INFO:_master_model_container: 27
2025-03-20 19:32:04,279:INFO:_display_container: 9
2025-03-20 19:32:04,279:INFO:LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07)
2025-03-20 19:32:04,279:INFO:create_model() successfully completed......................................
2025-03-20 19:32:04,349:INFO:SubProcess create_model() end ==================================
2025-03-20 19:32:04,349:INFO:choose_better activated
2025-03-20 19:32:04,353:INFO:SubProcess create_model() called ==================================
2025-03-20 19:32:04,353:INFO:Initializing create_model()
2025-03-20 19:32:04,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:32:04,353:INFO:Checking exceptions
2025-03-20 19:32:04,355:INFO:Importing libraries
2025-03-20 19:32:04,355:INFO:Copying training dataset
2025-03-20 19:32:04,358:INFO:Defining folds
2025-03-20 19:32:04,358:INFO:Declaring metric variables
2025-03-20 19:32:04,359:INFO:Importing untrained model
2025-03-20 19:32:04,359:INFO:Declaring custom model
2025-03-20 19:32:04,359:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:32:04,359:INFO:Starting cross validation
2025-03-20 19:32:04,361:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:32:04,854:INFO:Calculating mean and std
2025-03-20 19:32:04,855:INFO:Creating metrics dataframe
2025-03-20 19:32:04,856:INFO:Finalizing model
2025-03-20 19:32:04,901:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:32:04,902:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
2025-03-20 19:32:04,902:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:32:04,902:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:32:04,903:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:32:04,903:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:32:05,018:INFO:Uploading results into container
2025-03-20 19:32:05,019:INFO:Uploading model into container now
2025-03-20 19:32:05,019:INFO:_master_model_container: 28
2025-03-20 19:32:05,019:INFO:_display_container: 10
2025-03-20 19:32:05,019:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:32:05,019:INFO:create_model() successfully completed......................................
2025-03-20 19:32:05,083:INFO:SubProcess create_model() end ==================================
2025-03-20 19:32:05,084:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0233
2025-03-20 19:32:05,084:INFO:LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07) result for MAPE is 0.0213
2025-03-20 19:32:05,085:INFO:LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07) is best model
2025-03-20 19:32:05,085:INFO:choose_better completed
2025-03-20 19:32:05,085:INFO:Creating Dashboard logs
2025-03-20 19:32:05,087:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:32:05,114:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1529461355569285, 'max_depth': -1, 'min_child_samples': 3, 'min_child_weight': 0.001, 'min_split_gain': 0.9404501687571057, 'n_estimators': 62, 'n_jobs': -1, 'num_leaves': 17, 'objective': None, 'random_state': 888, 'reg_alpha': 4.582936528169156e-06, 'reg_lambda': 5.288031134612004e-07, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5153652354600231, 'bagging_fraction': 0.7023764860621651, 'bagging_freq': 6}
2025-03-20 19:32:05,349:INFO:Initializing predict_model()
2025-03-20 19:32:05,349:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD7E641EE0>)
2025-03-20 19:32:05,349:INFO:Checking exceptions
2025-03-20 19:32:05,349:INFO:Preloading libraries
2025-03-20 19:32:05,542:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:32:05,549:INFO:_master_model_container: 28
2025-03-20 19:32:05,549:INFO:_display_container: 9
2025-03-20 19:32:05,549:INFO:LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07)
2025-03-20 19:32:05,550:INFO:tune_model() successfully completed......................................
2025-03-20 19:32:05,618:INFO:Initializing predict_model()
2025-03-20 19:32:05,618:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6E9D9C10>)
2025-03-20 19:32:05,618:INFO:Checking exceptions
2025-03-20 19:32:05,618:INFO:Preloading libraries
2025-03-20 19:32:05,763:INFO:Initializing tune_model()
2025-03-20 19:32:05,763:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>)
2025-03-20 19:32:05,763:INFO:Checking exceptions
2025-03-20 19:32:05,763:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:32:05,774:INFO:Copying training dataset
2025-03-20 19:32:05,777:INFO:Checking base model
2025-03-20 19:32:05,777:INFO:Base model : Extreme Gradient Boosting
2025-03-20 19:32:05,781:INFO:Declaring metric variables
2025-03-20 19:32:05,783:INFO:Defining Hyperparameters
2025-03-20 19:32:05,843:INFO:Tuning with n_jobs=-1
2025-03-20 19:32:05,844:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:32:05,844:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:32:05,844:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:32:05,844:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:32:05,844:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:32:05,844:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:33:13,384:INFO:best_params: {'actual_estimator__learning_rate': 0.14756656644624855, 'actual_estimator__n_estimators': 60, 'actual_estimator__subsample': 0.77789034349956, 'actual_estimator__max_depth': 4, 'actual_estimator__colsample_bytree': 0.5691299919074995, 'actual_estimator__min_child_weight': 1, 'actual_estimator__reg_alpha': 7.846180507559925e-09, 'actual_estimator__reg_lambda': 7.506181196830966e-09, 'actual_estimator__scale_pos_weight': 7.505151612391351}
2025-03-20 19:33:13,392:INFO:Hyperparameter search completed
2025-03-20 19:33:13,392:INFO:SubProcess create_model() called ==================================
2025-03-20 19:33:13,393:INFO:Initializing create_model()
2025-03-20 19:33:13,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD6A973550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.14756656644624855, 'n_estimators': 60, 'subsample': 0.77789034349956, 'max_depth': 4, 'colsample_bytree': 0.5691299919074995, 'min_child_weight': 1, 'reg_alpha': 7.846180507559925e-09, 'reg_lambda': 7.506181196830966e-09, 'scale_pos_weight': 7.505151612391351})
2025-03-20 19:33:13,393:INFO:Checking exceptions
2025-03-20 19:33:13,393:INFO:Importing libraries
2025-03-20 19:33:13,393:INFO:Copying training dataset
2025-03-20 19:33:13,396:INFO:Defining folds
2025-03-20 19:33:13,397:INFO:Declaring metric variables
2025-03-20 19:33:13,398:INFO:Importing untrained model
2025-03-20 19:33:13,399:INFO:Declaring custom model
2025-03-20 19:33:13,401:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:33:13,406:INFO:Starting cross validation
2025-03-20 19:33:13,407:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:33:13,770:INFO:Calculating mean and std
2025-03-20 19:33:13,770:INFO:Creating metrics dataframe
2025-03-20 19:33:13,774:INFO:Finalizing model
2025-03-20 19:33:13,868:INFO:Uploading results into container
2025-03-20 19:33:13,868:INFO:Uploading model into container now
2025-03-20 19:33:13,869:INFO:_master_model_container: 29
2025-03-20 19:33:13,869:INFO:_display_container: 11
2025-03-20 19:33:13,869:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:33:13,870:INFO:create_model() successfully completed......................................
2025-03-20 19:33:13,937:INFO:SubProcess create_model() end ==================================
2025-03-20 19:33:13,937:INFO:choose_better activated
2025-03-20 19:33:13,940:INFO:SubProcess create_model() called ==================================
2025-03-20 19:33:13,941:INFO:Initializing create_model()
2025-03-20 19:33:13,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:33:13,941:INFO:Checking exceptions
2025-03-20 19:33:13,942:INFO:Importing libraries
2025-03-20 19:33:13,942:INFO:Copying training dataset
2025-03-20 19:33:13,945:INFO:Defining folds
2025-03-20 19:33:13,945:INFO:Declaring metric variables
2025-03-20 19:33:13,945:INFO:Importing untrained model
2025-03-20 19:33:13,945:INFO:Declaring custom model
2025-03-20 19:33:13,946:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:33:13,947:INFO:Starting cross validation
2025-03-20 19:33:13,948:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:33:14,278:INFO:Calculating mean and std
2025-03-20 19:33:14,278:INFO:Creating metrics dataframe
2025-03-20 19:33:14,279:INFO:Finalizing model
2025-03-20 19:33:14,465:INFO:Uploading results into container
2025-03-20 19:33:14,465:INFO:Uploading model into container now
2025-03-20 19:33:14,466:INFO:_master_model_container: 30
2025-03-20 19:33:14,466:INFO:_display_container: 12
2025-03-20 19:33:14,466:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:33:14,466:INFO:create_model() successfully completed......................................
2025-03-20 19:33:14,526:INFO:SubProcess create_model() end ==================================
2025-03-20 19:33:14,527:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.0235
2025-03-20 19:33:14,528:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.0207
2025-03-20 19:33:14,528:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) is best model
2025-03-20 19:33:14,528:INFO:choose_better completed
2025-03-20 19:33:14,528:INFO:Creating Dashboard logs
2025-03-20 19:33:14,531:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:33:14,558:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5691299919074995, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.14756656644624855, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 4, 'max_leaves': None, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 60, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': 7.846180507559925e-09, 'reg_lambda': 7.506181196830966e-09, 'sampling_method': None, 'scale_pos_weight': 7.505151612391351, 'subsample': 0.77789034349956, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:33:14,808:INFO:Initializing predict_model()
2025-03-20 19:33:14,808:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD955B4D30>)
2025-03-20 19:33:14,808:INFO:Checking exceptions
2025-03-20 19:33:14,808:INFO:Preloading libraries
2025-03-20 19:33:14,970:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:33:14,976:INFO:_master_model_container: 30
2025-03-20 19:33:14,976:INFO:_display_container: 11
2025-03-20 19:33:14,977:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:33:14,977:INFO:tune_model() successfully completed......................................
2025-03-20 19:33:15,042:INFO:Initializing predict_model()
2025-03-20 19:33:15,042:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6A575550>)
2025-03-20 19:33:15,042:INFO:Checking exceptions
2025-03-20 19:33:15,042:INFO:Preloading libraries
2025-03-20 19:44:14,609:INFO:Initializing blend_models()
2025-03-20 19:44:14,609:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator_list=[GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569), LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 19:44:14,609:INFO:Checking exceptions
2025-03-20 19:44:14,618:INFO:Importing libraries
2025-03-20 19:44:14,618:INFO:Copying training dataset
2025-03-20 19:44:14,621:INFO:Getting model names
2025-03-20 19:44:14,623:INFO:SubProcess create_model() called ==================================
2025-03-20 19:44:14,628:INFO:Initializing create_model()
2025-03-20 19:44:14,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14756656644624855,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=4,
                                          max_leaves=None, min_child_weight=1,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=60,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD68F4C670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:44:14,628:INFO:Checking exceptions
2025-03-20 19:44:14,628:INFO:Importing libraries
2025-03-20 19:44:14,628:INFO:Copying training dataset
2025-03-20 19:44:14,631:INFO:Defining folds
2025-03-20 19:44:14,631:INFO:Declaring metric variables
2025-03-20 19:44:14,633:INFO:Importing untrained model
2025-03-20 19:44:14,633:INFO:Declaring custom model
2025-03-20 19:44:14,637:INFO:Voting Regressor Imported successfully
2025-03-20 19:44:14,642:INFO:Starting cross validation
2025-03-20 19:44:14,644:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:44:17,809:INFO:Calculating mean and std
2025-03-20 19:44:17,811:INFO:Creating metrics dataframe
2025-03-20 19:44:17,814:INFO:Finalizing model
2025-03-20 19:44:19,124:INFO:Uploading results into container
2025-03-20 19:44:19,124:INFO:Uploading model into container now
2025-03-20 19:44:19,125:INFO:_master_model_container: 31
2025-03-20 19:44:19,125:INFO:_display_container: 13
2025-03-20 19:44:19,132:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14756656644624855,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=4,
                                          max_leaves=None, min_child_weight=1,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=60,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 19:44:19,132:INFO:create_model() successfully completed......................................
2025-03-20 19:44:19,201:INFO:SubProcess create_model() end ==================================
2025-03-20 19:44:19,202:INFO:Creating Dashboard logs
2025-03-20 19:44:19,205:INFO:Model: Voting Regressor
2025-03-20 19:44:19,235:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.06590961269907711, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': 0.7202572740441111, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.00015133586537456308, 'Gradient Boosting Regressor__min_samples_leaf': 4, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 104, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.5133438772875569, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1529461355569285, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 3, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.9404501687571057, 'Light Gradient Boosting Machine__n_estimators': 62, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 17, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 4.582936528169156e-06, 'Light Gradient Boosting Machine__reg_lambda': 5.288031134612004e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.5153652354600231, 'Light Gradient Boosting Machine__bagging_fraction': 0.7023764860621651, 'Light Gradient Boosting Machine__bagging_freq': 6, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': 0.5691299919074995, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': 0.14756656644624855, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': 4, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': 1, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': 60, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': 7.846180507559925e-09, 'Extreme Gradient Boosting__reg_lambda': 7.506181196830966e-09, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': 7.505151612391351, 'Extreme Gradient Boosting__subsample': 0.77789034349956, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0}
2025-03-20 19:44:19,521:INFO:Initializing predict_model()
2025-03-20 19:44:19,521:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14756656644624855,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=4,
                                          max_leaves=None, min_child_weight=1,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=60,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DDA98E0790>)
2025-03-20 19:44:19,521:INFO:Checking exceptions
2025-03-20 19:44:19,522:INFO:Preloading libraries
2025-03-20 19:44:19,708:ERROR:_log_model() for VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14756656644624855,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=4,
                                          max_leaves=None, min_child_weight=1,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=60,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:44:19,714:INFO:_master_model_container: 31
2025-03-20 19:44:19,714:INFO:_display_container: 13
2025-03-20 19:44:19,721:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14756656644624855,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=4,
                                          max_leaves=None, min_child_weight=1,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=60,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 19:44:19,722:INFO:blend_models() successfully completed......................................
2025-03-20 19:44:57,874:INFO:Initializing blend_models()
2025-03-20 19:44:57,874:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator_list=[GradientBoostingRegressor(learning_rate=0.06590961269907711,
                          max_features=0.7202572740441111,
                          min_impurity_decrease=0.00015133586537456308,
                          min_samples_leaf=4, min_samples_split=3,
                          n_estimators=104, random_state=888,
                          subsample=0.5133438772875569), LGBMRegressor(bagging_fraction=0.7023764860621651, bagging_freq=6,
              feature_fraction=0.5153652354600231,
              learning_rate=0.1529461355569285, min_child_samples=3,
              min_split_gain=0.9404501687571057, n_estimators=62, n_jobs=-1,
              num_leaves=17, random_state=888, reg_alpha=4.582936528169156e-06,
              reg_lambda=5.288031134612004e-07), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5691299919074995, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14756656644624855, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=60, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14756656644624855,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=4,
                                          max_leaves=None, min_child_weight=1,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=60,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 19:44:57,874:INFO:Checking exceptions
2025-03-20 19:44:57,888:INFO:Importing libraries
2025-03-20 19:44:57,888:INFO:Copying training dataset
2025-03-20 19:44:57,891:INFO:Getting model names
2025-03-20 19:44:57,894:INFO:SubProcess create_model() called ==================================
2025-03-20 19:44:57,910:INFO:Initializing create_model()
2025-03-20 19:44:57,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                                                       importance_type=None,
                                                                       interaction_constraints=None,
                                                                       learning_rate=0.14756656644624855,
                                                                       max_bin=None,
                                                                       max_cat_threshold=None,
                                                                       max_cat_to_onehot=None,
                                                                       max_delta_step=None,
                                                                       max_depth=4,
                                                                       max_leaves=None,
                                                                       min_child_weight=1,
                                                                       missing=nan,
                                                                       monotone_constraints=None,
                                                                       multi_strategy=None,
                                                                       n_estimators=60,
                                                                       n_jobs=-1,
                                                                       num_parallel_tree=None,
                                                                       random_state=888, ...))],
                                             n_jobs=-1))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DDB48BFE80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:44:57,911:INFO:Checking exceptions
2025-03-20 19:44:57,911:INFO:Importing libraries
2025-03-20 19:44:57,911:INFO:Copying training dataset
2025-03-20 19:44:57,913:INFO:Defining folds
2025-03-20 19:44:57,913:INFO:Declaring metric variables
2025-03-20 19:44:57,915:INFO:Importing untrained model
2025-03-20 19:44:57,916:INFO:Declaring custom model
2025-03-20 19:44:57,920:INFO:Voting Regressor Imported successfully
2025-03-20 19:44:57,924:INFO:Starting cross validation
2025-03-20 19:44:57,925:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:45:00,712:INFO:Calculating mean and std
2025-03-20 19:45:00,713:INFO:Creating metrics dataframe
2025-03-20 19:45:00,716:INFO:Finalizing model
2025-03-20 19:45:02,568:INFO:Uploading results into container
2025-03-20 19:45:02,569:INFO:Uploading model into container now
2025-03-20 19:45:02,569:INFO:_master_model_container: 32
2025-03-20 19:45:02,569:INFO:_display_container: 14
2025-03-20 19:45:02,590:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                                                       importance_type=None,
                                                                       interaction_constraints=None,
                                                                       learning_rate=0.14756656644624855,
                                                                       max_bin=None,
                                                                       max_cat_threshold=None,
                                                                       max_cat_to_onehot=None,
                                                                       max_delta_step=None,
                                                                       max_depth=4,
                                                                       max_leaves=None,
                                                                       min_child_weight=1,
                                                                       missing=nan,
                                                                       monotone_constraints=None,
                                                                       multi_strategy=None,
                                                                       n_estimators=60,
                                                                       n_jobs=-1,
                                                                       num_parallel_tree=None,
                                                                       random_state=888, ...))],
                                             n_jobs=-1))],
                n_jobs=-1)
2025-03-20 19:45:02,590:INFO:create_model() successfully completed......................................
2025-03-20 19:45:02,656:INFO:SubProcess create_model() end ==================================
2025-03-20 19:45:02,656:INFO:Creating Dashboard logs
2025-03-20 19:45:02,659:INFO:Model: Voting Regressor
2025-03-20 19:45:02,692:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.06590961269907711, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': 0.7202572740441111, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.00015133586537456308, 'Gradient Boosting Regressor__min_samples_leaf': 4, 'Gradient Boosting Regressor__min_samples_split': 3, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 104, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.5133438772875569, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1529461355569285, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 3, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.9404501687571057, 'Light Gradient Boosting Machine__n_estimators': 62, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 17, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 4.582936528169156e-06, 'Light Gradient Boosting Machine__reg_lambda': 5.288031134612004e-07, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.5153652354600231, 'Light Gradient Boosting Machine__bagging_fraction': 0.7023764860621651, 'Light Gradient Boosting Machine__bagging_freq': 6, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': 0.5691299919074995, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': 0.14756656644624855, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': 4, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': 1, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': 60, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': 7.846180507559925e-09, 'Extreme Gradient Boosting__reg_lambda': 7.506181196830966e-09, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': 7.505151612391351, 'Extreme Gradient Boosting__subsample': 0.77789034349956, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0, 'Voting Regressor__n_jobs': -1, 'Voting Regressor__verbose': False, 'Voting Regressor__weights': None, 'Voting Regressor__Gradient Boosting Regressor__alpha': 0.9, 'Voting Regressor__Gradient Boosting Regressor__ccp_alpha': 0.0, 'Voting Regressor__Gradient Boosting Regressor__criterion': 'friedman_mse', 'Voting Regressor__Gradient Boosting Regressor__init': None, 'Voting Regressor__Gradient Boosting Regressor__learning_rate': 0.06590961269907711, 'Voting Regressor__Gradient Boosting Regressor__loss': 'squared_error', 'Voting Regressor__Gradient Boosting Regressor__max_depth': 3, 'Voting Regressor__Gradient Boosting Regressor__max_features': 0.7202572740441111, 'Voting Regressor__Gradient Boosting Regressor__max_leaf_nodes': None, 'Voting Regressor__Gradient Boosting Regressor__min_impurity_decrease': 0.00015133586537456308, 'Voting Regressor__Gradient Boosting Regressor__min_samples_leaf': 4, 'Voting Regressor__Gradient Boosting Regressor__min_samples_split': 3, 'Voting Regressor__Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Voting Regressor__Gradient Boosting Regressor__n_estimators': 104, 'Voting Regressor__Gradient Boosting Regressor__n_iter_no_change': None, 'Voting Regressor__Gradient Boosting Regressor__random_state': 888, 'Voting Regressor__Gradient Boosting Regressor__subsample': 0.5133438772875569, 'Voting Regressor__Gradient Boosting Regressor__tol': 0.0001, 'Voting Regressor__Gradient Boosting Regressor__validation_fraction': 0.1, 'Voting Regressor__Gradient Boosting Regressor__verbose': 0, 'Voting Regressor__Gradient Boosting Regressor__warm_start': False, 'Voting Regressor__Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Voting Regressor__Light Gradient Boosting Machine__class_weight': None, 'Voting Regressor__Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Voting Regressor__Light Gradient Boosting Machine__importance_type': 'split', 'Voting Regressor__Light Gradient Boosting Machine__learning_rate': 0.1529461355569285, 'Voting Regressor__Light Gradient Boosting Machine__max_depth': -1, 'Voting Regressor__Light Gradient Boosting Machine__min_child_samples': 3, 'Voting Regressor__Light Gradient Boosting Machine__min_child_weight': 0.001, 'Voting Regressor__Light Gradient Boosting Machine__min_split_gain': 0.9404501687571057, 'Voting Regressor__Light Gradient Boosting Machine__n_estimators': 62, 'Voting Regressor__Light Gradient Boosting Machine__n_jobs': -1, 'Voting Regressor__Light Gradient Boosting Machine__num_leaves': 17, 'Voting Regressor__Light Gradient Boosting Machine__objective': None, 'Voting Regressor__Light Gradient Boosting Machine__random_state': 888, 'Voting Regressor__Light Gradient Boosting Machine__reg_alpha': 4.582936528169156e-06, 'Voting Regressor__Light Gradient Boosting Machine__reg_lambda': 5.288031134612004e-07, 'Voting Regressor__Light Gradient Boosting Machine__subsample': 1.0, 'Voting Regressor__Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Voting Regressor__Light Gradient Boosting Machine__subsample_freq': 0, 'Voting Regressor__Light Gradient Boosting Machine__feature_fraction': 0.5153652354600231, 'Voting Regressor__Light Gradient Boosting Machine__bagging_fraction': 0.7023764860621651, 'Voting Regressor__Light Gradient Boosting Machine__bagging_freq': 6, 'Voting Regressor__Extreme Gradient Boosting__objective': 'reg:squarederror', 'Voting Regressor__Extreme Gradient Boosting__base_score': None, 'Voting Regressor__Extreme Gradient Boosting__booster': 'gbtree', 'Voting Regressor__Extreme Gradient Boosting__callbacks': None, 'Voting Regressor__Extreme Gradient Boosting__colsample_bylevel': None, 'Voting Regressor__Extreme Gradient Boosting__colsample_bynode': None, 'Voting Regressor__Extreme Gradient Boosting__colsample_bytree': 0.5691299919074995, 'Voting Regressor__Extreme Gradient Boosting__device': 'cpu', 'Voting Regressor__Extreme Gradient Boosting__early_stopping_rounds': None, 'Voting Regressor__Extreme Gradient Boosting__enable_categorical': False, 'Voting Regressor__Extreme Gradient Boosting__eval_metric': None, 'Voting Regressor__Extreme Gradient Boosting__feature_types': None, 'Voting Regressor__Extreme Gradient Boosting__gamma': None, 'Voting Regressor__Extreme Gradient Boosting__grow_policy': None, 'Voting Regressor__Extreme Gradient Boosting__importance_type': None, 'Voting Regressor__Extreme Gradient Boosting__interaction_constraints': None, 'Voting Regressor__Extreme Gradient Boosting__learning_rate': 0.14756656644624855, 'Voting Regressor__Extreme Gradient Boosting__max_bin': None, 'Voting Regressor__Extreme Gradient Boosting__max_cat_threshold': None, 'Voting Regressor__Extreme Gradient Boosting__max_cat_to_onehot': None, 'Voting Regressor__Extreme Gradient Boosting__max_delta_step': None, 'Voting Regressor__Extreme Gradient Boosting__max_depth': 4, 'Voting Regressor__Extreme Gradient Boosting__max_leaves': None, 'Voting Regressor__Extreme Gradient Boosting__min_child_weight': 1, 'Voting Regressor__Extreme Gradient Boosting__missing': nan, 'Voting Regressor__Extreme Gradient Boosting__monotone_constraints': None, 'Voting Regressor__Extreme Gradient Boosting__multi_strategy': None, 'Voting Regressor__Extreme Gradient Boosting__n_estimators': 60, 'Voting Regressor__Extreme Gradient Boosting__n_jobs': -1, 'Voting Regressor__Extreme Gradient Boosting__num_parallel_tree': None, 'Voting Regressor__Extreme Gradient Boosting__random_state': 888, 'Voting Regressor__Extreme Gradient Boosting__reg_alpha': 7.846180507559925e-09, 'Voting Regressor__Extreme Gradient Boosting__reg_lambda': 7.506181196830966e-09, 'Voting Regressor__Extreme Gradient Boosting__sampling_method': None, 'Voting Regressor__Extreme Gradient Boosting__scale_pos_weight': 7.505151612391351, 'Voting Regressor__Extreme Gradient Boosting__subsample': 0.77789034349956, 'Voting Regressor__Extreme Gradient Boosting__tree_method': 'auto', 'Voting Regressor__Extreme Gradient Boosting__validate_parameters': None, 'Voting Regressor__Extreme Gradient Boosting__verbosity': 0}
2025-03-20 19:45:03,043:INFO:Initializing predict_model()
2025-03-20 19:45:03,043:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD7FE9CDF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                                                       importance_type=None,
                                                                       interaction_constraints=None,
                                                                       learning_rate=0.14756656644624855,
                                                                       max_bin=None,
                                                                       max_cat_threshold=None,
                                                                       max_cat_to_onehot=None,
                                                                       max_delta_step=None,
                                                                       max_depth=4,
                                                                       max_leaves=None,
                                                                       min_child_weight=1,
                                                                       missing=nan,
                                                                       monotone_constraints=None,
                                                                       multi_strategy=None,
                                                                       n_estimators=60,
                                                                       n_jobs=-1,
                                                                       num_parallel_tree=None,
                                                                       random_state=888, ...))],
                                             n_jobs=-1))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001DD6EAACEE0>)
2025-03-20 19:45:03,043:INFO:Checking exceptions
2025-03-20 19:45:03,043:INFO:Preloading libraries
2025-03-20 19:45:03,253:ERROR:_log_model() for VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                                                       importance_type=None,
                                                                       interaction_constraints=None,
                                                                       learning_rate=0.14756656644624855,
                                                                       max_bin=None,
                                                                       max_cat_threshold=None,
                                                                       max_cat_to_onehot=None,
                                                                       max_delta_step=None,
                                                                       max_depth=4,
                                                                       max_leaves=None,
                                                                       min_child_weight=1,
                                                                       missing=nan,
                                                                       monotone_constraints=None,
                                                                       multi_strategy=None,
                                                                       n_estimators=60,
                                                                       n_jobs=-1,
                                                                       num_parallel_tree=None,
                                                                       random_state=888, ...))],
                                             n_jobs=-1))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:45:03,259:INFO:_master_model_container: 32
2025-03-20 19:45:03,259:INFO:_display_container: 14
2025-03-20 19:45:03,280:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.06590961269907711,
                                                       max_features=0.7202572740441111,
                                                       min_impurity_decrease=0.00015133586537456308,
                                                       min_samples_leaf=4,
                                                       min_samples_split=3,
                                                       n_estimators=104,
                                                       random_state=888,
                                                       subsample=0.5133438772875569)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(baggin...
                                                                       importance_type=None,
                                                                       interaction_constraints=None,
                                                                       learning_rate=0.14756656644624855,
                                                                       max_bin=None,
                                                                       max_cat_threshold=None,
                                                                       max_cat_to_onehot=None,
                                                                       max_delta_step=None,
                                                                       max_depth=4,
                                                                       max_leaves=None,
                                                                       min_child_weight=1,
                                                                       missing=nan,
                                                                       monotone_constraints=None,
                                                                       multi_strategy=None,
                                                                       n_estimators=60,
                                                                       n_jobs=-1,
                                                                       num_parallel_tree=None,
                                                                       random_state=888, ...))],
                                             n_jobs=-1))],
                n_jobs=-1)
2025-03-20 19:45:03,280:INFO:blend_models() successfully completed......................................
2025-03-20 19:53:21,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:53:21,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:53:21,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:53:21,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:53:21,851:INFO:PyCaret RegressionExperiment
2025-03-20 19:53:21,851:INFO:Logging name: reg-default-name
2025-03-20 19:53:21,851:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 19:53:21,851:INFO:version 3.2.0
2025-03-20 19:53:21,851:INFO:Initializing setup()
2025-03-20 19:53:21,851:INFO:self.USI: 1bf8
2025-03-20 19:53:21,851:INFO:self._variable_keys: {'logging_param', 'y_train', 'y', '_ml_usecase', 'exp_name_log', 'log_plots_param', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'pipeline', '_available_plots', 'memory', 'target_param', 'exp_id', 'transform_target_param', 'fold_groups_param', 'X_train', 'X_test', 'idx', 'html_param', 'data', 'gpu_n_jobs_param', 'USI', 'y_test', 'gpu_param', 'X', 'fold_generator'}
2025-03-20 19:53:21,851:INFO:Checking environment
2025-03-20 19:53:21,851:INFO:python_version: 3.8.20
2025-03-20 19:53:21,851:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 19:53:21,851:INFO:machine: AMD64
2025-03-20 19:53:21,851:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 19:53:21,857:INFO:Memory: svmem(total=68447973376, available=41229443072, percent=39.8, used=27218530304, free=41229443072)
2025-03-20 19:53:21,858:INFO:Physical Core: 24
2025-03-20 19:53:21,858:INFO:Logical Core: 32
2025-03-20 19:53:21,858:INFO:Checking libraries
2025-03-20 19:53:21,858:INFO:System:
2025-03-20 19:53:21,858:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 19:53:21,858:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 19:53:21,858:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 19:53:21,858:INFO:PyCaret required dependencies:
2025-03-20 19:53:22,357:INFO:                 pip: 24.2
2025-03-20 19:53:22,357:INFO:          setuptools: 75.1.0
2025-03-20 19:53:22,357:INFO:             pycaret: 3.2.0
2025-03-20 19:53:22,357:INFO:             IPython: 8.12.3
2025-03-20 19:53:22,357:INFO:          ipywidgets: 8.1.5
2025-03-20 19:53:22,357:INFO:                tqdm: 4.67.1
2025-03-20 19:53:22,357:INFO:               numpy: 1.24.4
2025-03-20 19:53:22,358:INFO:              pandas: 1.5.3
2025-03-20 19:53:22,358:INFO:              jinja2: 3.1.4
2025-03-20 19:53:22,358:INFO:               scipy: 1.10.1
2025-03-20 19:53:22,358:INFO:              joblib: 1.3.2
2025-03-20 19:53:22,358:INFO:             sklearn: 1.2.2
2025-03-20 19:53:22,358:INFO:                pyod: 2.0.2
2025-03-20 19:53:22,358:INFO:            imblearn: 0.12.4
2025-03-20 19:53:22,358:INFO:   category_encoders: 2.6.4
2025-03-20 19:53:22,358:INFO:            lightgbm: 4.5.0
2025-03-20 19:53:22,358:INFO:               numba: 0.58.1
2025-03-20 19:53:22,358:INFO:            requests: 2.32.3
2025-03-20 19:53:22,358:INFO:          matplotlib: 3.6.0
2025-03-20 19:53:22,358:INFO:          scikitplot: 0.3.7
2025-03-20 19:53:22,358:INFO:         yellowbrick: 1.5
2025-03-20 19:53:22,358:INFO:              plotly: 5.24.1
2025-03-20 19:53:22,358:INFO:    plotly-resampler: Not installed
2025-03-20 19:53:22,358:INFO:             kaleido: 0.2.1
2025-03-20 19:53:22,358:INFO:           schemdraw: 0.15
2025-03-20 19:53:22,358:INFO:         statsmodels: 0.14.1
2025-03-20 19:53:22,358:INFO:              sktime: 0.21.1
2025-03-20 19:53:22,358:INFO:               tbats: 1.1.3
2025-03-20 19:53:22,358:INFO:            pmdarima: 2.0.4
2025-03-20 19:53:22,358:INFO:              psutil: 6.1.0
2025-03-20 19:53:22,358:INFO:          markupsafe: 2.1.5
2025-03-20 19:53:22,358:INFO:             pickle5: Not installed
2025-03-20 19:53:22,358:INFO:         cloudpickle: 2.2.1
2025-03-20 19:53:22,358:INFO:         deprecation: 2.1.0
2025-03-20 19:53:22,358:INFO:              xxhash: 3.5.0
2025-03-20 19:53:22,358:INFO:           wurlitzer: Not installed
2025-03-20 19:53:22,358:INFO:PyCaret optional dependencies:
2025-03-20 19:53:23,809:INFO:                shap: 0.44.1
2025-03-20 19:53:23,809:INFO:           interpret: 0.6.6
2025-03-20 19:53:23,809:INFO:                umap: 0.5.7
2025-03-20 19:53:23,809:INFO:     ydata_profiling: 4.6.0
2025-03-20 19:53:23,809:INFO:  explainerdashboard: 0.4.7
2025-03-20 19:53:23,809:INFO:             autoviz: Not installed
2025-03-20 19:53:23,809:INFO:           fairlearn: 0.7.0
2025-03-20 19:53:23,809:INFO:          deepchecks: Not installed
2025-03-20 19:53:23,809:INFO:             xgboost: 2.1.3
2025-03-20 19:53:23,809:INFO:            catboost: 1.2.7
2025-03-20 19:53:23,809:INFO:              kmodes: 0.12.2
2025-03-20 19:53:23,809:INFO:             mlxtend: 0.23.1
2025-03-20 19:53:23,809:INFO:       statsforecast: 1.5.0
2025-03-20 19:53:23,809:INFO:        tune_sklearn: 0.5.0
2025-03-20 19:53:23,809:INFO:                 ray: 2.10.0
2025-03-20 19:53:23,809:INFO:            hyperopt: 0.2.7
2025-03-20 19:53:23,809:INFO:              optuna: 4.1.0
2025-03-20 19:53:23,809:INFO:               skopt: 0.10.2
2025-03-20 19:53:23,809:INFO:              mlflow: 1.30.1
2025-03-20 19:53:23,809:INFO:              gradio: 3.50.2
2025-03-20 19:53:23,809:INFO:             fastapi: 0.115.5
2025-03-20 19:53:23,809:INFO:             uvicorn: 0.32.1
2025-03-20 19:53:23,809:INFO:              m2cgen: 0.10.0
2025-03-20 19:53:23,809:INFO:           evidently: 0.2.8
2025-03-20 19:53:23,809:INFO:               fugue: 0.8.6
2025-03-20 19:53:23,809:INFO:           streamlit: Not installed
2025-03-20 19:53:23,809:INFO:             prophet: Not installed
2025-03-20 19:53:23,809:INFO:None
2025-03-20 19:53:23,809:INFO:Set up data.
2025-03-20 19:53:23,815:INFO:Set up folding strategy.
2025-03-20 19:53:23,815:INFO:Set up train/test split.
2025-03-20 19:53:23,815:INFO:Set up data.
2025-03-20 19:53:23,820:INFO:Set up index.
2025-03-20 19:53:23,820:INFO:Assigning column types.
2025-03-20 19:53:23,822:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 19:53:23,822:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,824:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,826:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,851:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,870:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,870:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:23,871:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:23,883:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,885:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,887:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,932:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:23,933:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:23,933:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 19:53:23,935:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,937:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,982:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:23,983:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:23,985:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 19:53:23,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,031:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,032:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,032:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 19:53:24,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,081:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,081:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,082:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,111:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,130:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,132:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,132:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 19:53:24,161:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,180:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,181:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,229:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,230:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,231:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,231:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 19:53:24,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,279:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,280:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 19:53:24,329:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,330:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,330:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 19:53:24,392:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,393:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,442:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,443:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,445:INFO:Preparing preprocessing pipeline...
2025-03-20 19:53:24,445:INFO:Set up simple imputation.
2025-03-20 19:53:24,446:INFO:Set up encoding of categorical features.
2025-03-20 19:53:24,447:INFO:Set up feature normalization.
2025-03-20 19:53:24,447:INFO:Set up column name cleaning.
2025-03-20 19:53:24,495:INFO:Finished creating preprocessing pipeline.
2025-03-20 19:53:24,500:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:53:24,500:INFO:Creating final display dataframe.
2025-03-20 19:53:24,626:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              1bf8
2025-03-20 19:53:24,682:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,683:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,732:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:24,733:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 19:53:24,734:INFO:Logging experiment in loggers
2025-03-20 19:53:24,887:INFO:SubProcess save_model() called ==================================
2025-03-20 19:53:24,895:INFO:Initializing save_model()
2025-03-20 19:53:24,895:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpn88j_n8l\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:53:24,895:INFO:Adding model into prep_pipe
2025-03-20 19:53:24,895:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:53:24,899:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpn88j_n8l\Transformation Pipeline.pkl saved in current working directory
2025-03-20 19:53:24,903:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 19:53:24,903:INFO:save_model() successfully completed......................................
2025-03-20 19:53:24,962:INFO:SubProcess save_model() end ==================================
2025-03-20 19:53:24,968:INFO:setup() successfully completed in 2.89s...............
2025-03-20 19:53:24,968:INFO:Initializing compare_models()
2025-03-20 19:53:24,968:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 19:53:24,968:INFO:Checking exceptions
2025-03-20 19:53:24,969:INFO:Preparing display monitor
2025-03-20 19:53:24,982:INFO:Initializing Linear Regression
2025-03-20 19:53:24,982:INFO:Total runtime is 0.0 minutes
2025-03-20 19:53:24,984:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:24,984:INFO:Initializing create_model()
2025-03-20 19:53:24,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:24,984:INFO:Checking exceptions
2025-03-20 19:53:24,984:INFO:Importing libraries
2025-03-20 19:53:24,984:INFO:Copying training dataset
2025-03-20 19:53:24,986:INFO:Defining folds
2025-03-20 19:53:24,986:INFO:Declaring metric variables
2025-03-20 19:53:24,988:INFO:Importing untrained model
2025-03-20 19:53:24,990:INFO:Linear Regression Imported successfully
2025-03-20 19:53:24,993:INFO:Starting cross validation
2025-03-20 19:53:24,996:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:27,601:INFO:Calculating mean and std
2025-03-20 19:53:27,602:INFO:Creating metrics dataframe
2025-03-20 19:53:27,604:INFO:Uploading results into container
2025-03-20 19:53:27,604:INFO:Uploading model into container now
2025-03-20 19:53:27,605:INFO:_master_model_container: 1
2025-03-20 19:53:27,605:INFO:_display_container: 2
2025-03-20 19:53:27,605:INFO:LinearRegression(n_jobs=-1)
2025-03-20 19:53:27,605:INFO:create_model() successfully completed......................................
2025-03-20 19:53:27,661:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:27,661:INFO:Creating metrics dataframe
2025-03-20 19:53:27,665:INFO:Initializing Lasso Regression
2025-03-20 19:53:27,665:INFO:Total runtime is 0.044716501235961915 minutes
2025-03-20 19:53:27,667:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:27,667:INFO:Initializing create_model()
2025-03-20 19:53:27,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:27,667:INFO:Checking exceptions
2025-03-20 19:53:27,667:INFO:Importing libraries
2025-03-20 19:53:27,667:INFO:Copying training dataset
2025-03-20 19:53:27,669:INFO:Defining folds
2025-03-20 19:53:27,669:INFO:Declaring metric variables
2025-03-20 19:53:27,670:INFO:Importing untrained model
2025-03-20 19:53:27,672:INFO:Lasso Regression Imported successfully
2025-03-20 19:53:27,676:INFO:Starting cross validation
2025-03-20 19:53:27,676:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:29,880:INFO:Calculating mean and std
2025-03-20 19:53:29,881:INFO:Creating metrics dataframe
2025-03-20 19:53:29,883:INFO:Uploading results into container
2025-03-20 19:53:29,883:INFO:Uploading model into container now
2025-03-20 19:53:29,883:INFO:_master_model_container: 2
2025-03-20 19:53:29,883:INFO:_display_container: 2
2025-03-20 19:53:29,883:INFO:Lasso(random_state=888)
2025-03-20 19:53:29,883:INFO:create_model() successfully completed......................................
2025-03-20 19:53:29,940:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:29,940:INFO:Creating metrics dataframe
2025-03-20 19:53:29,944:INFO:Initializing Ridge Regression
2025-03-20 19:53:29,945:INFO:Total runtime is 0.08271145423253377 minutes
2025-03-20 19:53:29,946:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:29,946:INFO:Initializing create_model()
2025-03-20 19:53:29,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:29,946:INFO:Checking exceptions
2025-03-20 19:53:29,946:INFO:Importing libraries
2025-03-20 19:53:29,947:INFO:Copying training dataset
2025-03-20 19:53:29,949:INFO:Defining folds
2025-03-20 19:53:29,949:INFO:Declaring metric variables
2025-03-20 19:53:29,950:INFO:Importing untrained model
2025-03-20 19:53:29,952:INFO:Ridge Regression Imported successfully
2025-03-20 19:53:29,954:INFO:Starting cross validation
2025-03-20 19:53:29,955:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:32,036:INFO:Calculating mean and std
2025-03-20 19:53:32,036:INFO:Creating metrics dataframe
2025-03-20 19:53:32,039:INFO:Uploading results into container
2025-03-20 19:53:32,039:INFO:Uploading model into container now
2025-03-20 19:53:32,039:INFO:_master_model_container: 3
2025-03-20 19:53:32,039:INFO:_display_container: 2
2025-03-20 19:53:32,040:INFO:Ridge(random_state=888)
2025-03-20 19:53:32,040:INFO:create_model() successfully completed......................................
2025-03-20 19:53:32,097:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:32,097:INFO:Creating metrics dataframe
2025-03-20 19:53:32,102:INFO:Initializing Elastic Net
2025-03-20 19:53:32,102:INFO:Total runtime is 0.11867008209228516 minutes
2025-03-20 19:53:32,104:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:32,104:INFO:Initializing create_model()
2025-03-20 19:53:32,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:32,105:INFO:Checking exceptions
2025-03-20 19:53:32,105:INFO:Importing libraries
2025-03-20 19:53:32,105:INFO:Copying training dataset
2025-03-20 19:53:32,107:INFO:Defining folds
2025-03-20 19:53:32,107:INFO:Declaring metric variables
2025-03-20 19:53:32,108:INFO:Importing untrained model
2025-03-20 19:53:32,110:INFO:Elastic Net Imported successfully
2025-03-20 19:53:32,113:INFO:Starting cross validation
2025-03-20 19:53:32,114:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:34,176:INFO:Calculating mean and std
2025-03-20 19:53:34,176:INFO:Creating metrics dataframe
2025-03-20 19:53:34,178:INFO:Uploading results into container
2025-03-20 19:53:34,179:INFO:Uploading model into container now
2025-03-20 19:53:34,179:INFO:_master_model_container: 4
2025-03-20 19:53:34,179:INFO:_display_container: 2
2025-03-20 19:53:34,179:INFO:ElasticNet(random_state=888)
2025-03-20 19:53:34,179:INFO:create_model() successfully completed......................................
2025-03-20 19:53:34,234:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:34,235:INFO:Creating metrics dataframe
2025-03-20 19:53:34,239:INFO:Initializing Least Angle Regression
2025-03-20 19:53:34,239:INFO:Total runtime is 0.15428930918375652 minutes
2025-03-20 19:53:34,241:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:34,241:INFO:Initializing create_model()
2025-03-20 19:53:34,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:34,241:INFO:Checking exceptions
2025-03-20 19:53:34,241:INFO:Importing libraries
2025-03-20 19:53:34,241:INFO:Copying training dataset
2025-03-20 19:53:34,243:INFO:Defining folds
2025-03-20 19:53:34,243:INFO:Declaring metric variables
2025-03-20 19:53:34,245:INFO:Importing untrained model
2025-03-20 19:53:34,246:INFO:Least Angle Regression Imported successfully
2025-03-20 19:53:34,249:INFO:Starting cross validation
2025-03-20 19:53:34,250:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:36,355:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.010e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,355:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.349e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,408:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,408:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,408:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,409:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,409:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,409:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.688e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.114e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.912e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.216e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.707e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.503e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.848e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.186e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.737e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 19:53:36,454:INFO:Calculating mean and std
2025-03-20 19:53:36,456:INFO:Creating metrics dataframe
2025-03-20 19:53:36,458:INFO:Uploading results into container
2025-03-20 19:53:36,458:INFO:Uploading model into container now
2025-03-20 19:53:36,458:INFO:_master_model_container: 5
2025-03-20 19:53:36,458:INFO:_display_container: 2
2025-03-20 19:53:36,458:INFO:Lars(random_state=888)
2025-03-20 19:53:36,458:INFO:create_model() successfully completed......................................
2025-03-20 19:53:36,514:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:36,514:INFO:Creating metrics dataframe
2025-03-20 19:53:36,519:INFO:Initializing Lasso Least Angle Regression
2025-03-20 19:53:36,519:INFO:Total runtime is 0.19227599302927656 minutes
2025-03-20 19:53:36,520:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:36,520:INFO:Initializing create_model()
2025-03-20 19:53:36,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:36,520:INFO:Checking exceptions
2025-03-20 19:53:36,521:INFO:Importing libraries
2025-03-20 19:53:36,521:INFO:Copying training dataset
2025-03-20 19:53:36,523:INFO:Defining folds
2025-03-20 19:53:36,523:INFO:Declaring metric variables
2025-03-20 19:53:36,525:INFO:Importing untrained model
2025-03-20 19:53:36,527:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 19:53:36,530:INFO:Starting cross validation
2025-03-20 19:53:36,531:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:38,656:INFO:Calculating mean and std
2025-03-20 19:53:38,657:INFO:Creating metrics dataframe
2025-03-20 19:53:38,658:INFO:Uploading results into container
2025-03-20 19:53:38,659:INFO:Uploading model into container now
2025-03-20 19:53:38,659:INFO:_master_model_container: 6
2025-03-20 19:53:38,659:INFO:_display_container: 2
2025-03-20 19:53:38,660:INFO:LassoLars(random_state=888)
2025-03-20 19:53:38,660:INFO:create_model() successfully completed......................................
2025-03-20 19:53:38,712:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:38,712:INFO:Creating metrics dataframe
2025-03-20 19:53:38,718:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 19:53:38,718:INFO:Total runtime is 0.22892994085947677 minutes
2025-03-20 19:53:38,719:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:38,720:INFO:Initializing create_model()
2025-03-20 19:53:38,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:38,720:INFO:Checking exceptions
2025-03-20 19:53:38,720:INFO:Importing libraries
2025-03-20 19:53:38,720:INFO:Copying training dataset
2025-03-20 19:53:38,722:INFO:Defining folds
2025-03-20 19:53:38,722:INFO:Declaring metric variables
2025-03-20 19:53:38,723:INFO:Importing untrained model
2025-03-20 19:53:38,725:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 19:53:38,728:INFO:Starting cross validation
2025-03-20 19:53:38,729:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:40,596:INFO:Calculating mean and std
2025-03-20 19:53:40,597:INFO:Creating metrics dataframe
2025-03-20 19:53:40,598:INFO:Uploading results into container
2025-03-20 19:53:40,599:INFO:Uploading model into container now
2025-03-20 19:53:40,599:INFO:_master_model_container: 7
2025-03-20 19:53:40,599:INFO:_display_container: 2
2025-03-20 19:53:40,599:INFO:OrthogonalMatchingPursuit()
2025-03-20 19:53:40,599:INFO:create_model() successfully completed......................................
2025-03-20 19:53:40,655:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:40,656:INFO:Creating metrics dataframe
2025-03-20 19:53:40,661:INFO:Initializing Bayesian Ridge
2025-03-20 19:53:40,661:INFO:Total runtime is 0.26131257216135667 minutes
2025-03-20 19:53:40,662:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:40,663:INFO:Initializing create_model()
2025-03-20 19:53:40,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:40,663:INFO:Checking exceptions
2025-03-20 19:53:40,663:INFO:Importing libraries
2025-03-20 19:53:40,663:INFO:Copying training dataset
2025-03-20 19:53:40,665:INFO:Defining folds
2025-03-20 19:53:40,665:INFO:Declaring metric variables
2025-03-20 19:53:40,666:INFO:Importing untrained model
2025-03-20 19:53:40,668:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:53:40,671:INFO:Starting cross validation
2025-03-20 19:53:40,672:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:40,734:INFO:Calculating mean and std
2025-03-20 19:53:40,735:INFO:Creating metrics dataframe
2025-03-20 19:53:40,737:INFO:Uploading results into container
2025-03-20 19:53:40,737:INFO:Uploading model into container now
2025-03-20 19:53:40,737:INFO:_master_model_container: 8
2025-03-20 19:53:40,737:INFO:_display_container: 2
2025-03-20 19:53:40,737:INFO:BayesianRidge()
2025-03-20 19:53:40,738:INFO:create_model() successfully completed......................................
2025-03-20 19:53:40,792:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:40,792:INFO:Creating metrics dataframe
2025-03-20 19:53:40,797:INFO:Initializing Passive Aggressive Regressor
2025-03-20 19:53:40,797:INFO:Total runtime is 0.2635889609654745 minutes
2025-03-20 19:53:40,799:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:40,799:INFO:Initializing create_model()
2025-03-20 19:53:40,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:40,799:INFO:Checking exceptions
2025-03-20 19:53:40,799:INFO:Importing libraries
2025-03-20 19:53:40,799:INFO:Copying training dataset
2025-03-20 19:53:40,801:INFO:Defining folds
2025-03-20 19:53:40,801:INFO:Declaring metric variables
2025-03-20 19:53:40,802:INFO:Importing untrained model
2025-03-20 19:53:40,804:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 19:53:40,807:INFO:Starting cross validation
2025-03-20 19:53:40,808:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:40,873:INFO:Calculating mean and std
2025-03-20 19:53:40,873:INFO:Creating metrics dataframe
2025-03-20 19:53:40,875:INFO:Uploading results into container
2025-03-20 19:53:40,875:INFO:Uploading model into container now
2025-03-20 19:53:40,876:INFO:_master_model_container: 9
2025-03-20 19:53:40,876:INFO:_display_container: 2
2025-03-20 19:53:40,876:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 19:53:40,876:INFO:create_model() successfully completed......................................
2025-03-20 19:53:40,928:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:40,928:INFO:Creating metrics dataframe
2025-03-20 19:53:40,934:INFO:Initializing Huber Regressor
2025-03-20 19:53:40,934:INFO:Total runtime is 0.2658653457959494 minutes
2025-03-20 19:53:40,935:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:40,936:INFO:Initializing create_model()
2025-03-20 19:53:40,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:40,936:INFO:Checking exceptions
2025-03-20 19:53:40,936:INFO:Importing libraries
2025-03-20 19:53:40,936:INFO:Copying training dataset
2025-03-20 19:53:40,937:INFO:Defining folds
2025-03-20 19:53:40,937:INFO:Declaring metric variables
2025-03-20 19:53:40,939:INFO:Importing untrained model
2025-03-20 19:53:40,941:INFO:Huber Regressor Imported successfully
2025-03-20 19:53:40,944:INFO:Starting cross validation
2025-03-20 19:53:40,945:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:40,985:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:53:40,990:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:53:40,992:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:53:40,999:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:53:41,000:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 19:53:41,027:INFO:Calculating mean and std
2025-03-20 19:53:41,028:INFO:Creating metrics dataframe
2025-03-20 19:53:41,029:INFO:Uploading results into container
2025-03-20 19:53:41,030:INFO:Uploading model into container now
2025-03-20 19:53:41,030:INFO:_master_model_container: 10
2025-03-20 19:53:41,030:INFO:_display_container: 2
2025-03-20 19:53:41,030:INFO:HuberRegressor()
2025-03-20 19:53:41,030:INFO:create_model() successfully completed......................................
2025-03-20 19:53:41,084:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:41,084:INFO:Creating metrics dataframe
2025-03-20 19:53:41,089:INFO:Initializing K Neighbors Regressor
2025-03-20 19:53:41,089:INFO:Total runtime is 0.26845629215240485 minutes
2025-03-20 19:53:41,091:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:41,091:INFO:Initializing create_model()
2025-03-20 19:53:41,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:41,091:INFO:Checking exceptions
2025-03-20 19:53:41,091:INFO:Importing libraries
2025-03-20 19:53:41,091:INFO:Copying training dataset
2025-03-20 19:53:41,093:INFO:Defining folds
2025-03-20 19:53:41,093:INFO:Declaring metric variables
2025-03-20 19:53:41,095:INFO:Importing untrained model
2025-03-20 19:53:41,097:INFO:K Neighbors Regressor Imported successfully
2025-03-20 19:53:41,100:INFO:Starting cross validation
2025-03-20 19:53:41,101:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:41,197:INFO:Calculating mean and std
2025-03-20 19:53:41,197:INFO:Creating metrics dataframe
2025-03-20 19:53:41,199:INFO:Uploading results into container
2025-03-20 19:53:41,199:INFO:Uploading model into container now
2025-03-20 19:53:41,199:INFO:_master_model_container: 11
2025-03-20 19:53:41,199:INFO:_display_container: 2
2025-03-20 19:53:41,200:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 19:53:41,200:INFO:create_model() successfully completed......................................
2025-03-20 19:53:41,256:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:41,256:INFO:Creating metrics dataframe
2025-03-20 19:53:41,262:INFO:Initializing Decision Tree Regressor
2025-03-20 19:53:41,262:INFO:Total runtime is 0.2713369528452556 minutes
2025-03-20 19:53:41,264:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:41,265:INFO:Initializing create_model()
2025-03-20 19:53:41,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:41,265:INFO:Checking exceptions
2025-03-20 19:53:41,265:INFO:Importing libraries
2025-03-20 19:53:41,265:INFO:Copying training dataset
2025-03-20 19:53:41,267:INFO:Defining folds
2025-03-20 19:53:41,267:INFO:Declaring metric variables
2025-03-20 19:53:41,268:INFO:Importing untrained model
2025-03-20 19:53:41,270:INFO:Decision Tree Regressor Imported successfully
2025-03-20 19:53:41,274:INFO:Starting cross validation
2025-03-20 19:53:41,275:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:41,350:INFO:Calculating mean and std
2025-03-20 19:53:41,351:INFO:Creating metrics dataframe
2025-03-20 19:53:41,353:INFO:Uploading results into container
2025-03-20 19:53:41,353:INFO:Uploading model into container now
2025-03-20 19:53:41,353:INFO:_master_model_container: 12
2025-03-20 19:53:41,353:INFO:_display_container: 2
2025-03-20 19:53:41,354:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 19:53:41,354:INFO:create_model() successfully completed......................................
2025-03-20 19:53:41,410:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:41,410:INFO:Creating metrics dataframe
2025-03-20 19:53:41,416:INFO:Initializing Random Forest Regressor
2025-03-20 19:53:41,416:INFO:Total runtime is 0.2739030559857687 minutes
2025-03-20 19:53:41,418:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:41,418:INFO:Initializing create_model()
2025-03-20 19:53:41,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:41,418:INFO:Checking exceptions
2025-03-20 19:53:41,418:INFO:Importing libraries
2025-03-20 19:53:41,419:INFO:Copying training dataset
2025-03-20 19:53:41,421:INFO:Defining folds
2025-03-20 19:53:41,421:INFO:Declaring metric variables
2025-03-20 19:53:41,422:INFO:Importing untrained model
2025-03-20 19:53:41,424:INFO:Random Forest Regressor Imported successfully
2025-03-20 19:53:41,428:INFO:Starting cross validation
2025-03-20 19:53:41,429:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:41,797:INFO:Calculating mean and std
2025-03-20 19:53:41,798:INFO:Creating metrics dataframe
2025-03-20 19:53:41,799:INFO:Uploading results into container
2025-03-20 19:53:41,800:INFO:Uploading model into container now
2025-03-20 19:53:41,800:INFO:_master_model_container: 13
2025-03-20 19:53:41,800:INFO:_display_container: 2
2025-03-20 19:53:41,800:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:53:41,800:INFO:create_model() successfully completed......................................
2025-03-20 19:53:41,855:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:41,855:INFO:Creating metrics dataframe
2025-03-20 19:53:41,863:INFO:Initializing Extra Trees Regressor
2025-03-20 19:53:41,863:INFO:Total runtime is 0.28135304848353077 minutes
2025-03-20 19:53:41,865:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:41,865:INFO:Initializing create_model()
2025-03-20 19:53:41,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:41,865:INFO:Checking exceptions
2025-03-20 19:53:41,866:INFO:Importing libraries
2025-03-20 19:53:41,866:INFO:Copying training dataset
2025-03-20 19:53:41,867:INFO:Defining folds
2025-03-20 19:53:41,868:INFO:Declaring metric variables
2025-03-20 19:53:41,869:INFO:Importing untrained model
2025-03-20 19:53:41,871:INFO:Extra Trees Regressor Imported successfully
2025-03-20 19:53:41,875:INFO:Starting cross validation
2025-03-20 19:53:41,876:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:42,089:INFO:Calculating mean and std
2025-03-20 19:53:42,090:INFO:Creating metrics dataframe
2025-03-20 19:53:42,092:INFO:Uploading results into container
2025-03-20 19:53:42,092:INFO:Uploading model into container now
2025-03-20 19:53:42,092:INFO:_master_model_container: 14
2025-03-20 19:53:42,092:INFO:_display_container: 2
2025-03-20 19:53:42,093:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:53:42,093:INFO:create_model() successfully completed......................................
2025-03-20 19:53:42,147:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:42,147:INFO:Creating metrics dataframe
2025-03-20 19:53:42,153:INFO:Initializing AdaBoost Regressor
2025-03-20 19:53:42,153:INFO:Total runtime is 0.2861881097157797 minutes
2025-03-20 19:53:42,155:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:42,155:INFO:Initializing create_model()
2025-03-20 19:53:42,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:42,155:INFO:Checking exceptions
2025-03-20 19:53:42,156:INFO:Importing libraries
2025-03-20 19:53:42,156:INFO:Copying training dataset
2025-03-20 19:53:42,158:INFO:Defining folds
2025-03-20 19:53:42,158:INFO:Declaring metric variables
2025-03-20 19:53:42,159:INFO:Importing untrained model
2025-03-20 19:53:42,161:INFO:AdaBoost Regressor Imported successfully
2025-03-20 19:53:42,164:INFO:Starting cross validation
2025-03-20 19:53:42,165:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:42,366:INFO:Calculating mean and std
2025-03-20 19:53:42,367:INFO:Creating metrics dataframe
2025-03-20 19:53:42,369:INFO:Uploading results into container
2025-03-20 19:53:42,369:INFO:Uploading model into container now
2025-03-20 19:53:42,369:INFO:_master_model_container: 15
2025-03-20 19:53:42,370:INFO:_display_container: 2
2025-03-20 19:53:42,370:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 19:53:42,370:INFO:create_model() successfully completed......................................
2025-03-20 19:53:42,423:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:42,423:INFO:Creating metrics dataframe
2025-03-20 19:53:42,429:INFO:Initializing Gradient Boosting Regressor
2025-03-20 19:53:42,429:INFO:Total runtime is 0.29079054991404224 minutes
2025-03-20 19:53:42,431:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:42,431:INFO:Initializing create_model()
2025-03-20 19:53:42,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:42,431:INFO:Checking exceptions
2025-03-20 19:53:42,431:INFO:Importing libraries
2025-03-20 19:53:42,431:INFO:Copying training dataset
2025-03-20 19:53:42,433:INFO:Defining folds
2025-03-20 19:53:42,433:INFO:Declaring metric variables
2025-03-20 19:53:42,435:INFO:Importing untrained model
2025-03-20 19:53:42,437:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:53:42,440:INFO:Starting cross validation
2025-03-20 19:53:42,441:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:43,044:INFO:Calculating mean and std
2025-03-20 19:53:43,045:INFO:Creating metrics dataframe
2025-03-20 19:53:43,046:INFO:Uploading results into container
2025-03-20 19:53:43,047:INFO:Uploading model into container now
2025-03-20 19:53:43,047:INFO:_master_model_container: 16
2025-03-20 19:53:43,047:INFO:_display_container: 2
2025-03-20 19:53:43,047:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:53:43,047:INFO:create_model() successfully completed......................................
2025-03-20 19:53:43,103:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:43,103:INFO:Creating metrics dataframe
2025-03-20 19:53:43,110:INFO:Initializing Extreme Gradient Boosting
2025-03-20 19:53:43,110:INFO:Total runtime is 0.3021393616994223 minutes
2025-03-20 19:53:43,112:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:43,112:INFO:Initializing create_model()
2025-03-20 19:53:43,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:43,112:INFO:Checking exceptions
2025-03-20 19:53:43,112:INFO:Importing libraries
2025-03-20 19:53:43,112:INFO:Copying training dataset
2025-03-20 19:53:43,114:INFO:Defining folds
2025-03-20 19:53:43,114:INFO:Declaring metric variables
2025-03-20 19:53:43,116:INFO:Importing untrained model
2025-03-20 19:53:43,117:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:53:43,120:INFO:Starting cross validation
2025-03-20 19:53:43,121:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:43,598:INFO:Calculating mean and std
2025-03-20 19:53:43,599:INFO:Creating metrics dataframe
2025-03-20 19:53:43,601:INFO:Uploading results into container
2025-03-20 19:53:43,601:INFO:Uploading model into container now
2025-03-20 19:53:43,601:INFO:_master_model_container: 17
2025-03-20 19:53:43,601:INFO:_display_container: 2
2025-03-20 19:53:43,602:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:53:43,602:INFO:create_model() successfully completed......................................
2025-03-20 19:53:43,655:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:43,655:INFO:Creating metrics dataframe
2025-03-20 19:53:43,662:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 19:53:43,662:INFO:Total runtime is 0.31133596499760957 minutes
2025-03-20 19:53:43,664:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:43,664:INFO:Initializing create_model()
2025-03-20 19:53:43,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:43,664:INFO:Checking exceptions
2025-03-20 19:53:43,664:INFO:Importing libraries
2025-03-20 19:53:43,664:INFO:Copying training dataset
2025-03-20 19:53:43,666:INFO:Defining folds
2025-03-20 19:53:43,667:INFO:Declaring metric variables
2025-03-20 19:53:43,668:INFO:Importing untrained model
2025-03-20 19:53:43,670:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:53:43,673:INFO:Starting cross validation
2025-03-20 19:53:43,674:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:44,152:INFO:Calculating mean and std
2025-03-20 19:53:44,153:INFO:Creating metrics dataframe
2025-03-20 19:53:44,156:INFO:Uploading results into container
2025-03-20 19:53:44,156:INFO:Uploading model into container now
2025-03-20 19:53:44,156:INFO:_master_model_container: 18
2025-03-20 19:53:44,156:INFO:_display_container: 2
2025-03-20 19:53:44,157:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:53:44,157:INFO:create_model() successfully completed......................................
2025-03-20 19:53:44,219:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:44,219:INFO:Creating metrics dataframe
2025-03-20 19:53:44,227:INFO:Initializing CatBoost Regressor
2025-03-20 19:53:44,227:INFO:Total runtime is 0.32075605789820366 minutes
2025-03-20 19:53:44,229:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:44,230:INFO:Initializing create_model()
2025-03-20 19:53:44,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:44,230:INFO:Checking exceptions
2025-03-20 19:53:44,230:INFO:Importing libraries
2025-03-20 19:53:44,230:INFO:Copying training dataset
2025-03-20 19:53:44,233:INFO:Defining folds
2025-03-20 19:53:44,233:INFO:Declaring metric variables
2025-03-20 19:53:44,235:INFO:Importing untrained model
2025-03-20 19:53:44,237:INFO:CatBoost Regressor Imported successfully
2025-03-20 19:53:44,241:INFO:Starting cross validation
2025-03-20 19:53:44,242:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:46,862:INFO:Calculating mean and std
2025-03-20 19:53:46,863:INFO:Creating metrics dataframe
2025-03-20 19:53:46,865:INFO:Uploading results into container
2025-03-20 19:53:46,866:INFO:Uploading model into container now
2025-03-20 19:53:46,866:INFO:_master_model_container: 19
2025-03-20 19:53:46,866:INFO:_display_container: 2
2025-03-20 19:53:46,866:INFO:<catboost.core.CatBoostRegressor object at 0x000001AF674DC070>
2025-03-20 19:53:46,866:INFO:create_model() successfully completed......................................
2025-03-20 19:53:46,925:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:46,926:INFO:Creating metrics dataframe
2025-03-20 19:53:46,932:INFO:Initializing Dummy Regressor
2025-03-20 19:53:46,933:INFO:Total runtime is 0.36584506432215386 minutes
2025-03-20 19:53:46,934:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:46,935:INFO:Initializing create_model()
2025-03-20 19:53:46,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6889B550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:46,935:INFO:Checking exceptions
2025-03-20 19:53:46,935:INFO:Importing libraries
2025-03-20 19:53:46,935:INFO:Copying training dataset
2025-03-20 19:53:46,937:INFO:Defining folds
2025-03-20 19:53:46,937:INFO:Declaring metric variables
2025-03-20 19:53:46,938:INFO:Importing untrained model
2025-03-20 19:53:46,940:INFO:Dummy Regressor Imported successfully
2025-03-20 19:53:46,943:INFO:Starting cross validation
2025-03-20 19:53:46,944:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:47,016:INFO:Calculating mean and std
2025-03-20 19:53:47,017:INFO:Creating metrics dataframe
2025-03-20 19:53:47,019:INFO:Uploading results into container
2025-03-20 19:53:47,019:INFO:Uploading model into container now
2025-03-20 19:53:47,020:INFO:_master_model_container: 20
2025-03-20 19:53:47,020:INFO:_display_container: 2
2025-03-20 19:53:47,020:INFO:DummyRegressor()
2025-03-20 19:53:47,020:INFO:create_model() successfully completed......................................
2025-03-20 19:53:47,081:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:47,081:INFO:Creating metrics dataframe
2025-03-20 19:53:47,094:INFO:Initializing create_model()
2025-03-20 19:53:47,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:47,094:INFO:Checking exceptions
2025-03-20 19:53:47,095:INFO:Importing libraries
2025-03-20 19:53:47,095:INFO:Copying training dataset
2025-03-20 19:53:47,097:INFO:Defining folds
2025-03-20 19:53:47,097:INFO:Declaring metric variables
2025-03-20 19:53:47,097:INFO:Importing untrained model
2025-03-20 19:53:47,097:INFO:Declaring custom model
2025-03-20 19:53:47,097:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:53:47,098:INFO:Cross validation set to False
2025-03-20 19:53:47,098:INFO:Fitting Model
2025-03-20 19:53:47,138:INFO:BayesianRidge()
2025-03-20 19:53:47,138:INFO:create_model() successfully completed......................................
2025-03-20 19:53:47,197:INFO:Creating Dashboard logs
2025-03-20 19:53:47,199:INFO:Model: Bayesian Ridge
2025-03-20 19:53:47,220:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:53:47,261:INFO:Initializing predict_model()
2025-03-20 19:53:47,261:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF68CF3310>)
2025-03-20 19:53:47,261:INFO:Checking exceptions
2025-03-20 19:53:47,261:INFO:Preloading libraries
2025-03-20 19:53:47,389:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 19:53:47,403:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:47,406:INFO:Initializing create_model()
2025-03-20 19:53:47,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:47,406:INFO:Checking exceptions
2025-03-20 19:53:47,407:INFO:Importing libraries
2025-03-20 19:53:47,407:INFO:Copying training dataset
2025-03-20 19:53:47,409:INFO:Defining folds
2025-03-20 19:53:47,409:INFO:Declaring metric variables
2025-03-20 19:53:47,409:INFO:Importing untrained model
2025-03-20 19:53:47,409:INFO:Declaring custom model
2025-03-20 19:53:47,409:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:53:47,410:INFO:Cross validation set to False
2025-03-20 19:53:47,410:INFO:Fitting Model
2025-03-20 19:53:48,086:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:53:48,087:INFO:create_model() successfully completed......................................
2025-03-20 19:53:48,139:INFO:Creating Dashboard logs
2025-03-20 19:53:48,141:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:53:48,161:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:53:48,211:INFO:Initializing predict_model()
2025-03-20 19:53:48,211:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF68CD45E0>)
2025-03-20 19:53:48,211:INFO:Checking exceptions
2025-03-20 19:53:48,211:INFO:Preloading libraries
2025-03-20 19:53:48,358:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:48,361:INFO:Initializing create_model()
2025-03-20 19:53:48,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:48,361:INFO:Checking exceptions
2025-03-20 19:53:48,362:INFO:Importing libraries
2025-03-20 19:53:48,363:INFO:Copying training dataset
2025-03-20 19:53:48,365:INFO:Defining folds
2025-03-20 19:53:48,365:INFO:Declaring metric variables
2025-03-20 19:53:48,365:INFO:Importing untrained model
2025-03-20 19:53:48,365:INFO:Declaring custom model
2025-03-20 19:53:48,365:INFO:Ridge Regression Imported successfully
2025-03-20 19:53:48,366:INFO:Cross validation set to False
2025-03-20 19:53:48,366:INFO:Fitting Model
2025-03-20 19:53:48,399:INFO:Ridge(random_state=888)
2025-03-20 19:53:48,399:INFO:create_model() successfully completed......................................
2025-03-20 19:53:48,456:INFO:Creating Dashboard logs
2025-03-20 19:53:48,458:INFO:Model: Ridge Regression
2025-03-20 19:53:48,476:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:53:48,532:INFO:Initializing predict_model()
2025-03-20 19:53:48,532:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF68CCE700>)
2025-03-20 19:53:48,532:INFO:Checking exceptions
2025-03-20 19:53:48,532:INFO:Preloading libraries
2025-03-20 19:53:48,668:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:48,671:INFO:Initializing create_model()
2025-03-20 19:53:48,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:48,671:INFO:Checking exceptions
2025-03-20 19:53:48,672:INFO:Importing libraries
2025-03-20 19:53:48,672:INFO:Copying training dataset
2025-03-20 19:53:48,673:INFO:Defining folds
2025-03-20 19:53:48,673:INFO:Declaring metric variables
2025-03-20 19:53:48,673:INFO:Importing untrained model
2025-03-20 19:53:48,674:INFO:Declaring custom model
2025-03-20 19:53:48,674:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:53:48,674:INFO:Cross validation set to False
2025-03-20 19:53:48,674:INFO:Fitting Model
2025-03-20 19:53:48,709:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:53:48,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.
2025-03-20 19:53:48,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:53:48,710:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:53:48,711:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:53:48,711:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:53:48,814:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:53:48,814:INFO:create_model() successfully completed......................................
2025-03-20 19:53:48,880:INFO:Creating Dashboard logs
2025-03-20 19:53:48,883:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:53:48,910:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:53:48,974:INFO:Initializing predict_model()
2025-03-20 19:53:48,974:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF68CD88B0>)
2025-03-20 19:53:48,974:INFO:Checking exceptions
2025-03-20 19:53:48,974:INFO:Preloading libraries
2025-03-20 19:53:49,161:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:49,166:INFO:Initializing create_model()
2025-03-20 19:53:49,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:49,166:INFO:Checking exceptions
2025-03-20 19:53:49,167:INFO:Importing libraries
2025-03-20 19:53:49,167:INFO:Copying training dataset
2025-03-20 19:53:49,170:INFO:Defining folds
2025-03-20 19:53:49,170:INFO:Declaring metric variables
2025-03-20 19:53:49,170:INFO:Importing untrained model
2025-03-20 19:53:49,170:INFO:Declaring custom model
2025-03-20 19:53:49,171:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:53:49,173:INFO:Cross validation set to False
2025-03-20 19:53:49,173:INFO:Fitting Model
2025-03-20 19:53:49,396:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:53:49,396:INFO:create_model() successfully completed......................................
2025-03-20 19:53:49,468:INFO:Creating Dashboard logs
2025-03-20 19:53:49,470:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:53:49,502:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:53:49,595:INFO:Initializing predict_model()
2025-03-20 19:53:49,595:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF687C69D0>)
2025-03-20 19:53:49,595:INFO:Checking exceptions
2025-03-20 19:53:49,596:INFO:Preloading libraries
2025-03-20 19:53:49,787:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:49,788:INFO:Creating Dashboard logs
2025-03-20 19:53:49,791:INFO:Model: Random Forest Regressor
2025-03-20 19:53:49,816:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:53:49,924:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:49,925:INFO:Creating Dashboard logs
2025-03-20 19:53:49,927:INFO:Model: AdaBoost Regressor
2025-03-20 19:53:49,948:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 19:53:50,062:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:50,063:INFO:Creating Dashboard logs
2025-03-20 19:53:50,064:INFO:Model: CatBoost Regressor
2025-03-20 19:53:50,086:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-20 19:53:50,086:INFO:Logged params: {}
2025-03-20 19:53:50,194:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x000001AF674DC070> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:50,195:INFO:Creating Dashboard logs
2025-03-20 19:53:50,197:INFO:Model: Extra Trees Regressor
2025-03-20 19:53:50,219:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 19:53:50,344:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:50,344:INFO:Creating Dashboard logs
2025-03-20 19:53:50,346:INFO:Model: Decision Tree Regressor
2025-03-20 19:53:50,367:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 19:53:50,485:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:50,486:INFO:Creating Dashboard logs
2025-03-20 19:53:50,488:INFO:Model: Passive Aggressive Regressor
2025-03-20 19:53:50,508:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:53:50,633:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:50,634:INFO:Creating Dashboard logs
2025-03-20 19:53:50,636:INFO:Model: Huber Regressor
2025-03-20 19:53:50,656:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 19:53:50,792:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:50,793:INFO:Creating Dashboard logs
2025-03-20 19:53:50,795:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 19:53:50,816:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 19:53:50,959:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:50,959:INFO:Creating Dashboard logs
2025-03-20 19:53:50,961:INFO:Model: K Neighbors Regressor
2025-03-20 19:53:50,982:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 19:53:51,140:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:51,140:INFO:Creating Dashboard logs
2025-03-20 19:53:51,142:INFO:Model: Elastic Net
2025-03-20 19:53:51,163:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:53:51,311:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:51,311:INFO:Creating Dashboard logs
2025-03-20 19:53:51,314:INFO:Model: Lasso Regression
2025-03-20 19:53:51,335:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 19:53:51,499:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:51,499:INFO:Creating Dashboard logs
2025-03-20 19:53:51,502:INFO:Model: Lasso Least Angle Regression
2025-03-20 19:53:51,523:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:53:51,703:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:51,704:INFO:Creating Dashboard logs
2025-03-20 19:53:51,706:INFO:Model: Dummy Regressor
2025-03-20 19:53:51,728:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 19:53:51,907:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:51,908:INFO:Creating Dashboard logs
2025-03-20 19:53:51,910:INFO:Model: Linear Regression
2025-03-20 19:53:51,932:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 19:53:52,107:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:52,107:INFO:Creating Dashboard logs
2025-03-20 19:53:52,109:INFO:Model: Least Angle Regression
2025-03-20 19:53:52,129:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 19:53:52,302:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:52,310:INFO:_master_model_container: 20
2025-03-20 19:53:52,310:INFO:_display_container: 2
2025-03-20 19:53:52,311:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)]
2025-03-20 19:53:52,311:INFO:compare_models() successfully completed......................................
2025-03-20 19:53:52,338:INFO:Initializing tune_model()
2025-03-20 19:53:52,338:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=1, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>)
2025-03-20 19:53:52,338:INFO:Checking exceptions
2025-03-20 19:53:52,338:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:53:52,379:INFO:Copying training dataset
2025-03-20 19:53:52,381:INFO:Checking base model
2025-03-20 19:53:52,381:INFO:Base model : Bayesian Ridge
2025-03-20 19:53:52,383:INFO:Declaring metric variables
2025-03-20 19:53:52,385:INFO:Defining Hyperparameters
2025-03-20 19:53:52,442:INFO:Tuning with n_jobs=-1
2025-03-20 19:53:52,443:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:52,443:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:52,443:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:53:52,448:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:52,448:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:53:52,448:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:53:52,672:INFO:best_params: {'actual_estimator__alpha_1': 2.2822973510657272e-07, 'actual_estimator__alpha_2': 0.13134218272687026, 'actual_estimator__lambda_1': 0.0002237819791636297, 'actual_estimator__lambda_2': 7.055374025254077e-09, 'actual_estimator__compute_score': False, 'actual_estimator__fit_intercept': False}
2025-03-20 19:53:52,672:INFO:Hyperparameter search completed
2025-03-20 19:53:52,672:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:52,673:INFO:Initializing create_model()
2025-03-20 19:53:52,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF68895070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 2.2822973510657272e-07, 'alpha_2': 0.13134218272687026, 'lambda_1': 0.0002237819791636297, 'lambda_2': 7.055374025254077e-09, 'compute_score': False, 'fit_intercept': False})
2025-03-20 19:53:52,673:INFO:Checking exceptions
2025-03-20 19:53:52,673:INFO:Importing libraries
2025-03-20 19:53:52,673:INFO:Copying training dataset
2025-03-20 19:53:52,674:INFO:Defining folds
2025-03-20 19:53:52,675:INFO:Declaring metric variables
2025-03-20 19:53:52,676:INFO:Importing untrained model
2025-03-20 19:53:52,676:INFO:Declaring custom model
2025-03-20 19:53:52,678:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:53:52,681:INFO:Starting cross validation
2025-03-20 19:53:52,682:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:52,744:INFO:Calculating mean and std
2025-03-20 19:53:52,744:INFO:Creating metrics dataframe
2025-03-20 19:53:52,747:INFO:Finalizing model
2025-03-20 19:53:52,783:INFO:Uploading results into container
2025-03-20 19:53:52,784:INFO:Uploading model into container now
2025-03-20 19:53:52,784:INFO:_master_model_container: 21
2025-03-20 19:53:52,784:INFO:_display_container: 3
2025-03-20 19:53:52,784:INFO:BayesianRidge(alpha_1=2.2822973510657272e-07, alpha_2=0.13134218272687026,
              fit_intercept=False, lambda_1=0.0002237819791636297,
              lambda_2=7.055374025254077e-09)
2025-03-20 19:53:52,784:INFO:create_model() successfully completed......................................
2025-03-20 19:53:52,840:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:52,840:INFO:choose_better activated
2025-03-20 19:53:52,841:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:52,842:INFO:Initializing create_model()
2025-03-20 19:53:52,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:52,842:INFO:Checking exceptions
2025-03-20 19:53:52,843:INFO:Importing libraries
2025-03-20 19:53:52,843:INFO:Copying training dataset
2025-03-20 19:53:52,845:INFO:Defining folds
2025-03-20 19:53:52,845:INFO:Declaring metric variables
2025-03-20 19:53:52,845:INFO:Importing untrained model
2025-03-20 19:53:52,845:INFO:Declaring custom model
2025-03-20 19:53:52,845:INFO:Bayesian Ridge Imported successfully
2025-03-20 19:53:52,845:INFO:Starting cross validation
2025-03-20 19:53:52,845:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:52,928:INFO:Calculating mean and std
2025-03-20 19:53:52,929:INFO:Creating metrics dataframe
2025-03-20 19:53:52,930:INFO:Finalizing model
2025-03-20 19:53:52,969:INFO:Uploading results into container
2025-03-20 19:53:52,969:INFO:Uploading model into container now
2025-03-20 19:53:52,969:INFO:_master_model_container: 22
2025-03-20 19:53:52,970:INFO:_display_container: 4
2025-03-20 19:53:52,970:INFO:BayesianRidge()
2025-03-20 19:53:52,970:INFO:create_model() successfully completed......................................
2025-03-20 19:53:53,025:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:53,025:INFO:BayesianRidge() result for MAPE is 0.0211
2025-03-20 19:53:53,025:INFO:BayesianRidge(alpha_1=2.2822973510657272e-07, alpha_2=0.13134218272687026,
              fit_intercept=False, lambda_1=0.0002237819791636297,
              lambda_2=7.055374025254077e-09) result for MAPE is 0.0596
2025-03-20 19:53:53,025:INFO:BayesianRidge() is best model
2025-03-20 19:53:53,025:INFO:choose_better completed
2025-03-20 19:53:53,026:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 19:53:53,026:INFO:Creating Dashboard logs
2025-03-20 19:53:53,028:INFO:Model: Bayesian Ridge
2025-03-20 19:53:53,049:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 19:53:53,242:INFO:Initializing predict_model()
2025-03-20 19:53:53,242:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF6D1DC4C0>)
2025-03-20 19:53:53,243:INFO:Checking exceptions
2025-03-20 19:53:53,243:INFO:Preloading libraries
2025-03-20 19:53:53,384:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:53,388:INFO:_master_model_container: 22
2025-03-20 19:53:53,388:INFO:_display_container: 3
2025-03-20 19:53:53,388:INFO:BayesianRidge()
2025-03-20 19:53:53,388:INFO:tune_model() successfully completed......................................
2025-03-20 19:53:53,441:INFO:Initializing predict_model()
2025-03-20 19:53:53,441:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF7E63F3A0>)
2025-03-20 19:53:53,441:INFO:Checking exceptions
2025-03-20 19:53:53,441:INFO:Preloading libraries
2025-03-20 19:53:53,567:INFO:Initializing tune_model()
2025-03-20 19:53:53,567:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=1, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>)
2025-03-20 19:53:53,567:INFO:Checking exceptions
2025-03-20 19:53:53,567:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:53:53,577:INFO:Copying training dataset
2025-03-20 19:53:53,579:INFO:Checking base model
2025-03-20 19:53:53,579:INFO:Base model : Gradient Boosting Regressor
2025-03-20 19:53:53,581:INFO:Declaring metric variables
2025-03-20 19:53:53,583:INFO:Defining Hyperparameters
2025-03-20 19:53:53,637:INFO:Tuning with n_jobs=-1
2025-03-20 19:53:53,638:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:53,638:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:53,638:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:53:53,638:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:53,638:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:53:53,638:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:53:54,427:INFO:best_params: {'actual_estimator__n_estimators': 274, 'actual_estimator__learning_rate': 0.018369665607816426, 'actual_estimator__subsample': 0.259374807731568, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__max_depth': 2, 'actual_estimator__max_features': 0.43935441983985374, 'actual_estimator__min_impurity_decrease': 4.7637313820104854e-07}
2025-03-20 19:53:54,427:INFO:Hyperparameter search completed
2025-03-20 19:53:54,427:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:54,427:INFO:Initializing create_model()
2025-03-20 19:53:54,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF674EC5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 274, 'learning_rate': 0.018369665607816426, 'subsample': 0.259374807731568, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_depth': 2, 'max_features': 0.43935441983985374, 'min_impurity_decrease': 4.7637313820104854e-07})
2025-03-20 19:53:54,427:INFO:Checking exceptions
2025-03-20 19:53:54,427:INFO:Importing libraries
2025-03-20 19:53:54,427:INFO:Copying training dataset
2025-03-20 19:53:54,429:INFO:Defining folds
2025-03-20 19:53:54,429:INFO:Declaring metric variables
2025-03-20 19:53:54,431:INFO:Importing untrained model
2025-03-20 19:53:54,431:INFO:Declaring custom model
2025-03-20 19:53:54,433:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:53:54,436:INFO:Starting cross validation
2025-03-20 19:53:54,437:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:54,684:INFO:Calculating mean and std
2025-03-20 19:53:54,685:INFO:Creating metrics dataframe
2025-03-20 19:53:54,687:INFO:Finalizing model
2025-03-20 19:53:54,913:INFO:Uploading results into container
2025-03-20 19:53:54,914:INFO:Uploading model into container now
2025-03-20 19:53:54,914:INFO:_master_model_container: 23
2025-03-20 19:53:54,914:INFO:_display_container: 5
2025-03-20 19:53:54,915:INFO:GradientBoostingRegressor(learning_rate=0.018369665607816426, max_depth=2,
                          max_features=0.43935441983985374,
                          min_impurity_decrease=4.7637313820104854e-07,
                          min_samples_leaf=5, min_samples_split=5,
                          n_estimators=274, random_state=888,
                          subsample=0.259374807731568)
2025-03-20 19:53:54,915:INFO:create_model() successfully completed......................................
2025-03-20 19:53:54,970:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:54,970:INFO:choose_better activated
2025-03-20 19:53:54,973:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:54,973:INFO:Initializing create_model()
2025-03-20 19:53:54,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:54,973:INFO:Checking exceptions
2025-03-20 19:53:54,974:INFO:Importing libraries
2025-03-20 19:53:54,974:INFO:Copying training dataset
2025-03-20 19:53:54,976:INFO:Defining folds
2025-03-20 19:53:54,976:INFO:Declaring metric variables
2025-03-20 19:53:54,976:INFO:Importing untrained model
2025-03-20 19:53:54,976:INFO:Declaring custom model
2025-03-20 19:53:54,976:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:53:54,976:INFO:Starting cross validation
2025-03-20 19:53:54,977:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:55,592:INFO:Calculating mean and std
2025-03-20 19:53:55,593:INFO:Creating metrics dataframe
2025-03-20 19:53:55,594:INFO:Finalizing model
2025-03-20 19:53:56,274:INFO:Uploading results into container
2025-03-20 19:53:56,275:INFO:Uploading model into container now
2025-03-20 19:53:56,275:INFO:_master_model_container: 24
2025-03-20 19:53:56,275:INFO:_display_container: 6
2025-03-20 19:53:56,275:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:53:56,275:INFO:create_model() successfully completed......................................
2025-03-20 19:53:56,331:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:56,331:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.0217
2025-03-20 19:53:56,332:INFO:GradientBoostingRegressor(learning_rate=0.018369665607816426, max_depth=2,
                          max_features=0.43935441983985374,
                          min_impurity_decrease=4.7637313820104854e-07,
                          min_samples_leaf=5, min_samples_split=5,
                          n_estimators=274, random_state=888,
                          subsample=0.259374807731568) result for MAPE is 0.0223
2025-03-20 19:53:56,332:INFO:GradientBoostingRegressor(random_state=888) is best model
2025-03-20 19:53:56,332:INFO:choose_better completed
2025-03-20 19:53:56,332:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 19:53:56,332:INFO:Creating Dashboard logs
2025-03-20 19:53:56,335:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:53:56,355:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:53:56,570:INFO:Initializing predict_model()
2025-03-20 19:53:56,570:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF6D227D30>)
2025-03-20 19:53:56,570:INFO:Checking exceptions
2025-03-20 19:53:56,570:INFO:Preloading libraries
2025-03-20 19:53:56,712:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:56,717:INFO:_master_model_container: 24
2025-03-20 19:53:56,717:INFO:_display_container: 5
2025-03-20 19:53:56,717:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:53:56,717:INFO:tune_model() successfully completed......................................
2025-03-20 19:53:56,771:INFO:Initializing predict_model()
2025-03-20 19:53:56,771:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF67503550>)
2025-03-20 19:53:56,771:INFO:Checking exceptions
2025-03-20 19:53:56,771:INFO:Preloading libraries
2025-03-20 19:53:56,900:INFO:Initializing tune_model()
2025-03-20 19:53:56,900:INFO:tune_model(estimator=Ridge(random_state=888), fold=None, round=4, n_iter=1, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>)
2025-03-20 19:53:56,900:INFO:Checking exceptions
2025-03-20 19:53:56,900:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:53:56,908:INFO:Copying training dataset
2025-03-20 19:53:56,911:INFO:Checking base model
2025-03-20 19:53:56,911:INFO:Base model : Ridge Regression
2025-03-20 19:53:56,914:INFO:Declaring metric variables
2025-03-20 19:53:56,916:INFO:Defining Hyperparameters
2025-03-20 19:53:56,973:INFO:Tuning with n_jobs=-1
2025-03-20 19:53:56,974:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:56,974:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:56,974:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:53:56,974:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:56,974:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:53:56,974:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:53:57,180:INFO:best_params: {'actual_estimator__alpha': 6.838529768909101, 'actual_estimator__fit_intercept': True}
2025-03-20 19:53:57,180:INFO:Hyperparameter search completed
2025-03-20 19:53:57,180:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:57,180:INFO:Initializing create_model()
2025-03-20 19:53:57,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF67508310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 6.838529768909101, 'fit_intercept': True})
2025-03-20 19:53:57,180:INFO:Checking exceptions
2025-03-20 19:53:57,181:INFO:Importing libraries
2025-03-20 19:53:57,181:INFO:Copying training dataset
2025-03-20 19:53:57,182:INFO:Defining folds
2025-03-20 19:53:57,182:INFO:Declaring metric variables
2025-03-20 19:53:57,184:INFO:Importing untrained model
2025-03-20 19:53:57,184:INFO:Declaring custom model
2025-03-20 19:53:57,186:INFO:Ridge Regression Imported successfully
2025-03-20 19:53:57,189:INFO:Starting cross validation
2025-03-20 19:53:57,190:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:57,270:INFO:Calculating mean and std
2025-03-20 19:53:57,271:INFO:Creating metrics dataframe
2025-03-20 19:53:57,273:INFO:Finalizing model
2025-03-20 19:53:57,306:INFO:Uploading results into container
2025-03-20 19:53:57,306:INFO:Uploading model into container now
2025-03-20 19:53:57,306:INFO:_master_model_container: 25
2025-03-20 19:53:57,306:INFO:_display_container: 7
2025-03-20 19:53:57,307:INFO:Ridge(alpha=6.838529768909101, random_state=888)
2025-03-20 19:53:57,307:INFO:create_model() successfully completed......................................
2025-03-20 19:53:57,375:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:57,375:INFO:choose_better activated
2025-03-20 19:53:57,378:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:57,378:INFO:Initializing create_model()
2025-03-20 19:53:57,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:57,378:INFO:Checking exceptions
2025-03-20 19:53:57,379:INFO:Importing libraries
2025-03-20 19:53:57,379:INFO:Copying training dataset
2025-03-20 19:53:57,381:INFO:Defining folds
2025-03-20 19:53:57,381:INFO:Declaring metric variables
2025-03-20 19:53:57,382:INFO:Importing untrained model
2025-03-20 19:53:57,382:INFO:Declaring custom model
2025-03-20 19:53:57,382:INFO:Ridge Regression Imported successfully
2025-03-20 19:53:57,382:INFO:Starting cross validation
2025-03-20 19:53:57,383:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:57,455:INFO:Calculating mean and std
2025-03-20 19:53:57,456:INFO:Creating metrics dataframe
2025-03-20 19:53:57,457:INFO:Finalizing model
2025-03-20 19:53:57,486:INFO:Uploading results into container
2025-03-20 19:53:57,487:INFO:Uploading model into container now
2025-03-20 19:53:57,487:INFO:_master_model_container: 26
2025-03-20 19:53:57,487:INFO:_display_container: 8
2025-03-20 19:53:57,487:INFO:Ridge(random_state=888)
2025-03-20 19:53:57,487:INFO:create_model() successfully completed......................................
2025-03-20 19:53:57,545:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:57,546:INFO:Ridge(random_state=888) result for MAPE is 0.0222
2025-03-20 19:53:57,546:INFO:Ridge(alpha=6.838529768909101, random_state=888) result for MAPE is 0.0302
2025-03-20 19:53:57,546:INFO:Ridge(random_state=888) is best model
2025-03-20 19:53:57,546:INFO:choose_better completed
2025-03-20 19:53:57,546:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 19:53:57,546:INFO:Creating Dashboard logs
2025-03-20 19:53:57,549:INFO:Model: Ridge Regression
2025-03-20 19:53:57,570:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 19:53:57,774:INFO:Initializing predict_model()
2025-03-20 19:53:57,774:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF6D2270D0>)
2025-03-20 19:53:57,775:INFO:Checking exceptions
2025-03-20 19:53:57,775:INFO:Preloading libraries
2025-03-20 19:53:57,916:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:53:57,920:INFO:_master_model_container: 26
2025-03-20 19:53:57,920:INFO:_display_container: 7
2025-03-20 19:53:57,921:INFO:Ridge(random_state=888)
2025-03-20 19:53:57,921:INFO:tune_model() successfully completed......................................
2025-03-20 19:53:57,976:INFO:Initializing predict_model()
2025-03-20 19:53:57,976:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF6CF2CB80>)
2025-03-20 19:53:57,976:INFO:Checking exceptions
2025-03-20 19:53:57,976:INFO:Preloading libraries
2025-03-20 19:53:58,110:INFO:Initializing tune_model()
2025-03-20 19:53:58,111:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=1, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>)
2025-03-20 19:53:58,111:INFO:Checking exceptions
2025-03-20 19:53:58,111:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:53:58,119:INFO:Copying training dataset
2025-03-20 19:53:58,122:INFO:Checking base model
2025-03-20 19:53:58,122:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 19:53:58,124:INFO:Declaring metric variables
2025-03-20 19:53:58,126:INFO:Defining Hyperparameters
2025-03-20 19:53:58,184:INFO:Tuning with n_jobs=-1
2025-03-20 19:53:58,185:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:58,185:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:53:58,185:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:53:58,185:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:53:58,185:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:53:58,185:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:53:58,896:INFO:best_params: {'actual_estimator__num_leaves': 29, 'actual_estimator__learning_rate': 0.015417636154272347, 'actual_estimator__n_estimators': 96, 'actual_estimator__min_split_gain': 0.23227415085295844, 'actual_estimator__reg_alpha': 2.328056271075051e-07, 'actual_estimator__reg_lambda': 0.005811879214737407, 'actual_estimator__feature_fraction': 0.6040615241446243, 'actual_estimator__bagging_fraction': 0.6423447432605528, 'actual_estimator__bagging_freq': 6, 'actual_estimator__min_child_samples': 7}
2025-03-20 19:53:58,897:INFO:Hyperparameter search completed
2025-03-20 19:53:58,897:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:58,897:INFO:Initializing create_model()
2025-03-20 19:53:58,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF6750FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 29, 'learning_rate': 0.015417636154272347, 'n_estimators': 96, 'min_split_gain': 0.23227415085295844, 'reg_alpha': 2.328056271075051e-07, 'reg_lambda': 0.005811879214737407, 'feature_fraction': 0.6040615241446243, 'bagging_fraction': 0.6423447432605528, 'bagging_freq': 6, 'min_child_samples': 7})
2025-03-20 19:53:58,897:INFO:Checking exceptions
2025-03-20 19:53:58,897:INFO:Importing libraries
2025-03-20 19:53:58,897:INFO:Copying training dataset
2025-03-20 19:53:58,899:INFO:Defining folds
2025-03-20 19:53:58,900:INFO:Declaring metric variables
2025-03-20 19:53:58,902:INFO:Importing untrained model
2025-03-20 19:53:58,902:INFO:Declaring custom model
2025-03-20 19:53:58,905:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:53:58,909:INFO:Starting cross validation
2025-03-20 19:53:58,910:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:53:59,380:INFO:Calculating mean and std
2025-03-20 19:53:59,381:INFO:Creating metrics dataframe
2025-03-20 19:53:59,385:INFO:Finalizing model
2025-03-20 19:53:59,430:INFO:[LightGBM] [Warning] feature_fraction is set=0.6040615241446243, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040615241446243
2025-03-20 19:53:59,430:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6423447432605528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6423447432605528
2025-03-20 19:53:59,430:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 19:53:59,432:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:53:59,432:INFO:[LightGBM] [Warning] feature_fraction is set=0.6040615241446243, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040615241446243
2025-03-20 19:53:59,432:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6423447432605528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6423447432605528
2025-03-20 19:53:59,432:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-03-20 19:53:59,433:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-03-20 19:53:59,433:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:53:59,433:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:53:59,433:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:53:59,433:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:53:59,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 19:53:59,553:INFO:Uploading results into container
2025-03-20 19:53:59,553:INFO:Uploading model into container now
2025-03-20 19:53:59,554:INFO:_master_model_container: 27
2025-03-20 19:53:59,554:INFO:_display_container: 9
2025-03-20 19:53:59,554:INFO:LGBMRegressor(bagging_fraction=0.6423447432605528, bagging_freq=6,
              feature_fraction=0.6040615241446243,
              learning_rate=0.015417636154272347, min_child_samples=7,
              min_split_gain=0.23227415085295844, n_estimators=96, n_jobs=-1,
              num_leaves=29, random_state=888, reg_alpha=2.328056271075051e-07,
              reg_lambda=0.005811879214737407)
2025-03-20 19:53:59,555:INFO:create_model() successfully completed......................................
2025-03-20 19:53:59,620:INFO:SubProcess create_model() end ==================================
2025-03-20 19:53:59,620:INFO:choose_better activated
2025-03-20 19:53:59,623:INFO:SubProcess create_model() called ==================================
2025-03-20 19:53:59,623:INFO:Initializing create_model()
2025-03-20 19:53:59,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:53:59,624:INFO:Checking exceptions
2025-03-20 19:53:59,625:INFO:Importing libraries
2025-03-20 19:53:59,625:INFO:Copying training dataset
2025-03-20 19:53:59,628:INFO:Defining folds
2025-03-20 19:53:59,628:INFO:Declaring metric variables
2025-03-20 19:53:59,629:INFO:Importing untrained model
2025-03-20 19:53:59,629:INFO:Declaring custom model
2025-03-20 19:53:59,629:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:53:59,629:INFO:Starting cross validation
2025-03-20 19:53:59,631:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:00,103:INFO:Calculating mean and std
2025-03-20 19:54:00,104:INFO:Creating metrics dataframe
2025-03-20 19:54:00,105:INFO:Finalizing model
2025-03-20 19:54:00,144:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:54:00,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
2025-03-20 19:54:00,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:54:00,145:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 19:54:00,145:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 19:54:00,145:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 19:54:00,268:INFO:Uploading results into container
2025-03-20 19:54:00,269:INFO:Uploading model into container now
2025-03-20 19:54:00,269:INFO:_master_model_container: 28
2025-03-20 19:54:00,269:INFO:_display_container: 10
2025-03-20 19:54:00,269:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:54:00,269:INFO:create_model() successfully completed......................................
2025-03-20 19:54:00,337:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:00,337:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0233
2025-03-20 19:54:00,338:INFO:LGBMRegressor(bagging_fraction=0.6423447432605528, bagging_freq=6,
              feature_fraction=0.6040615241446243,
              learning_rate=0.015417636154272347, min_child_samples=7,
              min_split_gain=0.23227415085295844, n_estimators=96, n_jobs=-1,
              num_leaves=29, random_state=888, reg_alpha=2.328056271075051e-07,
              reg_lambda=0.005811879214737407) result for MAPE is 0.0294
2025-03-20 19:54:00,338:INFO:LGBMRegressor(n_jobs=-1, random_state=888) is best model
2025-03-20 19:54:00,338:INFO:choose_better completed
2025-03-20 19:54:00,339:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 19:54:00,339:INFO:Creating Dashboard logs
2025-03-20 19:54:00,341:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:54:00,369:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:54:00,601:INFO:Initializing predict_model()
2025-03-20 19:54:00,601:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF7957D4C0>)
2025-03-20 19:54:00,601:INFO:Checking exceptions
2025-03-20 19:54:00,601:INFO:Preloading libraries
2025-03-20 19:54:00,753:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:00,758:INFO:_master_model_container: 28
2025-03-20 19:54:00,759:INFO:_display_container: 9
2025-03-20 19:54:00,759:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:54:00,759:INFO:tune_model() successfully completed......................................
2025-03-20 19:54:00,840:INFO:Initializing predict_model()
2025-03-20 19:54:00,840:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF68DB2F70>)
2025-03-20 19:54:00,840:INFO:Checking exceptions
2025-03-20 19:54:00,840:INFO:Preloading libraries
2025-03-20 19:54:00,986:INFO:Initializing tune_model()
2025-03-20 19:54:00,986:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=None, round=4, n_iter=1, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>)
2025-03-20 19:54:00,986:INFO:Checking exceptions
2025-03-20 19:54:00,986:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 19:54:00,996:INFO:Copying training dataset
2025-03-20 19:54:00,999:INFO:Checking base model
2025-03-20 19:54:00,999:INFO:Base model : Extreme Gradient Boosting
2025-03-20 19:54:01,002:INFO:Declaring metric variables
2025-03-20 19:54:01,004:INFO:Defining Hyperparameters
2025-03-20 19:54:01,063:INFO:Tuning with n_jobs=-1
2025-03-20 19:54:01,064:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:54:01,064:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 19:54:01,064:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 19:54:01,064:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 19:54:01,065:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 19:54:01,065:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 19:54:01,717:INFO:best_params: {'actual_estimator__learning_rate': 2.7297040303278296e-05, 'actual_estimator__n_estimators': 128, 'actual_estimator__subsample': 0.9860048387559062, 'actual_estimator__max_depth': 2, 'actual_estimator__colsample_bytree': 0.7808459366605868, 'actual_estimator__min_child_weight': 3, 'actual_estimator__reg_alpha': 1.2215022028362604e-07, 'actual_estimator__reg_lambda': 2.4805808110360847, 'actual_estimator__scale_pos_weight': 41.07329457286953}
2025-03-20 19:54:01,717:INFO:Hyperparameter search completed
2025-03-20 19:54:01,717:INFO:SubProcess create_model() called ==================================
2025-03-20 19:54:01,717:INFO:Initializing create_model()
2025-03-20 19:54:01,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF674F89A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 2.7297040303278296e-05, 'n_estimators': 128, 'subsample': 0.9860048387559062, 'max_depth': 2, 'colsample_bytree': 0.7808459366605868, 'min_child_weight': 3, 'reg_alpha': 1.2215022028362604e-07, 'reg_lambda': 2.4805808110360847, 'scale_pos_weight': 41.07329457286953})
2025-03-20 19:54:01,717:INFO:Checking exceptions
2025-03-20 19:54:01,717:INFO:Importing libraries
2025-03-20 19:54:01,717:INFO:Copying training dataset
2025-03-20 19:54:01,719:INFO:Defining folds
2025-03-20 19:54:01,719:INFO:Declaring metric variables
2025-03-20 19:54:01,722:INFO:Importing untrained model
2025-03-20 19:54:01,722:INFO:Declaring custom model
2025-03-20 19:54:01,724:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:54:01,728:INFO:Starting cross validation
2025-03-20 19:54:01,729:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:02,043:INFO:Calculating mean and std
2025-03-20 19:54:02,044:INFO:Creating metrics dataframe
2025-03-20 19:54:02,047:INFO:Finalizing model
2025-03-20 19:54:02,141:INFO:Uploading results into container
2025-03-20 19:54:02,142:INFO:Uploading model into container now
2025-03-20 19:54:02,142:INFO:_master_model_container: 29
2025-03-20 19:54:02,142:INFO:_display_container: 11
2025-03-20 19:54:02,143:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.7808459366605868, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=2.7297040303278296e-05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=128, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:54:02,143:INFO:create_model() successfully completed......................................
2025-03-20 19:54:02,204:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:02,204:INFO:choose_better activated
2025-03-20 19:54:02,206:INFO:SubProcess create_model() called ==================================
2025-03-20 19:54:02,207:INFO:Initializing create_model()
2025-03-20 19:54:02,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:02,207:INFO:Checking exceptions
2025-03-20 19:54:02,208:INFO:Importing libraries
2025-03-20 19:54:02,208:INFO:Copying training dataset
2025-03-20 19:54:02,210:INFO:Defining folds
2025-03-20 19:54:02,210:INFO:Declaring metric variables
2025-03-20 19:54:02,210:INFO:Importing untrained model
2025-03-20 19:54:02,210:INFO:Declaring custom model
2025-03-20 19:54:02,211:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:54:02,211:INFO:Starting cross validation
2025-03-20 19:54:02,212:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:02,552:INFO:Calculating mean and std
2025-03-20 19:54:02,552:INFO:Creating metrics dataframe
2025-03-20 19:54:02,553:INFO:Finalizing model
2025-03-20 19:54:02,671:INFO:Uploading results into container
2025-03-20 19:54:02,671:INFO:Uploading model into container now
2025-03-20 19:54:02,672:INFO:_master_model_container: 30
2025-03-20 19:54:02,672:INFO:_display_container: 12
2025-03-20 19:54:02,672:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:54:02,672:INFO:create_model() successfully completed......................................
2025-03-20 19:54:02,737:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:02,738:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.0235
2025-03-20 19:54:02,739:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.7808459366605868, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=2.7297040303278296e-05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=3, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=128, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.0849
2025-03-20 19:54:02,739:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) is best model
2025-03-20 19:54:02,739:INFO:choose_better completed
2025-03-20 19:54:02,740:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 19:54:02,740:INFO:Creating Dashboard logs
2025-03-20 19:54:02,743:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:54:02,773:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:54:03,027:INFO:Initializing predict_model()
2025-03-20 19:54:03,027:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF7959F940>)
2025-03-20 19:54:03,027:INFO:Checking exceptions
2025-03-20 19:54:03,027:INFO:Preloading libraries
2025-03-20 19:54:03,189:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:03,194:INFO:_master_model_container: 30
2025-03-20 19:54:03,194:INFO:_display_container: 11
2025-03-20 19:54:03,195:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:54:03,195:INFO:tune_model() successfully completed......................................
2025-03-20 19:54:03,256:INFO:Initializing predict_model()
2025-03-20 19:54:03,257:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF6CF2CB80>)
2025-03-20 19:54:03,257:INFO:Checking exceptions
2025-03-20 19:54:03,257:INFO:Preloading libraries
2025-03-20 19:54:03,450:INFO:Initializing blend_models()
2025-03-20 19:54:03,450:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator_list=[GradientBoostingRegressor(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 19:54:03,450:INFO:Checking exceptions
2025-03-20 19:54:03,464:INFO:Importing libraries
2025-03-20 19:54:03,464:INFO:Copying training dataset
2025-03-20 19:54:03,467:INFO:Getting model names
2025-03-20 19:54:03,470:INFO:SubProcess create_model() called ==================================
2025-03-20 19:54:03,474:INFO:Initializing create_model()
2025-03-20 19:54:03,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF67508310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:03,474:INFO:Checking exceptions
2025-03-20 19:54:03,474:INFO:Importing libraries
2025-03-20 19:54:03,474:INFO:Copying training dataset
2025-03-20 19:54:03,476:INFO:Defining folds
2025-03-20 19:54:03,476:INFO:Declaring metric variables
2025-03-20 19:54:03,478:INFO:Importing untrained model
2025-03-20 19:54:03,478:INFO:Declaring custom model
2025-03-20 19:54:03,481:INFO:Voting Regressor Imported successfully
2025-03-20 19:54:03,484:INFO:Starting cross validation
2025-03-20 19:54:03,485:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:04,307:INFO:Calculating mean and std
2025-03-20 19:54:04,307:INFO:Creating metrics dataframe
2025-03-20 19:54:04,310:INFO:Finalizing model
2025-03-20 19:54:05,096:INFO:Uploading results into container
2025-03-20 19:54:05,096:INFO:Uploading model into container now
2025-03-20 19:54:05,097:INFO:_master_model_container: 31
2025-03-20 19:54:05,097:INFO:_display_container: 13
2025-03-20 19:54:05,100:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 19:54:05,100:INFO:create_model() successfully completed......................................
2025-03-20 19:54:05,154:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:05,154:INFO:Creating Dashboard logs
2025-03-20 19:54:05,156:INFO:Model: Voting Regressor
2025-03-20 19:54:05,179:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=888), 'Light Gradient Boosting Machine': LGBMRegressor(n_jobs=-1, random_state=888), 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.1, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': None, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.0, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 2, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 100, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 1.0, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 20, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.0, 'Light Gradient Boosting Machine__n_estimators': 100, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 31, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.0, 'Light Gradient Boosting Machine__reg_lambda': 0.0, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': None, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': None, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': None, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': None, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': None, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': None, 'Extreme Gradient Boosting__reg_lambda': None, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': None, 'Extreme Gradient Boosting__subsample': None, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0}
2025-03-20 19:54:05,472:INFO:Initializing predict_model()
2025-03-20 19:54:05,472:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF795A6C10>)
2025-03-20 19:54:05,472:INFO:Checking exceptions
2025-03-20 19:54:05,472:INFO:Preloading libraries
2025-03-20 19:54:05,637:ERROR:_log_model() for VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:05,642:INFO:_master_model_container: 31
2025-03-20 19:54:05,642:INFO:_display_container: 13
2025-03-20 19:54:05,647:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 19:54:05,647:INFO:blend_models() successfully completed......................................
2025-03-20 19:54:05,718:INFO:Initializing compare_models()
2025-03-20 19:54:05,718:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, include=[GradientBoostingRegressor(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, 'include': [GradientBoostingRegressor(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 19:54:05,718:INFO:Checking exceptions
2025-03-20 19:54:05,719:INFO:Preparing display monitor
2025-03-20 19:54:05,730:INFO:Initializing custom model Gradient Boosting Regressor
2025-03-20 19:54:05,730:INFO:Total runtime is 0.0 minutes
2025-03-20 19:54:05,732:INFO:SubProcess create_model() called ==================================
2025-03-20 19:54:05,732:INFO:Initializing create_model()
2025-03-20 19:54:05,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF687A4760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:05,732:INFO:Checking exceptions
2025-03-20 19:54:05,732:INFO:Importing libraries
2025-03-20 19:54:05,732:INFO:Copying training dataset
2025-03-20 19:54:05,734:INFO:Defining folds
2025-03-20 19:54:05,734:INFO:Declaring metric variables
2025-03-20 19:54:05,736:INFO:Importing untrained model
2025-03-20 19:54:05,736:INFO:Declaring custom model
2025-03-20 19:54:05,737:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:54:05,741:INFO:Starting cross validation
2025-03-20 19:54:05,742:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:06,370:INFO:Calculating mean and std
2025-03-20 19:54:06,370:INFO:Creating metrics dataframe
2025-03-20 19:54:06,372:INFO:Uploading results into container
2025-03-20 19:54:06,372:INFO:Uploading model into container now
2025-03-20 19:54:06,372:INFO:_master_model_container: 32
2025-03-20 19:54:06,372:INFO:_display_container: 14
2025-03-20 19:54:06,372:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:54:06,372:INFO:create_model() successfully completed......................................
2025-03-20 19:54:06,427:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:06,427:INFO:Creating metrics dataframe
2025-03-20 19:54:06,431:INFO:Initializing custom model Light Gradient Boosting Machine
2025-03-20 19:54:06,431:INFO:Total runtime is 0.01168826421101888 minutes
2025-03-20 19:54:06,434:INFO:SubProcess create_model() called ==================================
2025-03-20 19:54:06,434:INFO:Initializing create_model()
2025-03-20 19:54:06,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF687A4760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:06,434:INFO:Checking exceptions
2025-03-20 19:54:06,434:INFO:Importing libraries
2025-03-20 19:54:06,434:INFO:Copying training dataset
2025-03-20 19:54:06,436:INFO:Defining folds
2025-03-20 19:54:06,436:INFO:Declaring metric variables
2025-03-20 19:54:06,438:INFO:Importing untrained model
2025-03-20 19:54:06,439:INFO:Declaring custom model
2025-03-20 19:54:06,441:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:54:06,444:INFO:Starting cross validation
2025-03-20 19:54:06,445:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:06,893:INFO:Calculating mean and std
2025-03-20 19:54:06,894:INFO:Creating metrics dataframe
2025-03-20 19:54:06,896:INFO:Uploading results into container
2025-03-20 19:54:06,897:INFO:Uploading model into container now
2025-03-20 19:54:06,897:INFO:_master_model_container: 33
2025-03-20 19:54:06,897:INFO:_display_container: 14
2025-03-20 19:54:06,898:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:54:06,898:INFO:create_model() successfully completed......................................
2025-03-20 19:54:06,958:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:06,958:INFO:Creating metrics dataframe
2025-03-20 19:54:06,964:INFO:Initializing custom model Extreme Gradient Boosting
2025-03-20 19:54:06,964:INFO:Total runtime is 0.020570234457651774 minutes
2025-03-20 19:54:06,966:INFO:SubProcess create_model() called ==================================
2025-03-20 19:54:06,967:INFO:Initializing create_model()
2025-03-20 19:54:06,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF687A4760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:06,967:INFO:Checking exceptions
2025-03-20 19:54:06,967:INFO:Importing libraries
2025-03-20 19:54:06,967:INFO:Copying training dataset
2025-03-20 19:54:06,970:INFO:Defining folds
2025-03-20 19:54:06,970:INFO:Declaring metric variables
2025-03-20 19:54:06,972:INFO:Importing untrained model
2025-03-20 19:54:06,972:INFO:Declaring custom model
2025-03-20 19:54:06,975:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:54:06,979:INFO:Starting cross validation
2025-03-20 19:54:06,980:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:07,371:INFO:Calculating mean and std
2025-03-20 19:54:07,372:INFO:Creating metrics dataframe
2025-03-20 19:54:07,373:INFO:Uploading results into container
2025-03-20 19:54:07,374:INFO:Uploading model into container now
2025-03-20 19:54:07,374:INFO:_master_model_container: 34
2025-03-20 19:54:07,374:INFO:_display_container: 14
2025-03-20 19:54:07,374:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:54:07,374:INFO:create_model() successfully completed......................................
2025-03-20 19:54:07,429:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:07,429:INFO:Creating metrics dataframe
2025-03-20 19:54:07,434:INFO:Initializing custom model Voting Regressor
2025-03-20 19:54:07,434:INFO:Total runtime is 0.02840285301208496 minutes
2025-03-20 19:54:07,436:INFO:SubProcess create_model() called ==================================
2025-03-20 19:54:07,439:INFO:Initializing create_model()
2025-03-20 19:54:07,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AF687A4760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:07,439:INFO:Checking exceptions
2025-03-20 19:54:07,439:INFO:Importing libraries
2025-03-20 19:54:07,439:INFO:Copying training dataset
2025-03-20 19:54:07,441:INFO:Defining folds
2025-03-20 19:54:07,441:INFO:Declaring metric variables
2025-03-20 19:54:07,443:INFO:Importing untrained model
2025-03-20 19:54:07,443:INFO:Declaring custom model
2025-03-20 19:54:07,445:INFO:Voting Regressor Imported successfully
2025-03-20 19:54:07,449:INFO:Starting cross validation
2025-03-20 19:54:07,449:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 19:54:08,587:INFO:Calculating mean and std
2025-03-20 19:54:08,588:INFO:Creating metrics dataframe
2025-03-20 19:54:08,590:INFO:Uploading results into container
2025-03-20 19:54:08,590:INFO:Uploading model into container now
2025-03-20 19:54:08,591:INFO:_master_model_container: 35
2025-03-20 19:54:08,591:INFO:_display_container: 14
2025-03-20 19:54:08,594:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 19:54:08,594:INFO:create_model() successfully completed......................................
2025-03-20 19:54:08,652:INFO:SubProcess create_model() end ==================================
2025-03-20 19:54:08,652:INFO:Creating metrics dataframe
2025-03-20 19:54:08,661:INFO:Initializing create_model()
2025-03-20 19:54:08,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:08,662:INFO:Checking exceptions
2025-03-20 19:54:08,662:INFO:Importing libraries
2025-03-20 19:54:08,662:INFO:Copying training dataset
2025-03-20 19:54:08,664:INFO:Defining folds
2025-03-20 19:54:08,664:INFO:Declaring metric variables
2025-03-20 19:54:08,664:INFO:Importing untrained model
2025-03-20 19:54:08,664:INFO:Declaring custom model
2025-03-20 19:54:08,665:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:54:08,665:INFO:Cross validation set to False
2025-03-20 19:54:08,665:INFO:Fitting Model
2025-03-20 19:54:09,342:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:54:09,342:INFO:create_model() successfully completed......................................
2025-03-20 19:54:09,401:INFO:Creating Dashboard logs
2025-03-20 19:54:09,403:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:54:09,426:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:54:09,692:INFO:Initializing predict_model()
2025-03-20 19:54:09,692:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AF7959F940>)
2025-03-20 19:54:09,692:INFO:Checking exceptions
2025-03-20 19:54:09,692:INFO:Preloading libraries
2025-03-20 19:54:09,829:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:09,829:INFO:Creating Dashboard logs
2025-03-20 19:54:09,831:INFO:Model: Voting Regressor
2025-03-20 19:54:09,852:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=888), 'Light Gradient Boosting Machine': LGBMRegressor(n_jobs=-1, random_state=888), 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.1, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': None, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.0, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 2, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 100, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 1.0, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 20, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.0, 'Light Gradient Boosting Machine__n_estimators': 100, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 31, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.0, 'Light Gradient Boosting Machine__reg_lambda': 0.0, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': None, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': None, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': None, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': None, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': None, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': None, 'Extreme Gradient Boosting__reg_lambda': None, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': None, 'Extreme Gradient Boosting__subsample': None, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0}
2025-03-20 19:54:10,182:ERROR:_log_model() for VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:10,182:INFO:Creating Dashboard logs
2025-03-20 19:54:10,184:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:54:10,207:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:54:10,512:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:10,513:INFO:Creating Dashboard logs
2025-03-20 19:54:10,515:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:54:10,535:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:54:10,832:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:10,839:INFO:_master_model_container: 35
2025-03-20 19:54:10,839:INFO:_display_container: 14
2025-03-20 19:54:10,839:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 19:54:10,839:INFO:compare_models() successfully completed......................................
2025-03-20 19:54:10,949:INFO:Initializing finalize_model()
2025-03-20 19:54:10,950:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:54:10,950:INFO:Finalizing GradientBoostingRegressor(random_state=888)
2025-03-20 19:54:10,952:INFO:Initializing create_model()
2025-03-20 19:54:10,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:10,952:INFO:Checking exceptions
2025-03-20 19:54:10,952:INFO:Importing libraries
2025-03-20 19:54:10,953:INFO:Copying training dataset
2025-03-20 19:54:10,953:INFO:Defining folds
2025-03-20 19:54:10,953:INFO:Declaring metric variables
2025-03-20 19:54:10,953:INFO:Importing untrained model
2025-03-20 19:54:10,953:INFO:Declaring custom model
2025-03-20 19:54:10,953:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 19:54:10,954:INFO:Cross validation set to False
2025-03-20 19:54:10,954:INFO:Fitting Model
2025-03-20 19:54:11,820:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=888))])
2025-03-20 19:54:11,820:INFO:create_model() successfully completed......................................
2025-03-20 19:54:11,878:INFO:Creating Dashboard logs
2025-03-20 19:54:11,878:INFO:Model: Gradient Boosting Regressor
2025-03-20 19:54:11,897:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 19:54:12,191:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=888))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:12,191:INFO:_master_model_container: 35
2025-03-20 19:54:12,191:INFO:_display_container: 14
2025-03-20 19:54:12,196:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=888))])
2025-03-20 19:54:12,196:INFO:finalize_model() successfully completed......................................
2025-03-20 19:54:12,260:INFO:Initializing save_model()
2025-03-20 19:54:12,260:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=888))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_195410, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:54:12,261:INFO:Adding model into prep_pipe
2025-03-20 19:54:12,261:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:54:12,266:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_195410.pkl saved in current working directory
2025-03-20 19:54:12,271:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=888))])
2025-03-20 19:54:12,271:INFO:save_model() successfully completed......................................
2025-03-20 19:54:12,328:INFO:Initializing finalize_model()
2025-03-20 19:54:12,328:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:54:12,328:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 19:54:12,329:INFO:Initializing create_model()
2025-03-20 19:54:12,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:12,329:INFO:Checking exceptions
2025-03-20 19:54:12,330:INFO:Importing libraries
2025-03-20 19:54:12,330:INFO:Copying training dataset
2025-03-20 19:54:12,331:INFO:Defining folds
2025-03-20 19:54:12,331:INFO:Declaring metric variables
2025-03-20 19:54:12,331:INFO:Importing untrained model
2025-03-20 19:54:12,331:INFO:Declaring custom model
2025-03-20 19:54:12,331:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 19:54:12,332:INFO:Cross validation set to False
2025-03-20 19:54:12,332:INFO:Fitting Model
2025-03-20 19:54:12,364:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 19:54:12,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
2025-03-20 19:54:12,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 19:54:12,365:INFO:[LightGBM] [Info] Total Bins 4616
2025-03-20 19:54:12,365:INFO:[LightGBM] [Info] Number of data points in the train set: 1769, number of used features: 37
2025-03-20 19:54:12,365:INFO:[LightGBM] [Info] Start training from score 15.920889
2025-03-20 19:54:12,453:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=888))])
2025-03-20 19:54:12,453:INFO:create_model() successfully completed......................................
2025-03-20 19:54:12,522:INFO:Creating Dashboard logs
2025-03-20 19:54:12,522:INFO:Model: Light Gradient Boosting Machine
2025-03-20 19:54:12,552:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 19:54:12,888:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=888))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:12,888:INFO:_master_model_container: 35
2025-03-20 19:54:12,888:INFO:_display_container: 14
2025-03-20 19:54:12,893:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=888))])
2025-03-20 19:54:12,893:INFO:finalize_model() successfully completed......................................
2025-03-20 19:54:12,971:INFO:Initializing save_model()
2025-03-20 19:54:12,971:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=888))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_195412, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:54:12,971:INFO:Adding model into prep_pipe
2025-03-20 19:54:12,971:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:54:12,979:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_195412.pkl saved in current working directory
2025-03-20 19:54:12,985:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=888))])
2025-03-20 19:54:12,985:INFO:save_model() successfully completed......................................
2025-03-20 19:54:13,050:INFO:Initializing finalize_model()
2025-03-20 19:54:13,050:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:54:13,051:INFO:Finalizing XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 19:54:13,053:INFO:Initializing create_model()
2025-03-20 19:54:13,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:13,053:INFO:Checking exceptions
2025-03-20 19:54:13,054:INFO:Importing libraries
2025-03-20 19:54:13,054:INFO:Copying training dataset
2025-03-20 19:54:13,054:INFO:Defining folds
2025-03-20 19:54:13,054:INFO:Declaring metric variables
2025-03-20 19:54:13,055:INFO:Importing untrained model
2025-03-20 19:54:13,055:INFO:Declaring custom model
2025-03-20 19:54:13,056:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 19:54:13,057:INFO:Cross validation set to False
2025-03-20 19:54:13,057:INFO:Fitting Model
2025-03-20 19:54:13,202:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))])
2025-03-20 19:54:13,202:INFO:create_model() successfully completed......................................
2025-03-20 19:54:13,273:INFO:Creating Dashboard logs
2025-03-20 19:54:13,273:INFO:Model: Extreme Gradient Boosting
2025-03-20 19:54:13,302:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 19:54:13,662:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:13,662:INFO:_master_model_container: 35
2025-03-20 19:54:13,662:INFO:_display_container: 14
2025-03-20 19:54:13,668:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))])
2025-03-20 19:54:13,668:INFO:finalize_model() successfully completed......................................
2025-03-20 19:54:13,744:INFO:Initializing save_model()
2025-03-20 19:54:13,744:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\xgboost_250320_195413, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:54:13,744:INFO:Adding model into prep_pipe
2025-03-20 19:54:13,744:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:54:13,750:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\xgboost_250320_195413.pkl saved in current working directory
2025-03-20 19:54:13,759:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))])
2025-03-20 19:54:13,759:INFO:save_model() successfully completed......................................
2025-03-20 19:54:13,830:INFO:Initializing finalize_model()
2025-03-20 19:54:13,830:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 19:54:13,834:INFO:Finalizing VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 19:54:13,840:INFO:Initializing create_model()
2025-03-20 19:54:13,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AF7E624AF0>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=888)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=888)),
                            ('Extreme Gradient Boosting',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, device='cpu',
                                          early...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=None, max_bin=None,
                                          max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None,
                                          n_estimators=None, n_jobs=-1,
                                          num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 19:54:13,840:INFO:Checking exceptions
2025-03-20 19:54:13,841:INFO:Importing libraries
2025-03-20 19:54:13,841:INFO:Copying training dataset
2025-03-20 19:54:13,841:INFO:Defining folds
2025-03-20 19:54:13,841:INFO:Declaring metric variables
2025-03-20 19:54:13,841:INFO:Importing untrained model
2025-03-20 19:54:13,841:INFO:Declaring custom model
2025-03-20 19:54:13,843:INFO:Voting Regressor Imported successfully
2025-03-20 19:54:13,844:INFO:Cross validation set to False
2025-03-20 19:54:13,844:INFO:Fitting Model
2025-03-20 19:54:14,851:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=None,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=None,
                                                           max_leaves=None,
                                                           min_child_weight=None,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=None,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))])
2025-03-20 19:54:14,851:INFO:create_model() successfully completed......................................
2025-03-20 19:54:14,908:INFO:Creating Dashboard logs
2025-03-20 19:54:14,909:INFO:Model: Voting Regressor
2025-03-20 19:54:14,937:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=888), 'Light Gradient Boosting Machine': LGBMRegressor(n_jobs=-1, random_state=888), 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.1, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 3, 'Gradient Boosting Regressor__max_features': None, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 0.0, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 2, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 100, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 1.0, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.1, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 20, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.0, 'Light Gradient Boosting Machine__n_estimators': 100, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 31, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.0, 'Light Gradient Boosting Machine__reg_lambda': 0.0, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': None, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': None, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': None, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': None, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': None, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': None, 'Extreme Gradient Boosting__reg_lambda': None, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': None, 'Extreme Gradient Boosting__subsample': None, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0}
2025-03-20 19:54:15,350:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=None,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=None,
                                                           max_leaves=None,
                                                           min_child_weight=None,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=None,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 19:54:15,350:INFO:_master_model_container: 35
2025-03-20 19:54:15,350:INFO:_display_container: 14
2025-03-20 19:54:15,364:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=None,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=None,
                                                           max_leaves=None,
                                                           min_child_weight=None,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=None,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))])
2025-03-20 19:54:15,365:INFO:finalize_model() successfully completed......................................
2025-03-20 19:54:15,456:INFO:Initializing save_model()
2025-03-20 19:54:15,456:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=None,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=None,
                                                           max_leaves=None,
                                                           min_child_weight=None,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=None,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_195413, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 19:54:15,456:INFO:Adding model into prep_pipe
2025-03-20 19:54:15,456:WARNING:Only Model saved as it was a pipeline.
2025-03-20 19:54:15,468:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_195413.pkl saved in current working directory
2025-03-20 19:54:15,487:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=None,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=None,
                                                           max_leaves=None,
                                                           min_child_weight=None,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=None,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))])
2025-03-20 19:54:15,487:INFO:save_model() successfully completed......................................
2025-03-20 19:55:24,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:55:24,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:55:24,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:55:24,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 19:55:24,345:INFO:Initializing load_model()
2025-03-20 19:55:24,345:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_195410, platform=None, authentication=None, verbose=True)
2025-03-20 19:55:24,953:INFO:Initializing predict_model()
2025-03-20 19:55:24,953:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000287A9BC15E0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=888))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002878F28D9D0>)
2025-03-20 19:55:24,953:INFO:Checking exceptions
2025-03-20 19:55:24,953:INFO:Preloading libraries
2025-03-20 19:55:24,953:INFO:Set up data.
2025-03-20 19:55:24,958:INFO:Set up index.
2025-03-20 19:55:25,013:INFO:Initializing load_model()
2025-03-20 19:55:25,013:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_195410, platform=None, authentication=None, verbose=True)
2025-03-20 19:55:25,022:INFO:Initializing predict_model()
2025-03-20 19:55:25,022:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002878E48AFD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=888))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002878F28D9D0>)
2025-03-20 19:55:25,022:INFO:Checking exceptions
2025-03-20 19:55:25,022:INFO:Preloading libraries
2025-03-20 19:55:25,022:INFO:Set up data.
2025-03-20 19:55:25,027:INFO:Set up index.
2025-03-20 19:55:28,393:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 19:55:30,591:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 20:01:20,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 20:01:20,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 20:01:20,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 20:01:20,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 20:01:21,140:INFO:PyCaret RegressionExperiment
2025-03-20 20:01:21,140:INFO:Logging name: reg-default-name
2025-03-20 20:01:21,140:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-20 20:01:21,140:INFO:version 3.2.0
2025-03-20 20:01:21,140:INFO:Initializing setup()
2025-03-20 20:01:21,140:INFO:self.USI: fb54
2025-03-20 20:01:21,140:INFO:self._variable_keys: {'gpu_n_jobs_param', 'USI', 'gpu_param', 'html_param', '_ml_usecase', 'y', 'X_train', 'exp_id', 'transform_target_param', 'y_test', 'n_jobs_param', 'target_param', 'y_train', 'fold_generator', 'X', 'log_plots_param', 'exp_name_log', 'fold_shuffle_param', 'X_test', 'seed', 'pipeline', '_available_plots', 'data', 'fold_groups_param', 'logging_param', 'memory', 'idx'}
2025-03-20 20:01:21,140:INFO:Checking environment
2025-03-20 20:01:21,140:INFO:python_version: 3.8.20
2025-03-20 20:01:21,140:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-20 20:01:21,140:INFO:machine: AMD64
2025-03-20 20:01:21,140:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-20 20:01:21,147:INFO:Memory: svmem(total=68447973376, available=40623063040, percent=40.7, used=27824910336, free=40623063040)
2025-03-20 20:01:21,147:INFO:Physical Core: 24
2025-03-20 20:01:21,147:INFO:Logical Core: 32
2025-03-20 20:01:21,147:INFO:Checking libraries
2025-03-20 20:01:21,147:INFO:System:
2025-03-20 20:01:21,147:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-20 20:01:21,147:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-20 20:01:21,147:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-20 20:01:21,147:INFO:PyCaret required dependencies:
2025-03-20 20:01:21,670:INFO:                 pip: 24.2
2025-03-20 20:01:21,670:INFO:          setuptools: 75.1.0
2025-03-20 20:01:21,670:INFO:             pycaret: 3.2.0
2025-03-20 20:01:21,670:INFO:             IPython: 8.12.3
2025-03-20 20:01:21,670:INFO:          ipywidgets: 8.1.5
2025-03-20 20:01:21,670:INFO:                tqdm: 4.67.1
2025-03-20 20:01:21,670:INFO:               numpy: 1.24.4
2025-03-20 20:01:21,671:INFO:              pandas: 1.5.3
2025-03-20 20:01:21,671:INFO:              jinja2: 3.1.4
2025-03-20 20:01:21,671:INFO:               scipy: 1.10.1
2025-03-20 20:01:21,671:INFO:              joblib: 1.3.2
2025-03-20 20:01:21,671:INFO:             sklearn: 1.2.2
2025-03-20 20:01:21,671:INFO:                pyod: 2.0.2
2025-03-20 20:01:21,671:INFO:            imblearn: 0.12.4
2025-03-20 20:01:21,671:INFO:   category_encoders: 2.6.4
2025-03-20 20:01:21,671:INFO:            lightgbm: 4.5.0
2025-03-20 20:01:21,671:INFO:               numba: 0.58.1
2025-03-20 20:01:21,671:INFO:            requests: 2.32.3
2025-03-20 20:01:21,671:INFO:          matplotlib: 3.6.0
2025-03-20 20:01:21,671:INFO:          scikitplot: 0.3.7
2025-03-20 20:01:21,671:INFO:         yellowbrick: 1.5
2025-03-20 20:01:21,671:INFO:              plotly: 5.24.1
2025-03-20 20:01:21,671:INFO:    plotly-resampler: Not installed
2025-03-20 20:01:21,671:INFO:             kaleido: 0.2.1
2025-03-20 20:01:21,671:INFO:           schemdraw: 0.15
2025-03-20 20:01:21,671:INFO:         statsmodels: 0.14.1
2025-03-20 20:01:21,671:INFO:              sktime: 0.21.1
2025-03-20 20:01:21,671:INFO:               tbats: 1.1.3
2025-03-20 20:01:21,671:INFO:            pmdarima: 2.0.4
2025-03-20 20:01:21,671:INFO:              psutil: 6.1.0
2025-03-20 20:01:21,671:INFO:          markupsafe: 2.1.5
2025-03-20 20:01:21,671:INFO:             pickle5: Not installed
2025-03-20 20:01:21,671:INFO:         cloudpickle: 2.2.1
2025-03-20 20:01:21,671:INFO:         deprecation: 2.1.0
2025-03-20 20:01:21,671:INFO:              xxhash: 3.5.0
2025-03-20 20:01:21,671:INFO:           wurlitzer: Not installed
2025-03-20 20:01:21,671:INFO:PyCaret optional dependencies:
2025-03-20 20:01:23,159:INFO:                shap: 0.44.1
2025-03-20 20:01:23,159:INFO:           interpret: 0.6.6
2025-03-20 20:01:23,159:INFO:                umap: 0.5.7
2025-03-20 20:01:23,159:INFO:     ydata_profiling: 4.6.0
2025-03-20 20:01:23,159:INFO:  explainerdashboard: 0.4.7
2025-03-20 20:01:23,159:INFO:             autoviz: Not installed
2025-03-20 20:01:23,159:INFO:           fairlearn: 0.7.0
2025-03-20 20:01:23,159:INFO:          deepchecks: Not installed
2025-03-20 20:01:23,159:INFO:             xgboost: 2.1.3
2025-03-20 20:01:23,159:INFO:            catboost: 1.2.7
2025-03-20 20:01:23,159:INFO:              kmodes: 0.12.2
2025-03-20 20:01:23,159:INFO:             mlxtend: 0.23.1
2025-03-20 20:01:23,159:INFO:       statsforecast: 1.5.0
2025-03-20 20:01:23,159:INFO:        tune_sklearn: 0.5.0
2025-03-20 20:01:23,159:INFO:                 ray: 2.10.0
2025-03-20 20:01:23,159:INFO:            hyperopt: 0.2.7
2025-03-20 20:01:23,159:INFO:              optuna: 4.1.0
2025-03-20 20:01:23,159:INFO:               skopt: 0.10.2
2025-03-20 20:01:23,159:INFO:              mlflow: 1.30.1
2025-03-20 20:01:23,159:INFO:              gradio: 3.50.2
2025-03-20 20:01:23,159:INFO:             fastapi: 0.115.5
2025-03-20 20:01:23,159:INFO:             uvicorn: 0.32.1
2025-03-20 20:01:23,159:INFO:              m2cgen: 0.10.0
2025-03-20 20:01:23,159:INFO:           evidently: 0.2.8
2025-03-20 20:01:23,159:INFO:               fugue: 0.8.6
2025-03-20 20:01:23,159:INFO:           streamlit: Not installed
2025-03-20 20:01:23,159:INFO:             prophet: Not installed
2025-03-20 20:01:23,159:INFO:None
2025-03-20 20:01:23,159:INFO:Set up data.
2025-03-20 20:01:23,165:INFO:Set up folding strategy.
2025-03-20 20:01:23,165:INFO:Set up train/test split.
2025-03-20 20:01:23,165:INFO:Set up data.
2025-03-20 20:01:23,170:INFO:Set up index.
2025-03-20 20:01:23,171:INFO:Assigning column types.
2025-03-20 20:01:23,172:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-20 20:01:23,173:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,175:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,177:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,222:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,223:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,236:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,238:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,240:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,285:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,286:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,286:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-20 20:01:23,288:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,334:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,335:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,338:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,383:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,385:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,385:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-20 20:01:23,389:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,413:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,432:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,433:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,437:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,481:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,482:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,482:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-20 20:01:23,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,530:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,531:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,579:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,580:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,580:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-20 20:01:23,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,629:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,630:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,659:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-20 20:01:23,678:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,679:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,679:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-20 20:01:23,727:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,728:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,777:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:23,778:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:23,779:INFO:Preparing preprocessing pipeline...
2025-03-20 20:01:23,779:INFO:Set up simple imputation.
2025-03-20 20:01:23,781:INFO:Set up encoding of categorical features.
2025-03-20 20:01:23,781:INFO:Set up feature normalization.
2025-03-20 20:01:23,781:INFO:Set up column name cleaning.
2025-03-20 20:01:23,833:INFO:Finished creating preprocessing pipeline.
2025-03-20 20:01:23,838:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 20:01:23,838:INFO:Creating final display dataframe.
2025-03-20 20:01:23,976:INFO:Setup _display_container:                     Description             Value
0                    Session id               888
1                        Target           MSW_log
2                   Target type        Regression
3           Original data shape        (1769, 25)
4        Transformed data shape        (1769, 38)
5   Transformed train set shape        (1399, 38)
6    Transformed test set shape         (370, 38)
7              Numeric features                21
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   TimeSeriesSplit
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment      MlflowLogger
22              Experiment Name  reg-default-name
23                          USI              fb54
2025-03-20 20:01:24,030:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:24,031:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:24,081:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:24,082:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-20 20:01:24,082:INFO:Logging experiment in loggers
2025-03-20 20:01:24,227:INFO:SubProcess save_model() called ==================================
2025-03-20 20:01:24,234:INFO:Initializing save_model()
2025-03-20 20:01:24,234:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpsjsd48ab\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 20:01:24,234:INFO:Adding model into prep_pipe
2025-03-20 20:01:24,234:WARNING:Only Model saved as it was a pipeline.
2025-03-20 20:01:24,238:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpsjsd48ab\Transformation Pipeline.pkl saved in current working directory
2025-03-20 20:01:24,242:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-20 20:01:24,242:INFO:save_model() successfully completed......................................
2025-03-20 20:01:24,296:INFO:SubProcess save_model() end ==================================
2025-03-20 20:01:24,301:INFO:setup() successfully completed in 2.94s...............
2025-03-20 20:01:24,302:INFO:Initializing compare_models()
2025-03-20 20:01:24,302:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 20:01:24,302:INFO:Checking exceptions
2025-03-20 20:01:24,303:INFO:Preparing display monitor
2025-03-20 20:01:24,315:INFO:Initializing Linear Regression
2025-03-20 20:01:24,315:INFO:Total runtime is 0.0 minutes
2025-03-20 20:01:24,316:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:24,316:INFO:Initializing create_model()
2025-03-20 20:01:24,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:24,317:INFO:Checking exceptions
2025-03-20 20:01:24,317:INFO:Importing libraries
2025-03-20 20:01:24,317:INFO:Copying training dataset
2025-03-20 20:01:24,319:INFO:Defining folds
2025-03-20 20:01:24,319:INFO:Declaring metric variables
2025-03-20 20:01:24,320:INFO:Importing untrained model
2025-03-20 20:01:24,322:INFO:Linear Regression Imported successfully
2025-03-20 20:01:24,326:INFO:Starting cross validation
2025-03-20 20:01:24,328:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:27,124:INFO:Calculating mean and std
2025-03-20 20:01:27,125:INFO:Creating metrics dataframe
2025-03-20 20:01:27,127:INFO:Uploading results into container
2025-03-20 20:01:27,128:INFO:Uploading model into container now
2025-03-20 20:01:27,129:INFO:_master_model_container: 1
2025-03-20 20:01:27,129:INFO:_display_container: 2
2025-03-20 20:01:27,129:INFO:LinearRegression(n_jobs=-1)
2025-03-20 20:01:27,129:INFO:create_model() successfully completed......................................
2025-03-20 20:01:27,199:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:27,199:INFO:Creating metrics dataframe
2025-03-20 20:01:27,203:INFO:Initializing Lasso Regression
2025-03-20 20:01:27,203:INFO:Total runtime is 0.048143498102823895 minutes
2025-03-20 20:01:27,205:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:27,205:INFO:Initializing create_model()
2025-03-20 20:01:27,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:27,205:INFO:Checking exceptions
2025-03-20 20:01:27,205:INFO:Importing libraries
2025-03-20 20:01:27,205:INFO:Copying training dataset
2025-03-20 20:01:27,207:INFO:Defining folds
2025-03-20 20:01:27,207:INFO:Declaring metric variables
2025-03-20 20:01:27,209:INFO:Importing untrained model
2025-03-20 20:01:27,211:INFO:Lasso Regression Imported successfully
2025-03-20 20:01:27,214:INFO:Starting cross validation
2025-03-20 20:01:27,215:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:29,403:INFO:Calculating mean and std
2025-03-20 20:01:29,404:INFO:Creating metrics dataframe
2025-03-20 20:01:29,406:INFO:Uploading results into container
2025-03-20 20:01:29,406:INFO:Uploading model into container now
2025-03-20 20:01:29,407:INFO:_master_model_container: 2
2025-03-20 20:01:29,407:INFO:_display_container: 2
2025-03-20 20:01:29,407:INFO:Lasso(random_state=888)
2025-03-20 20:01:29,407:INFO:create_model() successfully completed......................................
2025-03-20 20:01:29,466:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:29,466:INFO:Creating metrics dataframe
2025-03-20 20:01:29,470:INFO:Initializing Ridge Regression
2025-03-20 20:01:29,471:INFO:Total runtime is 0.08593979279200237 minutes
2025-03-20 20:01:29,472:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:29,472:INFO:Initializing create_model()
2025-03-20 20:01:29,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:29,472:INFO:Checking exceptions
2025-03-20 20:01:29,473:INFO:Importing libraries
2025-03-20 20:01:29,473:INFO:Copying training dataset
2025-03-20 20:01:29,474:INFO:Defining folds
2025-03-20 20:01:29,474:INFO:Declaring metric variables
2025-03-20 20:01:29,476:INFO:Importing untrained model
2025-03-20 20:01:29,478:INFO:Ridge Regression Imported successfully
2025-03-20 20:01:29,481:INFO:Starting cross validation
2025-03-20 20:01:29,481:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:31,651:INFO:Calculating mean and std
2025-03-20 20:01:31,652:INFO:Creating metrics dataframe
2025-03-20 20:01:31,655:INFO:Uploading results into container
2025-03-20 20:01:31,656:INFO:Uploading model into container now
2025-03-20 20:01:31,656:INFO:_master_model_container: 3
2025-03-20 20:01:31,656:INFO:_display_container: 2
2025-03-20 20:01:31,657:INFO:Ridge(random_state=888)
2025-03-20 20:01:31,657:INFO:create_model() successfully completed......................................
2025-03-20 20:01:31,715:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:31,715:INFO:Creating metrics dataframe
2025-03-20 20:01:31,719:INFO:Initializing Elastic Net
2025-03-20 20:01:31,719:INFO:Total runtime is 0.1234132448832194 minutes
2025-03-20 20:01:31,721:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:31,721:INFO:Initializing create_model()
2025-03-20 20:01:31,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:31,721:INFO:Checking exceptions
2025-03-20 20:01:31,721:INFO:Importing libraries
2025-03-20 20:01:31,721:INFO:Copying training dataset
2025-03-20 20:01:31,723:INFO:Defining folds
2025-03-20 20:01:31,723:INFO:Declaring metric variables
2025-03-20 20:01:31,725:INFO:Importing untrained model
2025-03-20 20:01:31,727:INFO:Elastic Net Imported successfully
2025-03-20 20:01:31,730:INFO:Starting cross validation
2025-03-20 20:01:31,731:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:33,884:INFO:Calculating mean and std
2025-03-20 20:01:33,885:INFO:Creating metrics dataframe
2025-03-20 20:01:33,887:INFO:Uploading results into container
2025-03-20 20:01:33,887:INFO:Uploading model into container now
2025-03-20 20:01:33,887:INFO:_master_model_container: 4
2025-03-20 20:01:33,887:INFO:_display_container: 2
2025-03-20 20:01:33,888:INFO:ElasticNet(random_state=888)
2025-03-20 20:01:33,888:INFO:create_model() successfully completed......................................
2025-03-20 20:01:33,945:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:33,945:INFO:Creating metrics dataframe
2025-03-20 20:01:33,950:INFO:Initializing Least Angle Regression
2025-03-20 20:01:33,950:INFO:Total runtime is 0.1605886975924174 minutes
2025-03-20 20:01:33,952:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:33,952:INFO:Initializing create_model()
2025-03-20 20:01:33,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:33,952:INFO:Checking exceptions
2025-03-20 20:01:33,952:INFO:Importing libraries
2025-03-20 20:01:33,952:INFO:Copying training dataset
2025-03-20 20:01:33,954:INFO:Defining folds
2025-03-20 20:01:33,954:INFO:Declaring metric variables
2025-03-20 20:01:33,956:INFO:Importing untrained model
2025-03-20 20:01:33,957:INFO:Least Angle Regression Imported successfully
2025-03-20 20:01:33,961:INFO:Starting cross validation
2025-03-20 20:01:33,961:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:36,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.010e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.349e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.665e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.693e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.707e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.908e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.685e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,039:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.247e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,039:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.688e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,040:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.114e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,040:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.912e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,040:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.216e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,041:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.707e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,041:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.503e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,041:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.848e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,041:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.186e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,041:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.737e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-20 20:01:36,070:INFO:Calculating mean and std
2025-03-20 20:01:36,071:INFO:Creating metrics dataframe
2025-03-20 20:01:36,073:INFO:Uploading results into container
2025-03-20 20:01:36,073:INFO:Uploading model into container now
2025-03-20 20:01:36,074:INFO:_master_model_container: 5
2025-03-20 20:01:36,074:INFO:_display_container: 2
2025-03-20 20:01:36,074:INFO:Lars(random_state=888)
2025-03-20 20:01:36,074:INFO:create_model() successfully completed......................................
2025-03-20 20:01:36,132:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:36,132:INFO:Creating metrics dataframe
2025-03-20 20:01:36,137:INFO:Initializing Lasso Least Angle Regression
2025-03-20 20:01:36,137:INFO:Total runtime is 0.19703570206960042 minutes
2025-03-20 20:01:36,138:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:36,139:INFO:Initializing create_model()
2025-03-20 20:01:36,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:36,139:INFO:Checking exceptions
2025-03-20 20:01:36,139:INFO:Importing libraries
2025-03-20 20:01:36,139:INFO:Copying training dataset
2025-03-20 20:01:36,141:INFO:Defining folds
2025-03-20 20:01:36,141:INFO:Declaring metric variables
2025-03-20 20:01:36,143:INFO:Importing untrained model
2025-03-20 20:01:36,144:INFO:Lasso Least Angle Regression Imported successfully
2025-03-20 20:01:36,148:INFO:Starting cross validation
2025-03-20 20:01:36,148:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:38,425:INFO:Calculating mean and std
2025-03-20 20:01:38,427:INFO:Creating metrics dataframe
2025-03-20 20:01:38,430:INFO:Uploading results into container
2025-03-20 20:01:38,430:INFO:Uploading model into container now
2025-03-20 20:01:38,431:INFO:_master_model_container: 6
2025-03-20 20:01:38,431:INFO:_display_container: 2
2025-03-20 20:01:38,431:INFO:LassoLars(random_state=888)
2025-03-20 20:01:38,431:INFO:create_model() successfully completed......................................
2025-03-20 20:01:38,493:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:38,493:INFO:Creating metrics dataframe
2025-03-20 20:01:38,498:INFO:Initializing Orthogonal Matching Pursuit
2025-03-20 20:01:38,498:INFO:Total runtime is 0.23639649152755737 minutes
2025-03-20 20:01:38,500:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:38,500:INFO:Initializing create_model()
2025-03-20 20:01:38,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:38,500:INFO:Checking exceptions
2025-03-20 20:01:38,500:INFO:Importing libraries
2025-03-20 20:01:38,500:INFO:Copying training dataset
2025-03-20 20:01:38,502:INFO:Defining folds
2025-03-20 20:01:38,502:INFO:Declaring metric variables
2025-03-20 20:01:38,504:INFO:Importing untrained model
2025-03-20 20:01:38,506:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-20 20:01:38,509:INFO:Starting cross validation
2025-03-20 20:01:38,510:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:40,319:INFO:Calculating mean and std
2025-03-20 20:01:40,320:INFO:Creating metrics dataframe
2025-03-20 20:01:40,322:INFO:Uploading results into container
2025-03-20 20:01:40,322:INFO:Uploading model into container now
2025-03-20 20:01:40,323:INFO:_master_model_container: 7
2025-03-20 20:01:40,323:INFO:_display_container: 2
2025-03-20 20:01:40,323:INFO:OrthogonalMatchingPursuit()
2025-03-20 20:01:40,323:INFO:create_model() successfully completed......................................
2025-03-20 20:01:40,378:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:40,378:INFO:Creating metrics dataframe
2025-03-20 20:01:40,384:INFO:Initializing Bayesian Ridge
2025-03-20 20:01:40,384:INFO:Total runtime is 0.2678188999493917 minutes
2025-03-20 20:01:40,386:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:40,386:INFO:Initializing create_model()
2025-03-20 20:01:40,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:40,386:INFO:Checking exceptions
2025-03-20 20:01:40,386:INFO:Importing libraries
2025-03-20 20:01:40,386:INFO:Copying training dataset
2025-03-20 20:01:40,388:INFO:Defining folds
2025-03-20 20:01:40,388:INFO:Declaring metric variables
2025-03-20 20:01:40,389:INFO:Importing untrained model
2025-03-20 20:01:40,391:INFO:Bayesian Ridge Imported successfully
2025-03-20 20:01:40,394:INFO:Starting cross validation
2025-03-20 20:01:40,395:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:40,458:INFO:Calculating mean and std
2025-03-20 20:01:40,459:INFO:Creating metrics dataframe
2025-03-20 20:01:40,460:INFO:Uploading results into container
2025-03-20 20:01:40,460:INFO:Uploading model into container now
2025-03-20 20:01:40,461:INFO:_master_model_container: 8
2025-03-20 20:01:40,461:INFO:_display_container: 2
2025-03-20 20:01:40,461:INFO:BayesianRidge()
2025-03-20 20:01:40,461:INFO:create_model() successfully completed......................................
2025-03-20 20:01:40,528:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:40,528:INFO:Creating metrics dataframe
2025-03-20 20:01:40,534:INFO:Initializing Passive Aggressive Regressor
2025-03-20 20:01:40,534:INFO:Total runtime is 0.2703187823295593 minutes
2025-03-20 20:01:40,536:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:40,536:INFO:Initializing create_model()
2025-03-20 20:01:40,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:40,536:INFO:Checking exceptions
2025-03-20 20:01:40,536:INFO:Importing libraries
2025-03-20 20:01:40,536:INFO:Copying training dataset
2025-03-20 20:01:40,538:INFO:Defining folds
2025-03-20 20:01:40,538:INFO:Declaring metric variables
2025-03-20 20:01:40,540:INFO:Importing untrained model
2025-03-20 20:01:40,542:INFO:Passive Aggressive Regressor Imported successfully
2025-03-20 20:01:40,544:INFO:Starting cross validation
2025-03-20 20:01:40,545:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:40,612:INFO:Calculating mean and std
2025-03-20 20:01:40,613:INFO:Creating metrics dataframe
2025-03-20 20:01:40,614:INFO:Uploading results into container
2025-03-20 20:01:40,614:INFO:Uploading model into container now
2025-03-20 20:01:40,615:INFO:_master_model_container: 9
2025-03-20 20:01:40,615:INFO:_display_container: 2
2025-03-20 20:01:40,615:INFO:PassiveAggressiveRegressor(random_state=888)
2025-03-20 20:01:40,615:INFO:create_model() successfully completed......................................
2025-03-20 20:01:40,668:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:40,668:INFO:Creating metrics dataframe
2025-03-20 20:01:40,674:INFO:Initializing Huber Regressor
2025-03-20 20:01:40,674:INFO:Total runtime is 0.27265311479568477 minutes
2025-03-20 20:01:40,676:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:40,676:INFO:Initializing create_model()
2025-03-20 20:01:40,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:40,676:INFO:Checking exceptions
2025-03-20 20:01:40,676:INFO:Importing libraries
2025-03-20 20:01:40,676:INFO:Copying training dataset
2025-03-20 20:01:40,678:INFO:Defining folds
2025-03-20 20:01:40,678:INFO:Declaring metric variables
2025-03-20 20:01:40,679:INFO:Importing untrained model
2025-03-20 20:01:40,681:INFO:Huber Regressor Imported successfully
2025-03-20 20:01:40,684:INFO:Starting cross validation
2025-03-20 20:01:40,685:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:40,725:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 20:01:40,729:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 20:01:40,733:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 20:01:40,740:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 20:01:40,744:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-20 20:01:40,766:INFO:Calculating mean and std
2025-03-20 20:01:40,767:INFO:Creating metrics dataframe
2025-03-20 20:01:40,768:INFO:Uploading results into container
2025-03-20 20:01:40,769:INFO:Uploading model into container now
2025-03-20 20:01:40,769:INFO:_master_model_container: 10
2025-03-20 20:01:40,769:INFO:_display_container: 2
2025-03-20 20:01:40,769:INFO:HuberRegressor()
2025-03-20 20:01:40,769:INFO:create_model() successfully completed......................................
2025-03-20 20:01:40,826:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:40,826:INFO:Creating metrics dataframe
2025-03-20 20:01:40,832:INFO:Initializing K Neighbors Regressor
2025-03-20 20:01:40,832:INFO:Total runtime is 0.2752937237421671 minutes
2025-03-20 20:01:40,834:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:40,834:INFO:Initializing create_model()
2025-03-20 20:01:40,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:40,835:INFO:Checking exceptions
2025-03-20 20:01:40,835:INFO:Importing libraries
2025-03-20 20:01:40,835:INFO:Copying training dataset
2025-03-20 20:01:40,837:INFO:Defining folds
2025-03-20 20:01:40,837:INFO:Declaring metric variables
2025-03-20 20:01:40,839:INFO:Importing untrained model
2025-03-20 20:01:40,841:INFO:K Neighbors Regressor Imported successfully
2025-03-20 20:01:40,845:INFO:Starting cross validation
2025-03-20 20:01:40,846:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:40,950:INFO:Calculating mean and std
2025-03-20 20:01:40,951:INFO:Creating metrics dataframe
2025-03-20 20:01:40,953:INFO:Uploading results into container
2025-03-20 20:01:40,953:INFO:Uploading model into container now
2025-03-20 20:01:40,953:INFO:_master_model_container: 11
2025-03-20 20:01:40,953:INFO:_display_container: 2
2025-03-20 20:01:40,954:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-20 20:01:40,954:INFO:create_model() successfully completed......................................
2025-03-20 20:01:41,007:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:41,007:INFO:Creating metrics dataframe
2025-03-20 20:01:41,013:INFO:Initializing Decision Tree Regressor
2025-03-20 20:01:41,013:INFO:Total runtime is 0.27830682992935174 minutes
2025-03-20 20:01:41,015:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:41,015:INFO:Initializing create_model()
2025-03-20 20:01:41,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:41,015:INFO:Checking exceptions
2025-03-20 20:01:41,015:INFO:Importing libraries
2025-03-20 20:01:41,015:INFO:Copying training dataset
2025-03-20 20:01:41,017:INFO:Defining folds
2025-03-20 20:01:41,017:INFO:Declaring metric variables
2025-03-20 20:01:41,018:INFO:Importing untrained model
2025-03-20 20:01:41,020:INFO:Decision Tree Regressor Imported successfully
2025-03-20 20:01:41,024:INFO:Starting cross validation
2025-03-20 20:01:41,024:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:41,104:INFO:Calculating mean and std
2025-03-20 20:01:41,105:INFO:Creating metrics dataframe
2025-03-20 20:01:41,107:INFO:Uploading results into container
2025-03-20 20:01:41,107:INFO:Uploading model into container now
2025-03-20 20:01:41,107:INFO:_master_model_container: 12
2025-03-20 20:01:41,107:INFO:_display_container: 2
2025-03-20 20:01:41,107:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 20:01:41,107:INFO:create_model() successfully completed......................................
2025-03-20 20:01:41,160:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:41,160:INFO:Creating metrics dataframe
2025-03-20 20:01:41,165:INFO:Initializing Random Forest Regressor
2025-03-20 20:01:41,165:INFO:Total runtime is 0.2808481057484944 minutes
2025-03-20 20:01:41,167:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:41,167:INFO:Initializing create_model()
2025-03-20 20:01:41,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:41,167:INFO:Checking exceptions
2025-03-20 20:01:41,168:INFO:Importing libraries
2025-03-20 20:01:41,168:INFO:Copying training dataset
2025-03-20 20:01:41,170:INFO:Defining folds
2025-03-20 20:01:41,170:INFO:Declaring metric variables
2025-03-20 20:01:41,171:INFO:Importing untrained model
2025-03-20 20:01:41,173:INFO:Random Forest Regressor Imported successfully
2025-03-20 20:01:41,176:INFO:Starting cross validation
2025-03-20 20:01:41,177:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:41,520:INFO:Calculating mean and std
2025-03-20 20:01:41,521:INFO:Creating metrics dataframe
2025-03-20 20:01:41,523:INFO:Uploading results into container
2025-03-20 20:01:41,523:INFO:Uploading model into container now
2025-03-20 20:01:41,523:INFO:_master_model_container: 13
2025-03-20 20:01:41,524:INFO:_display_container: 2
2025-03-20 20:01:41,524:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:01:41,524:INFO:create_model() successfully completed......................................
2025-03-20 20:01:41,577:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:41,577:INFO:Creating metrics dataframe
2025-03-20 20:01:41,583:INFO:Initializing Extra Trees Regressor
2025-03-20 20:01:41,583:INFO:Total runtime is 0.2878097097078958 minutes
2025-03-20 20:01:41,585:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:41,585:INFO:Initializing create_model()
2025-03-20 20:01:41,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:41,585:INFO:Checking exceptions
2025-03-20 20:01:41,585:INFO:Importing libraries
2025-03-20 20:01:41,586:INFO:Copying training dataset
2025-03-20 20:01:41,587:INFO:Defining folds
2025-03-20 20:01:41,587:INFO:Declaring metric variables
2025-03-20 20:01:41,589:INFO:Importing untrained model
2025-03-20 20:01:41,591:INFO:Extra Trees Regressor Imported successfully
2025-03-20 20:01:41,594:INFO:Starting cross validation
2025-03-20 20:01:41,595:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:41,797:INFO:Calculating mean and std
2025-03-20 20:01:41,798:INFO:Creating metrics dataframe
2025-03-20 20:01:41,800:INFO:Uploading results into container
2025-03-20 20:01:41,800:INFO:Uploading model into container now
2025-03-20 20:01:41,801:INFO:_master_model_container: 14
2025-03-20 20:01:41,801:INFO:_display_container: 2
2025-03-20 20:01:41,801:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:01:41,801:INFO:create_model() successfully completed......................................
2025-03-20 20:01:41,856:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:41,856:INFO:Creating metrics dataframe
2025-03-20 20:01:41,862:INFO:Initializing AdaBoost Regressor
2025-03-20 20:01:41,862:INFO:Total runtime is 0.2924618124961852 minutes
2025-03-20 20:01:41,864:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:41,865:INFO:Initializing create_model()
2025-03-20 20:01:41,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:41,865:INFO:Checking exceptions
2025-03-20 20:01:41,865:INFO:Importing libraries
2025-03-20 20:01:41,865:INFO:Copying training dataset
2025-03-20 20:01:41,867:INFO:Defining folds
2025-03-20 20:01:41,867:INFO:Declaring metric variables
2025-03-20 20:01:41,868:INFO:Importing untrained model
2025-03-20 20:01:41,870:INFO:AdaBoost Regressor Imported successfully
2025-03-20 20:01:41,875:INFO:Starting cross validation
2025-03-20 20:01:41,876:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:42,090:INFO:Calculating mean and std
2025-03-20 20:01:42,091:INFO:Creating metrics dataframe
2025-03-20 20:01:42,092:INFO:Uploading results into container
2025-03-20 20:01:42,093:INFO:Uploading model into container now
2025-03-20 20:01:42,093:INFO:_master_model_container: 15
2025-03-20 20:01:42,093:INFO:_display_container: 2
2025-03-20 20:01:42,093:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 20:01:42,093:INFO:create_model() successfully completed......................................
2025-03-20 20:01:42,145:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:42,145:INFO:Creating metrics dataframe
2025-03-20 20:01:42,151:INFO:Initializing Gradient Boosting Regressor
2025-03-20 20:01:42,151:INFO:Total runtime is 0.2972794731458027 minutes
2025-03-20 20:01:42,154:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:42,154:INFO:Initializing create_model()
2025-03-20 20:01:42,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:42,154:INFO:Checking exceptions
2025-03-20 20:01:42,154:INFO:Importing libraries
2025-03-20 20:01:42,154:INFO:Copying training dataset
2025-03-20 20:01:42,156:INFO:Defining folds
2025-03-20 20:01:42,156:INFO:Declaring metric variables
2025-03-20 20:01:42,157:INFO:Importing untrained model
2025-03-20 20:01:42,159:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 20:01:42,162:INFO:Starting cross validation
2025-03-20 20:01:42,163:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:42,767:INFO:Calculating mean and std
2025-03-20 20:01:42,768:INFO:Creating metrics dataframe
2025-03-20 20:01:42,771:INFO:Uploading results into container
2025-03-20 20:01:42,771:INFO:Uploading model into container now
2025-03-20 20:01:42,772:INFO:_master_model_container: 16
2025-03-20 20:01:42,772:INFO:_display_container: 2
2025-03-20 20:01:42,772:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 20:01:42,772:INFO:create_model() successfully completed......................................
2025-03-20 20:01:42,824:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:42,824:INFO:Creating metrics dataframe
2025-03-20 20:01:42,831:INFO:Initializing Extreme Gradient Boosting
2025-03-20 20:01:42,831:INFO:Total runtime is 0.30860345760981234 minutes
2025-03-20 20:01:42,832:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:42,833:INFO:Initializing create_model()
2025-03-20 20:01:42,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:42,833:INFO:Checking exceptions
2025-03-20 20:01:42,833:INFO:Importing libraries
2025-03-20 20:01:42,833:INFO:Copying training dataset
2025-03-20 20:01:42,835:INFO:Defining folds
2025-03-20 20:01:42,835:INFO:Declaring metric variables
2025-03-20 20:01:42,836:INFO:Importing untrained model
2025-03-20 20:01:42,838:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 20:01:42,841:INFO:Starting cross validation
2025-03-20 20:01:42,842:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:43,321:INFO:Calculating mean and std
2025-03-20 20:01:43,322:INFO:Creating metrics dataframe
2025-03-20 20:01:43,324:INFO:Uploading results into container
2025-03-20 20:01:43,324:INFO:Uploading model into container now
2025-03-20 20:01:43,325:INFO:_master_model_container: 17
2025-03-20 20:01:43,325:INFO:_display_container: 2
2025-03-20 20:01:43,325:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 20:01:43,325:INFO:create_model() successfully completed......................................
2025-03-20 20:01:43,382:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:43,382:INFO:Creating metrics dataframe
2025-03-20 20:01:43,388:INFO:Initializing Light Gradient Boosting Machine
2025-03-20 20:01:43,388:INFO:Total runtime is 0.3178911129633585 minutes
2025-03-20 20:01:43,390:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:43,390:INFO:Initializing create_model()
2025-03-20 20:01:43,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:43,390:INFO:Checking exceptions
2025-03-20 20:01:43,390:INFO:Importing libraries
2025-03-20 20:01:43,390:INFO:Copying training dataset
2025-03-20 20:01:43,392:INFO:Defining folds
2025-03-20 20:01:43,392:INFO:Declaring metric variables
2025-03-20 20:01:43,394:INFO:Importing untrained model
2025-03-20 20:01:43,395:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 20:01:43,399:INFO:Starting cross validation
2025-03-20 20:01:43,400:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:43,891:INFO:Calculating mean and std
2025-03-20 20:01:43,892:INFO:Creating metrics dataframe
2025-03-20 20:01:43,895:INFO:Uploading results into container
2025-03-20 20:01:43,895:INFO:Uploading model into container now
2025-03-20 20:01:43,896:INFO:_master_model_container: 18
2025-03-20 20:01:43,896:INFO:_display_container: 2
2025-03-20 20:01:43,896:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:01:43,896:INFO:create_model() successfully completed......................................
2025-03-20 20:01:43,959:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:43,959:INFO:Creating metrics dataframe
2025-03-20 20:01:43,968:INFO:Initializing CatBoost Regressor
2025-03-20 20:01:43,968:INFO:Total runtime is 0.3275512695312499 minutes
2025-03-20 20:01:43,970:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:43,971:INFO:Initializing create_model()
2025-03-20 20:01:43,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:43,971:INFO:Checking exceptions
2025-03-20 20:01:43,971:INFO:Importing libraries
2025-03-20 20:01:43,971:INFO:Copying training dataset
2025-03-20 20:01:43,973:INFO:Defining folds
2025-03-20 20:01:43,973:INFO:Declaring metric variables
2025-03-20 20:01:43,975:INFO:Importing untrained model
2025-03-20 20:01:43,977:INFO:CatBoost Regressor Imported successfully
2025-03-20 20:01:43,981:INFO:Starting cross validation
2025-03-20 20:01:43,982:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:46,447:INFO:Calculating mean and std
2025-03-20 20:01:46,448:INFO:Creating metrics dataframe
2025-03-20 20:01:46,450:INFO:Uploading results into container
2025-03-20 20:01:46,450:INFO:Uploading model into container now
2025-03-20 20:01:46,450:INFO:_master_model_container: 19
2025-03-20 20:01:46,451:INFO:_display_container: 2
2025-03-20 20:01:46,451:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A2CA01880>
2025-03-20 20:01:46,451:INFO:create_model() successfully completed......................................
2025-03-20 20:01:46,504:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:46,504:INFO:Creating metrics dataframe
2025-03-20 20:01:46,511:INFO:Initializing Dummy Regressor
2025-03-20 20:01:46,511:INFO:Total runtime is 0.36993344227472935 minutes
2025-03-20 20:01:46,513:INFO:SubProcess create_model() called ==================================
2025-03-20 20:01:46,513:INFO:Initializing create_model()
2025-03-20 20:01:46,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E12FD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:46,513:INFO:Checking exceptions
2025-03-20 20:01:46,513:INFO:Importing libraries
2025-03-20 20:01:46,513:INFO:Copying training dataset
2025-03-20 20:01:46,515:INFO:Defining folds
2025-03-20 20:01:46,515:INFO:Declaring metric variables
2025-03-20 20:01:46,517:INFO:Importing untrained model
2025-03-20 20:01:46,519:INFO:Dummy Regressor Imported successfully
2025-03-20 20:01:46,522:INFO:Starting cross validation
2025-03-20 20:01:46,523:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:01:46,586:INFO:Calculating mean and std
2025-03-20 20:01:46,587:INFO:Creating metrics dataframe
2025-03-20 20:01:46,588:INFO:Uploading results into container
2025-03-20 20:01:46,589:INFO:Uploading model into container now
2025-03-20 20:01:46,589:INFO:_master_model_container: 20
2025-03-20 20:01:46,589:INFO:_display_container: 2
2025-03-20 20:01:46,589:INFO:DummyRegressor()
2025-03-20 20:01:46,589:INFO:create_model() successfully completed......................................
2025-03-20 20:01:46,645:INFO:SubProcess create_model() end ==================================
2025-03-20 20:01:46,645:INFO:Creating metrics dataframe
2025-03-20 20:01:46,656:INFO:Initializing create_model()
2025-03-20 20:01:46,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:46,656:INFO:Checking exceptions
2025-03-20 20:01:46,657:INFO:Importing libraries
2025-03-20 20:01:46,657:INFO:Copying training dataset
2025-03-20 20:01:46,659:INFO:Defining folds
2025-03-20 20:01:46,659:INFO:Declaring metric variables
2025-03-20 20:01:46,659:INFO:Importing untrained model
2025-03-20 20:01:46,660:INFO:Declaring custom model
2025-03-20 20:01:46,660:INFO:Bayesian Ridge Imported successfully
2025-03-20 20:01:46,660:INFO:Cross validation set to False
2025-03-20 20:01:46,660:INFO:Fitting Model
2025-03-20 20:01:46,694:INFO:BayesianRidge()
2025-03-20 20:01:46,694:INFO:create_model() successfully completed......................................
2025-03-20 20:01:46,754:INFO:Creating Dashboard logs
2025-03-20 20:01:46,756:INFO:Model: Bayesian Ridge
2025-03-20 20:01:46,777:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 20:01:46,817:INFO:Initializing predict_model()
2025-03-20 20:01:46,817:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E1EB310>)
2025-03-20 20:01:46,817:INFO:Checking exceptions
2025-03-20 20:01:46,818:INFO:Preloading libraries
2025-03-20 20:01:46,947:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-20 20:01:46,960:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:46,963:INFO:Initializing create_model()
2025-03-20 20:01:46,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:46,963:INFO:Checking exceptions
2025-03-20 20:01:46,963:INFO:Importing libraries
2025-03-20 20:01:46,964:INFO:Copying training dataset
2025-03-20 20:01:46,965:INFO:Defining folds
2025-03-20 20:01:46,965:INFO:Declaring metric variables
2025-03-20 20:01:46,966:INFO:Importing untrained model
2025-03-20 20:01:46,966:INFO:Declaring custom model
2025-03-20 20:01:46,966:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 20:01:46,967:INFO:Cross validation set to False
2025-03-20 20:01:46,967:INFO:Fitting Model
2025-03-20 20:01:47,649:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 20:01:47,649:INFO:create_model() successfully completed......................................
2025-03-20 20:01:47,703:INFO:Creating Dashboard logs
2025-03-20 20:01:47,705:INFO:Model: Gradient Boosting Regressor
2025-03-20 20:01:47,728:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 20:01:47,782:INFO:Initializing predict_model()
2025-03-20 20:01:47,782:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E5C25E0>)
2025-03-20 20:01:47,782:INFO:Checking exceptions
2025-03-20 20:01:47,782:INFO:Preloading libraries
2025-03-20 20:01:47,918:ERROR:_log_model() for GradientBoostingRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:47,920:INFO:Initializing create_model()
2025-03-20 20:01:47,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:47,920:INFO:Checking exceptions
2025-03-20 20:01:47,921:INFO:Importing libraries
2025-03-20 20:01:47,921:INFO:Copying training dataset
2025-03-20 20:01:47,923:INFO:Defining folds
2025-03-20 20:01:47,923:INFO:Declaring metric variables
2025-03-20 20:01:47,923:INFO:Importing untrained model
2025-03-20 20:01:47,923:INFO:Declaring custom model
2025-03-20 20:01:47,923:INFO:Ridge Regression Imported successfully
2025-03-20 20:01:47,924:INFO:Cross validation set to False
2025-03-20 20:01:47,924:INFO:Fitting Model
2025-03-20 20:01:47,952:INFO:Ridge(random_state=888)
2025-03-20 20:01:47,952:INFO:create_model() successfully completed......................................
2025-03-20 20:01:48,007:INFO:Creating Dashboard logs
2025-03-20 20:01:48,009:INFO:Model: Ridge Regression
2025-03-20 20:01:48,030:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 20:01:48,087:INFO:Initializing predict_model()
2025-03-20 20:01:48,087:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=Ridge(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E5CE700>)
2025-03-20 20:01:48,087:INFO:Checking exceptions
2025-03-20 20:01:48,087:INFO:Preloading libraries
2025-03-20 20:01:48,235:ERROR:_log_model() for Ridge(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:48,237:INFO:Initializing create_model()
2025-03-20 20:01:48,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:48,237:INFO:Checking exceptions
2025-03-20 20:01:48,238:INFO:Importing libraries
2025-03-20 20:01:48,238:INFO:Copying training dataset
2025-03-20 20:01:48,240:INFO:Defining folds
2025-03-20 20:01:48,240:INFO:Declaring metric variables
2025-03-20 20:01:48,240:INFO:Importing untrained model
2025-03-20 20:01:48,240:INFO:Declaring custom model
2025-03-20 20:01:48,241:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 20:01:48,241:INFO:Cross validation set to False
2025-03-20 20:01:48,241:INFO:Fitting Model
2025-03-20 20:01:48,278:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 20:01:48,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2025-03-20 20:01:48,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 20:01:48,279:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 20:01:48,280:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 20:01:48,280:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 20:01:48,391:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:01:48,391:INFO:create_model() successfully completed......................................
2025-03-20 20:01:48,454:INFO:Creating Dashboard logs
2025-03-20 20:01:48,457:INFO:Model: Light Gradient Boosting Machine
2025-03-20 20:01:48,488:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 888, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-20 20:01:48,553:INFO:Initializing predict_model()
2025-03-20 20:01:48,553:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E5CF8B0>)
2025-03-20 20:01:48,553:INFO:Checking exceptions
2025-03-20 20:01:48,553:INFO:Preloading libraries
2025-03-20 20:01:48,701:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:48,705:INFO:Initializing create_model()
2025-03-20 20:01:48,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:48,705:INFO:Checking exceptions
2025-03-20 20:01:48,706:INFO:Importing libraries
2025-03-20 20:01:48,706:INFO:Copying training dataset
2025-03-20 20:01:48,708:INFO:Defining folds
2025-03-20 20:01:48,708:INFO:Declaring metric variables
2025-03-20 20:01:48,709:INFO:Importing untrained model
2025-03-20 20:01:48,709:INFO:Declaring custom model
2025-03-20 20:01:48,709:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 20:01:48,710:INFO:Cross validation set to False
2025-03-20 20:01:48,710:INFO:Fitting Model
2025-03-20 20:01:48,926:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 20:01:48,926:INFO:create_model() successfully completed......................................
2025-03-20 20:01:49,005:INFO:Creating Dashboard logs
2025-03-20 20:01:49,008:INFO:Model: Extreme Gradient Boosting
2025-03-20 20:01:49,041:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 20:01:49,143:INFO:Initializing predict_model()
2025-03-20 20:01:49,144:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E5C69D0>)
2025-03-20 20:01:49,144:INFO:Checking exceptions
2025-03-20 20:01:49,144:INFO:Preloading libraries
2025-03-20 20:01:49,312:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:49,315:INFO:Initializing create_model()
2025-03-20 20:01:49,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:49,315:INFO:Checking exceptions
2025-03-20 20:01:49,317:INFO:Importing libraries
2025-03-20 20:01:49,317:INFO:Copying training dataset
2025-03-20 20:01:49,319:INFO:Defining folds
2025-03-20 20:01:49,319:INFO:Declaring metric variables
2025-03-20 20:01:49,320:INFO:Importing untrained model
2025-03-20 20:01:49,320:INFO:Declaring custom model
2025-03-20 20:01:49,320:INFO:Random Forest Regressor Imported successfully
2025-03-20 20:01:49,321:INFO:Cross validation set to False
2025-03-20 20:01:49,321:INFO:Fitting Model
2025-03-20 20:01:49,543:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:01:49,543:INFO:create_model() successfully completed......................................
2025-03-20 20:01:49,601:INFO:Creating Dashboard logs
2025-03-20 20:01:49,604:INFO:Model: Random Forest Regressor
2025-03-20 20:01:49,626:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 20:01:49,711:INFO:Initializing predict_model()
2025-03-20 20:01:49,711:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E1A1DC0>)
2025-03-20 20:01:49,711:INFO:Checking exceptions
2025-03-20 20:01:49,711:INFO:Preloading libraries
2025-03-20 20:01:49,887:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:49,889:INFO:Initializing create_model()
2025-03-20 20:01:49,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=AdaBoostRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:49,889:INFO:Checking exceptions
2025-03-20 20:01:49,890:INFO:Importing libraries
2025-03-20 20:01:49,890:INFO:Copying training dataset
2025-03-20 20:01:49,892:INFO:Defining folds
2025-03-20 20:01:49,892:INFO:Declaring metric variables
2025-03-20 20:01:49,892:INFO:Importing untrained model
2025-03-20 20:01:49,892:INFO:Declaring custom model
2025-03-20 20:01:49,892:INFO:AdaBoost Regressor Imported successfully
2025-03-20 20:01:49,893:INFO:Cross validation set to False
2025-03-20 20:01:49,893:INFO:Fitting Model
2025-03-20 20:01:50,068:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 20:01:50,068:INFO:create_model() successfully completed......................................
2025-03-20 20:01:50,122:INFO:Creating Dashboard logs
2025-03-20 20:01:50,124:INFO:Model: AdaBoost Regressor
2025-03-20 20:01:50,144:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 888}
2025-03-20 20:01:50,227:INFO:Initializing predict_model()
2025-03-20 20:01:50,227:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=AdaBoostRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E345F70>)
2025-03-20 20:01:50,227:INFO:Checking exceptions
2025-03-20 20:01:50,227:INFO:Preloading libraries
2025-03-20 20:01:50,365:ERROR:_log_model() for AdaBoostRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:50,368:INFO:Initializing create_model()
2025-03-20 20:01:50,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000022A2CA01880>, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:50,368:INFO:Checking exceptions
2025-03-20 20:01:50,369:INFO:Importing libraries
2025-03-20 20:01:50,369:INFO:Copying training dataset
2025-03-20 20:01:50,371:INFO:Defining folds
2025-03-20 20:01:50,371:INFO:Declaring metric variables
2025-03-20 20:01:50,371:INFO:Importing untrained model
2025-03-20 20:01:50,371:INFO:Declaring custom model
2025-03-20 20:01:50,371:INFO:CatBoost Regressor Imported successfully
2025-03-20 20:01:50,372:INFO:Cross validation set to False
2025-03-20 20:01:50,372:INFO:Fitting Model
2025-03-20 20:01:51,641:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A2E33ADC0>
2025-03-20 20:01:51,641:INFO:create_model() successfully completed......................................
2025-03-20 20:01:51,697:INFO:Creating Dashboard logs
2025-03-20 20:01:51,699:INFO:Model: CatBoost Regressor
2025-03-20 20:01:51,723:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 888, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.04317399859428406, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2025-03-20 20:01:51,839:INFO:Initializing predict_model()
2025-03-20 20:01:51,839:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000022A2E33ADC0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E1A1160>)
2025-03-20 20:01:51,839:INFO:Checking exceptions
2025-03-20 20:01:51,839:INFO:Preloading libraries
2025-03-20 20:01:51,982:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x0000022A2E33ADC0> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:51,984:INFO:Initializing create_model()
2025-03-20 20:01:51,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:51,984:INFO:Checking exceptions
2025-03-20 20:01:51,985:INFO:Importing libraries
2025-03-20 20:01:51,985:INFO:Copying training dataset
2025-03-20 20:01:51,987:INFO:Defining folds
2025-03-20 20:01:51,987:INFO:Declaring metric variables
2025-03-20 20:01:51,987:INFO:Importing untrained model
2025-03-20 20:01:51,987:INFO:Declaring custom model
2025-03-20 20:01:51,987:INFO:Extra Trees Regressor Imported successfully
2025-03-20 20:01:51,988:INFO:Cross validation set to False
2025-03-20 20:01:51,988:INFO:Fitting Model
2025-03-20 20:01:52,098:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:01:52,098:INFO:create_model() successfully completed......................................
2025-03-20 20:01:52,154:INFO:Creating Dashboard logs
2025-03-20 20:01:52,156:INFO:Model: Extra Trees Regressor
2025-03-20 20:01:52,179:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 20:01:52,286:INFO:Initializing predict_model()
2025-03-20 20:01:52,286:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E349280>)
2025-03-20 20:01:52,286:INFO:Checking exceptions
2025-03-20 20:01:52,286:INFO:Preloading libraries
2025-03-20 20:01:52,457:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:52,460:INFO:Initializing create_model()
2025-03-20 20:01:52,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=DecisionTreeRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:01:52,460:INFO:Checking exceptions
2025-03-20 20:01:52,461:INFO:Importing libraries
2025-03-20 20:01:52,461:INFO:Copying training dataset
2025-03-20 20:01:52,463:INFO:Defining folds
2025-03-20 20:01:52,463:INFO:Declaring metric variables
2025-03-20 20:01:52,463:INFO:Importing untrained model
2025-03-20 20:01:52,463:INFO:Declaring custom model
2025-03-20 20:01:52,464:INFO:Decision Tree Regressor Imported successfully
2025-03-20 20:01:52,464:INFO:Cross validation set to False
2025-03-20 20:01:52,464:INFO:Fitting Model
2025-03-20 20:01:52,506:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 20:01:52,506:INFO:create_model() successfully completed......................................
2025-03-20 20:01:52,567:INFO:Creating Dashboard logs
2025-03-20 20:01:52,570:INFO:Model: Decision Tree Regressor
2025-03-20 20:01:52,604:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 20:01:52,727:INFO:Initializing predict_model()
2025-03-20 20:01:52,727:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=DecisionTreeRegressor(random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E31B430>)
2025-03-20 20:01:52,727:INFO:Checking exceptions
2025-03-20 20:01:52,727:INFO:Preloading libraries
2025-03-20 20:01:52,865:ERROR:_log_model() for DecisionTreeRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:52,865:INFO:Creating Dashboard logs
2025-03-20 20:01:52,867:INFO:Model: Passive Aggressive Regressor
2025-03-20 20:01:52,888:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 888, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 20:01:53,019:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:53,020:INFO:Creating Dashboard logs
2025-03-20 20:01:53,022:INFO:Model: Huber Regressor
2025-03-20 20:01:53,041:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-20 20:01:53,180:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:53,181:INFO:Creating Dashboard logs
2025-03-20 20:01:53,183:INFO:Model: Orthogonal Matching Pursuit
2025-03-20 20:01:53,206:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-20 20:01:53,371:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:53,372:INFO:Creating Dashboard logs
2025-03-20 20:01:53,374:INFO:Model: K Neighbors Regressor
2025-03-20 20:01:53,396:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-20 20:01:53,556:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:53,556:INFO:Creating Dashboard logs
2025-03-20 20:01:53,558:INFO:Model: Elastic Net
2025-03-20 20:01:53,580:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 20:01:53,744:ERROR:_log_model() for ElasticNet(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:53,745:INFO:Creating Dashboard logs
2025-03-20 20:01:53,746:INFO:Model: Lasso Regression
2025-03-20 20:01:53,767:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 888, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-20 20:01:53,937:ERROR:_log_model() for Lasso(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:53,938:INFO:Creating Dashboard logs
2025-03-20 20:01:53,940:INFO:Model: Lasso Least Angle Regression
2025-03-20 20:01:53,962:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 20:01:54,149:ERROR:_log_model() for LassoLars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:54,149:INFO:Creating Dashboard logs
2025-03-20 20:01:54,152:INFO:Model: Dummy Regressor
2025-03-20 20:01:54,174:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-20 20:01:54,363:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:54,364:INFO:Creating Dashboard logs
2025-03-20 20:01:54,366:INFO:Model: Linear Regression
2025-03-20 20:01:54,387:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-20 20:01:54,570:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:54,571:INFO:Creating Dashboard logs
2025-03-20 20:01:54,572:INFO:Model: Least Angle Regression
2025-03-20 20:01:54,593:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 888, 'verbose': False}
2025-03-20 20:01:54,774:ERROR:_log_model() for Lars(random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:01:54,782:INFO:_master_model_container: 20
2025-03-20 20:01:54,782:INFO:_display_container: 2
2025-03-20 20:01:54,783:INFO:[BayesianRidge(), GradientBoostingRegressor(random_state=888), Ridge(random_state=888), LGBMRegressor(n_jobs=-1, random_state=888), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), RandomForestRegressor(n_jobs=-1, random_state=888), AdaBoostRegressor(random_state=888), <catboost.core.CatBoostRegressor object at 0x0000022A2E33ADC0>, ExtraTreesRegressor(n_jobs=-1, random_state=888), DecisionTreeRegressor(random_state=888)]
2025-03-20 20:01:54,783:INFO:compare_models() successfully completed......................................
2025-03-20 20:01:54,806:INFO:Initializing tune_model()
2025-03-20 20:01:54,806:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:01:54,806:INFO:Checking exceptions
2025-03-20 20:01:54,806:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:01:54,854:INFO:Copying training dataset
2025-03-20 20:01:54,856:INFO:Checking base model
2025-03-20 20:01:54,856:INFO:Base model : Bayesian Ridge
2025-03-20 20:01:54,858:INFO:Declaring metric variables
2025-03-20 20:01:54,860:INFO:Defining Hyperparameters
2025-03-20 20:01:54,919:INFO:Tuning with n_jobs=-1
2025-03-20 20:01:54,920:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:01:54,920:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:01:54,920:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:01:54,925:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:01:54,925:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:01:54,926:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:02:21,625:INFO:best_params: {'actual_estimator__alpha_1': 0.00036634659930726997, 'actual_estimator__alpha_2': 3.1836872538740605e-05, 'actual_estimator__lambda_1': 0.874752585887542, 'actual_estimator__lambda_2': 3.403322954426461e-07, 'actual_estimator__compute_score': False, 'actual_estimator__fit_intercept': True}
2025-03-20 20:02:21,629:INFO:Hyperparameter search completed
2025-03-20 20:02:21,629:INFO:SubProcess create_model() called ==================================
2025-03-20 20:02:21,629:INFO:Initializing create_model()
2025-03-20 20:02:21,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A43CA3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha_1': 0.00036634659930726997, 'alpha_2': 3.1836872538740605e-05, 'lambda_1': 0.874752585887542, 'lambda_2': 3.403322954426461e-07, 'compute_score': False, 'fit_intercept': True})
2025-03-20 20:02:21,629:INFO:Checking exceptions
2025-03-20 20:02:21,630:INFO:Importing libraries
2025-03-20 20:02:21,630:INFO:Copying training dataset
2025-03-20 20:02:21,633:INFO:Defining folds
2025-03-20 20:02:21,633:INFO:Declaring metric variables
2025-03-20 20:02:21,635:INFO:Importing untrained model
2025-03-20 20:02:21,635:INFO:Declaring custom model
2025-03-20 20:02:21,637:INFO:Bayesian Ridge Imported successfully
2025-03-20 20:02:21,640:INFO:Starting cross validation
2025-03-20 20:02:21,641:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:02:21,720:INFO:Calculating mean and std
2025-03-20 20:02:21,721:INFO:Creating metrics dataframe
2025-03-20 20:02:21,724:INFO:Finalizing model
2025-03-20 20:02:21,761:INFO:Uploading results into container
2025-03-20 20:02:21,761:INFO:Uploading model into container now
2025-03-20 20:02:21,761:INFO:_master_model_container: 21
2025-03-20 20:02:21,761:INFO:_display_container: 3
2025-03-20 20:02:21,761:INFO:BayesianRidge(alpha_1=0.00036634659930726997, alpha_2=3.1836872538740605e-05,
              lambda_1=0.874752585887542, lambda_2=3.403322954426461e-07)
2025-03-20 20:02:21,761:INFO:create_model() successfully completed......................................
2025-03-20 20:02:21,821:INFO:SubProcess create_model() end ==================================
2025-03-20 20:02:21,821:INFO:choose_better activated
2025-03-20 20:02:21,823:INFO:SubProcess create_model() called ==================================
2025-03-20 20:02:21,823:INFO:Initializing create_model()
2025-03-20 20:02:21,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=BayesianRidge(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:02:21,823:INFO:Checking exceptions
2025-03-20 20:02:21,824:INFO:Importing libraries
2025-03-20 20:02:21,824:INFO:Copying training dataset
2025-03-20 20:02:21,826:INFO:Defining folds
2025-03-20 20:02:21,826:INFO:Declaring metric variables
2025-03-20 20:02:21,826:INFO:Importing untrained model
2025-03-20 20:02:21,826:INFO:Declaring custom model
2025-03-20 20:02:21,827:INFO:Bayesian Ridge Imported successfully
2025-03-20 20:02:21,827:INFO:Starting cross validation
2025-03-20 20:02:21,828:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:02:21,906:INFO:Calculating mean and std
2025-03-20 20:02:21,906:INFO:Creating metrics dataframe
2025-03-20 20:02:21,907:INFO:Finalizing model
2025-03-20 20:02:21,942:INFO:Uploading results into container
2025-03-20 20:02:21,943:INFO:Uploading model into container now
2025-03-20 20:02:21,943:INFO:_master_model_container: 22
2025-03-20 20:02:21,943:INFO:_display_container: 4
2025-03-20 20:02:21,943:INFO:BayesianRidge()
2025-03-20 20:02:21,943:INFO:create_model() successfully completed......................................
2025-03-20 20:02:21,997:INFO:SubProcess create_model() end ==================================
2025-03-20 20:02:21,998:INFO:BayesianRidge() result for MAPE is 0.0211
2025-03-20 20:02:21,998:INFO:BayesianRidge(alpha_1=0.00036634659930726997, alpha_2=3.1836872538740605e-05,
              lambda_1=0.874752585887542, lambda_2=3.403322954426461e-07) result for MAPE is 0.0211
2025-03-20 20:02:21,998:INFO:BayesianRidge() is best model
2025-03-20 20:02:21,998:INFO:choose_better completed
2025-03-20 20:02:21,998:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-03-20 20:02:21,998:INFO:Creating Dashboard logs
2025-03-20 20:02:22,000:INFO:Model: Bayesian Ridge
2025-03-20 20:02:22,022:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-20 20:02:22,220:INFO:Initializing predict_model()
2025-03-20 20:02:22,220:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9870CF70>)
2025-03-20 20:02:22,220:INFO:Checking exceptions
2025-03-20 20:02:22,220:INFO:Preloading libraries
2025-03-20 20:02:22,367:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:02:22,372:INFO:_master_model_container: 22
2025-03-20 20:02:22,372:INFO:_display_container: 3
2025-03-20 20:02:22,372:INFO:BayesianRidge()
2025-03-20 20:02:22,372:INFO:tune_model() successfully completed......................................
2025-03-20 20:02:22,440:INFO:Initializing predict_model()
2025-03-20 20:02:22,440:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E34D9D0>)
2025-03-20 20:02:22,440:INFO:Checking exceptions
2025-03-20 20:02:22,440:INFO:Preloading libraries
2025-03-20 20:02:22,575:INFO:Initializing tune_model()
2025-03-20 20:02:22,575:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:02:22,575:INFO:Checking exceptions
2025-03-20 20:02:22,575:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:02:22,584:INFO:Copying training dataset
2025-03-20 20:02:22,586:INFO:Checking base model
2025-03-20 20:02:22,586:INFO:Base model : Gradient Boosting Regressor
2025-03-20 20:02:22,588:INFO:Declaring metric variables
2025-03-20 20:02:22,590:INFO:Defining Hyperparameters
2025-03-20 20:02:22,647:INFO:Tuning with n_jobs=-1
2025-03-20 20:02:22,647:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:02:22,647:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:02:22,647:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:02:22,647:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:02:22,647:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:02:22,648:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:03:28,710:INFO:best_params: {'actual_estimator__n_estimators': 66, 'actual_estimator__learning_rate': 0.19558561781467235, 'actual_estimator__subsample': 0.9352898226810128, 'actual_estimator__min_samples_split': 8, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 2, 'actual_estimator__max_features': 0.43275761279752, 'actual_estimator__min_impurity_decrease': 2.7229260127058637e-09}
2025-03-20 20:03:28,718:INFO:Hyperparameter search completed
2025-03-20 20:03:28,718:INFO:SubProcess create_model() called ==================================
2025-03-20 20:03:28,719:INFO:Initializing create_model()
2025-03-20 20:03:28,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E3E8760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 66, 'learning_rate': 0.19558561781467235, 'subsample': 0.9352898226810128, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 2, 'max_features': 0.43275761279752, 'min_impurity_decrease': 2.7229260127058637e-09})
2025-03-20 20:03:28,719:INFO:Checking exceptions
2025-03-20 20:03:28,719:INFO:Importing libraries
2025-03-20 20:03:28,719:INFO:Copying training dataset
2025-03-20 20:03:28,723:INFO:Defining folds
2025-03-20 20:03:28,723:INFO:Declaring metric variables
2025-03-20 20:03:28,725:INFO:Importing untrained model
2025-03-20 20:03:28,725:INFO:Declaring custom model
2025-03-20 20:03:28,728:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 20:03:28,733:INFO:Starting cross validation
2025-03-20 20:03:28,734:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:03:28,989:INFO:Calculating mean and std
2025-03-20 20:03:28,990:INFO:Creating metrics dataframe
2025-03-20 20:03:28,994:INFO:Finalizing model
2025-03-20 20:03:29,227:INFO:Uploading results into container
2025-03-20 20:03:29,228:INFO:Uploading model into container now
2025-03-20 20:03:29,228:INFO:_master_model_container: 23
2025-03-20 20:03:29,228:INFO:_display_container: 5
2025-03-20 20:03:29,229:INFO:GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128)
2025-03-20 20:03:29,229:INFO:create_model() successfully completed......................................
2025-03-20 20:03:29,332:INFO:SubProcess create_model() end ==================================
2025-03-20 20:03:29,332:INFO:choose_better activated
2025-03-20 20:03:29,335:INFO:SubProcess create_model() called ==================================
2025-03-20 20:03:29,336:INFO:Initializing create_model()
2025-03-20 20:03:29,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:03:29,336:INFO:Checking exceptions
2025-03-20 20:03:29,337:INFO:Importing libraries
2025-03-20 20:03:29,337:INFO:Copying training dataset
2025-03-20 20:03:29,341:INFO:Defining folds
2025-03-20 20:03:29,341:INFO:Declaring metric variables
2025-03-20 20:03:29,341:INFO:Importing untrained model
2025-03-20 20:03:29,341:INFO:Declaring custom model
2025-03-20 20:03:29,342:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 20:03:29,342:INFO:Starting cross validation
2025-03-20 20:03:29,343:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:03:30,205:INFO:Calculating mean and std
2025-03-20 20:03:30,205:INFO:Creating metrics dataframe
2025-03-20 20:03:30,207:INFO:Finalizing model
2025-03-20 20:03:31,163:INFO:Uploading results into container
2025-03-20 20:03:31,164:INFO:Uploading model into container now
2025-03-20 20:03:31,164:INFO:_master_model_container: 24
2025-03-20 20:03:31,164:INFO:_display_container: 6
2025-03-20 20:03:31,164:INFO:GradientBoostingRegressor(random_state=888)
2025-03-20 20:03:31,164:INFO:create_model() successfully completed......................................
2025-03-20 20:03:31,264:INFO:SubProcess create_model() end ==================================
2025-03-20 20:03:31,265:INFO:GradientBoostingRegressor(random_state=888) result for MAPE is 0.0217
2025-03-20 20:03:31,265:INFO:GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128) result for MAPE is 0.0203
2025-03-20 20:03:31,266:INFO:GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128) is best model
2025-03-20 20:03:31,266:INFO:choose_better completed
2025-03-20 20:03:31,266:INFO:Creating Dashboard logs
2025-03-20 20:03:31,269:INFO:Model: Gradient Boosting Regressor
2025-03-20 20:03:31,307:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.19558561781467235, 'loss': 'squared_error', 'max_depth': 2, 'max_features': 0.43275761279752, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.7229260127058637e-09, 'min_samples_leaf': 1, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 66, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.9352898226810128, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 20:03:31,702:INFO:Initializing predict_model()
2025-03-20 20:03:31,702:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9A767820>)
2025-03-20 20:03:31,702:INFO:Checking exceptions
2025-03-20 20:03:31,702:INFO:Preloading libraries
2025-03-20 20:03:31,939:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:03:31,947:INFO:_master_model_container: 24
2025-03-20 20:03:31,947:INFO:_display_container: 5
2025-03-20 20:03:31,948:INFO:GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128)
2025-03-20 20:03:31,948:INFO:tune_model() successfully completed......................................
2025-03-20 20:03:32,051:INFO:Initializing predict_model()
2025-03-20 20:03:32,051:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E33FCA0>)
2025-03-20 20:03:32,051:INFO:Checking exceptions
2025-03-20 20:03:32,051:INFO:Preloading libraries
2025-03-20 20:03:32,282:INFO:Initializing tune_model()
2025-03-20 20:03:32,282:INFO:tune_model(estimator=Ridge(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:03:32,282:INFO:Checking exceptions
2025-03-20 20:03:32,282:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:03:32,296:INFO:Copying training dataset
2025-03-20 20:03:32,299:INFO:Checking base model
2025-03-20 20:03:32,299:INFO:Base model : Ridge Regression
2025-03-20 20:03:32,302:INFO:Declaring metric variables
2025-03-20 20:03:32,305:INFO:Defining Hyperparameters
2025-03-20 20:03:32,409:INFO:Tuning with n_jobs=-1
2025-03-20 20:03:32,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:03:32,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:03:32,410:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:03:32,410:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:03:32,410:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:03:32,410:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:04:12,236:INFO:best_params: {'actual_estimator__alpha': 0.13792515249313964, 'actual_estimator__fit_intercept': True}
2025-03-20 20:04:12,243:INFO:Hyperparameter search completed
2025-03-20 20:04:12,243:INFO:SubProcess create_model() called ==================================
2025-03-20 20:04:12,243:INFO:Initializing create_model()
2025-03-20 20:04:12,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E336880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 0.13792515249313964, 'fit_intercept': True})
2025-03-20 20:04:12,243:INFO:Checking exceptions
2025-03-20 20:04:12,243:INFO:Importing libraries
2025-03-20 20:04:12,243:INFO:Copying training dataset
2025-03-20 20:04:12,247:INFO:Defining folds
2025-03-20 20:04:12,247:INFO:Declaring metric variables
2025-03-20 20:04:12,249:INFO:Importing untrained model
2025-03-20 20:04:12,249:INFO:Declaring custom model
2025-03-20 20:04:12,252:INFO:Ridge Regression Imported successfully
2025-03-20 20:04:12,257:INFO:Starting cross validation
2025-03-20 20:04:12,258:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:04:12,361:INFO:Calculating mean and std
2025-03-20 20:04:12,362:INFO:Creating metrics dataframe
2025-03-20 20:04:12,366:INFO:Finalizing model
2025-03-20 20:04:12,418:INFO:Uploading results into container
2025-03-20 20:04:12,418:INFO:Uploading model into container now
2025-03-20 20:04:12,418:INFO:_master_model_container: 25
2025-03-20 20:04:12,419:INFO:_display_container: 7
2025-03-20 20:04:12,419:INFO:Ridge(alpha=0.13792515249313964, random_state=888)
2025-03-20 20:04:12,419:INFO:create_model() successfully completed......................................
2025-03-20 20:04:12,520:INFO:SubProcess create_model() end ==================================
2025-03-20 20:04:12,520:INFO:choose_better activated
2025-03-20 20:04:12,523:INFO:SubProcess create_model() called ==================================
2025-03-20 20:04:12,523:INFO:Initializing create_model()
2025-03-20 20:04:12,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=Ridge(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:04:12,524:INFO:Checking exceptions
2025-03-20 20:04:12,525:INFO:Importing libraries
2025-03-20 20:04:12,525:INFO:Copying training dataset
2025-03-20 20:04:12,528:INFO:Defining folds
2025-03-20 20:04:12,528:INFO:Declaring metric variables
2025-03-20 20:04:12,528:INFO:Importing untrained model
2025-03-20 20:04:12,528:INFO:Declaring custom model
2025-03-20 20:04:12,529:INFO:Ridge Regression Imported successfully
2025-03-20 20:04:12,529:INFO:Starting cross validation
2025-03-20 20:04:12,530:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:04:12,638:INFO:Calculating mean and std
2025-03-20 20:04:12,639:INFO:Creating metrics dataframe
2025-03-20 20:04:12,640:INFO:Finalizing model
2025-03-20 20:04:12,686:INFO:Uploading results into container
2025-03-20 20:04:12,686:INFO:Uploading model into container now
2025-03-20 20:04:12,687:INFO:_master_model_container: 26
2025-03-20 20:04:12,687:INFO:_display_container: 8
2025-03-20 20:04:12,687:INFO:Ridge(random_state=888)
2025-03-20 20:04:12,687:INFO:create_model() successfully completed......................................
2025-03-20 20:04:12,784:INFO:SubProcess create_model() end ==================================
2025-03-20 20:04:12,784:INFO:Ridge(random_state=888) result for MAPE is 0.0222
2025-03-20 20:04:12,785:INFO:Ridge(alpha=0.13792515249313964, random_state=888) result for MAPE is 0.0205
2025-03-20 20:04:12,785:INFO:Ridge(alpha=0.13792515249313964, random_state=888) is best model
2025-03-20 20:04:12,785:INFO:choose_better completed
2025-03-20 20:04:12,785:INFO:Creating Dashboard logs
2025-03-20 20:04:12,788:INFO:Model: Ridge Regression
2025-03-20 20:04:12,826:INFO:Logged params: {'alpha': 0.13792515249313964, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 888, 'solver': 'auto', 'tol': 0.0001}
2025-03-20 20:04:13,211:INFO:Initializing predict_model()
2025-03-20 20:04:13,211:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=Ridge(alpha=0.13792515249313964, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A964EC9D0>)
2025-03-20 20:04:13,211:INFO:Checking exceptions
2025-03-20 20:04:13,211:INFO:Preloading libraries
2025-03-20 20:04:13,454:ERROR:_log_model() for Ridge(alpha=0.13792515249313964, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:04:13,460:INFO:_master_model_container: 26
2025-03-20 20:04:13,460:INFO:_display_container: 7
2025-03-20 20:04:13,461:INFO:Ridge(alpha=0.13792515249313964, random_state=888)
2025-03-20 20:04:13,461:INFO:tune_model() successfully completed......................................
2025-03-20 20:04:13,564:INFO:Initializing predict_model()
2025-03-20 20:04:13,564:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=Ridge(alpha=0.13792515249313964, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E33FCA0>)
2025-03-20 20:04:13,564:INFO:Checking exceptions
2025-03-20 20:04:13,564:INFO:Preloading libraries
2025-03-20 20:04:13,783:INFO:Initializing tune_model()
2025-03-20 20:04:13,783:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:04:13,783:INFO:Checking exceptions
2025-03-20 20:04:13,783:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:04:13,796:INFO:Copying training dataset
2025-03-20 20:04:13,799:INFO:Checking base model
2025-03-20 20:04:13,800:INFO:Base model : Light Gradient Boosting Machine
2025-03-20 20:04:13,803:INFO:Declaring metric variables
2025-03-20 20:04:13,806:INFO:Defining Hyperparameters
2025-03-20 20:04:13,906:INFO:Tuning with n_jobs=-1
2025-03-20 20:04:13,906:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:04:13,906:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:04:13,907:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:04:13,907:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:04:13,907:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:04:13,907:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:05:00,845:INFO:best_params: {'actual_estimator__num_leaves': 51, 'actual_estimator__learning_rate': 0.08238180235960571, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_split_gain': 0.43973678872935484, 'actual_estimator__reg_alpha': 0.2500694964077735, 'actual_estimator__reg_lambda': 1.0873476871223965e-05, 'actual_estimator__feature_fraction': 0.7548601542467179, 'actual_estimator__bagging_fraction': 0.7451949080123305, 'actual_estimator__bagging_freq': 4, 'actual_estimator__min_child_samples': 11}
2025-03-20 20:05:00,853:INFO:Hyperparameter search completed
2025-03-20 20:05:00,854:INFO:SubProcess create_model() called ==================================
2025-03-20 20:05:00,854:INFO:Initializing create_model()
2025-03-20 20:05:00,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E347FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 51, 'learning_rate': 0.08238180235960571, 'n_estimators': 140, 'min_split_gain': 0.43973678872935484, 'reg_alpha': 0.2500694964077735, 'reg_lambda': 1.0873476871223965e-05, 'feature_fraction': 0.7548601542467179, 'bagging_fraction': 0.7451949080123305, 'bagging_freq': 4, 'min_child_samples': 11})
2025-03-20 20:05:00,854:INFO:Checking exceptions
2025-03-20 20:05:00,855:INFO:Importing libraries
2025-03-20 20:05:00,855:INFO:Copying training dataset
2025-03-20 20:05:00,858:INFO:Defining folds
2025-03-20 20:05:00,858:INFO:Declaring metric variables
2025-03-20 20:05:00,861:INFO:Importing untrained model
2025-03-20 20:05:00,861:INFO:Declaring custom model
2025-03-20 20:05:00,864:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 20:05:00,870:INFO:Starting cross validation
2025-03-20 20:05:00,871:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:05:01,183:INFO:Calculating mean and std
2025-03-20 20:05:01,184:INFO:Creating metrics dataframe
2025-03-20 20:05:01,189:INFO:Finalizing model
2025-03-20 20:05:01,239:INFO:[LightGBM] [Warning] feature_fraction is set=0.7548601542467179, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7548601542467179
2025-03-20 20:05:01,239:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7451949080123305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7451949080123305
2025-03-20 20:05:01,239:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-20 20:05:01,241:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 20:05:01,242:INFO:[LightGBM] [Warning] feature_fraction is set=0.7548601542467179, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7548601542467179
2025-03-20 20:05:01,242:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7451949080123305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7451949080123305
2025-03-20 20:05:01,242:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-20 20:05:01,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000776 seconds.
2025-03-20 20:05:01,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 20:05:01,243:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 20:05:01,244:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 20:05:01,244:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 20:05:01,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:05:01,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:05:01,346:INFO:Uploading results into container
2025-03-20 20:05:01,346:INFO:Uploading model into container now
2025-03-20 20:05:01,347:INFO:_master_model_container: 27
2025-03-20 20:05:01,347:INFO:_display_container: 9
2025-03-20 20:05:01,348:INFO:LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05)
2025-03-20 20:05:01,348:INFO:create_model() successfully completed......................................
2025-03-20 20:05:01,455:INFO:SubProcess create_model() end ==================================
2025-03-20 20:05:01,455:INFO:choose_better activated
2025-03-20 20:05:01,459:INFO:SubProcess create_model() called ==================================
2025-03-20 20:05:01,459:INFO:Initializing create_model()
2025-03-20 20:05:01,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:05:01,459:INFO:Checking exceptions
2025-03-20 20:05:01,461:INFO:Importing libraries
2025-03-20 20:05:01,461:INFO:Copying training dataset
2025-03-20 20:05:01,464:INFO:Defining folds
2025-03-20 20:05:01,464:INFO:Declaring metric variables
2025-03-20 20:05:01,464:INFO:Importing untrained model
2025-03-20 20:05:01,464:INFO:Declaring custom model
2025-03-20 20:05:01,465:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 20:05:01,465:INFO:Starting cross validation
2025-03-20 20:05:01,466:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:05:02,291:INFO:Calculating mean and std
2025-03-20 20:05:02,292:INFO:Creating metrics dataframe
2025-03-20 20:05:02,294:INFO:Finalizing model
2025-03-20 20:05:02,346:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 20:05:02,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000733 seconds.
2025-03-20 20:05:02,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 20:05:02,347:INFO:[LightGBM] [Info] Total Bins 4605
2025-03-20 20:05:02,347:INFO:[LightGBM] [Info] Number of data points in the train set: 1399, number of used features: 37
2025-03-20 20:05:02,348:INFO:[LightGBM] [Info] Start training from score 15.652847
2025-03-20 20:05:02,627:INFO:Uploading results into container
2025-03-20 20:05:02,627:INFO:Uploading model into container now
2025-03-20 20:05:02,628:INFO:_master_model_container: 28
2025-03-20 20:05:02,628:INFO:_display_container: 10
2025-03-20 20:05:02,628:INFO:LGBMRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:05:02,628:INFO:create_model() successfully completed......................................
2025-03-20 20:05:02,723:INFO:SubProcess create_model() end ==================================
2025-03-20 20:05:02,724:INFO:LGBMRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0233
2025-03-20 20:05:02,724:INFO:LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05) result for MAPE is 0.0217
2025-03-20 20:05:02,724:INFO:LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05) is best model
2025-03-20 20:05:02,724:INFO:choose_better completed
2025-03-20 20:05:02,725:INFO:Creating Dashboard logs
2025-03-20 20:05:02,728:INFO:Model: Light Gradient Boosting Machine
2025-03-20 20:05:02,765:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.08238180235960571, 'max_depth': -1, 'min_child_samples': 11, 'min_child_weight': 0.001, 'min_split_gain': 0.43973678872935484, 'n_estimators': 140, 'n_jobs': -1, 'num_leaves': 51, 'objective': None, 'random_state': 888, 'reg_alpha': 0.2500694964077735, 'reg_lambda': 1.0873476871223965e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7548601542467179, 'bagging_fraction': 0.7451949080123305, 'bagging_freq': 4}
2025-03-20 20:05:03,207:INFO:Initializing predict_model()
2025-03-20 20:05:03,207:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A964ECC10>)
2025-03-20 20:05:03,207:INFO:Checking exceptions
2025-03-20 20:05:03,207:INFO:Preloading libraries
2025-03-20 20:05:03,461:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:05:03,468:INFO:_master_model_container: 28
2025-03-20 20:05:03,468:INFO:_display_container: 9
2025-03-20 20:05:03,469:INFO:LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05)
2025-03-20 20:05:03,469:INFO:tune_model() successfully completed......................................
2025-03-20 20:05:03,570:INFO:Initializing predict_model()
2025-03-20 20:05:03,571:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E34D9D0>)
2025-03-20 20:05:03,571:INFO:Checking exceptions
2025-03-20 20:05:03,571:INFO:Preloading libraries
2025-03-20 20:05:03,791:INFO:Initializing tune_model()
2025-03-20 20:05:03,791:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:05:03,792:INFO:Checking exceptions
2025-03-20 20:05:03,792:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:05:03,806:INFO:Copying training dataset
2025-03-20 20:05:03,810:INFO:Checking base model
2025-03-20 20:05:03,810:INFO:Base model : Extreme Gradient Boosting
2025-03-20 20:05:03,814:INFO:Declaring metric variables
2025-03-20 20:05:03,818:INFO:Defining Hyperparameters
2025-03-20 20:05:03,922:INFO:Tuning with n_jobs=-1
2025-03-20 20:05:03,922:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:05:03,922:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:05:03,923:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:05:03,923:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:05:03,923:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:05:03,923:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:06:18,808:INFO:best_params: {'actual_estimator__learning_rate': 0.14022679386198442, 'actual_estimator__n_estimators': 275, 'actual_estimator__subsample': 0.862993333858407, 'actual_estimator__max_depth': 1, 'actual_estimator__colsample_bytree': 0.5409878744572405, 'actual_estimator__min_child_weight': 4, 'actual_estimator__reg_alpha': 0.00042516619781516175, 'actual_estimator__reg_lambda': 3.4722837594342337e-08, 'actual_estimator__scale_pos_weight': 35.83948389577335}
2025-03-20 20:06:18,817:INFO:Hyperparameter search completed
2025-03-20 20:06:18,817:INFO:SubProcess create_model() called ==================================
2025-03-20 20:06:18,818:INFO:Initializing create_model()
2025-03-20 20:06:18,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A32816B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.14022679386198442, 'n_estimators': 275, 'subsample': 0.862993333858407, 'max_depth': 1, 'colsample_bytree': 0.5409878744572405, 'min_child_weight': 4, 'reg_alpha': 0.00042516619781516175, 'reg_lambda': 3.4722837594342337e-08, 'scale_pos_weight': 35.83948389577335})
2025-03-20 20:06:18,818:INFO:Checking exceptions
2025-03-20 20:06:18,818:INFO:Importing libraries
2025-03-20 20:06:18,818:INFO:Copying training dataset
2025-03-20 20:06:18,822:INFO:Defining folds
2025-03-20 20:06:18,822:INFO:Declaring metric variables
2025-03-20 20:06:18,825:INFO:Importing untrained model
2025-03-20 20:06:18,825:INFO:Declaring custom model
2025-03-20 20:06:18,829:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 20:06:18,834:INFO:Starting cross validation
2025-03-20 20:06:18,836:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:06:19,259:INFO:Calculating mean and std
2025-03-20 20:06:19,261:INFO:Creating metrics dataframe
2025-03-20 20:06:19,266:INFO:Finalizing model
2025-03-20 20:06:19,452:INFO:Uploading results into container
2025-03-20 20:06:19,452:INFO:Uploading model into container now
2025-03-20 20:06:19,453:INFO:_master_model_container: 29
2025-03-20 20:06:19,453:INFO:_display_container: 11
2025-03-20 20:06:19,454:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 20:06:19,454:INFO:create_model() successfully completed......................................
2025-03-20 20:06:19,557:INFO:SubProcess create_model() end ==================================
2025-03-20 20:06:19,557:INFO:choose_better activated
2025-03-20 20:06:19,560:INFO:SubProcess create_model() called ==================================
2025-03-20 20:06:19,561:INFO:Initializing create_model()
2025-03-20 20:06:19,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:06:19,561:INFO:Checking exceptions
2025-03-20 20:06:19,562:INFO:Importing libraries
2025-03-20 20:06:19,562:INFO:Copying training dataset
2025-03-20 20:06:19,566:INFO:Defining folds
2025-03-20 20:06:19,566:INFO:Declaring metric variables
2025-03-20 20:06:19,566:INFO:Importing untrained model
2025-03-20 20:06:19,566:INFO:Declaring custom model
2025-03-20 20:06:19,567:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 20:06:19,567:INFO:Starting cross validation
2025-03-20 20:06:19,568:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:06:20,060:INFO:Calculating mean and std
2025-03-20 20:06:20,060:INFO:Creating metrics dataframe
2025-03-20 20:06:20,062:INFO:Finalizing model
2025-03-20 20:06:20,299:INFO:Uploading results into container
2025-03-20 20:06:20,300:INFO:Uploading model into container now
2025-03-20 20:06:20,300:INFO:_master_model_container: 30
2025-03-20 20:06:20,300:INFO:_display_container: 12
2025-03-20 20:06:20,301:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 20:06:20,301:INFO:create_model() successfully completed......................................
2025-03-20 20:06:20,395:INFO:SubProcess create_model() end ==================================
2025-03-20 20:06:20,396:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.0235
2025-03-20 20:06:20,396:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) result for MAPE is 0.021
2025-03-20 20:06:20,397:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) is best model
2025-03-20 20:06:20,397:INFO:choose_better completed
2025-03-20 20:06:20,397:INFO:Creating Dashboard logs
2025-03-20 20:06:20,400:INFO:Model: Extreme Gradient Boosting
2025-03-20 20:06:20,439:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5409878744572405, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.14022679386198442, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 1, 'max_leaves': None, 'min_child_weight': 4, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 275, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': 0.00042516619781516175, 'reg_lambda': 3.4722837594342337e-08, 'sampling_method': None, 'scale_pos_weight': 35.83948389577335, 'subsample': 0.862993333858407, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 20:06:20,899:INFO:Initializing predict_model()
2025-03-20 20:06:20,899:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A965321F0>)
2025-03-20 20:06:20,899:INFO:Checking exceptions
2025-03-20 20:06:20,899:INFO:Preloading libraries
2025-03-20 20:06:21,154:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:06:21,161:INFO:_master_model_container: 30
2025-03-20 20:06:21,161:INFO:_display_container: 11
2025-03-20 20:06:21,162:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 20:06:21,163:INFO:tune_model() successfully completed......................................
2025-03-20 20:06:21,262:INFO:Initializing predict_model()
2025-03-20 20:06:21,262:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E34D9D0>)
2025-03-20 20:06:21,262:INFO:Checking exceptions
2025-03-20 20:06:21,263:INFO:Preloading libraries
2025-03-20 20:06:21,498:INFO:Initializing tune_model()
2025-03-20 20:06:21,498:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:06:21,498:INFO:Checking exceptions
2025-03-20 20:06:21,498:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:06:21,511:INFO:Copying training dataset
2025-03-20 20:06:21,517:INFO:Checking base model
2025-03-20 20:06:21,517:INFO:Base model : Random Forest Regressor
2025-03-20 20:06:21,521:INFO:Declaring metric variables
2025-03-20 20:06:21,524:INFO:Defining Hyperparameters
2025-03-20 20:06:21,629:INFO:Tuning with n_jobs=-1
2025-03-20 20:06:21,630:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:06:21,630:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:06:21,630:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:06:21,630:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:06:21,630:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:06:21,631:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:09:03,210:INFO:best_params: {'actual_estimator__n_estimators': 284, 'actual_estimator__max_depth': 5, 'actual_estimator__min_impurity_decrease': 3.5679344378735776e-08, 'actual_estimator__max_features': 0.40088847529944527, 'actual_estimator__min_samples_split': 6, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__bootstrap': True, 'actual_estimator__criterion': 'squared_error'}
2025-03-20 20:09:03,218:INFO:Hyperparameter search completed
2025-03-20 20:09:03,218:INFO:SubProcess create_model() called ==================================
2025-03-20 20:09:03,219:INFO:Initializing create_model()
2025-03-20 20:09:03,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A328169D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 284, 'max_depth': 5, 'min_impurity_decrease': 3.5679344378735776e-08, 'max_features': 0.40088847529944527, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': True, 'criterion': 'squared_error'})
2025-03-20 20:09:03,219:INFO:Checking exceptions
2025-03-20 20:09:03,219:INFO:Importing libraries
2025-03-20 20:09:03,219:INFO:Copying training dataset
2025-03-20 20:09:03,225:INFO:Defining folds
2025-03-20 20:09:03,225:INFO:Declaring metric variables
2025-03-20 20:09:03,228:INFO:Importing untrained model
2025-03-20 20:09:03,228:INFO:Declaring custom model
2025-03-20 20:09:03,231:INFO:Random Forest Regressor Imported successfully
2025-03-20 20:09:03,236:INFO:Starting cross validation
2025-03-20 20:09:03,238:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:09:03,728:INFO:Calculating mean and std
2025-03-20 20:09:03,730:INFO:Creating metrics dataframe
2025-03-20 20:09:03,735:INFO:Finalizing model
2025-03-20 20:09:04,089:INFO:Uploading results into container
2025-03-20 20:09:04,090:INFO:Uploading model into container now
2025-03-20 20:09:04,090:INFO:_master_model_container: 31
2025-03-20 20:09:04,091:INFO:_display_container: 13
2025-03-20 20:09:04,091:INFO:RandomForestRegressor(max_depth=5, max_features=0.40088847529944527,
                      min_impurity_decrease=3.5679344378735776e-08,
                      min_samples_leaf=2, min_samples_split=6, n_estimators=284,
                      n_jobs=-1, random_state=888)
2025-03-20 20:09:04,091:INFO:create_model() successfully completed......................................
2025-03-20 20:09:04,189:INFO:SubProcess create_model() end ==================================
2025-03-20 20:09:04,189:INFO:choose_better activated
2025-03-20 20:09:04,193:INFO:SubProcess create_model() called ==================================
2025-03-20 20:09:04,193:INFO:Initializing create_model()
2025-03-20 20:09:04,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:09:04,194:INFO:Checking exceptions
2025-03-20 20:09:04,195:INFO:Importing libraries
2025-03-20 20:09:04,195:INFO:Copying training dataset
2025-03-20 20:09:04,199:INFO:Defining folds
2025-03-20 20:09:04,199:INFO:Declaring metric variables
2025-03-20 20:09:04,200:INFO:Importing untrained model
2025-03-20 20:09:04,200:INFO:Declaring custom model
2025-03-20 20:09:04,200:INFO:Random Forest Regressor Imported successfully
2025-03-20 20:09:04,200:INFO:Starting cross validation
2025-03-20 20:09:04,201:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:09:04,745:INFO:Calculating mean and std
2025-03-20 20:09:04,745:INFO:Creating metrics dataframe
2025-03-20 20:09:04,746:INFO:Finalizing model
2025-03-20 20:09:05,024:INFO:Uploading results into container
2025-03-20 20:09:05,024:INFO:Uploading model into container now
2025-03-20 20:09:05,025:INFO:_master_model_container: 32
2025-03-20 20:09:05,025:INFO:_display_container: 14
2025-03-20 20:09:05,025:INFO:RandomForestRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:09:05,025:INFO:create_model() successfully completed......................................
2025-03-20 20:09:05,121:INFO:SubProcess create_model() end ==================================
2025-03-20 20:09:05,122:INFO:RandomForestRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0236
2025-03-20 20:09:05,122:INFO:RandomForestRegressor(max_depth=5, max_features=0.40088847529944527,
                      min_impurity_decrease=3.5679344378735776e-08,
                      min_samples_leaf=2, min_samples_split=6, n_estimators=284,
                      n_jobs=-1, random_state=888) result for MAPE is 0.0218
2025-03-20 20:09:05,123:INFO:RandomForestRegressor(max_depth=5, max_features=0.40088847529944527,
                      min_impurity_decrease=3.5679344378735776e-08,
                      min_samples_leaf=2, min_samples_split=6, n_estimators=284,
                      n_jobs=-1, random_state=888) is best model
2025-03-20 20:09:05,123:INFO:choose_better completed
2025-03-20 20:09:05,123:INFO:Creating Dashboard logs
2025-03-20 20:09:05,127:INFO:Model: Random Forest Regressor
2025-03-20 20:09:05,167:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 5, 'max_features': 0.40088847529944527, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 3.5679344378735776e-08, 'min_samples_leaf': 2, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 284, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 20:09:05,640:INFO:Initializing predict_model()
2025-03-20 20:09:05,640:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=RandomForestRegressor(max_depth=5, max_features=0.40088847529944527,
                      min_impurity_decrease=3.5679344378735776e-08,
                      min_samples_leaf=2, min_samples_split=6, n_estimators=284,
                      n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A965323A0>)
2025-03-20 20:09:05,640:INFO:Checking exceptions
2025-03-20 20:09:05,640:INFO:Preloading libraries
2025-03-20 20:09:05,943:ERROR:_log_model() for RandomForestRegressor(max_depth=5, max_features=0.40088847529944527,
                      min_impurity_decrease=3.5679344378735776e-08,
                      min_samples_leaf=2, min_samples_split=6, n_estimators=284,
                      n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:09:05,951:INFO:_master_model_container: 32
2025-03-20 20:09:05,951:INFO:_display_container: 13
2025-03-20 20:09:05,952:INFO:RandomForestRegressor(max_depth=5, max_features=0.40088847529944527,
                      min_impurity_decrease=3.5679344378735776e-08,
                      min_samples_leaf=2, min_samples_split=6, n_estimators=284,
                      n_jobs=-1, random_state=888)
2025-03-20 20:09:05,952:INFO:tune_model() successfully completed......................................
2025-03-20 20:09:06,050:INFO:Initializing predict_model()
2025-03-20 20:09:06,050:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=RandomForestRegressor(max_depth=5, max_features=0.40088847529944527,
                      min_impurity_decrease=3.5679344378735776e-08,
                      min_samples_leaf=2, min_samples_split=6, n_estimators=284,
                      n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E5A5D30>)
2025-03-20 20:09:06,050:INFO:Checking exceptions
2025-03-20 20:09:06,050:INFO:Preloading libraries
2025-03-20 20:09:06,316:INFO:Initializing tune_model()
2025-03-20 20:09:06,316:INFO:tune_model(estimator=AdaBoostRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:09:06,316:INFO:Checking exceptions
2025-03-20 20:09:06,316:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:09:06,330:INFO:Copying training dataset
2025-03-20 20:09:06,335:INFO:Checking base model
2025-03-20 20:09:06,335:INFO:Base model : AdaBoost Regressor
2025-03-20 20:09:06,338:INFO:Declaring metric variables
2025-03-20 20:09:06,341:INFO:Defining Hyperparameters
2025-03-20 20:09:06,443:INFO:Tuning with n_jobs=-1
2025-03-20 20:09:06,444:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:09:06,444:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:09:06,444:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:09:06,444:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:09:06,444:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:09:06,444:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:11:45,162:INFO:best_params: {'actual_estimator__learning_rate': 0.49713020911876504, 'actual_estimator__n_estimators': 278, 'actual_estimator__loss': 'square'}
2025-03-20 20:11:45,169:INFO:Hyperparameter search completed
2025-03-20 20:11:45,169:INFO:SubProcess create_model() called ==================================
2025-03-20 20:11:45,169:INFO:Initializing create_model()
2025-03-20 20:11:45,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=AdaBoostRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A327E63D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.49713020911876504, 'n_estimators': 278, 'loss': 'square'})
2025-03-20 20:11:45,169:INFO:Checking exceptions
2025-03-20 20:11:45,169:INFO:Importing libraries
2025-03-20 20:11:45,170:INFO:Copying training dataset
2025-03-20 20:11:45,174:INFO:Defining folds
2025-03-20 20:11:45,174:INFO:Declaring metric variables
2025-03-20 20:11:45,177:INFO:Importing untrained model
2025-03-20 20:11:45,177:INFO:Declaring custom model
2025-03-20 20:11:45,180:INFO:AdaBoost Regressor Imported successfully
2025-03-20 20:11:45,185:INFO:Starting cross validation
2025-03-20 20:11:45,186:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:11:48,642:INFO:Calculating mean and std
2025-03-20 20:11:48,643:INFO:Creating metrics dataframe
2025-03-20 20:11:48,648:INFO:Finalizing model
2025-03-20 20:11:49,735:INFO:Uploading results into container
2025-03-20 20:11:49,736:INFO:Uploading model into container now
2025-03-20 20:11:49,737:INFO:_master_model_container: 33
2025-03-20 20:11:49,737:INFO:_display_container: 15
2025-03-20 20:11:49,737:INFO:AdaBoostRegressor(learning_rate=0.49713020911876504, loss='square',
                  n_estimators=278, random_state=888)
2025-03-20 20:11:49,738:INFO:create_model() successfully completed......................................
2025-03-20 20:11:49,839:INFO:SubProcess create_model() end ==================================
2025-03-20 20:11:49,839:INFO:choose_better activated
2025-03-20 20:11:49,843:INFO:SubProcess create_model() called ==================================
2025-03-20 20:11:49,843:INFO:Initializing create_model()
2025-03-20 20:11:49,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=AdaBoostRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:11:49,843:INFO:Checking exceptions
2025-03-20 20:11:49,845:INFO:Importing libraries
2025-03-20 20:11:49,845:INFO:Copying training dataset
2025-03-20 20:11:49,849:INFO:Defining folds
2025-03-20 20:11:49,849:INFO:Declaring metric variables
2025-03-20 20:11:49,849:INFO:Importing untrained model
2025-03-20 20:11:49,849:INFO:Declaring custom model
2025-03-20 20:11:49,850:INFO:AdaBoost Regressor Imported successfully
2025-03-20 20:11:49,850:INFO:Starting cross validation
2025-03-20 20:11:49,851:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:11:50,151:INFO:Calculating mean and std
2025-03-20 20:11:50,151:INFO:Creating metrics dataframe
2025-03-20 20:11:50,153:INFO:Finalizing model
2025-03-20 20:11:50,429:INFO:Uploading results into container
2025-03-20 20:11:50,429:INFO:Uploading model into container now
2025-03-20 20:11:50,430:INFO:_master_model_container: 34
2025-03-20 20:11:50,430:INFO:_display_container: 16
2025-03-20 20:11:50,430:INFO:AdaBoostRegressor(random_state=888)
2025-03-20 20:11:50,430:INFO:create_model() successfully completed......................................
2025-03-20 20:11:50,531:INFO:SubProcess create_model() end ==================================
2025-03-20 20:11:50,532:INFO:AdaBoostRegressor(random_state=888) result for MAPE is 0.0246
2025-03-20 20:11:50,532:INFO:AdaBoostRegressor(learning_rate=0.49713020911876504, loss='square',
                  n_estimators=278, random_state=888) result for MAPE is 0.0226
2025-03-20 20:11:50,532:INFO:AdaBoostRegressor(learning_rate=0.49713020911876504, loss='square',
                  n_estimators=278, random_state=888) is best model
2025-03-20 20:11:50,532:INFO:choose_better completed
2025-03-20 20:11:50,533:INFO:Creating Dashboard logs
2025-03-20 20:11:50,536:INFO:Model: AdaBoost Regressor
2025-03-20 20:11:50,575:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 0.49713020911876504, 'loss': 'square', 'n_estimators': 278, 'random_state': 888}
2025-03-20 20:11:51,026:INFO:Initializing predict_model()
2025-03-20 20:11:51,027:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=AdaBoostRegressor(learning_rate=0.49713020911876504, loss='square',
                  n_estimators=278, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9E8254C0>)
2025-03-20 20:11:51,027:INFO:Checking exceptions
2025-03-20 20:11:51,027:INFO:Preloading libraries
2025-03-20 20:11:51,322:ERROR:_log_model() for AdaBoostRegressor(learning_rate=0.49713020911876504, loss='square',
                  n_estimators=278, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:11:51,331:INFO:_master_model_container: 34
2025-03-20 20:11:51,331:INFO:_display_container: 15
2025-03-20 20:11:51,331:INFO:AdaBoostRegressor(learning_rate=0.49713020911876504, loss='square',
                  n_estimators=278, random_state=888)
2025-03-20 20:11:51,331:INFO:tune_model() successfully completed......................................
2025-03-20 20:11:51,434:INFO:Initializing predict_model()
2025-03-20 20:11:51,435:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=AdaBoostRegressor(learning_rate=0.49713020911876504, loss='square',
                  n_estimators=278, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A964EC5E0>)
2025-03-20 20:11:51,435:INFO:Checking exceptions
2025-03-20 20:11:51,435:INFO:Preloading libraries
2025-03-20 20:11:51,693:INFO:Initializing tune_model()
2025-03-20 20:11:51,693:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x0000022A2E33ADC0>, fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:11:51,694:INFO:Checking exceptions
2025-03-20 20:11:51,694:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:11:51,707:INFO:Copying training dataset
2025-03-20 20:11:51,712:INFO:Checking base model
2025-03-20 20:11:51,712:INFO:Base model : CatBoost Regressor
2025-03-20 20:11:51,715:INFO:Declaring metric variables
2025-03-20 20:11:51,718:INFO:Defining Hyperparameters
2025-03-20 20:11:51,819:INFO:Tuning with n_jobs=-1
2025-03-20 20:11:51,820:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:11:51,820:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:11:51,820:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:11:51,820:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:11:51,820:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:11:51,821:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:15:27,299:INFO:best_params: {'actual_estimator__eta': 0.09914742930290876, 'actual_estimator__depth': 2, 'actual_estimator__n_estimators': 85, 'actual_estimator__random_strength': 0.5888645385426435, 'actual_estimator__l2_leaf_reg': 4}
2025-03-20 20:15:27,306:INFO:Hyperparameter search completed
2025-03-20 20:15:27,306:INFO:SubProcess create_model() called ==================================
2025-03-20 20:15:27,307:INFO:Initializing create_model()
2025-03-20 20:15:27,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000022A738ABE50>, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022ABA8F5310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'eta': 0.09914742930290876, 'depth': 2, 'n_estimators': 85, 'random_strength': 0.5888645385426435, 'l2_leaf_reg': 4})
2025-03-20 20:15:27,307:INFO:Checking exceptions
2025-03-20 20:15:27,307:INFO:Importing libraries
2025-03-20 20:15:27,307:INFO:Copying training dataset
2025-03-20 20:15:27,311:INFO:Defining folds
2025-03-20 20:15:27,311:INFO:Declaring metric variables
2025-03-20 20:15:27,314:INFO:Importing untrained model
2025-03-20 20:15:27,314:INFO:Declaring custom model
2025-03-20 20:15:27,317:INFO:CatBoost Regressor Imported successfully
2025-03-20 20:15:27,323:INFO:Starting cross validation
2025-03-20 20:15:27,324:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:15:31,276:INFO:Calculating mean and std
2025-03-20 20:15:31,277:INFO:Creating metrics dataframe
2025-03-20 20:15:31,283:INFO:Finalizing model
2025-03-20 20:15:31,424:INFO:Uploading results into container
2025-03-20 20:15:31,425:INFO:Uploading model into container now
2025-03-20 20:15:31,425:INFO:_master_model_container: 35
2025-03-20 20:15:31,426:INFO:_display_container: 17
2025-03-20 20:15:31,426:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A96531F70>
2025-03-20 20:15:31,426:INFO:create_model() successfully completed......................................
2025-03-20 20:15:31,525:INFO:SubProcess create_model() end ==================================
2025-03-20 20:15:31,525:INFO:choose_better activated
2025-03-20 20:15:31,528:INFO:SubProcess create_model() called ==================================
2025-03-20 20:15:31,529:INFO:Initializing create_model()
2025-03-20 20:15:31,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000022A2E33ADC0>, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:15:31,529:INFO:Checking exceptions
2025-03-20 20:15:31,530:INFO:Importing libraries
2025-03-20 20:15:31,530:INFO:Copying training dataset
2025-03-20 20:15:31,535:INFO:Defining folds
2025-03-20 20:15:31,535:INFO:Declaring metric variables
2025-03-20 20:15:31,535:INFO:Importing untrained model
2025-03-20 20:15:31,535:INFO:Declaring custom model
2025-03-20 20:15:31,535:INFO:CatBoost Regressor Imported successfully
2025-03-20 20:15:31,535:INFO:Starting cross validation
2025-03-20 20:15:31,536:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:15:38,651:INFO:Calculating mean and std
2025-03-20 20:15:38,651:INFO:Creating metrics dataframe
2025-03-20 20:15:38,653:INFO:Finalizing model
2025-03-20 20:15:40,182:INFO:Uploading results into container
2025-03-20 20:15:40,183:INFO:Uploading model into container now
2025-03-20 20:15:40,183:INFO:_master_model_container: 36
2025-03-20 20:15:40,183:INFO:_display_container: 18
2025-03-20 20:15:40,183:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A9A7D0760>
2025-03-20 20:15:40,183:INFO:create_model() successfully completed......................................
2025-03-20 20:15:40,281:INFO:SubProcess create_model() end ==================================
2025-03-20 20:15:40,281:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A9A7D0760> result for MAPE is 0.0249
2025-03-20 20:15:40,281:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A96531F70> result for MAPE is 0.0208
2025-03-20 20:15:40,281:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A96531F70> is best model
2025-03-20 20:15:40,281:INFO:choose_better completed
2025-03-20 20:15:40,281:INFO:Creating Dashboard logs
2025-03-20 20:15:40,285:INFO:Model: CatBoost Regressor
2025-03-20 20:15:40,323:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 85, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 4, 'random_strength': 0.5888645648956299, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 888, 'depth': 2, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.09914743155241013, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 4}
2025-03-20 20:15:40,800:INFO:Initializing predict_model()
2025-03-20 20:15:40,800:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000022A96531F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9E825D30>)
2025-03-20 20:15:40,800:INFO:Checking exceptions
2025-03-20 20:15:40,800:INFO:Preloading libraries
2025-03-20 20:15:41,042:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x0000022A96531F70> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:15:41,049:INFO:_master_model_container: 36
2025-03-20 20:15:41,049:INFO:_display_container: 17
2025-03-20 20:15:41,049:INFO:<catboost.core.CatBoostRegressor object at 0x0000022A96531F70>
2025-03-20 20:15:41,050:INFO:tune_model() successfully completed......................................
2025-03-20 20:15:41,147:INFO:Initializing predict_model()
2025-03-20 20:15:41,147:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000022A96531F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A2E34D430>)
2025-03-20 20:15:41,147:INFO:Checking exceptions
2025-03-20 20:15:41,147:INFO:Preloading libraries
2025-03-20 20:15:41,371:INFO:Initializing tune_model()
2025-03-20 20:15:41,372:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:15:41,372:INFO:Checking exceptions
2025-03-20 20:15:41,372:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:15:41,386:INFO:Copying training dataset
2025-03-20 20:15:41,389:INFO:Checking base model
2025-03-20 20:15:41,389:INFO:Base model : Extra Trees Regressor
2025-03-20 20:15:41,392:INFO:Declaring metric variables
2025-03-20 20:15:41,395:INFO:Defining Hyperparameters
2025-03-20 20:15:41,493:INFO:Tuning with n_jobs=-1
2025-03-20 20:15:41,494:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:15:41,494:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:15:41,494:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:15:41,494:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:15:41,494:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:15:41,494:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:17:55,197:INFO:best_params: {'actual_estimator__n_estimators': 65, 'actual_estimator__max_depth': 7, 'actual_estimator__min_samples_split': 4, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_features': 0.6210739062761141, 'actual_estimator__min_impurity_decrease': 7.306226778318376e-08, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2025-03-20 20:17:55,205:INFO:Hyperparameter search completed
2025-03-20 20:17:55,205:INFO:SubProcess create_model() called ==================================
2025-03-20 20:17:55,205:INFO:Initializing create_model()
2025-03-20 20:17:55,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E48E250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 65, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 0.6210739062761141, 'min_impurity_decrease': 7.306226778318376e-08, 'criterion': 'squared_error', 'bootstrap': True})
2025-03-20 20:17:55,206:INFO:Checking exceptions
2025-03-20 20:17:55,206:INFO:Importing libraries
2025-03-20 20:17:55,206:INFO:Copying training dataset
2025-03-20 20:17:55,211:INFO:Defining folds
2025-03-20 20:17:55,211:INFO:Declaring metric variables
2025-03-20 20:17:55,214:INFO:Importing untrained model
2025-03-20 20:17:55,214:INFO:Declaring custom model
2025-03-20 20:17:55,217:INFO:Extra Trees Regressor Imported successfully
2025-03-20 20:17:55,223:INFO:Starting cross validation
2025-03-20 20:17:55,225:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:17:58,223:INFO:Calculating mean and std
2025-03-20 20:17:58,225:INFO:Creating metrics dataframe
2025-03-20 20:17:58,229:INFO:Finalizing model
2025-03-20 20:17:58,369:INFO:Uploading results into container
2025-03-20 20:17:58,369:INFO:Uploading model into container now
2025-03-20 20:17:58,370:INFO:_master_model_container: 37
2025-03-20 20:17:58,370:INFO:_display_container: 19
2025-03-20 20:17:58,370:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=7,
                    max_features=0.6210739062761141,
                    min_impurity_decrease=7.306226778318376e-08,
                    min_samples_leaf=2, min_samples_split=4, n_estimators=65,
                    n_jobs=-1, random_state=888)
2025-03-20 20:17:58,370:INFO:create_model() successfully completed......................................
2025-03-20 20:17:58,471:INFO:SubProcess create_model() end ==================================
2025-03-20 20:17:58,471:INFO:choose_better activated
2025-03-20 20:17:58,475:INFO:SubProcess create_model() called ==================================
2025-03-20 20:17:58,475:INFO:Initializing create_model()
2025-03-20 20:17:58,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:17:58,475:INFO:Checking exceptions
2025-03-20 20:17:58,476:INFO:Importing libraries
2025-03-20 20:17:58,476:INFO:Copying training dataset
2025-03-20 20:17:58,480:INFO:Defining folds
2025-03-20 20:17:58,480:INFO:Declaring metric variables
2025-03-20 20:17:58,481:INFO:Importing untrained model
2025-03-20 20:17:58,481:INFO:Declaring custom model
2025-03-20 20:17:58,481:INFO:Extra Trees Regressor Imported successfully
2025-03-20 20:17:58,481:INFO:Starting cross validation
2025-03-20 20:17:58,482:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:17:58,762:INFO:Calculating mean and std
2025-03-20 20:17:58,763:INFO:Creating metrics dataframe
2025-03-20 20:17:58,765:INFO:Finalizing model
2025-03-20 20:17:58,934:INFO:Uploading results into container
2025-03-20 20:17:58,934:INFO:Uploading model into container now
2025-03-20 20:17:58,934:INFO:_master_model_container: 38
2025-03-20 20:17:58,934:INFO:_display_container: 20
2025-03-20 20:17:58,935:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888)
2025-03-20 20:17:58,935:INFO:create_model() successfully completed......................................
2025-03-20 20:17:59,031:INFO:SubProcess create_model() end ==================================
2025-03-20 20:17:59,032:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=888) result for MAPE is 0.0259
2025-03-20 20:17:59,032:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=7,
                    max_features=0.6210739062761141,
                    min_impurity_decrease=7.306226778318376e-08,
                    min_samples_leaf=2, min_samples_split=4, n_estimators=65,
                    n_jobs=-1, random_state=888) result for MAPE is 0.0243
2025-03-20 20:17:59,033:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=7,
                    max_features=0.6210739062761141,
                    min_impurity_decrease=7.306226778318376e-08,
                    min_samples_leaf=2, min_samples_split=4, n_estimators=65,
                    n_jobs=-1, random_state=888) is best model
2025-03-20 20:17:59,033:INFO:choose_better completed
2025-03-20 20:17:59,033:INFO:Creating Dashboard logs
2025-03-20 20:17:59,038:INFO:Model: Extra Trees Regressor
2025-03-20 20:17:59,074:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 7, 'max_features': 0.6210739062761141, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 7.306226778318376e-08, 'min_samples_leaf': 2, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 65, 'n_jobs': -1, 'oob_score': False, 'random_state': 888, 'verbose': 0, 'warm_start': False}
2025-03-20 20:17:59,566:INFO:Initializing predict_model()
2025-03-20 20:17:59,567:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ExtraTreesRegressor(bootstrap=True, max_depth=7,
                    max_features=0.6210739062761141,
                    min_impurity_decrease=7.306226778318376e-08,
                    min_samples_leaf=2, min_samples_split=4, n_estimators=65,
                    n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9E825820>)
2025-03-20 20:17:59,567:INFO:Checking exceptions
2025-03-20 20:17:59,567:INFO:Preloading libraries
2025-03-20 20:17:59,847:ERROR:_log_model() for ExtraTreesRegressor(bootstrap=True, max_depth=7,
                    max_features=0.6210739062761141,
                    min_impurity_decrease=7.306226778318376e-08,
                    min_samples_leaf=2, min_samples_split=4, n_estimators=65,
                    n_jobs=-1, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:17:59,854:INFO:_master_model_container: 38
2025-03-20 20:17:59,854:INFO:_display_container: 19
2025-03-20 20:17:59,854:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=7,
                    max_features=0.6210739062761141,
                    min_impurity_decrease=7.306226778318376e-08,
                    min_samples_leaf=2, min_samples_split=4, n_estimators=65,
                    n_jobs=-1, random_state=888)
2025-03-20 20:17:59,855:INFO:tune_model() successfully completed......................................
2025-03-20 20:17:59,953:INFO:Initializing predict_model()
2025-03-20 20:17:59,953:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=ExtraTreesRegressor(bootstrap=True, max_depth=7,
                    max_features=0.6210739062761141,
                    min_impurity_decrease=7.306226778318376e-08,
                    min_samples_leaf=2, min_samples_split=4, n_estimators=65,
                    n_jobs=-1, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9870C790>)
2025-03-20 20:17:59,953:INFO:Checking exceptions
2025-03-20 20:17:59,953:INFO:Preloading libraries
2025-03-20 20:18:00,209:INFO:Initializing tune_model()
2025-03-20 20:18:00,209:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=888), fold=None, round=4, n_iter=100, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=10, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>)
2025-03-20 20:18:00,209:INFO:Checking exceptions
2025-03-20 20:18:00,209:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-20 20:18:00,224:INFO:Copying training dataset
2025-03-20 20:18:00,228:INFO:Checking base model
2025-03-20 20:18:00,228:INFO:Base model : Decision Tree Regressor
2025-03-20 20:18:00,231:INFO:Declaring metric variables
2025-03-20 20:18:00,234:INFO:Defining Hyperparameters
2025-03-20 20:18:00,333:INFO:Tuning with n_jobs=-1
2025-03-20 20:18:00,333:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:18:00,333:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-20 20:18:00,334:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-20 20:18:00,334:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-20 20:18:00,334:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-20 20:18:00,334:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-20 20:19:03,971:INFO:best_params: {'actual_estimator__max_depth': 7, 'actual_estimator__max_features': 0.9154415568825216, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_impurity_decrease': 2.0217193367449296e-09, 'actual_estimator__criterion': 'squared_error'}
2025-03-20 20:19:03,979:INFO:Hyperparameter search completed
2025-03-20 20:19:03,979:INFO:SubProcess create_model() called ==================================
2025-03-20 20:19:03,979:INFO:Initializing create_model()
2025-03-20 20:19:03,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=DecisionTreeRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A327F2550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': 7, 'max_features': 0.9154415568825216, 'min_samples_leaf': 3, 'min_samples_split': 2, 'min_impurity_decrease': 2.0217193367449296e-09, 'criterion': 'squared_error'})
2025-03-20 20:19:03,979:INFO:Checking exceptions
2025-03-20 20:19:03,979:INFO:Importing libraries
2025-03-20 20:19:03,979:INFO:Copying training dataset
2025-03-20 20:19:03,984:INFO:Defining folds
2025-03-20 20:19:03,984:INFO:Declaring metric variables
2025-03-20 20:19:03,987:INFO:Importing untrained model
2025-03-20 20:19:03,987:INFO:Declaring custom model
2025-03-20 20:19:03,990:INFO:Decision Tree Regressor Imported successfully
2025-03-20 20:19:03,995:INFO:Starting cross validation
2025-03-20 20:19:03,996:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:19:06,878:INFO:Calculating mean and std
2025-03-20 20:19:06,879:INFO:Creating metrics dataframe
2025-03-20 20:19:06,884:INFO:Finalizing model
2025-03-20 20:19:06,953:INFO:Uploading results into container
2025-03-20 20:19:06,953:INFO:Uploading model into container now
2025-03-20 20:19:06,953:INFO:_master_model_container: 39
2025-03-20 20:19:06,953:INFO:_display_container: 21
2025-03-20 20:19:06,954:INFO:DecisionTreeRegressor(max_depth=7, max_features=0.9154415568825216,
                      min_impurity_decrease=2.0217193367449296e-09,
                      min_samples_leaf=3, random_state=888)
2025-03-20 20:19:06,954:INFO:create_model() successfully completed......................................
2025-03-20 20:19:07,051:INFO:SubProcess create_model() end ==================================
2025-03-20 20:19:07,051:INFO:choose_better activated
2025-03-20 20:19:07,055:INFO:SubProcess create_model() called ==================================
2025-03-20 20:19:07,055:INFO:Initializing create_model()
2025-03-20 20:19:07,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=DecisionTreeRegressor(random_state=888), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:07,055:INFO:Checking exceptions
2025-03-20 20:19:07,056:INFO:Importing libraries
2025-03-20 20:19:07,056:INFO:Copying training dataset
2025-03-20 20:19:07,061:INFO:Defining folds
2025-03-20 20:19:07,061:INFO:Declaring metric variables
2025-03-20 20:19:07,061:INFO:Importing untrained model
2025-03-20 20:19:07,061:INFO:Declaring custom model
2025-03-20 20:19:07,061:INFO:Decision Tree Regressor Imported successfully
2025-03-20 20:19:07,062:INFO:Starting cross validation
2025-03-20 20:19:07,063:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:19:10,096:INFO:Calculating mean and std
2025-03-20 20:19:10,096:INFO:Creating metrics dataframe
2025-03-20 20:19:10,098:INFO:Finalizing model
2025-03-20 20:19:10,166:INFO:Uploading results into container
2025-03-20 20:19:10,166:INFO:Uploading model into container now
2025-03-20 20:19:10,167:INFO:_master_model_container: 40
2025-03-20 20:19:10,167:INFO:_display_container: 22
2025-03-20 20:19:10,167:INFO:DecisionTreeRegressor(random_state=888)
2025-03-20 20:19:10,167:INFO:create_model() successfully completed......................................
2025-03-20 20:19:10,263:INFO:SubProcess create_model() end ==================================
2025-03-20 20:19:10,264:INFO:DecisionTreeRegressor(random_state=888) result for MAPE is 0.0269
2025-03-20 20:19:10,264:INFO:DecisionTreeRegressor(max_depth=7, max_features=0.9154415568825216,
                      min_impurity_decrease=2.0217193367449296e-09,
                      min_samples_leaf=3, random_state=888) result for MAPE is 0.0247
2025-03-20 20:19:10,265:INFO:DecisionTreeRegressor(max_depth=7, max_features=0.9154415568825216,
                      min_impurity_decrease=2.0217193367449296e-09,
                      min_samples_leaf=3, random_state=888) is best model
2025-03-20 20:19:10,265:INFO:choose_better completed
2025-03-20 20:19:10,265:INFO:Creating Dashboard logs
2025-03-20 20:19:10,269:INFO:Model: Decision Tree Regressor
2025-03-20 20:19:10,308:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 7, 'max_features': 0.9154415568825216, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.0217193367449296e-09, 'min_samples_leaf': 3, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 888, 'splitter': 'best'}
2025-03-20 20:19:10,812:INFO:Initializing predict_model()
2025-03-20 20:19:10,812:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=DecisionTreeRegressor(max_depth=7, max_features=0.9154415568825216,
                      min_impurity_decrease=2.0217193367449296e-09,
                      min_samples_leaf=3, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A964ECC10>)
2025-03-20 20:19:10,812:INFO:Checking exceptions
2025-03-20 20:19:10,812:INFO:Preloading libraries
2025-03-20 20:19:11,055:ERROR:_log_model() for DecisionTreeRegressor(max_depth=7, max_features=0.9154415568825216,
                      min_impurity_decrease=2.0217193367449296e-09,
                      min_samples_leaf=3, random_state=888) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:11,063:INFO:_master_model_container: 40
2025-03-20 20:19:11,063:INFO:_display_container: 21
2025-03-20 20:19:11,064:INFO:DecisionTreeRegressor(max_depth=7, max_features=0.9154415568825216,
                      min_impurity_decrease=2.0217193367449296e-09,
                      min_samples_leaf=3, random_state=888)
2025-03-20 20:19:11,064:INFO:tune_model() successfully completed......................................
2025-03-20 20:19:11,163:INFO:Initializing predict_model()
2025-03-20 20:19:11,163:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=DecisionTreeRegressor(max_depth=7, max_features=0.9154415568825216,
                      min_impurity_decrease=2.0217193367449296e-09,
                      min_samples_leaf=3, random_state=888), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A964C04C0>)
2025-03-20 20:19:11,163:INFO:Checking exceptions
2025-03-20 20:19:11,163:INFO:Preloading libraries
2025-03-20 20:19:11,456:INFO:Initializing blend_models()
2025-03-20 20:19:11,456:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator_list=[GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-03-20 20:19:11,457:INFO:Checking exceptions
2025-03-20 20:19:11,470:INFO:Importing libraries
2025-03-20 20:19:11,471:INFO:Copying training dataset
2025-03-20 20:19:11,474:INFO:Getting model names
2025-03-20 20:19:11,477:INFO:SubProcess create_model() called ==================================
2025-03-20 20:19:11,484:INFO:Initializing create_model()
2025-03-20 20:19:11,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A43C947F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:11,485:INFO:Checking exceptions
2025-03-20 20:19:11,485:INFO:Importing libraries
2025-03-20 20:19:11,485:INFO:Copying training dataset
2025-03-20 20:19:11,491:INFO:Defining folds
2025-03-20 20:19:11,491:INFO:Declaring metric variables
2025-03-20 20:19:11,494:INFO:Importing untrained model
2025-03-20 20:19:11,494:INFO:Declaring custom model
2025-03-20 20:19:11,498:INFO:Voting Regressor Imported successfully
2025-03-20 20:19:11,503:INFO:Starting cross validation
2025-03-20 20:19:11,505:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:19:14,714:INFO:Calculating mean and std
2025-03-20 20:19:14,715:INFO:Creating metrics dataframe
2025-03-20 20:19:14,721:INFO:Finalizing model
2025-03-20 20:19:16,782:INFO:Uploading results into container
2025-03-20 20:19:16,782:INFO:Uploading model into container now
2025-03-20 20:19:16,783:INFO:_master_model_container: 41
2025-03-20 20:19:16,783:INFO:_display_container: 23
2025-03-20 20:19:16,790:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 20:19:16,790:INFO:create_model() successfully completed......................................
2025-03-20 20:19:16,890:INFO:SubProcess create_model() end ==================================
2025-03-20 20:19:16,890:INFO:Creating Dashboard logs
2025-03-20 20:19:16,894:INFO:Model: Voting Regressor
2025-03-20 20:19:16,935:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.19558561781467235, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 2, 'Gradient Boosting Regressor__max_features': 0.43275761279752, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 2.7229260127058637e-09, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 8, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 66, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.9352898226810128, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.08238180235960571, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 11, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.43973678872935484, 'Light Gradient Boosting Machine__n_estimators': 140, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 51, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.2500694964077735, 'Light Gradient Boosting Machine__reg_lambda': 1.0873476871223965e-05, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.7548601542467179, 'Light Gradient Boosting Machine__bagging_fraction': 0.7451949080123305, 'Light Gradient Boosting Machine__bagging_freq': 4, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': 0.5409878744572405, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': 0.14022679386198442, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': 1, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': 4, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': 275, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': 0.00042516619781516175, 'Extreme Gradient Boosting__reg_lambda': 3.4722837594342337e-08, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': 35.83948389577335, 'Extreme Gradient Boosting__subsample': 0.862993333858407, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0}
2025-03-20 20:19:17,520:INFO:Initializing predict_model()
2025-03-20 20:19:17,520:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9E8251F0>)
2025-03-20 20:19:17,520:INFO:Checking exceptions
2025-03-20 20:19:17,520:INFO:Preloading libraries
2025-03-20 20:19:17,783:ERROR:_log_model() for VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:17,791:INFO:_master_model_container: 41
2025-03-20 20:19:17,791:INFO:_display_container: 23
2025-03-20 20:19:17,798:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 20:19:17,798:INFO:blend_models() successfully completed......................................
2025-03-20 20:19:17,913:INFO:Initializing compare_models()
2025-03-20 20:19:17,913:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, include=[GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, 'include': [GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-20 20:19:17,913:INFO:Checking exceptions
2025-03-20 20:19:17,915:INFO:Preparing display monitor
2025-03-20 20:19:17,931:INFO:Initializing custom model Gradient Boosting Regressor
2025-03-20 20:19:17,931:INFO:Total runtime is 8.281071980794271e-06 minutes
2025-03-20 20:19:17,934:INFO:SubProcess create_model() called ==================================
2025-03-20 20:19:17,935:INFO:Initializing create_model()
2025-03-20 20:19:17,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E3DF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:17,935:INFO:Checking exceptions
2025-03-20 20:19:17,935:INFO:Importing libraries
2025-03-20 20:19:17,935:INFO:Copying training dataset
2025-03-20 20:19:17,942:INFO:Defining folds
2025-03-20 20:19:17,942:INFO:Declaring metric variables
2025-03-20 20:19:17,945:INFO:Importing untrained model
2025-03-20 20:19:17,945:INFO:Declaring custom model
2025-03-20 20:19:17,948:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 20:19:17,953:INFO:Starting cross validation
2025-03-20 20:19:17,954:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:19:21,227:INFO:Calculating mean and std
2025-03-20 20:19:21,228:INFO:Creating metrics dataframe
2025-03-20 20:19:21,231:INFO:Uploading results into container
2025-03-20 20:19:21,231:INFO:Uploading model into container now
2025-03-20 20:19:21,232:INFO:_master_model_container: 42
2025-03-20 20:19:21,232:INFO:_display_container: 24
2025-03-20 20:19:21,232:INFO:GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128)
2025-03-20 20:19:21,233:INFO:create_model() successfully completed......................................
2025-03-20 20:19:21,331:INFO:SubProcess create_model() end ==================================
2025-03-20 20:19:21,331:INFO:Creating metrics dataframe
2025-03-20 20:19:21,338:INFO:Initializing custom model Light Gradient Boosting Machine
2025-03-20 20:19:21,339:INFO:Total runtime is 0.05679973363876343 minutes
2025-03-20 20:19:21,342:INFO:SubProcess create_model() called ==================================
2025-03-20 20:19:21,342:INFO:Initializing create_model()
2025-03-20 20:19:21,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E3DF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:21,343:INFO:Checking exceptions
2025-03-20 20:19:21,343:INFO:Importing libraries
2025-03-20 20:19:21,343:INFO:Copying training dataset
2025-03-20 20:19:21,347:INFO:Defining folds
2025-03-20 20:19:21,348:INFO:Declaring metric variables
2025-03-20 20:19:21,350:INFO:Importing untrained model
2025-03-20 20:19:21,351:INFO:Declaring custom model
2025-03-20 20:19:21,354:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 20:19:21,360:INFO:Starting cross validation
2025-03-20 20:19:21,361:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:19:24,214:INFO:Calculating mean and std
2025-03-20 20:19:24,215:INFO:Creating metrics dataframe
2025-03-20 20:19:24,218:INFO:Uploading results into container
2025-03-20 20:19:24,218:INFO:Uploading model into container now
2025-03-20 20:19:24,218:INFO:_master_model_container: 43
2025-03-20 20:19:24,219:INFO:_display_container: 24
2025-03-20 20:19:24,219:INFO:LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05)
2025-03-20 20:19:24,219:INFO:create_model() successfully completed......................................
2025-03-20 20:19:24,318:INFO:SubProcess create_model() end ==================================
2025-03-20 20:19:24,318:INFO:Creating metrics dataframe
2025-03-20 20:19:24,326:INFO:Initializing custom model Extreme Gradient Boosting
2025-03-20 20:19:24,326:INFO:Total runtime is 0.10659130414326987 minutes
2025-03-20 20:19:24,329:INFO:SubProcess create_model() called ==================================
2025-03-20 20:19:24,330:INFO:Initializing create_model()
2025-03-20 20:19:24,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E3DF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:24,330:INFO:Checking exceptions
2025-03-20 20:19:24,330:INFO:Importing libraries
2025-03-20 20:19:24,330:INFO:Copying training dataset
2025-03-20 20:19:24,334:INFO:Defining folds
2025-03-20 20:19:24,334:INFO:Declaring metric variables
2025-03-20 20:19:24,337:INFO:Importing untrained model
2025-03-20 20:19:24,337:INFO:Declaring custom model
2025-03-20 20:19:24,341:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 20:19:24,346:INFO:Starting cross validation
2025-03-20 20:19:24,347:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:19:24,798:INFO:Calculating mean and std
2025-03-20 20:19:24,799:INFO:Creating metrics dataframe
2025-03-20 20:19:24,802:INFO:Uploading results into container
2025-03-20 20:19:24,802:INFO:Uploading model into container now
2025-03-20 20:19:24,802:INFO:_master_model_container: 44
2025-03-20 20:19:24,802:INFO:_display_container: 24
2025-03-20 20:19:24,803:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 20:19:24,803:INFO:create_model() successfully completed......................................
2025-03-20 20:19:24,902:INFO:SubProcess create_model() end ==================================
2025-03-20 20:19:24,902:INFO:Creating metrics dataframe
2025-03-20 20:19:24,911:INFO:Initializing custom model Voting Regressor
2025-03-20 20:19:24,911:INFO:Total runtime is 0.116340176264445 minutes
2025-03-20 20:19:24,914:INFO:SubProcess create_model() called ==================================
2025-03-20 20:19:24,921:INFO:Initializing create_model()
2025-03-20 20:19:24,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A2E3DF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:24,921:INFO:Checking exceptions
2025-03-20 20:19:24,921:INFO:Importing libraries
2025-03-20 20:19:24,922:INFO:Copying training dataset
2025-03-20 20:19:24,926:INFO:Defining folds
2025-03-20 20:19:24,926:INFO:Declaring metric variables
2025-03-20 20:19:24,929:INFO:Importing untrained model
2025-03-20 20:19:24,929:INFO:Declaring custom model
2025-03-20 20:19:24,934:INFO:Voting Regressor Imported successfully
2025-03-20 20:19:24,940:INFO:Starting cross validation
2025-03-20 20:19:24,941:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-20 20:19:25,507:INFO:Calculating mean and std
2025-03-20 20:19:25,508:INFO:Creating metrics dataframe
2025-03-20 20:19:25,511:INFO:Uploading results into container
2025-03-20 20:19:25,511:INFO:Uploading model into container now
2025-03-20 20:19:25,511:INFO:_master_model_container: 45
2025-03-20 20:19:25,512:INFO:_display_container: 24
2025-03-20 20:19:25,518:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 20:19:25,518:INFO:create_model() successfully completed......................................
2025-03-20 20:19:25,615:INFO:SubProcess create_model() end ==================================
2025-03-20 20:19:25,615:INFO:Creating metrics dataframe
2025-03-20 20:19:25,632:INFO:Initializing create_model()
2025-03-20 20:19:25,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:25,632:INFO:Checking exceptions
2025-03-20 20:19:25,633:INFO:Importing libraries
2025-03-20 20:19:25,633:INFO:Copying training dataset
2025-03-20 20:19:25,636:INFO:Defining folds
2025-03-20 20:19:25,637:INFO:Declaring metric variables
2025-03-20 20:19:25,637:INFO:Importing untrained model
2025-03-20 20:19:25,637:INFO:Declaring custom model
2025-03-20 20:19:25,637:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 20:19:25,638:INFO:Cross validation set to False
2025-03-20 20:19:25,638:INFO:Fitting Model
2025-03-20 20:19:25,867:INFO:GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128)
2025-03-20 20:19:25,867:INFO:create_model() successfully completed......................................
2025-03-20 20:19:25,972:INFO:Creating Dashboard logs
2025-03-20 20:19:25,975:INFO:Model: Gradient Boosting Regressor
2025-03-20 20:19:26,011:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.19558561781467235, 'loss': 'squared_error', 'max_depth': 2, 'max_features': 0.43275761279752, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.7229260127058637e-09, 'min_samples_leaf': 1, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 66, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.9352898226810128, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 20:19:26,566:INFO:Initializing predict_model()
2025-03-20 20:19:26,566:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022A9E825F70>)
2025-03-20 20:19:26,566:INFO:Checking exceptions
2025-03-20 20:19:26,566:INFO:Preloading libraries
2025-03-20 20:19:26,805:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:26,806:INFO:Creating Dashboard logs
2025-03-20 20:19:26,809:INFO:Model: Voting Regressor
2025-03-20 20:19:26,849:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.19558561781467235, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 2, 'Gradient Boosting Regressor__max_features': 0.43275761279752, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 2.7229260127058637e-09, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 8, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 66, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.9352898226810128, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.08238180235960571, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 11, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.43973678872935484, 'Light Gradient Boosting Machine__n_estimators': 140, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 51, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.2500694964077735, 'Light Gradient Boosting Machine__reg_lambda': 1.0873476871223965e-05, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.7548601542467179, 'Light Gradient Boosting Machine__bagging_fraction': 0.7451949080123305, 'Light Gradient Boosting Machine__bagging_freq': 4, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': 0.5409878744572405, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': 0.14022679386198442, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': 1, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': 4, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': 275, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': 0.00042516619781516175, 'Extreme Gradient Boosting__reg_lambda': 3.4722837594342337e-08, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': 35.83948389577335, 'Extreme Gradient Boosting__subsample': 0.862993333858407, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0}
2025-03-20 20:19:27,484:ERROR:_log_model() for VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:27,485:INFO:Creating Dashboard logs
2025-03-20 20:19:27,487:INFO:Model: Extreme Gradient Boosting
2025-03-20 20:19:27,523:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5409878744572405, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.14022679386198442, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 1, 'max_leaves': None, 'min_child_weight': 4, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 275, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': 0.00042516619781516175, 'reg_lambda': 3.4722837594342337e-08, 'sampling_method': None, 'scale_pos_weight': 35.83948389577335, 'subsample': 0.862993333858407, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 20:19:28,156:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:28,157:INFO:Creating Dashboard logs
2025-03-20 20:19:28,160:INFO:Model: Light Gradient Boosting Machine
2025-03-20 20:19:28,196:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.08238180235960571, 'max_depth': -1, 'min_child_samples': 11, 'min_child_weight': 0.001, 'min_split_gain': 0.43973678872935484, 'n_estimators': 140, 'n_jobs': -1, 'num_leaves': 51, 'objective': None, 'random_state': 888, 'reg_alpha': 0.2500694964077735, 'reg_lambda': 1.0873476871223965e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7548601542467179, 'bagging_fraction': 0.7451949080123305, 'bagging_freq': 4}
2025-03-20 20:19:28,820:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:28,831:INFO:_master_model_container: 45
2025-03-20 20:19:28,831:INFO:_display_container: 24
2025-03-20 20:19:28,831:INFO:GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128)
2025-03-20 20:19:28,831:INFO:compare_models() successfully completed......................................
2025-03-20 20:19:29,018:INFO:Initializing finalize_model()
2025-03-20 20:19:29,018:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 20:19:29,019:INFO:Finalizing GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128)
2025-03-20 20:19:29,022:INFO:Initializing create_model()
2025-03-20 20:19:29,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=GradientBoostingRegressor(learning_rate=0.19558561781467235, max_depth=2,
                          max_features=0.43275761279752,
                          min_impurity_decrease=2.7229260127058637e-09,
                          min_samples_split=8, n_estimators=66,
                          random_state=888, subsample=0.9352898226810128), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:29,022:INFO:Checking exceptions
2025-03-20 20:19:29,023:INFO:Importing libraries
2025-03-20 20:19:29,023:INFO:Copying training dataset
2025-03-20 20:19:29,023:INFO:Defining folds
2025-03-20 20:19:29,024:INFO:Declaring metric variables
2025-03-20 20:19:29,024:INFO:Importing untrained model
2025-03-20 20:19:29,024:INFO:Declaring custom model
2025-03-20 20:19:29,024:INFO:Gradient Boosting Regressor Imported successfully
2025-03-20 20:19:29,025:INFO:Cross validation set to False
2025-03-20 20:19:29,025:INFO:Fitting Model
2025-03-20 20:19:29,311:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                           max_depth=2,
                                           max_features=0.43275761279752,
                                           min_impurity_decrease=2.7229260127058637e-09,
                                           min_samples_split=8, n_estimators=66,
                                           random_state=888,
                                           subsample=0.9352898226810128))])
2025-03-20 20:19:29,311:INFO:create_model() successfully completed......................................
2025-03-20 20:19:29,411:INFO:Creating Dashboard logs
2025-03-20 20:19:29,412:INFO:Model: Gradient Boosting Regressor
2025-03-20 20:19:29,450:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.19558561781467235, 'loss': 'squared_error', 'max_depth': 2, 'max_features': 0.43275761279752, 'max_leaf_nodes': None, 'min_impurity_decrease': 2.7229260127058637e-09, 'min_samples_leaf': 1, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 66, 'n_iter_no_change': None, 'random_state': 888, 'subsample': 0.9352898226810128, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-20 20:19:30,103:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                           max_depth=2,
                                           max_features=0.43275761279752,
                                           min_impurity_decrease=2.7229260127058637e-09,
                                           min_samples_split=8, n_estimators=66,
                                           random_state=888,
                                           subsample=0.9352898226810128))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:30,104:INFO:_master_model_container: 45
2025-03-20 20:19:30,104:INFO:_display_container: 24
2025-03-20 20:19:30,112:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                           max_depth=2,
                                           max_features=0.43275761279752,
                                           min_impurity_decrease=2.7229260127058637e-09,
                                           min_samples_split=8, n_estimators=66,
                                           random_state=888,
                                           subsample=0.9352898226810128))])
2025-03-20 20:19:30,112:INFO:finalize_model() successfully completed......................................
2025-03-20 20:19:30,230:INFO:Initializing save_model()
2025-03-20 20:19:30,230:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                           max_depth=2,
                                           max_features=0.43275761279752,
                                           min_impurity_decrease=2.7229260127058637e-09,
                                           min_samples_split=8, n_estimators=66,
                                           random_state=888,
                                           subsample=0.9352898226810128))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_200121, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 20:19:30,230:INFO:Adding model into prep_pipe
2025-03-20 20:19:30,230:WARNING:Only Model saved as it was a pipeline.
2025-03-20 20:19:30,239:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_200121.pkl saved in current working directory
2025-03-20 20:19:30,247:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                           max_depth=2,
                                           max_features=0.43275761279752,
                                           min_impurity_decrease=2.7229260127058637e-09,
                                           min_samples_split=8, n_estimators=66,
                                           random_state=888,
                                           subsample=0.9352898226810128))])
2025-03-20 20:19:30,247:INFO:save_model() successfully completed......................................
2025-03-20 20:19:30,349:INFO:Initializing finalize_model()
2025-03-20 20:19:30,349:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 20:19:30,350:INFO:Finalizing LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05)
2025-03-20 20:19:30,353:INFO:Initializing create_model()
2025-03-20 20:19:30,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=LGBMRegressor(bagging_fraction=0.7451949080123305, bagging_freq=4,
              feature_fraction=0.7548601542467179,
              learning_rate=0.08238180235960571, min_child_samples=11,
              min_split_gain=0.43973678872935484, n_estimators=140, n_jobs=-1,
              num_leaves=51, random_state=888, reg_alpha=0.2500694964077735,
              reg_lambda=1.0873476871223965e-05), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:30,353:INFO:Checking exceptions
2025-03-20 20:19:30,354:INFO:Importing libraries
2025-03-20 20:19:30,354:INFO:Copying training dataset
2025-03-20 20:19:30,354:INFO:Defining folds
2025-03-20 20:19:30,354:INFO:Declaring metric variables
2025-03-20 20:19:30,354:INFO:Importing untrained model
2025-03-20 20:19:30,354:INFO:Declaring custom model
2025-03-20 20:19:30,355:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-20 20:19:30,356:INFO:Cross validation set to False
2025-03-20 20:19:30,356:INFO:Fitting Model
2025-03-20 20:19:30,406:INFO:[LightGBM] [Warning] feature_fraction is set=0.7548601542467179, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7548601542467179
2025-03-20 20:19:30,406:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7451949080123305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7451949080123305
2025-03-20 20:19:30,406:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-20 20:19:30,408:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-20 20:19:30,408:INFO:[LightGBM] [Warning] feature_fraction is set=0.7548601542467179, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7548601542467179
2025-03-20 20:19:30,408:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7451949080123305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7451949080123305
2025-03-20 20:19:30,408:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-20 20:19:30,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.
2025-03-20 20:19:30,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-20 20:19:30,409:INFO:[LightGBM] [Info] Total Bins 4616
2025-03-20 20:19:30,411:INFO:[LightGBM] [Info] Number of data points in the train set: 1769, number of used features: 37
2025-03-20 20:19:30,411:INFO:[LightGBM] [Info] Start training from score 15.920889
2025-03-20 20:19:30,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,497:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,502:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,502:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-20 20:19:30,502:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-20 20:19:30,515:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7451949080123305,
                               bagging_freq=4,
                               feature_fraction=0.7548601542467179,
                               learning_rate=0.08238180235960571,
                               min_child_samples=11,
                               min_split_gain=0.43973678872935484,
                               n_estimators=140, n_jobs=-1, num_leaves=51,
                               random_state=888, reg_alpha=0.2500694964077735,
                               reg_lambda=1.0873476871223965e-05))])
2025-03-20 20:19:30,515:INFO:create_model() successfully completed......................................
2025-03-20 20:19:30,614:INFO:Creating Dashboard logs
2025-03-20 20:19:30,615:INFO:Model: Light Gradient Boosting Machine
2025-03-20 20:19:30,651:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.08238180235960571, 'max_depth': -1, 'min_child_samples': 11, 'min_child_weight': 0.001, 'min_split_gain': 0.43973678872935484, 'n_estimators': 140, 'n_jobs': -1, 'num_leaves': 51, 'objective': None, 'random_state': 888, 'reg_alpha': 0.2500694964077735, 'reg_lambda': 1.0873476871223965e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7548601542467179, 'bagging_fraction': 0.7451949080123305, 'bagging_freq': 4}
2025-03-20 20:19:31,336:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7451949080123305,
                               bagging_freq=4,
                               feature_fraction=0.7548601542467179,
                               learning_rate=0.08238180235960571,
                               min_child_samples=11,
                               min_split_gain=0.43973678872935484,
                               n_estimators=140, n_jobs=-1, num_leaves=51,
                               random_state=888, reg_alpha=0.2500694964077735,
                               reg_lambda=1.0873476871223965e-05))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:31,336:INFO:_master_model_container: 45
2025-03-20 20:19:31,336:INFO:_display_container: 24
2025-03-20 20:19:31,345:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7451949080123305,
                               bagging_freq=4,
                               feature_fraction=0.7548601542467179,
                               learning_rate=0.08238180235960571,
                               min_child_samples=11,
                               min_split_gain=0.43973678872935484,
                               n_estimators=140, n_jobs=-1, num_leaves=51,
                               random_state=888, reg_alpha=0.2500694964077735,
                               reg_lambda=1.0873476871223965e-05))])
2025-03-20 20:19:31,346:INFO:finalize_model() successfully completed......................................
2025-03-20 20:19:31,465:INFO:Initializing save_model()
2025-03-20 20:19:31,465:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7451949080123305,
                               bagging_freq=4,
                               feature_fraction=0.7548601542467179,
                               learning_rate=0.08238180235960571,
                               min_child_samples=11,
                               min_split_gain=0.43973678872935484,
                               n_estimators=140, n_jobs=-1, num_leaves=51,
                               random_state=888, reg_alpha=0.2500694964077735,
                               reg_lambda=1.0873476871223965e-05))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_200121, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 20:19:31,465:INFO:Adding model into prep_pipe
2025-03-20 20:19:31,465:WARNING:Only Model saved as it was a pipeline.
2025-03-20 20:19:31,474:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\lightgbm_250320_200121.pkl saved in current working directory
2025-03-20 20:19:31,483:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7451949080123305,
                               bagging_freq=4,
                               feature_fraction=0.7548601542467179,
                               learning_rate=0.08238180235960571,
                               min_child_samples=11,
                               min_split_gain=0.43973678872935484,
                               n_estimators=140, n_jobs=-1, num_leaves=51,
                               random_state=888, reg_alpha=0.2500694964077735,
                               reg_lambda=1.0873476871223965e-05))])
2025-03-20 20:19:31,483:INFO:save_model() successfully completed......................................
2025-03-20 20:19:31,587:INFO:Initializing finalize_model()
2025-03-20 20:19:31,588:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 20:19:31,588:INFO:Finalizing XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...)
2025-03-20 20:19:31,591:INFO:Initializing create_model()
2025-03-20 20:19:31,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5409878744572405, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.14022679386198442, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=1, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=275, n_jobs=-1,
             num_parallel_tree=None, random_state=888, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:31,591:INFO:Checking exceptions
2025-03-20 20:19:31,592:INFO:Importing libraries
2025-03-20 20:19:31,592:INFO:Copying training dataset
2025-03-20 20:19:31,592:INFO:Defining folds
2025-03-20 20:19:31,593:INFO:Declaring metric variables
2025-03-20 20:19:31,593:INFO:Importing untrained model
2025-03-20 20:19:31,593:INFO:Declaring custom model
2025-03-20 20:19:31,594:INFO:Extreme Gradient Boosting Imported successfully
2025-03-20 20:19:31,595:INFO:Cross validation set to False
2025-03-20 20:19:31,595:INFO:Fitting Model
2025-03-20 20:19:31,786:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None,
                              learning_rate=0.14022679386198442, max_bin=None,
                              max_cat_threshold=None, max_cat_to_onehot=None,
                              max_delta_step=None, max_depth=1, max_leaves=None,
                              min_child_weight=4, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=275, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))])
2025-03-20 20:19:31,786:INFO:create_model() successfully completed......................................
2025-03-20 20:19:31,888:INFO:Creating Dashboard logs
2025-03-20 20:19:31,888:INFO:Model: Extreme Gradient Boosting
2025-03-20 20:19:31,925:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5409878744572405, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.14022679386198442, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 1, 'max_leaves': None, 'min_child_weight': 4, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 275, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 888, 'reg_alpha': 0.00042516619781516175, 'reg_lambda': 3.4722837594342337e-08, 'sampling_method': None, 'scale_pos_weight': 35.83948389577335, 'subsample': 0.862993333858407, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-20 20:19:32,623:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None,
                              learning_rate=0.14022679386198442, max_bin=None,
                              max_cat_threshold=None, max_cat_to_onehot=None,
                              max_delta_step=None, max_depth=1, max_leaves=None,
                              min_child_weight=4, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=275, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:32,623:INFO:_master_model_container: 45
2025-03-20 20:19:32,623:INFO:_display_container: 24
2025-03-20 20:19:32,632:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None,
                              learning_rate=0.14022679386198442, max_bin=None,
                              max_cat_threshold=None, max_cat_to_onehot=None,
                              max_delta_step=None, max_depth=1, max_leaves=None,
                              min_child_weight=4, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=275, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))])
2025-03-20 20:19:32,632:INFO:finalize_model() successfully completed......................................
2025-03-20 20:19:32,751:INFO:Initializing save_model()
2025-03-20 20:19:32,751:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None,
                              learning_rate=0.14022679386198442, max_bin=None,
                              max_cat_threshold=None, max_cat_to_onehot=None,
                              max_delta_step=None, max_depth=1, max_leaves=None,
                              min_child_weight=4, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=275, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\xgboost_250320_200121, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 20:19:32,751:INFO:Adding model into prep_pipe
2025-03-20 20:19:32,751:WARNING:Only Model saved as it was a pipeline.
2025-03-20 20:19:32,762:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\xgboost_250320_200121.pkl saved in current working directory
2025-03-20 20:19:32,772:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None,
                              learning_rate=0.14022679386198442, max_bin=None,
                              max_cat_threshold=None, max_cat_to_onehot=None,
                              max_delta_step=None, max_depth=1, max_leaves=None,
                              min_child_weight=4, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=275, n_jobs=-1,
                              num_parallel_tree=None, random_state=888, ...))])
2025-03-20 20:19:32,772:INFO:save_model() successfully completed......................................
2025-03-20 20:19:32,882:INFO:Initializing finalize_model()
2025-03-20 20:19:32,882:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-20 20:19:32,889:INFO:Finalizing VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1)
2025-03-20 20:19:32,899:INFO:Initializing create_model()
2025-03-20 20:19:32,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022A44DDAD90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                                       max_depth=2,
                                                       max_features=0.43275761279752,
                                                       min_impurity_decrease=2.7229260127058637e-09,
                                                       min_samples_split=8,
                                                       n_estimators=66,
                                                       random_state=888,
                                                       subsample=0.9352898226810128)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(bagging_fraction...
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.14022679386198442,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=1,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=275,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=888, ...))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-20 20:19:32,899:INFO:Checking exceptions
2025-03-20 20:19:32,900:INFO:Importing libraries
2025-03-20 20:19:32,900:INFO:Copying training dataset
2025-03-20 20:19:32,900:INFO:Defining folds
2025-03-20 20:19:32,900:INFO:Declaring metric variables
2025-03-20 20:19:32,900:INFO:Importing untrained model
2025-03-20 20:19:32,900:INFO:Declaring custom model
2025-03-20 20:19:32,902:INFO:Voting Regressor Imported successfully
2025-03-20 20:19:32,904:INFO:Cross validation set to False
2025-03-20 20:19:32,904:INFO:Fitting Model
2025-03-20 20:19:33,245:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.14022679386198442,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=1,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=275,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))])
2025-03-20 20:19:33,245:INFO:create_model() successfully completed......................................
2025-03-20 20:19:33,350:INFO:Creating Dashboard logs
2025-03-20 20:19:33,351:INFO:Model: Voting Regressor
2025-03-20 20:19:33,390:INFO:Logged params: {'n_jobs': -1, 'verbose': False, 'weights': None, 'Gradient Boosting Regressor__alpha': 0.9, 'Gradient Boosting Regressor__ccp_alpha': 0.0, 'Gradient Boosting Regressor__criterion': 'friedman_mse', 'Gradient Boosting Regressor__init': None, 'Gradient Boosting Regressor__learning_rate': 0.19558561781467235, 'Gradient Boosting Regressor__loss': 'squared_error', 'Gradient Boosting Regressor__max_depth': 2, 'Gradient Boosting Regressor__max_features': 0.43275761279752, 'Gradient Boosting Regressor__max_leaf_nodes': None, 'Gradient Boosting Regressor__min_impurity_decrease': 2.7229260127058637e-09, 'Gradient Boosting Regressor__min_samples_leaf': 1, 'Gradient Boosting Regressor__min_samples_split': 8, 'Gradient Boosting Regressor__min_weight_fraction_leaf': 0.0, 'Gradient Boosting Regressor__n_estimators': 66, 'Gradient Boosting Regressor__n_iter_no_change': None, 'Gradient Boosting Regressor__random_state': 888, 'Gradient Boosting Regressor__subsample': 0.9352898226810128, 'Gradient Boosting Regressor__tol': 0.0001, 'Gradient Boosting Regressor__validation_fraction': 0.1, 'Gradient Boosting Regressor__verbose': 0, 'Gradient Boosting Regressor__warm_start': False, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.08238180235960571, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 11, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.43973678872935484, 'Light Gradient Boosting Machine__n_estimators': 140, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 51, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 888, 'Light Gradient Boosting Machine__reg_alpha': 0.2500694964077735, 'Light Gradient Boosting Machine__reg_lambda': 1.0873476871223965e-05, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.7548601542467179, 'Light Gradient Boosting Machine__bagging_fraction': 0.7451949080123305, 'Light Gradient Boosting Machine__bagging_freq': 4, 'Extreme Gradient Boosting__objective': 'reg:squarederror', 'Extreme Gradient Boosting__base_score': None, 'Extreme Gradient Boosting__booster': 'gbtree', 'Extreme Gradient Boosting__callbacks': None, 'Extreme Gradient Boosting__colsample_bylevel': None, 'Extreme Gradient Boosting__colsample_bynode': None, 'Extreme Gradient Boosting__colsample_bytree': 0.5409878744572405, 'Extreme Gradient Boosting__device': 'cpu', 'Extreme Gradient Boosting__early_stopping_rounds': None, 'Extreme Gradient Boosting__enable_categorical': False, 'Extreme Gradient Boosting__eval_metric': None, 'Extreme Gradient Boosting__feature_types': None, 'Extreme Gradient Boosting__gamma': None, 'Extreme Gradient Boosting__grow_policy': None, 'Extreme Gradient Boosting__importance_type': None, 'Extreme Gradient Boosting__interaction_constraints': None, 'Extreme Gradient Boosting__learning_rate': 0.14022679386198442, 'Extreme Gradient Boosting__max_bin': None, 'Extreme Gradient Boosting__max_cat_threshold': None, 'Extreme Gradient Boosting__max_cat_to_onehot': None, 'Extreme Gradient Boosting__max_delta_step': None, 'Extreme Gradient Boosting__max_depth': 1, 'Extreme Gradient Boosting__max_leaves': None, 'Extreme Gradient Boosting__min_child_weight': 4, 'Extreme Gradient Boosting__missing': nan, 'Extreme Gradient Boosting__monotone_constraints': None, 'Extreme Gradient Boosting__multi_strategy': None, 'Extreme Gradient Boosting__n_estimators': 275, 'Extreme Gradient Boosting__n_jobs': -1, 'Extreme Gradient Boosting__num_parallel_tree': None, 'Extreme Gradient Boosting__random_state': 888, 'Extreme Gradient Boosting__reg_alpha': 0.00042516619781516175, 'Extreme Gradient Boosting__reg_lambda': 3.4722837594342337e-08, 'Extreme Gradient Boosting__sampling_method': None, 'Extreme Gradient Boosting__scale_pos_weight': 35.83948389577335, 'Extreme Gradient Boosting__subsample': 0.862993333858407, 'Extreme Gradient Boosting__tree_method': 'auto', 'Extreme Gradient Boosting__validate_parameters': None, 'Extreme Gradient Boosting__verbosity': 0}
2025-03-20 20:19:34,192:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.14022679386198442,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=1,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=275,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-20 20:19:34,192:INFO:_master_model_container: 45
2025-03-20 20:19:34,192:INFO:_display_container: 24
2025-03-20 20:19:34,216:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.14022679386198442,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=1,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=275,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))])
2025-03-20 20:19:34,216:INFO:finalize_model() successfully completed......................................
2025-03-20 20:19:34,350:INFO:Initializing save_model()
2025-03-20 20:19:34,351:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.14022679386198442,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=1,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=275,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]), model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_200121, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capi...
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group',
                                             'development_stage'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group',
                                                                    'development_stage'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-20 20:19:34,351:INFO:Adding model into prep_pipe
2025-03-20 20:19:34,351:WARNING:Only Model saved as it was a pipeline.
2025-03-20 20:19:34,367:INFO:e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_200121.pkl saved in current working directory
2025-03-20 20:19:34,391:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.14022679386198442,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=1,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=275,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))])
2025-03-20 20:19:34,391:INFO:save_model() successfully completed......................................
2025-03-20 23:39:42,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:39:42,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:39:42,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:39:42,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:39:42,779:INFO:Initializing load_model()
2025-03-20 23:39:42,780:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_195410, platform=None, authentication=None, verbose=True)
2025-03-20 23:40:47,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:40:47,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:40:47,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:40:47,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:40:47,918:INFO:Initializing load_model()
2025-03-20 23:40:47,918:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_200121, platform=None, authentication=None, verbose=True)
2025-03-20 23:40:48,428:INFO:Initializing predict_model()
2025-03-20 23:40:48,428:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024CE09864F0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                           max_depth=2,
                                           max_features=0.43275761279752,
                                           min_impurity_decrease=2.7229260127058637e-09,
                                           min_samples_split=8, n_estimators=66,
                                           random_state=888,
                                           subsample=0.9352898226810128))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024CC6075940>)
2025-03-20 23:40:48,428:INFO:Checking exceptions
2025-03-20 23:40:48,428:INFO:Preloading libraries
2025-03-20 23:40:48,428:INFO:Set up data.
2025-03-20 23:40:48,433:INFO:Set up index.
2025-03-20 23:40:48,489:INFO:Initializing load_model()
2025-03-20 23:40:48,489:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\gbr_250320_200121, platform=None, authentication=None, verbose=True)
2025-03-20 23:40:48,498:INFO:Initializing predict_model()
2025-03-20 23:40:48,498:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024CC5108340>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.19558561781467235,
                                           max_depth=2,
                                           max_features=0.43275761279752,
                                           min_impurity_decrease=2.7229260127058637e-09,
                                           min_samples_split=8, n_estimators=66,
                                           random_state=888,
                                           subsample=0.9352898226810128))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024CC55EB280>)
2025-03-20 23:40:48,498:INFO:Checking exceptions
2025-03-20 23:40:48,498:INFO:Preloading libraries
2025-03-20 23:40:48,498:INFO:Set up data.
2025-03-20 23:40:48,502:INFO:Set up index.
2025-03-20 23:40:51,760:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 23:40:53,856:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 23:42:44,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:42:44,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:42:44,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:42:44,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-20 23:42:44,685:INFO:Initializing load_model()
2025-03-20 23:42:44,685:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_200121, platform=None, authentication=None, verbose=True)
2025-03-20 23:42:45,301:INFO:Initializing predict_model()
2025-03-20 23:42:45,301:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BD5D0335E0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.14022679386198442,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=1,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=275,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BD419C8B80>)
2025-03-20 23:42:45,301:INFO:Checking exceptions
2025-03-20 23:42:45,301:INFO:Preloading libraries
2025-03-20 23:42:45,301:INFO:Set up data.
2025-03-20 23:42:45,308:INFO:Set up index.
2025-03-20 23:42:45,383:INFO:Initializing load_model()
2025-03-20 23:42:45,383:INFO:load_model(model_name=e:\code\jupyter\固废产生\SW-Prediction\src\models\modelfile\blend_250320_200121, platform=None, authentication=None, verbose=True)
2025-03-20 23:42:45,414:INFO:Initializing predict_model()
2025-03-20 23:42:45,415:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BD427239D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'year_trend_log', 'gdp_5y_ma',
                                             'gdp_10y_ma', 'gdp_growth_rate',
                                             'pop_growth_rate',
                                             'pop_density_trend',
                                             'gdp_pop_interaction',
                                             'gdp_per_capita_growth',
                                             'gdp_pop_nonlinear',
                                             'gdp_per_cap...
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.14022679386198442,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=1,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=275,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=888, ...))],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BD419C8B80>)
2025-03-20 23:42:45,415:INFO:Checking exceptions
2025-03-20 23:42:45,415:INFO:Preloading libraries
2025-03-20 23:42:45,415:INFO:Set up data.
2025-03-20 23:42:45,421:INFO:Set up index.
2025-03-20 23:42:48,763:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

2025-03-20 23:42:50,857:WARNING:e:\code\jupyter\固废产生\SW-Prediction\src\visualization\visualizer.py:130: FutureWarning: 

The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.

  sns.lineplot(x='Year', y='Error_percent', hue='Income Group',

