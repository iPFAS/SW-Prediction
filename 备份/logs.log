2025-03-19 15:41:31,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:41:31,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:41:31,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:41:31,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:41:31,231:INFO:PyCaret RegressionExperiment
2025-03-19 15:41:31,232:INFO:Logging name: msw_prediction
2025-03-19 15:41:31,232:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-19 15:41:31,232:INFO:version 3.2.0
2025-03-19 15:41:31,232:INFO:Initializing setup()
2025-03-19 15:41:31,232:INFO:self.USI: 0c08
2025-03-19 15:41:31,232:INFO:self._variable_keys: {'X', 'data', 'transform_target_param', 'y', 'gpu_n_jobs_param', 'n_jobs_param', 'X_test', 'exp_id', 'y_test', '_ml_usecase', 'y_train', 'memory', 'pipeline', 'X_train', 'exp_name_log', 'seed', 'fold_shuffle_param', 'fold_generator', 'logging_param', 'idx', 'target_param', 'gpu_param', '_available_plots', 'USI', 'fold_groups_param', 'log_plots_param', 'html_param'}
2025-03-19 15:41:31,232:INFO:Checking environment
2025-03-19 15:41:31,232:INFO:python_version: 3.8.20
2025-03-19 15:41:31,232:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-19 15:41:31,232:INFO:machine: AMD64
2025-03-19 15:41:31,232:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-19 15:41:31,238:INFO:Memory: svmem(total=68447973376, available=43171311616, percent=36.9, used=25276661760, free=43171311616)
2025-03-19 15:41:31,238:INFO:Physical Core: 24
2025-03-19 15:41:31,238:INFO:Logical Core: 32
2025-03-19 15:41:31,238:INFO:Checking libraries
2025-03-19 15:41:31,238:INFO:System:
2025-03-19 15:41:31,238:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-19 15:41:31,238:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-19 15:41:31,238:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-19 15:41:31,238:INFO:PyCaret required dependencies:
2025-03-19 15:41:31,756:INFO:                 pip: 24.2
2025-03-19 15:41:31,756:INFO:          setuptools: 75.1.0
2025-03-19 15:41:31,756:INFO:             pycaret: 3.2.0
2025-03-19 15:41:31,756:INFO:             IPython: 8.12.3
2025-03-19 15:41:31,756:INFO:          ipywidgets: 8.1.5
2025-03-19 15:41:31,756:INFO:                tqdm: 4.67.1
2025-03-19 15:41:31,756:INFO:               numpy: 1.24.4
2025-03-19 15:41:31,756:INFO:              pandas: 1.5.3
2025-03-19 15:41:31,756:INFO:              jinja2: 3.1.4
2025-03-19 15:41:31,756:INFO:               scipy: 1.10.1
2025-03-19 15:41:31,756:INFO:              joblib: 1.3.2
2025-03-19 15:41:31,756:INFO:             sklearn: 1.2.2
2025-03-19 15:41:31,757:INFO:                pyod: 2.0.2
2025-03-19 15:41:31,757:INFO:            imblearn: 0.12.4
2025-03-19 15:41:31,757:INFO:   category_encoders: 2.6.4
2025-03-19 15:41:31,757:INFO:            lightgbm: 4.5.0
2025-03-19 15:41:31,757:INFO:               numba: 0.58.1
2025-03-19 15:41:31,757:INFO:            requests: 2.32.3
2025-03-19 15:41:31,757:INFO:          matplotlib: 3.6.0
2025-03-19 15:41:31,757:INFO:          scikitplot: 0.3.7
2025-03-19 15:41:31,757:INFO:         yellowbrick: 1.5
2025-03-19 15:41:31,757:INFO:              plotly: 5.24.1
2025-03-19 15:41:31,757:INFO:    plotly-resampler: Not installed
2025-03-19 15:41:31,757:INFO:             kaleido: 0.2.1
2025-03-19 15:41:31,757:INFO:           schemdraw: 0.15
2025-03-19 15:41:31,757:INFO:         statsmodels: 0.14.1
2025-03-19 15:41:31,757:INFO:              sktime: 0.21.1
2025-03-19 15:41:31,757:INFO:               tbats: 1.1.3
2025-03-19 15:41:31,757:INFO:            pmdarima: 2.0.4
2025-03-19 15:41:31,757:INFO:              psutil: 6.1.0
2025-03-19 15:41:31,757:INFO:          markupsafe: 2.1.5
2025-03-19 15:41:31,757:INFO:             pickle5: Not installed
2025-03-19 15:41:31,757:INFO:         cloudpickle: 2.2.1
2025-03-19 15:41:31,757:INFO:         deprecation: 2.1.0
2025-03-19 15:41:31,757:INFO:              xxhash: 3.5.0
2025-03-19 15:41:31,757:INFO:           wurlitzer: Not installed
2025-03-19 15:41:31,757:INFO:PyCaret optional dependencies:
2025-03-19 15:41:33,083:INFO:                shap: 0.44.1
2025-03-19 15:41:33,083:INFO:           interpret: 0.6.6
2025-03-19 15:41:33,083:INFO:                umap: 0.5.7
2025-03-19 15:41:33,083:INFO:     ydata_profiling: 4.6.0
2025-03-19 15:41:33,083:INFO:  explainerdashboard: 0.4.7
2025-03-19 15:41:33,083:INFO:             autoviz: Not installed
2025-03-19 15:41:33,083:INFO:           fairlearn: 0.7.0
2025-03-19 15:41:33,083:INFO:          deepchecks: Not installed
2025-03-19 15:41:33,083:INFO:             xgboost: 2.1.3
2025-03-19 15:41:33,083:INFO:            catboost: 1.2.7
2025-03-19 15:41:33,083:INFO:              kmodes: 0.12.2
2025-03-19 15:41:33,083:INFO:             mlxtend: 0.23.1
2025-03-19 15:41:33,083:INFO:       statsforecast: 1.5.0
2025-03-19 15:41:33,083:INFO:        tune_sklearn: 0.5.0
2025-03-19 15:41:33,083:INFO:                 ray: 2.10.0
2025-03-19 15:41:33,083:INFO:            hyperopt: 0.2.7
2025-03-19 15:41:33,083:INFO:              optuna: 4.1.0
2025-03-19 15:41:33,083:INFO:               skopt: 0.10.2
2025-03-19 15:41:33,083:INFO:              mlflow: 1.30.1
2025-03-19 15:41:33,083:INFO:              gradio: 3.50.2
2025-03-19 15:41:33,083:INFO:             fastapi: 0.115.5
2025-03-19 15:41:33,083:INFO:             uvicorn: 0.32.1
2025-03-19 15:41:33,083:INFO:              m2cgen: 0.10.0
2025-03-19 15:41:33,083:INFO:           evidently: 0.2.8
2025-03-19 15:41:33,083:INFO:               fugue: 0.8.6
2025-03-19 15:41:33,083:INFO:           streamlit: Not installed
2025-03-19 15:41:33,083:INFO:             prophet: Not installed
2025-03-19 15:41:33,083:INFO:None
2025-03-19 15:41:33,083:INFO:Set up data.
2025-03-19 15:41:33,087:INFO:Set up folding strategy.
2025-03-19 15:41:33,087:INFO:Set up train/test split.
2025-03-19 15:41:33,087:INFO:Set up data.
2025-03-19 15:41:33,091:INFO:Set up index.
2025-03-19 15:41:33,091:INFO:Assigning column types.
2025-03-19 15:41:33,093:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-19 15:41:33,093:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,095:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,097:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,121:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,141:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,142:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,153:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,155:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,201:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,202:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,202:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-19 15:41:33,204:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,250:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,251:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,254:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,256:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,299:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,299:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,300:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,301:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-19 15:41:33,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,329:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,348:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,349:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,353:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,397:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,398:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,398:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-19 15:41:33,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,446:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,448:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,495:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,496:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,496:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-19 15:41:33,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,544:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,545:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,573:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:41:33,593:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,594:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,594:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-19 15:41:33,641:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,642:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,690:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,691:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,693:INFO:Preparing preprocessing pipeline...
2025-03-19 15:41:33,693:INFO:Set up simple imputation.
2025-03-19 15:41:33,694:INFO:Set up encoding of categorical features.
2025-03-19 15:41:33,694:INFO:Set up feature normalization.
2025-03-19 15:41:33,694:INFO:Set up column name cleaning.
2025-03-19 15:41:33,736:INFO:Finished creating preprocessing pipeline.
2025-03-19 15:41:33,740:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 15:41:33,740:INFO:Creating final display dataframe.
2025-03-19 15:41:33,846:INFO:Setup _display_container:                     Description            Value
0                    Session id              456
1                        Target          MSW_log
2                   Target type       Regression
3           Original data shape       (1710, 19)
4        Transformed data shape       (1710, 28)
5   Transformed train set shape       (1483, 28)
6    Transformed test set shape        (227, 28)
7              Numeric features               16
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15                    Normalize             True
16             Normalize method           minmax
17               Fold Generator  TimeSeriesSplit
18                  Fold Number                5
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name   msw_prediction
23                          USI             0c08
2025-03-19 15:41:33,899:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,900:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,949:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:33,950:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:41:33,951:INFO:Logging experiment in loggers
2025-03-19 15:41:34,100:INFO:SubProcess save_model() called ==================================
2025-03-19 15:41:34,108:INFO:Initializing save_model()
2025-03-19 15:41:34,108:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpgwna7zb2\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-19 15:41:34,108:INFO:Adding model into prep_pipe
2025-03-19 15:41:34,108:WARNING:Only Model saved as it was a pipeline.
2025-03-19 15:41:34,111:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpgwna7zb2\Transformation Pipeline.pkl saved in current working directory
2025-03-19 15:41:34,115:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 15:41:34,115:INFO:save_model() successfully completed......................................
2025-03-19 15:41:34,169:INFO:SubProcess save_model() end ==================================
2025-03-19 15:41:34,174:INFO:setup() successfully completed in 2.72s...............
2025-03-19 15:41:34,174:INFO:Initializing compare_models()
2025-03-19 15:41:34,174:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, include=None, fold=None, round=4, cross_validation=True, sort=mape, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'mape', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-19 15:41:34,174:INFO:Checking exceptions
2025-03-19 15:41:34,175:INFO:Preparing display monitor
2025-03-19 15:41:34,186:INFO:Initializing Linear Regression
2025-03-19 15:41:34,186:INFO:Total runtime is 0.0 minutes
2025-03-19 15:41:34,188:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:34,188:INFO:Initializing create_model()
2025-03-19 15:41:34,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:34,188:INFO:Checking exceptions
2025-03-19 15:41:34,188:INFO:Importing libraries
2025-03-19 15:41:34,188:INFO:Copying training dataset
2025-03-19 15:41:34,190:INFO:Defining folds
2025-03-19 15:41:34,190:INFO:Declaring metric variables
2025-03-19 15:41:34,192:INFO:Importing untrained model
2025-03-19 15:41:34,195:INFO:Linear Regression Imported successfully
2025-03-19 15:41:34,201:INFO:Starting cross validation
2025-03-19 15:41:34,205:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:36,654:INFO:Calculating mean and std
2025-03-19 15:41:36,655:INFO:Creating metrics dataframe
2025-03-19 15:41:36,657:INFO:Uploading results into container
2025-03-19 15:41:36,658:INFO:Uploading model into container now
2025-03-19 15:41:36,658:INFO:_master_model_container: 1
2025-03-19 15:41:36,658:INFO:_display_container: 2
2025-03-19 15:41:36,658:INFO:LinearRegression(n_jobs=-1)
2025-03-19 15:41:36,658:INFO:create_model() successfully completed......................................
2025-03-19 15:41:36,715:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:36,715:INFO:Creating metrics dataframe
2025-03-19 15:41:36,719:INFO:Initializing Lasso Regression
2025-03-19 15:41:36,719:INFO:Total runtime is 0.04221661488215129 minutes
2025-03-19 15:41:36,721:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:36,721:INFO:Initializing create_model()
2025-03-19 15:41:36,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:36,721:INFO:Checking exceptions
2025-03-19 15:41:36,721:INFO:Importing libraries
2025-03-19 15:41:36,721:INFO:Copying training dataset
2025-03-19 15:41:36,723:INFO:Defining folds
2025-03-19 15:41:36,723:INFO:Declaring metric variables
2025-03-19 15:41:36,725:INFO:Importing untrained model
2025-03-19 15:41:36,726:INFO:Lasso Regression Imported successfully
2025-03-19 15:41:36,729:INFO:Starting cross validation
2025-03-19 15:41:36,730:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:38,732:INFO:Calculating mean and std
2025-03-19 15:41:38,733:INFO:Creating metrics dataframe
2025-03-19 15:41:38,735:INFO:Uploading results into container
2025-03-19 15:41:38,736:INFO:Uploading model into container now
2025-03-19 15:41:38,736:INFO:_master_model_container: 2
2025-03-19 15:41:38,736:INFO:_display_container: 2
2025-03-19 15:41:38,736:INFO:Lasso(random_state=456)
2025-03-19 15:41:38,736:INFO:create_model() successfully completed......................................
2025-03-19 15:41:38,802:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:38,802:INFO:Creating metrics dataframe
2025-03-19 15:41:38,807:INFO:Initializing Ridge Regression
2025-03-19 15:41:38,807:INFO:Total runtime is 0.07700807253519695 minutes
2025-03-19 15:41:38,809:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:38,809:INFO:Initializing create_model()
2025-03-19 15:41:38,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:38,809:INFO:Checking exceptions
2025-03-19 15:41:38,809:INFO:Importing libraries
2025-03-19 15:41:38,809:INFO:Copying training dataset
2025-03-19 15:41:38,811:INFO:Defining folds
2025-03-19 15:41:38,811:INFO:Declaring metric variables
2025-03-19 15:41:38,813:INFO:Importing untrained model
2025-03-19 15:41:38,815:INFO:Ridge Regression Imported successfully
2025-03-19 15:41:38,819:INFO:Starting cross validation
2025-03-19 15:41:38,819:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:40,780:INFO:Calculating mean and std
2025-03-19 15:41:40,781:INFO:Creating metrics dataframe
2025-03-19 15:41:40,783:INFO:Uploading results into container
2025-03-19 15:41:40,784:INFO:Uploading model into container now
2025-03-19 15:41:40,784:INFO:_master_model_container: 3
2025-03-19 15:41:40,784:INFO:_display_container: 2
2025-03-19 15:41:40,785:INFO:Ridge(random_state=456)
2025-03-19 15:41:40,785:INFO:create_model() successfully completed......................................
2025-03-19 15:41:40,856:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:40,856:INFO:Creating metrics dataframe
2025-03-19 15:41:40,860:INFO:Initializing Elastic Net
2025-03-19 15:41:40,861:INFO:Total runtime is 0.11124492088953655 minutes
2025-03-19 15:41:40,862:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:40,862:INFO:Initializing create_model()
2025-03-19 15:41:40,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:40,862:INFO:Checking exceptions
2025-03-19 15:41:40,862:INFO:Importing libraries
2025-03-19 15:41:40,862:INFO:Copying training dataset
2025-03-19 15:41:40,864:INFO:Defining folds
2025-03-19 15:41:40,864:INFO:Declaring metric variables
2025-03-19 15:41:40,865:INFO:Importing untrained model
2025-03-19 15:41:40,867:INFO:Elastic Net Imported successfully
2025-03-19 15:41:40,870:INFO:Starting cross validation
2025-03-19 15:41:40,871:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:42,859:INFO:Calculating mean and std
2025-03-19 15:41:42,860:INFO:Creating metrics dataframe
2025-03-19 15:41:42,861:INFO:Uploading results into container
2025-03-19 15:41:42,862:INFO:Uploading model into container now
2025-03-19 15:41:42,862:INFO:_master_model_container: 4
2025-03-19 15:41:42,862:INFO:_display_container: 2
2025-03-19 15:41:42,863:INFO:ElasticNet(random_state=456)
2025-03-19 15:41:42,863:INFO:create_model() successfully completed......................................
2025-03-19 15:41:42,924:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:42,924:INFO:Creating metrics dataframe
2025-03-19 15:41:42,929:INFO:Initializing Least Angle Regression
2025-03-19 15:41:42,929:INFO:Total runtime is 0.14570526679356893 minutes
2025-03-19 15:41:42,930:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:42,931:INFO:Initializing create_model()
2025-03-19 15:41:42,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:42,931:INFO:Checking exceptions
2025-03-19 15:41:42,931:INFO:Importing libraries
2025-03-19 15:41:42,931:INFO:Copying training dataset
2025-03-19 15:41:42,932:INFO:Defining folds
2025-03-19 15:41:42,933:INFO:Declaring metric variables
2025-03-19 15:41:42,934:INFO:Importing untrained model
2025-03-19 15:41:42,936:INFO:Least Angle Regression Imported successfully
2025-03-19 15:41:42,938:INFO:Starting cross validation
2025-03-19 15:41:42,939:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:44,895:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.720e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-19 15:41:44,895:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.391e-02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-19 15:41:44,922:INFO:Calculating mean and std
2025-03-19 15:41:44,923:INFO:Creating metrics dataframe
2025-03-19 15:41:44,924:INFO:Uploading results into container
2025-03-19 15:41:44,925:INFO:Uploading model into container now
2025-03-19 15:41:44,926:INFO:_master_model_container: 5
2025-03-19 15:41:44,926:INFO:_display_container: 2
2025-03-19 15:41:44,926:INFO:Lars(random_state=456)
2025-03-19 15:41:44,926:INFO:create_model() successfully completed......................................
2025-03-19 15:41:44,989:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:44,989:INFO:Creating metrics dataframe
2025-03-19 15:41:44,994:INFO:Initializing Lasso Least Angle Regression
2025-03-19 15:41:44,994:INFO:Total runtime is 0.1801325043042501 minutes
2025-03-19 15:41:44,996:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:44,996:INFO:Initializing create_model()
2025-03-19 15:41:44,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:44,996:INFO:Checking exceptions
2025-03-19 15:41:44,996:INFO:Importing libraries
2025-03-19 15:41:44,996:INFO:Copying training dataset
2025-03-19 15:41:44,998:INFO:Defining folds
2025-03-19 15:41:44,998:INFO:Declaring metric variables
2025-03-19 15:41:45,000:INFO:Importing untrained model
2025-03-19 15:41:45,001:INFO:Lasso Least Angle Regression Imported successfully
2025-03-19 15:41:45,005:INFO:Starting cross validation
2025-03-19 15:41:45,005:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:46,985:INFO:Calculating mean and std
2025-03-19 15:41:46,986:INFO:Creating metrics dataframe
2025-03-19 15:41:46,988:INFO:Uploading results into container
2025-03-19 15:41:46,989:INFO:Uploading model into container now
2025-03-19 15:41:46,989:INFO:_master_model_container: 6
2025-03-19 15:41:46,989:INFO:_display_container: 2
2025-03-19 15:41:46,989:INFO:LassoLars(random_state=456)
2025-03-19 15:41:46,989:INFO:create_model() successfully completed......................................
2025-03-19 15:41:47,049:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:47,049:INFO:Creating metrics dataframe
2025-03-19 15:41:47,054:INFO:Initializing Orthogonal Matching Pursuit
2025-03-19 15:41:47,054:INFO:Total runtime is 0.21446868578592937 minutes
2025-03-19 15:41:47,056:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:47,056:INFO:Initializing create_model()
2025-03-19 15:41:47,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:47,056:INFO:Checking exceptions
2025-03-19 15:41:47,056:INFO:Importing libraries
2025-03-19 15:41:47,056:INFO:Copying training dataset
2025-03-19 15:41:47,058:INFO:Defining folds
2025-03-19 15:41:47,058:INFO:Declaring metric variables
2025-03-19 15:41:47,059:INFO:Importing untrained model
2025-03-19 15:41:47,061:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-19 15:41:47,064:INFO:Starting cross validation
2025-03-19 15:41:47,065:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:48,740:INFO:Calculating mean and std
2025-03-19 15:41:48,741:INFO:Creating metrics dataframe
2025-03-19 15:41:48,744:INFO:Uploading results into container
2025-03-19 15:41:48,744:INFO:Uploading model into container now
2025-03-19 15:41:48,745:INFO:_master_model_container: 7
2025-03-19 15:41:48,745:INFO:_display_container: 2
2025-03-19 15:41:48,745:INFO:OrthogonalMatchingPursuit()
2025-03-19 15:41:48,745:INFO:create_model() successfully completed......................................
2025-03-19 15:41:48,804:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:48,804:INFO:Creating metrics dataframe
2025-03-19 15:41:48,809:INFO:Initializing Bayesian Ridge
2025-03-19 15:41:48,809:INFO:Total runtime is 0.24371403853098553 minutes
2025-03-19 15:41:48,811:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:48,811:INFO:Initializing create_model()
2025-03-19 15:41:48,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:48,811:INFO:Checking exceptions
2025-03-19 15:41:48,811:INFO:Importing libraries
2025-03-19 15:41:48,812:INFO:Copying training dataset
2025-03-19 15:41:48,813:INFO:Defining folds
2025-03-19 15:41:48,813:INFO:Declaring metric variables
2025-03-19 15:41:48,815:INFO:Importing untrained model
2025-03-19 15:41:48,817:INFO:Bayesian Ridge Imported successfully
2025-03-19 15:41:48,820:INFO:Starting cross validation
2025-03-19 15:41:48,821:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:48,879:INFO:Calculating mean and std
2025-03-19 15:41:48,880:INFO:Creating metrics dataframe
2025-03-19 15:41:48,881:INFO:Uploading results into container
2025-03-19 15:41:48,882:INFO:Uploading model into container now
2025-03-19 15:41:48,882:INFO:_master_model_container: 8
2025-03-19 15:41:48,882:INFO:_display_container: 2
2025-03-19 15:41:48,882:INFO:BayesianRidge()
2025-03-19 15:41:48,882:INFO:create_model() successfully completed......................................
2025-03-19 15:41:48,938:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:48,938:INFO:Creating metrics dataframe
2025-03-19 15:41:48,943:INFO:Initializing Passive Aggressive Regressor
2025-03-19 15:41:48,943:INFO:Total runtime is 0.24594811201095582 minutes
2025-03-19 15:41:48,945:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:48,945:INFO:Initializing create_model()
2025-03-19 15:41:48,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:48,945:INFO:Checking exceptions
2025-03-19 15:41:48,945:INFO:Importing libraries
2025-03-19 15:41:48,945:INFO:Copying training dataset
2025-03-19 15:41:48,947:INFO:Defining folds
2025-03-19 15:41:48,947:INFO:Declaring metric variables
2025-03-19 15:41:48,949:INFO:Importing untrained model
2025-03-19 15:41:48,950:INFO:Passive Aggressive Regressor Imported successfully
2025-03-19 15:41:48,954:INFO:Starting cross validation
2025-03-19 15:41:48,955:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:49,017:INFO:Calculating mean and std
2025-03-19 15:41:49,018:INFO:Creating metrics dataframe
2025-03-19 15:41:49,020:INFO:Uploading results into container
2025-03-19 15:41:49,020:INFO:Uploading model into container now
2025-03-19 15:41:49,020:INFO:_master_model_container: 9
2025-03-19 15:41:49,020:INFO:_display_container: 2
2025-03-19 15:41:49,021:INFO:PassiveAggressiveRegressor(random_state=456)
2025-03-19 15:41:49,021:INFO:create_model() successfully completed......................................
2025-03-19 15:41:49,077:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:49,077:INFO:Creating metrics dataframe
2025-03-19 15:41:49,082:INFO:Initializing Huber Regressor
2025-03-19 15:41:49,082:INFO:Total runtime is 0.24826606512069702 minutes
2025-03-19 15:41:49,085:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:49,085:INFO:Initializing create_model()
2025-03-19 15:41:49,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:49,085:INFO:Checking exceptions
2025-03-19 15:41:49,085:INFO:Importing libraries
2025-03-19 15:41:49,085:INFO:Copying training dataset
2025-03-19 15:41:49,086:INFO:Defining folds
2025-03-19 15:41:49,087:INFO:Declaring metric variables
2025-03-19 15:41:49,088:INFO:Importing untrained model
2025-03-19 15:41:49,090:INFO:Huber Regressor Imported successfully
2025-03-19 15:41:49,093:INFO:Starting cross validation
2025-03-19 15:41:49,094:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:49,131:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:41:49,139:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:41:49,141:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:41:49,142:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:41:49,155:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:41:49,171:INFO:Calculating mean and std
2025-03-19 15:41:49,172:INFO:Creating metrics dataframe
2025-03-19 15:41:49,174:INFO:Uploading results into container
2025-03-19 15:41:49,174:INFO:Uploading model into container now
2025-03-19 15:41:49,174:INFO:_master_model_container: 10
2025-03-19 15:41:49,175:INFO:_display_container: 2
2025-03-19 15:41:49,175:INFO:HuberRegressor()
2025-03-19 15:41:49,175:INFO:create_model() successfully completed......................................
2025-03-19 15:41:49,235:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:49,235:INFO:Creating metrics dataframe
2025-03-19 15:41:49,240:INFO:Initializing K Neighbors Regressor
2025-03-19 15:41:49,240:INFO:Total runtime is 0.25089860757191973 minutes
2025-03-19 15:41:49,242:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:49,242:INFO:Initializing create_model()
2025-03-19 15:41:49,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:49,242:INFO:Checking exceptions
2025-03-19 15:41:49,242:INFO:Importing libraries
2025-03-19 15:41:49,242:INFO:Copying training dataset
2025-03-19 15:41:49,244:INFO:Defining folds
2025-03-19 15:41:49,244:INFO:Declaring metric variables
2025-03-19 15:41:49,245:INFO:Importing untrained model
2025-03-19 15:41:49,247:INFO:K Neighbors Regressor Imported successfully
2025-03-19 15:41:49,250:INFO:Starting cross validation
2025-03-19 15:41:49,251:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:49,341:INFO:Calculating mean and std
2025-03-19 15:41:49,342:INFO:Creating metrics dataframe
2025-03-19 15:41:49,343:INFO:Uploading results into container
2025-03-19 15:41:49,343:INFO:Uploading model into container now
2025-03-19 15:41:49,344:INFO:_master_model_container: 11
2025-03-19 15:41:49,344:INFO:_display_container: 2
2025-03-19 15:41:49,344:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-19 15:41:49,344:INFO:create_model() successfully completed......................................
2025-03-19 15:41:49,400:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:49,400:INFO:Creating metrics dataframe
2025-03-19 15:41:49,406:INFO:Initializing Decision Tree Regressor
2025-03-19 15:41:49,406:INFO:Total runtime is 0.25366366306940713 minutes
2025-03-19 15:41:49,408:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:49,408:INFO:Initializing create_model()
2025-03-19 15:41:49,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:49,409:INFO:Checking exceptions
2025-03-19 15:41:49,409:INFO:Importing libraries
2025-03-19 15:41:49,409:INFO:Copying training dataset
2025-03-19 15:41:49,410:INFO:Defining folds
2025-03-19 15:41:49,410:INFO:Declaring metric variables
2025-03-19 15:41:49,412:INFO:Importing untrained model
2025-03-19 15:41:49,414:INFO:Decision Tree Regressor Imported successfully
2025-03-19 15:41:49,417:INFO:Starting cross validation
2025-03-19 15:41:49,418:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:49,495:INFO:Calculating mean and std
2025-03-19 15:41:49,495:INFO:Creating metrics dataframe
2025-03-19 15:41:49,497:INFO:Uploading results into container
2025-03-19 15:41:49,497:INFO:Uploading model into container now
2025-03-19 15:41:49,498:INFO:_master_model_container: 12
2025-03-19 15:41:49,498:INFO:_display_container: 2
2025-03-19 15:41:49,498:INFO:DecisionTreeRegressor(random_state=456)
2025-03-19 15:41:49,498:INFO:create_model() successfully completed......................................
2025-03-19 15:41:49,553:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:49,553:INFO:Creating metrics dataframe
2025-03-19 15:41:49,559:INFO:Initializing Random Forest Regressor
2025-03-19 15:41:49,559:INFO:Total runtime is 0.25621508757273354 minutes
2025-03-19 15:41:49,561:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:49,562:INFO:Initializing create_model()
2025-03-19 15:41:49,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:49,562:INFO:Checking exceptions
2025-03-19 15:41:49,562:INFO:Importing libraries
2025-03-19 15:41:49,562:INFO:Copying training dataset
2025-03-19 15:41:49,564:INFO:Defining folds
2025-03-19 15:41:49,564:INFO:Declaring metric variables
2025-03-19 15:41:49,565:INFO:Importing untrained model
2025-03-19 15:41:49,567:INFO:Random Forest Regressor Imported successfully
2025-03-19 15:41:49,571:INFO:Starting cross validation
2025-03-19 15:41:49,571:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:49,787:INFO:Calculating mean and std
2025-03-19 15:41:49,788:INFO:Creating metrics dataframe
2025-03-19 15:41:49,790:INFO:Uploading results into container
2025-03-19 15:41:49,790:INFO:Uploading model into container now
2025-03-19 15:41:49,790:INFO:_master_model_container: 13
2025-03-19 15:41:49,790:INFO:_display_container: 2
2025-03-19 15:41:49,790:INFO:RandomForestRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:41:49,790:INFO:create_model() successfully completed......................................
2025-03-19 15:41:49,847:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:49,847:INFO:Creating metrics dataframe
2025-03-19 15:41:49,854:INFO:Initializing Extra Trees Regressor
2025-03-19 15:41:49,854:INFO:Total runtime is 0.2611238121986389 minutes
2025-03-19 15:41:49,855:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:49,855:INFO:Initializing create_model()
2025-03-19 15:41:49,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:49,856:INFO:Checking exceptions
2025-03-19 15:41:49,856:INFO:Importing libraries
2025-03-19 15:41:49,856:INFO:Copying training dataset
2025-03-19 15:41:49,857:INFO:Defining folds
2025-03-19 15:41:49,858:INFO:Declaring metric variables
2025-03-19 15:41:49,859:INFO:Importing untrained model
2025-03-19 15:41:49,861:INFO:Extra Trees Regressor Imported successfully
2025-03-19 15:41:49,864:INFO:Starting cross validation
2025-03-19 15:41:49,865:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:50,034:INFO:Calculating mean and std
2025-03-19 15:41:50,035:INFO:Creating metrics dataframe
2025-03-19 15:41:50,036:INFO:Uploading results into container
2025-03-19 15:41:50,036:INFO:Uploading model into container now
2025-03-19 15:41:50,037:INFO:_master_model_container: 14
2025-03-19 15:41:50,037:INFO:_display_container: 2
2025-03-19 15:41:50,037:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:41:50,037:INFO:create_model() successfully completed......................................
2025-03-19 15:41:50,089:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:50,089:INFO:Creating metrics dataframe
2025-03-19 15:41:50,095:INFO:Initializing AdaBoost Regressor
2025-03-19 15:41:50,095:INFO:Total runtime is 0.26514680385589595 minutes
2025-03-19 15:41:50,097:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:50,098:INFO:Initializing create_model()
2025-03-19 15:41:50,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:50,098:INFO:Checking exceptions
2025-03-19 15:41:50,098:INFO:Importing libraries
2025-03-19 15:41:50,098:INFO:Copying training dataset
2025-03-19 15:41:50,099:INFO:Defining folds
2025-03-19 15:41:50,099:INFO:Declaring metric variables
2025-03-19 15:41:50,101:INFO:Importing untrained model
2025-03-19 15:41:50,103:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:41:50,106:INFO:Starting cross validation
2025-03-19 15:41:50,107:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:50,234:INFO:Calculating mean and std
2025-03-19 15:41:50,235:INFO:Creating metrics dataframe
2025-03-19 15:41:50,236:INFO:Uploading results into container
2025-03-19 15:41:50,237:INFO:Uploading model into container now
2025-03-19 15:41:50,237:INFO:_master_model_container: 15
2025-03-19 15:41:50,237:INFO:_display_container: 2
2025-03-19 15:41:50,237:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:41:50,237:INFO:create_model() successfully completed......................................
2025-03-19 15:41:50,294:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:50,294:INFO:Creating metrics dataframe
2025-03-19 15:41:50,300:INFO:Initializing Gradient Boosting Regressor
2025-03-19 15:41:50,300:INFO:Total runtime is 0.26856551965077713 minutes
2025-03-19 15:41:50,302:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:50,302:INFO:Initializing create_model()
2025-03-19 15:41:50,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:50,302:INFO:Checking exceptions
2025-03-19 15:41:50,302:INFO:Importing libraries
2025-03-19 15:41:50,302:INFO:Copying training dataset
2025-03-19 15:41:50,304:INFO:Defining folds
2025-03-19 15:41:50,304:INFO:Declaring metric variables
2025-03-19 15:41:50,305:INFO:Importing untrained model
2025-03-19 15:41:50,307:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:41:50,310:INFO:Starting cross validation
2025-03-19 15:41:50,311:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:50,542:INFO:Calculating mean and std
2025-03-19 15:41:50,543:INFO:Creating metrics dataframe
2025-03-19 15:41:50,544:INFO:Uploading results into container
2025-03-19 15:41:50,545:INFO:Uploading model into container now
2025-03-19 15:41:50,545:INFO:_master_model_container: 16
2025-03-19 15:41:50,545:INFO:_display_container: 2
2025-03-19 15:41:50,545:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:41:50,545:INFO:create_model() successfully completed......................................
2025-03-19 15:41:50,600:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:50,600:INFO:Creating metrics dataframe
2025-03-19 15:41:50,607:INFO:Initializing Extreme Gradient Boosting
2025-03-19 15:41:50,607:INFO:Total runtime is 0.2736811796824137 minutes
2025-03-19 15:41:50,609:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:50,609:INFO:Initializing create_model()
2025-03-19 15:41:50,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:50,609:INFO:Checking exceptions
2025-03-19 15:41:50,609:INFO:Importing libraries
2025-03-19 15:41:50,609:INFO:Copying training dataset
2025-03-19 15:41:50,611:INFO:Defining folds
2025-03-19 15:41:50,611:INFO:Declaring metric variables
2025-03-19 15:41:50,613:INFO:Importing untrained model
2025-03-19 15:41:50,614:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:41:50,618:INFO:Starting cross validation
2025-03-19 15:41:50,619:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:50,957:INFO:Calculating mean and std
2025-03-19 15:41:50,958:INFO:Creating metrics dataframe
2025-03-19 15:41:50,960:INFO:Uploading results into container
2025-03-19 15:41:50,960:INFO:Uploading model into container now
2025-03-19 15:41:50,960:INFO:_master_model_container: 17
2025-03-19 15:41:50,960:INFO:_display_container: 2
2025-03-19 15:41:50,961:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:41:50,961:INFO:create_model() successfully completed......................................
2025-03-19 15:41:51,016:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:51,016:INFO:Creating metrics dataframe
2025-03-19 15:41:51,023:INFO:Initializing Light Gradient Boosting Machine
2025-03-19 15:41:51,023:INFO:Total runtime is 0.2806179523468017 minutes
2025-03-19 15:41:51,025:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:51,025:INFO:Initializing create_model()
2025-03-19 15:41:51,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:51,025:INFO:Checking exceptions
2025-03-19 15:41:51,025:INFO:Importing libraries
2025-03-19 15:41:51,025:INFO:Copying training dataset
2025-03-19 15:41:51,027:INFO:Defining folds
2025-03-19 15:41:51,027:INFO:Declaring metric variables
2025-03-19 15:41:51,029:INFO:Importing untrained model
2025-03-19 15:41:51,030:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:41:51,033:INFO:Starting cross validation
2025-03-19 15:41:51,034:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:51,512:INFO:Calculating mean and std
2025-03-19 15:41:51,513:INFO:Creating metrics dataframe
2025-03-19 15:41:51,515:INFO:Uploading results into container
2025-03-19 15:41:51,515:INFO:Uploading model into container now
2025-03-19 15:41:51,516:INFO:_master_model_container: 18
2025-03-19 15:41:51,516:INFO:_display_container: 2
2025-03-19 15:41:51,516:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:41:51,516:INFO:create_model() successfully completed......................................
2025-03-19 15:41:51,577:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:51,577:INFO:Creating metrics dataframe
2025-03-19 15:41:51,586:INFO:Initializing CatBoost Regressor
2025-03-19 15:41:51,586:INFO:Total runtime is 0.28998837868372596 minutes
2025-03-19 15:41:51,588:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:51,588:INFO:Initializing create_model()
2025-03-19 15:41:51,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:51,588:INFO:Checking exceptions
2025-03-19 15:41:51,588:INFO:Importing libraries
2025-03-19 15:41:51,588:INFO:Copying training dataset
2025-03-19 15:41:51,590:INFO:Defining folds
2025-03-19 15:41:51,591:INFO:Declaring metric variables
2025-03-19 15:41:51,593:INFO:Importing untrained model
2025-03-19 15:41:51,594:INFO:CatBoost Regressor Imported successfully
2025-03-19 15:41:51,598:INFO:Starting cross validation
2025-03-19 15:41:51,599:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:53,251:INFO:Calculating mean and std
2025-03-19 15:41:53,252:INFO:Creating metrics dataframe
2025-03-19 15:41:53,254:INFO:Uploading results into container
2025-03-19 15:41:53,254:INFO:Uploading model into container now
2025-03-19 15:41:53,254:INFO:_master_model_container: 19
2025-03-19 15:41:53,254:INFO:_display_container: 2
2025-03-19 15:41:53,254:INFO:<catboost.core.CatBoostRegressor object at 0x0000025F86192DC0>
2025-03-19 15:41:53,255:INFO:create_model() successfully completed......................................
2025-03-19 15:41:53,313:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:53,313:INFO:Creating metrics dataframe
2025-03-19 15:41:53,319:INFO:Initializing Dummy Regressor
2025-03-19 15:41:53,319:INFO:Total runtime is 0.3188860694567362 minutes
2025-03-19 15:41:53,321:INFO:SubProcess create_model() called ==================================
2025-03-19 15:41:53,321:INFO:Initializing create_model()
2025-03-19 15:41:53,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F86460730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:53,321:INFO:Checking exceptions
2025-03-19 15:41:53,321:INFO:Importing libraries
2025-03-19 15:41:53,321:INFO:Copying training dataset
2025-03-19 15:41:53,323:INFO:Defining folds
2025-03-19 15:41:53,323:INFO:Declaring metric variables
2025-03-19 15:41:53,324:INFO:Importing untrained model
2025-03-19 15:41:53,326:INFO:Dummy Regressor Imported successfully
2025-03-19 15:41:53,329:INFO:Starting cross validation
2025-03-19 15:41:53,330:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:41:53,390:INFO:Calculating mean and std
2025-03-19 15:41:53,391:INFO:Creating metrics dataframe
2025-03-19 15:41:53,393:INFO:Uploading results into container
2025-03-19 15:41:53,393:INFO:Uploading model into container now
2025-03-19 15:41:53,393:INFO:_master_model_container: 20
2025-03-19 15:41:53,393:INFO:_display_container: 2
2025-03-19 15:41:53,394:INFO:DummyRegressor()
2025-03-19 15:41:53,394:INFO:create_model() successfully completed......................................
2025-03-19 15:41:53,453:INFO:SubProcess create_model() end ==================================
2025-03-19 15:41:53,453:INFO:Creating metrics dataframe
2025-03-19 15:41:53,463:INFO:Initializing create_model()
2025-03-19 15:41:53,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:53,463:INFO:Checking exceptions
2025-03-19 15:41:53,464:INFO:Importing libraries
2025-03-19 15:41:53,464:INFO:Copying training dataset
2025-03-19 15:41:53,466:INFO:Defining folds
2025-03-19 15:41:53,466:INFO:Declaring metric variables
2025-03-19 15:41:53,466:INFO:Importing untrained model
2025-03-19 15:41:53,466:INFO:Declaring custom model
2025-03-19 15:41:53,466:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:41:53,467:INFO:Cross validation set to False
2025-03-19 15:41:53,467:INFO:Fitting Model
2025-03-19 15:41:53,675:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:41:53,675:INFO:create_model() successfully completed......................................
2025-03-19 15:41:53,734:INFO:Creating Dashboard logs
2025-03-19 15:41:53,736:INFO:Model: Gradient Boosting Regressor
2025-03-19 15:41:53,751:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 456, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:41:53,786:INFO:Initializing predict_model()
2025-03-19 15:41:53,786:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=GradientBoostingRegressor(random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F84A4A0D0>)
2025-03-19 15:41:53,786:INFO:Checking exceptions
2025-03-19 15:41:53,786:INFO:Preloading libraries
2025-03-19 15:41:53,902:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-19 15:41:53,918:ERROR:_log_model() for GradientBoostingRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:53,920:INFO:Initializing create_model()
2025-03-19 15:41:53,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:53,921:INFO:Checking exceptions
2025-03-19 15:41:53,921:INFO:Importing libraries
2025-03-19 15:41:53,921:INFO:Copying training dataset
2025-03-19 15:41:53,922:INFO:Defining folds
2025-03-19 15:41:53,922:INFO:Declaring metric variables
2025-03-19 15:41:53,923:INFO:Importing untrained model
2025-03-19 15:41:53,923:INFO:Declaring custom model
2025-03-19 15:41:53,923:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:41:53,923:INFO:Cross validation set to False
2025-03-19 15:41:53,923:INFO:Fitting Model
2025-03-19 15:41:53,952:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:41:53,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2025-03-19 15:41:53,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:41:53,952:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:41:53,953:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:41:53,953:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:41:54,020:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:41:54,020:INFO:create_model() successfully completed......................................
2025-03-19 15:41:54,082:INFO:Creating Dashboard logs
2025-03-19 15:41:54,084:INFO:Model: Light Gradient Boosting Machine
2025-03-19 15:41:54,102:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 456, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-19 15:41:54,149:INFO:Initializing predict_model()
2025-03-19 15:41:54,149:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F866131F0>)
2025-03-19 15:41:54,149:INFO:Checking exceptions
2025-03-19 15:41:54,149:INFO:Preloading libraries
2025-03-19 15:41:54,290:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:54,294:INFO:Initializing create_model()
2025-03-19 15:41:54,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:54,294:INFO:Checking exceptions
2025-03-19 15:41:54,295:INFO:Importing libraries
2025-03-19 15:41:54,295:INFO:Copying training dataset
2025-03-19 15:41:54,297:INFO:Defining folds
2025-03-19 15:41:54,297:INFO:Declaring metric variables
2025-03-19 15:41:54,297:INFO:Importing untrained model
2025-03-19 15:41:54,297:INFO:Declaring custom model
2025-03-19 15:41:54,298:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:41:54,299:INFO:Cross validation set to False
2025-03-19 15:41:54,299:INFO:Fitting Model
2025-03-19 15:41:54,455:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:41:54,455:INFO:create_model() successfully completed......................................
2025-03-19 15:41:54,553:INFO:Creating Dashboard logs
2025-03-19 15:41:54,555:INFO:Model: Extreme Gradient Boosting
2025-03-19 15:41:54,569:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 456, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-19 15:41:54,628:INFO:Initializing predict_model()
2025-03-19 15:41:54,628:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F864411F0>)
2025-03-19 15:41:54,628:INFO:Checking exceptions
2025-03-19 15:41:54,628:INFO:Preloading libraries
2025-03-19 15:41:54,763:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:54,766:INFO:Initializing create_model()
2025-03-19 15:41:54,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=AdaBoostRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:41:54,767:INFO:Checking exceptions
2025-03-19 15:41:54,768:INFO:Importing libraries
2025-03-19 15:41:54,768:INFO:Copying training dataset
2025-03-19 15:41:54,770:INFO:Defining folds
2025-03-19 15:41:54,770:INFO:Declaring metric variables
2025-03-19 15:41:54,770:INFO:Importing untrained model
2025-03-19 15:41:54,770:INFO:Declaring custom model
2025-03-19 15:41:54,770:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:41:54,771:INFO:Cross validation set to False
2025-03-19 15:41:54,771:INFO:Fitting Model
2025-03-19 15:41:54,888:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:41:54,888:INFO:create_model() successfully completed......................................
2025-03-19 15:41:54,955:INFO:Creating Dashboard logs
2025-03-19 15:41:54,957:INFO:Model: AdaBoost Regressor
2025-03-19 15:41:54,971:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 456}
2025-03-19 15:41:55,029:INFO:Initializing predict_model()
2025-03-19 15:41:55,029:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=AdaBoostRegressor(random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F86441CA0>)
2025-03-19 15:41:55,029:INFO:Checking exceptions
2025-03-19 15:41:55,029:INFO:Preloading libraries
2025-03-19 15:41:55,156:ERROR:_log_model() for AdaBoostRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,157:INFO:Creating Dashboard logs
2025-03-19 15:41:55,158:INFO:Model: CatBoost Regressor
2025-03-19 15:41:55,175:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-19 15:41:55,175:INFO:Logged params: {}
2025-03-19 15:41:55,238:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x0000025F86192DC0> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,239:INFO:Creating Dashboard logs
2025-03-19 15:41:55,241:INFO:Model: Random Forest Regressor
2025-03-19 15:41:55,255:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 456, 'verbose': 0, 'warm_start': False}
2025-03-19 15:41:55,330:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,331:INFO:Creating Dashboard logs
2025-03-19 15:41:55,333:INFO:Model: Extra Trees Regressor
2025-03-19 15:41:55,345:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 456, 'verbose': 0, 'warm_start': False}
2025-03-19 15:41:55,424:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,425:INFO:Creating Dashboard logs
2025-03-19 15:41:55,427:INFO:Model: Decision Tree Regressor
2025-03-19 15:41:55,441:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 456, 'splitter': 'best'}
2025-03-19 15:41:55,526:ERROR:_log_model() for DecisionTreeRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,526:INFO:Creating Dashboard logs
2025-03-19 15:41:55,528:INFO:Model: Orthogonal Matching Pursuit
2025-03-19 15:41:55,541:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-19 15:41:55,631:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,632:INFO:Creating Dashboard logs
2025-03-19 15:41:55,634:INFO:Model: Bayesian Ridge
2025-03-19 15:41:55,648:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-19 15:41:55,745:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,746:INFO:Creating Dashboard logs
2025-03-19 15:41:55,748:INFO:Model: Ridge Regression
2025-03-19 15:41:55,762:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 456, 'solver': 'auto', 'tol': 0.0001}
2025-03-19 15:41:55,864:ERROR:_log_model() for Ridge(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,865:INFO:Creating Dashboard logs
2025-03-19 15:41:55,867:INFO:Model: Linear Regression
2025-03-19 15:41:55,880:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-19 15:41:55,984:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:55,985:INFO:Creating Dashboard logs
2025-03-19 15:41:55,986:INFO:Model: Huber Regressor
2025-03-19 15:41:56,000:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-19 15:41:56,119:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:56,120:INFO:Creating Dashboard logs
2025-03-19 15:41:56,122:INFO:Model: K Neighbors Regressor
2025-03-19 15:41:56,137:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-19 15:41:56,261:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:56,262:INFO:Creating Dashboard logs
2025-03-19 15:41:56,264:INFO:Model: Lasso Regression
2025-03-19 15:41:56,278:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 456, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-19 15:41:56,407:ERROR:_log_model() for Lasso(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:56,408:INFO:Creating Dashboard logs
2025-03-19 15:41:56,410:INFO:Model: Elastic Net
2025-03-19 15:41:56,424:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 456, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-19 15:41:56,555:ERROR:_log_model() for ElasticNet(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:56,556:INFO:Creating Dashboard logs
2025-03-19 15:41:56,558:INFO:Model: Lasso Least Angle Regression
2025-03-19 15:41:56,572:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 456, 'verbose': False}
2025-03-19 15:41:56,708:ERROR:_log_model() for LassoLars(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:56,708:INFO:Creating Dashboard logs
2025-03-19 15:41:56,710:INFO:Model: Dummy Regressor
2025-03-19 15:41:56,725:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-19 15:41:56,865:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:56,866:INFO:Creating Dashboard logs
2025-03-19 15:41:56,868:INFO:Model: Passive Aggressive Regressor
2025-03-19 15:41:56,883:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 456, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:41:57,037:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:57,038:INFO:Creating Dashboard logs
2025-03-19 15:41:57,040:INFO:Model: Least Angle Regression
2025-03-19 15:41:57,053:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 456, 'verbose': False}
2025-03-19 15:41:57,204:ERROR:_log_model() for Lars(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:41:57,213:INFO:_master_model_container: 20
2025-03-19 15:41:57,213:INFO:_display_container: 2
2025-03-19 15:41:57,213:INFO:[GradientBoostingRegressor(random_state=456), LGBMRegressor(n_jobs=-1, random_state=456), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), AdaBoostRegressor(random_state=456)]
2025-03-19 15:41:57,214:INFO:compare_models() successfully completed......................................
2025-03-19 15:41:57,231:INFO:Initializing tune_model()
2025-03-19 15:41:57,231:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>)
2025-03-19 15:41:57,231:INFO:Checking exceptions
2025-03-19 15:41:57,231:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:41:57,281:INFO:Copying training dataset
2025-03-19 15:41:57,283:INFO:Checking base model
2025-03-19 15:41:57,283:INFO:Base model : Gradient Boosting Regressor
2025-03-19 15:41:57,284:INFO:Declaring metric variables
2025-03-19 15:41:57,286:INFO:Defining Hyperparameters
2025-03-19 15:41:57,345:INFO:Tuning with n_jobs=-1
2025-03-19 15:41:57,346:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:41:57,346:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:41:57,346:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:41:57,351:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:41:57,351:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:41:57,352:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:42:43,839:INFO:best_params: {'actual_estimator__n_estimators': 69, 'actual_estimator__learning_rate': 0.09739316146926662, 'actual_estimator__subsample': 0.9364962052731374, 'actual_estimator__min_samples_split': 8, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__max_depth': 2, 'actual_estimator__max_features': 0.604534414872111, 'actual_estimator__min_impurity_decrease': 1.1090947187651228e-09}
2025-03-19 15:42:43,843:INFO:Hyperparameter search completed
2025-03-19 15:42:43,844:INFO:SubProcess create_model() called ==================================
2025-03-19 15:42:43,844:INFO:Initializing create_model()
2025-03-19 15:42:43,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F84A635B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 69, 'learning_rate': 0.09739316146926662, 'subsample': 0.9364962052731374, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_depth': 2, 'max_features': 0.604534414872111, 'min_impurity_decrease': 1.1090947187651228e-09})
2025-03-19 15:42:43,844:INFO:Checking exceptions
2025-03-19 15:42:43,844:INFO:Importing libraries
2025-03-19 15:42:43,844:INFO:Copying training dataset
2025-03-19 15:42:43,846:INFO:Defining folds
2025-03-19 15:42:43,846:INFO:Declaring metric variables
2025-03-19 15:42:43,848:INFO:Importing untrained model
2025-03-19 15:42:43,848:INFO:Declaring custom model
2025-03-19 15:42:43,850:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:42:43,853:INFO:Starting cross validation
2025-03-19 15:42:43,854:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:42:43,968:INFO:Calculating mean and std
2025-03-19 15:42:43,969:INFO:Creating metrics dataframe
2025-03-19 15:42:43,972:INFO:Finalizing model
2025-03-19 15:42:44,057:INFO:Uploading results into container
2025-03-19 15:42:44,057:INFO:Uploading model into container now
2025-03-19 15:42:44,058:INFO:_master_model_container: 21
2025-03-19 15:42:44,058:INFO:_display_container: 3
2025-03-19 15:42:44,058:INFO:GradientBoostingRegressor(learning_rate=0.09739316146926662, max_depth=2,
                          max_features=0.604534414872111,
                          min_impurity_decrease=1.1090947187651228e-09,
                          min_samples_leaf=5, min_samples_split=8,
                          n_estimators=69, random_state=456,
                          subsample=0.9364962052731374)
2025-03-19 15:42:44,058:INFO:create_model() successfully completed......................................
2025-03-19 15:42:44,117:INFO:SubProcess create_model() end ==================================
2025-03-19 15:42:44,117:INFO:choose_better activated
2025-03-19 15:42:44,119:INFO:SubProcess create_model() called ==================================
2025-03-19 15:42:44,119:INFO:Initializing create_model()
2025-03-19 15:42:44,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:42:44,119:INFO:Checking exceptions
2025-03-19 15:42:44,120:INFO:Importing libraries
2025-03-19 15:42:44,120:INFO:Copying training dataset
2025-03-19 15:42:44,122:INFO:Defining folds
2025-03-19 15:42:44,122:INFO:Declaring metric variables
2025-03-19 15:42:44,122:INFO:Importing untrained model
2025-03-19 15:42:44,122:INFO:Declaring custom model
2025-03-19 15:42:44,122:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:42:44,122:INFO:Starting cross validation
2025-03-19 15:42:44,123:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:42:44,353:INFO:Calculating mean and std
2025-03-19 15:42:44,353:INFO:Creating metrics dataframe
2025-03-19 15:42:44,354:INFO:Finalizing model
2025-03-19 15:42:44,563:INFO:Uploading results into container
2025-03-19 15:42:44,563:INFO:Uploading model into container now
2025-03-19 15:42:44,563:INFO:_master_model_container: 22
2025-03-19 15:42:44,563:INFO:_display_container: 4
2025-03-19 15:42:44,563:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:42:44,563:INFO:create_model() successfully completed......................................
2025-03-19 15:42:44,622:INFO:SubProcess create_model() end ==================================
2025-03-19 15:42:44,622:INFO:GradientBoostingRegressor(random_state=456) result for R2 is 0.8404
2025-03-19 15:42:44,622:INFO:GradientBoostingRegressor(learning_rate=0.09739316146926662, max_depth=2,
                          max_features=0.604534414872111,
                          min_impurity_decrease=1.1090947187651228e-09,
                          min_samples_leaf=5, min_samples_split=8,
                          n_estimators=69, random_state=456,
                          subsample=0.9364962052731374) result for R2 is 0.8699
2025-03-19 15:42:44,623:INFO:GradientBoostingRegressor(learning_rate=0.09739316146926662, max_depth=2,
                          max_features=0.604534414872111,
                          min_impurity_decrease=1.1090947187651228e-09,
                          min_samples_leaf=5, min_samples_split=8,
                          n_estimators=69, random_state=456,
                          subsample=0.9364962052731374) is best model
2025-03-19 15:42:44,623:INFO:choose_better completed
2025-03-19 15:42:44,623:INFO:Creating Dashboard logs
2025-03-19 15:42:44,625:INFO:Model: Gradient Boosting Regressor
2025-03-19 15:42:44,641:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.09739316146926662, 'loss': 'squared_error', 'max_depth': 2, 'max_features': 0.604534414872111, 'max_leaf_nodes': None, 'min_impurity_decrease': 1.1090947187651228e-09, 'min_samples_leaf': 5, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 69, 'n_iter_no_change': None, 'random_state': 456, 'subsample': 0.9364962052731374, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:42:44,807:INFO:Initializing predict_model()
2025-03-19 15:42:44,807:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=GradientBoostingRegressor(learning_rate=0.09739316146926662, max_depth=2,
                          max_features=0.604534414872111,
                          min_impurity_decrease=1.1090947187651228e-09,
                          min_samples_leaf=5, min_samples_split=8,
                          n_estimators=69, random_state=456,
                          subsample=0.9364962052731374), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F866E74C0>)
2025-03-19 15:42:44,807:INFO:Checking exceptions
2025-03-19 15:42:44,807:INFO:Preloading libraries
2025-03-19 15:42:44,938:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.09739316146926662, max_depth=2,
                          max_features=0.604534414872111,
                          min_impurity_decrease=1.1090947187651228e-09,
                          min_samples_leaf=5, min_samples_split=8,
                          n_estimators=69, random_state=456,
                          subsample=0.9364962052731374) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:42:44,944:INFO:_master_model_container: 22
2025-03-19 15:42:44,944:INFO:_display_container: 3
2025-03-19 15:42:44,944:INFO:GradientBoostingRegressor(learning_rate=0.09739316146926662, max_depth=2,
                          max_features=0.604534414872111,
                          min_impurity_decrease=1.1090947187651228e-09,
                          min_samples_leaf=5, min_samples_split=8,
                          n_estimators=69, random_state=456,
                          subsample=0.9364962052731374)
2025-03-19 15:42:44,944:INFO:tune_model() successfully completed......................................
2025-03-19 15:42:45,005:INFO:Initializing tune_model()
2025-03-19 15:42:45,005:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>)
2025-03-19 15:42:45,005:INFO:Checking exceptions
2025-03-19 15:42:45,005:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:42:45,014:INFO:Copying training dataset
2025-03-19 15:42:45,015:INFO:Checking base model
2025-03-19 15:42:45,015:INFO:Base model : Light Gradient Boosting Machine
2025-03-19 15:42:45,017:INFO:Declaring metric variables
2025-03-19 15:42:45,019:INFO:Defining Hyperparameters
2025-03-19 15:42:45,077:INFO:Tuning with n_jobs=-1
2025-03-19 15:42:45,078:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:42:45,078:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:42:45,078:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:42:45,078:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:42:45,078:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:42:45,078:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:43:23,229:INFO:best_params: {'actual_estimator__num_leaves': 39, 'actual_estimator__learning_rate': 0.06526894254543693, 'actual_estimator__n_estimators': 85, 'actual_estimator__min_split_gain': 0.046846169938751236, 'actual_estimator__reg_alpha': 2.2593868443131584e-10, 'actual_estimator__reg_lambda': 2.5495936232394463e-05, 'actual_estimator__feature_fraction': 0.7536180058484683, 'actual_estimator__bagging_fraction': 0.7892617014674217, 'actual_estimator__bagging_freq': 7, 'actual_estimator__min_child_samples': 3}
2025-03-19 15:43:23,238:INFO:Hyperparameter search completed
2025-03-19 15:43:23,238:INFO:SubProcess create_model() called ==================================
2025-03-19 15:43:23,239:INFO:Initializing create_model()
2025-03-19 15:43:23,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F862337F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 39, 'learning_rate': 0.06526894254543693, 'n_estimators': 85, 'min_split_gain': 0.046846169938751236, 'reg_alpha': 2.2593868443131584e-10, 'reg_lambda': 2.5495936232394463e-05, 'feature_fraction': 0.7536180058484683, 'bagging_fraction': 0.7892617014674217, 'bagging_freq': 7, 'min_child_samples': 3})
2025-03-19 15:43:23,239:INFO:Checking exceptions
2025-03-19 15:43:23,239:INFO:Importing libraries
2025-03-19 15:43:23,239:INFO:Copying training dataset
2025-03-19 15:43:23,242:INFO:Defining folds
2025-03-19 15:43:23,242:INFO:Declaring metric variables
2025-03-19 15:43:23,245:INFO:Importing untrained model
2025-03-19 15:43:23,245:INFO:Declaring custom model
2025-03-19 15:43:23,248:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:43:23,253:INFO:Starting cross validation
2025-03-19 15:43:23,254:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:43:23,676:INFO:Calculating mean and std
2025-03-19 15:43:23,678:INFO:Creating metrics dataframe
2025-03-19 15:43:23,681:INFO:Finalizing model
2025-03-19 15:43:23,717:INFO:[LightGBM] [Warning] feature_fraction is set=0.7536180058484683, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536180058484683
2025-03-19 15:43:23,717:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7892617014674217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7892617014674217
2025-03-19 15:43:23,718:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-03-19 15:43:23,719:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:43:23,720:INFO:[LightGBM] [Warning] feature_fraction is set=0.7536180058484683, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536180058484683
2025-03-19 15:43:23,720:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7892617014674217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7892617014674217
2025-03-19 15:43:23,720:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-03-19 15:43:23,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
2025-03-19 15:43:23,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:43:23,724:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:43:23,725:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:43:23,725:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:43:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:43:23,821:INFO:Uploading results into container
2025-03-19 15:43:23,821:INFO:Uploading model into container now
2025-03-19 15:43:23,822:INFO:_master_model_container: 23
2025-03-19 15:43:23,822:INFO:_display_container: 4
2025-03-19 15:43:23,823:INFO:LGBMRegressor(bagging_fraction=0.7892617014674217, bagging_freq=7,
              feature_fraction=0.7536180058484683,
              learning_rate=0.06526894254543693, min_child_samples=3,
              min_split_gain=0.046846169938751236, n_estimators=85, n_jobs=-1,
              num_leaves=39, random_state=456, reg_alpha=2.2593868443131584e-10,
              reg_lambda=2.5495936232394463e-05)
2025-03-19 15:43:23,823:INFO:create_model() successfully completed......................................
2025-03-19 15:43:23,891:INFO:SubProcess create_model() end ==================================
2025-03-19 15:43:23,891:INFO:choose_better activated
2025-03-19 15:43:23,893:INFO:SubProcess create_model() called ==================================
2025-03-19 15:43:23,894:INFO:Initializing create_model()
2025-03-19 15:43:23,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:43:23,894:INFO:Checking exceptions
2025-03-19 15:43:23,895:INFO:Importing libraries
2025-03-19 15:43:23,895:INFO:Copying training dataset
2025-03-19 15:43:23,898:INFO:Defining folds
2025-03-19 15:43:23,898:INFO:Declaring metric variables
2025-03-19 15:43:23,898:INFO:Importing untrained model
2025-03-19 15:43:23,898:INFO:Declaring custom model
2025-03-19 15:43:23,898:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:43:23,898:INFO:Starting cross validation
2025-03-19 15:43:23,899:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:43:24,384:INFO:Calculating mean and std
2025-03-19 15:43:24,385:INFO:Creating metrics dataframe
2025-03-19 15:43:24,386:INFO:Finalizing model
2025-03-19 15:43:24,421:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:43:24,422:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-03-19 15:43:24,422:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:43:24,422:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:43:24,422:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:43:24,422:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:43:24,541:INFO:Uploading results into container
2025-03-19 15:43:24,541:INFO:Uploading model into container now
2025-03-19 15:43:24,542:INFO:_master_model_container: 24
2025-03-19 15:43:24,542:INFO:_display_container: 5
2025-03-19 15:43:24,542:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:43:24,542:INFO:create_model() successfully completed......................................
2025-03-19 15:43:24,630:INFO:SubProcess create_model() end ==================================
2025-03-19 15:43:24,631:INFO:LGBMRegressor(n_jobs=-1, random_state=456) result for R2 is 0.8318
2025-03-19 15:43:24,631:INFO:LGBMRegressor(bagging_fraction=0.7892617014674217, bagging_freq=7,
              feature_fraction=0.7536180058484683,
              learning_rate=0.06526894254543693, min_child_samples=3,
              min_split_gain=0.046846169938751236, n_estimators=85, n_jobs=-1,
              num_leaves=39, random_state=456, reg_alpha=2.2593868443131584e-10,
              reg_lambda=2.5495936232394463e-05) result for R2 is 0.8648
2025-03-19 15:43:24,632:INFO:LGBMRegressor(bagging_fraction=0.7892617014674217, bagging_freq=7,
              feature_fraction=0.7536180058484683,
              learning_rate=0.06526894254543693, min_child_samples=3,
              min_split_gain=0.046846169938751236, n_estimators=85, n_jobs=-1,
              num_leaves=39, random_state=456, reg_alpha=2.2593868443131584e-10,
              reg_lambda=2.5495936232394463e-05) is best model
2025-03-19 15:43:24,632:INFO:choose_better completed
2025-03-19 15:43:24,632:INFO:Creating Dashboard logs
2025-03-19 15:43:24,635:INFO:Model: Light Gradient Boosting Machine
2025-03-19 15:43:24,656:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.06526894254543693, 'max_depth': -1, 'min_child_samples': 3, 'min_child_weight': 0.001, 'min_split_gain': 0.046846169938751236, 'n_estimators': 85, 'n_jobs': -1, 'num_leaves': 39, 'objective': None, 'random_state': 456, 'reg_alpha': 2.2593868443131584e-10, 'reg_lambda': 2.5495936232394463e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7536180058484683, 'bagging_fraction': 0.7892617014674217, 'bagging_freq': 7}
2025-03-19 15:43:24,829:INFO:Initializing predict_model()
2025-03-19 15:43:24,829:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=LGBMRegressor(bagging_fraction=0.7892617014674217, bagging_freq=7,
              feature_fraction=0.7536180058484683,
              learning_rate=0.06526894254543693, min_child_samples=3,
              min_split_gain=0.046846169938751236, n_estimators=85, n_jobs=-1,
              num_leaves=39, random_state=456, reg_alpha=2.2593868443131584e-10,
              reg_lambda=2.5495936232394463e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F865D1820>)
2025-03-19 15:43:24,829:INFO:Checking exceptions
2025-03-19 15:43:24,829:INFO:Preloading libraries
2025-03-19 15:43:24,970:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.7892617014674217, bagging_freq=7,
              feature_fraction=0.7536180058484683,
              learning_rate=0.06526894254543693, min_child_samples=3,
              min_split_gain=0.046846169938751236, n_estimators=85, n_jobs=-1,
              num_leaves=39, random_state=456, reg_alpha=2.2593868443131584e-10,
              reg_lambda=2.5495936232394463e-05) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:43:24,977:INFO:_master_model_container: 24
2025-03-19 15:43:24,977:INFO:_display_container: 4
2025-03-19 15:43:24,978:INFO:LGBMRegressor(bagging_fraction=0.7892617014674217, bagging_freq=7,
              feature_fraction=0.7536180058484683,
              learning_rate=0.06526894254543693, min_child_samples=3,
              min_split_gain=0.046846169938751236, n_estimators=85, n_jobs=-1,
              num_leaves=39, random_state=456, reg_alpha=2.2593868443131584e-10,
              reg_lambda=2.5495936232394463e-05)
2025-03-19 15:43:24,978:INFO:tune_model() successfully completed......................................
2025-03-19 15:43:25,048:INFO:Initializing tune_model()
2025-03-19 15:43:25,049:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>)
2025-03-19 15:43:25,049:INFO:Checking exceptions
2025-03-19 15:43:25,049:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:43:25,060:INFO:Copying training dataset
2025-03-19 15:43:25,063:INFO:Checking base model
2025-03-19 15:43:25,063:INFO:Base model : Extreme Gradient Boosting
2025-03-19 15:43:25,066:INFO:Declaring metric variables
2025-03-19 15:43:25,068:INFO:Defining Hyperparameters
2025-03-19 15:43:25,130:INFO:Tuning with n_jobs=-1
2025-03-19 15:43:25,130:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:43:25,130:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:43:25,131:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:43:25,131:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:43:25,131:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:43:25,131:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:44:21,147:INFO:best_params: {'actual_estimator__learning_rate': 0.03092979380839791, 'actual_estimator__n_estimators': 170, 'actual_estimator__subsample': 0.30987531170417904, 'actual_estimator__max_depth': 2, 'actual_estimator__colsample_bytree': 0.9964753214924489, 'actual_estimator__min_child_weight': 2, 'actual_estimator__reg_alpha': 1.4498639830951101e-07, 'actual_estimator__reg_lambda': 0.00043257240370452943, 'actual_estimator__scale_pos_weight': 22.733246746708247}
2025-03-19 15:44:21,154:INFO:Hyperparameter search completed
2025-03-19 15:44:21,154:INFO:SubProcess create_model() called ==================================
2025-03-19 15:44:21,155:INFO:Initializing create_model()
2025-03-19 15:44:21,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FFF387D60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.03092979380839791, 'n_estimators': 170, 'subsample': 0.30987531170417904, 'max_depth': 2, 'colsample_bytree': 0.9964753214924489, 'min_child_weight': 2, 'reg_alpha': 1.4498639830951101e-07, 'reg_lambda': 0.00043257240370452943, 'scale_pos_weight': 22.733246746708247})
2025-03-19 15:44:21,155:INFO:Checking exceptions
2025-03-19 15:44:21,155:INFO:Importing libraries
2025-03-19 15:44:21,155:INFO:Copying training dataset
2025-03-19 15:44:21,158:INFO:Defining folds
2025-03-19 15:44:21,158:INFO:Declaring metric variables
2025-03-19 15:44:21,162:INFO:Importing untrained model
2025-03-19 15:44:21,162:INFO:Declaring custom model
2025-03-19 15:44:21,166:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:44:21,171:INFO:Starting cross validation
2025-03-19 15:44:21,172:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:44:21,506:INFO:Calculating mean and std
2025-03-19 15:44:21,507:INFO:Creating metrics dataframe
2025-03-19 15:44:21,510:INFO:Finalizing model
2025-03-19 15:44:21,625:INFO:Uploading results into container
2025-03-19 15:44:21,625:INFO:Uploading model into container now
2025-03-19 15:44:21,626:INFO:_master_model_container: 25
2025-03-19 15:44:21,626:INFO:_display_container: 5
2025-03-19 15:44:21,627:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9964753214924489, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.03092979380839791, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=170, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:44:21,627:INFO:create_model() successfully completed......................................
2025-03-19 15:44:21,702:INFO:SubProcess create_model() end ==================================
2025-03-19 15:44:21,702:INFO:choose_better activated
2025-03-19 15:44:21,704:INFO:SubProcess create_model() called ==================================
2025-03-19 15:44:21,705:INFO:Initializing create_model()
2025-03-19 15:44:21,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:44:21,705:INFO:Checking exceptions
2025-03-19 15:44:21,706:INFO:Importing libraries
2025-03-19 15:44:21,706:INFO:Copying training dataset
2025-03-19 15:44:21,709:INFO:Defining folds
2025-03-19 15:44:21,709:INFO:Declaring metric variables
2025-03-19 15:44:21,709:INFO:Importing untrained model
2025-03-19 15:44:21,709:INFO:Declaring custom model
2025-03-19 15:44:21,710:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:44:21,710:INFO:Starting cross validation
2025-03-19 15:44:21,711:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:44:22,014:INFO:Calculating mean and std
2025-03-19 15:44:22,014:INFO:Creating metrics dataframe
2025-03-19 15:44:22,015:INFO:Finalizing model
2025-03-19 15:44:22,176:INFO:Uploading results into container
2025-03-19 15:44:22,176:INFO:Uploading model into container now
2025-03-19 15:44:22,176:INFO:_master_model_container: 26
2025-03-19 15:44:22,176:INFO:_display_container: 6
2025-03-19 15:44:22,177:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:44:22,177:INFO:create_model() successfully completed......................................
2025-03-19 15:44:22,274:INFO:SubProcess create_model() end ==================================
2025-03-19 15:44:22,275:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) result for R2 is 0.8356
2025-03-19 15:44:22,275:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9964753214924489, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.03092979380839791, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=170, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) result for R2 is 0.8832
2025-03-19 15:44:22,275:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9964753214924489, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.03092979380839791, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=170, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) is best model
2025-03-19 15:44:22,275:INFO:choose_better completed
2025-03-19 15:44:22,276:INFO:Creating Dashboard logs
2025-03-19 15:44:22,278:INFO:Model: Extreme Gradient Boosting
2025-03-19 15:44:22,292:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.9964753214924489, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.03092979380839791, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 2, 'max_leaves': None, 'min_child_weight': 2, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 170, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 456, 'reg_alpha': 1.4498639830951101e-07, 'reg_lambda': 0.00043257240370452943, 'sampling_method': None, 'scale_pos_weight': 22.733246746708247, 'subsample': 0.30987531170417904, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-19 15:44:22,478:INFO:Initializing predict_model()
2025-03-19 15:44:22,478:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9964753214924489, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.03092979380839791, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=170, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025F866E7940>)
2025-03-19 15:44:22,478:INFO:Checking exceptions
2025-03-19 15:44:22,478:INFO:Preloading libraries
2025-03-19 15:44:22,626:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9964753214924489, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.03092979380839791, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=170, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:44:22,633:INFO:_master_model_container: 26
2025-03-19 15:44:22,633:INFO:_display_container: 5
2025-03-19 15:44:22,634:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9964753214924489, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.03092979380839791, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=170, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:44:22,634:INFO:tune_model() successfully completed......................................
2025-03-19 15:44:22,705:INFO:Initializing tune_model()
2025-03-19 15:44:22,705:INFO:tune_model(estimator=AdaBoostRegressor(random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025F9A7D89D0>)
2025-03-19 15:44:22,705:INFO:Checking exceptions
2025-03-19 15:44:22,705:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:44:22,715:INFO:Copying training dataset
2025-03-19 15:44:22,718:INFO:Checking base model
2025-03-19 15:44:22,718:INFO:Base model : AdaBoost Regressor
2025-03-19 15:44:22,721:INFO:Declaring metric variables
2025-03-19 15:44:22,724:INFO:Defining Hyperparameters
2025-03-19 15:44:22,786:INFO:Tuning with n_jobs=-1
2025-03-19 15:44:22,786:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:44:22,786:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:44:22,786:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:44:22,786:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:44:22,786:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:44:22,786:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:45:44,868:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:45:44,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:45:44,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:45:44,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:45:44,946:INFO:PyCaret RegressionExperiment
2025-03-19 15:45:44,946:INFO:Logging name: msw_prediction
2025-03-19 15:45:44,946:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-19 15:45:44,946:INFO:version 3.2.0
2025-03-19 15:45:44,946:INFO:Initializing setup()
2025-03-19 15:45:44,946:INFO:self.USI: a6ad
2025-03-19 15:45:44,946:INFO:self._variable_keys: {'log_plots_param', 'html_param', 'y_train', '_available_plots', 'X_test', 'y_test', 'fold_generator', 'exp_id', '_ml_usecase', 'logging_param', 'data', 'X_train', 'memory', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'target_param', 'fold_groups_param', 'fold_shuffle_param', 'exp_name_log', 'idx', 'USI', 'y', 'transform_target_param', 'seed', 'X', 'gpu_param'}
2025-03-19 15:45:44,946:INFO:Checking environment
2025-03-19 15:45:44,946:INFO:python_version: 3.8.20
2025-03-19 15:45:44,946:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-19 15:45:44,946:INFO:machine: AMD64
2025-03-19 15:45:44,946:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-19 15:45:44,956:INFO:Memory: svmem(total=68447973376, available=42777378816, percent=37.5, used=25670594560, free=42777378816)
2025-03-19 15:45:44,956:INFO:Physical Core: 24
2025-03-19 15:45:44,956:INFO:Logical Core: 32
2025-03-19 15:45:44,956:INFO:Checking libraries
2025-03-19 15:45:44,956:INFO:System:
2025-03-19 15:45:44,956:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-19 15:45:44,956:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-19 15:45:44,956:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-19 15:45:44,956:INFO:PyCaret required dependencies:
2025-03-19 15:45:45,531:INFO:                 pip: 24.2
2025-03-19 15:45:45,531:INFO:          setuptools: 75.1.0
2025-03-19 15:45:45,531:INFO:             pycaret: 3.2.0
2025-03-19 15:45:45,531:INFO:             IPython: 8.12.3
2025-03-19 15:45:45,531:INFO:          ipywidgets: 8.1.5
2025-03-19 15:45:45,531:INFO:                tqdm: 4.67.1
2025-03-19 15:45:45,531:INFO:               numpy: 1.24.4
2025-03-19 15:45:45,531:INFO:              pandas: 1.5.3
2025-03-19 15:45:45,531:INFO:              jinja2: 3.1.4
2025-03-19 15:45:45,531:INFO:               scipy: 1.10.1
2025-03-19 15:45:45,531:INFO:              joblib: 1.3.2
2025-03-19 15:45:45,531:INFO:             sklearn: 1.2.2
2025-03-19 15:45:45,531:INFO:                pyod: 2.0.2
2025-03-19 15:45:45,531:INFO:            imblearn: 0.12.4
2025-03-19 15:45:45,531:INFO:   category_encoders: 2.6.4
2025-03-19 15:45:45,531:INFO:            lightgbm: 4.5.0
2025-03-19 15:45:45,531:INFO:               numba: 0.58.1
2025-03-19 15:45:45,531:INFO:            requests: 2.32.3
2025-03-19 15:45:45,531:INFO:          matplotlib: 3.6.0
2025-03-19 15:45:45,531:INFO:          scikitplot: 0.3.7
2025-03-19 15:45:45,531:INFO:         yellowbrick: 1.5
2025-03-19 15:45:45,531:INFO:              plotly: 5.24.1
2025-03-19 15:45:45,531:INFO:    plotly-resampler: Not installed
2025-03-19 15:45:45,531:INFO:             kaleido: 0.2.1
2025-03-19 15:45:45,531:INFO:           schemdraw: 0.15
2025-03-19 15:45:45,531:INFO:         statsmodels: 0.14.1
2025-03-19 15:45:45,531:INFO:              sktime: 0.21.1
2025-03-19 15:45:45,531:INFO:               tbats: 1.1.3
2025-03-19 15:45:45,531:INFO:            pmdarima: 2.0.4
2025-03-19 15:45:45,532:INFO:              psutil: 6.1.0
2025-03-19 15:45:45,532:INFO:          markupsafe: 2.1.5
2025-03-19 15:45:45,532:INFO:             pickle5: Not installed
2025-03-19 15:45:45,532:INFO:         cloudpickle: 2.2.1
2025-03-19 15:45:45,532:INFO:         deprecation: 2.1.0
2025-03-19 15:45:45,532:INFO:              xxhash: 3.5.0
2025-03-19 15:45:45,532:INFO:           wurlitzer: Not installed
2025-03-19 15:45:45,532:INFO:PyCaret optional dependencies:
2025-03-19 15:45:46,898:INFO:                shap: 0.44.1
2025-03-19 15:45:46,898:INFO:           interpret: 0.6.6
2025-03-19 15:45:46,898:INFO:                umap: 0.5.7
2025-03-19 15:45:46,898:INFO:     ydata_profiling: 4.6.0
2025-03-19 15:45:46,898:INFO:  explainerdashboard: 0.4.7
2025-03-19 15:45:46,898:INFO:             autoviz: Not installed
2025-03-19 15:45:46,898:INFO:           fairlearn: 0.7.0
2025-03-19 15:45:46,898:INFO:          deepchecks: Not installed
2025-03-19 15:45:46,898:INFO:             xgboost: 2.1.3
2025-03-19 15:45:46,898:INFO:            catboost: 1.2.7
2025-03-19 15:45:46,898:INFO:              kmodes: 0.12.2
2025-03-19 15:45:46,898:INFO:             mlxtend: 0.23.1
2025-03-19 15:45:46,898:INFO:       statsforecast: 1.5.0
2025-03-19 15:45:46,898:INFO:        tune_sklearn: 0.5.0
2025-03-19 15:45:46,898:INFO:                 ray: 2.10.0
2025-03-19 15:45:46,898:INFO:            hyperopt: 0.2.7
2025-03-19 15:45:46,898:INFO:              optuna: 4.1.0
2025-03-19 15:45:46,898:INFO:               skopt: 0.10.2
2025-03-19 15:45:46,898:INFO:              mlflow: 1.30.1
2025-03-19 15:45:46,898:INFO:              gradio: 3.50.2
2025-03-19 15:45:46,898:INFO:             fastapi: 0.115.5
2025-03-19 15:45:46,898:INFO:             uvicorn: 0.32.1
2025-03-19 15:45:46,898:INFO:              m2cgen: 0.10.0
2025-03-19 15:45:46,898:INFO:           evidently: 0.2.8
2025-03-19 15:45:46,898:INFO:               fugue: 0.8.6
2025-03-19 15:45:46,898:INFO:           streamlit: Not installed
2025-03-19 15:45:46,898:INFO:             prophet: Not installed
2025-03-19 15:45:46,898:INFO:None
2025-03-19 15:45:46,898:INFO:Set up data.
2025-03-19 15:45:46,903:INFO:Set up folding strategy.
2025-03-19 15:45:46,903:INFO:Set up train/test split.
2025-03-19 15:45:46,903:INFO:Set up data.
2025-03-19 15:45:46,907:INFO:Set up index.
2025-03-19 15:45:46,907:INFO:Assigning column types.
2025-03-19 15:45:46,908:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-19 15:45:46,908:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,910:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,912:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,937:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,957:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:46,957:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:46,967:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,969:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:45:46,996:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,016:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,017:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,017:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-19 15:45:47,019:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,021:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,064:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,065:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,068:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,070:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,114:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,115:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,115:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-19 15:45:47,119:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,144:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,163:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,164:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,168:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,213:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,214:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,214:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-19 15:45:47,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,261:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,261:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,262:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,310:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,312:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,312:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-19 15:45:47,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,359:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,360:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,389:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:45:47,407:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,408:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,409:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-19 15:45:47,456:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,458:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,505:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,506:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,507:INFO:Preparing preprocessing pipeline...
2025-03-19 15:45:47,507:INFO:Set up simple imputation.
2025-03-19 15:45:47,508:INFO:Set up encoding of categorical features.
2025-03-19 15:45:47,509:INFO:Set up feature normalization.
2025-03-19 15:45:47,509:INFO:Set up column name cleaning.
2025-03-19 15:45:47,549:INFO:Finished creating preprocessing pipeline.
2025-03-19 15:45:47,553:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 15:45:47,553:INFO:Creating final display dataframe.
2025-03-19 15:45:47,663:INFO:Setup _display_container:                     Description            Value
0                    Session id              456
1                        Target          MSW_log
2                   Target type       Regression
3           Original data shape       (1710, 19)
4        Transformed data shape       (1710, 28)
5   Transformed train set shape       (1483, 28)
6    Transformed test set shape        (227, 28)
7              Numeric features               16
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15                    Normalize             True
16             Normalize method           minmax
17               Fold Generator  TimeSeriesSplit
18                  Fold Number                5
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name   msw_prediction
23                          USI             a6ad
2025-03-19 15:45:47,717:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,719:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,768:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:45:47,769:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:45:47,770:INFO:Logging experiment in loggers
2025-03-19 15:45:47,905:INFO:SubProcess save_model() called ==================================
2025-03-19 15:45:47,913:INFO:Initializing save_model()
2025-03-19 15:45:47,913:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmp6nahcrzb\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-19 15:45:47,913:INFO:Adding model into prep_pipe
2025-03-19 15:45:47,913:WARNING:Only Model saved as it was a pipeline.
2025-03-19 15:45:47,916:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmp6nahcrzb\Transformation Pipeline.pkl saved in current working directory
2025-03-19 15:45:47,920:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 15:45:47,920:INFO:save_model() successfully completed......................................
2025-03-19 15:45:47,978:INFO:SubProcess save_model() end ==================================
2025-03-19 15:45:47,983:INFO:setup() successfully completed in 2.83s...............
2025-03-19 15:45:47,983:INFO:Initializing compare_models()
2025-03-19 15:45:47,983:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, include=None, fold=None, round=4, cross_validation=True, sort=mape, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'mape', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-19 15:45:47,984:INFO:Checking exceptions
2025-03-19 15:45:47,984:INFO:Preparing display monitor
2025-03-19 15:45:47,996:INFO:Initializing Linear Regression
2025-03-19 15:45:47,996:INFO:Total runtime is 0.0 minutes
2025-03-19 15:45:47,997:INFO:SubProcess create_model() called ==================================
2025-03-19 15:45:47,998:INFO:Initializing create_model()
2025-03-19 15:45:47,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:45:47,998:INFO:Checking exceptions
2025-03-19 15:45:47,998:INFO:Importing libraries
2025-03-19 15:45:47,998:INFO:Copying training dataset
2025-03-19 15:45:48,000:INFO:Defining folds
2025-03-19 15:45:48,000:INFO:Declaring metric variables
2025-03-19 15:45:48,001:INFO:Importing untrained model
2025-03-19 15:45:48,003:INFO:Linear Regression Imported successfully
2025-03-19 15:45:48,006:INFO:Starting cross validation
2025-03-19 15:45:48,009:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:45:50,507:INFO:Calculating mean and std
2025-03-19 15:45:50,507:INFO:Creating metrics dataframe
2025-03-19 15:45:50,509:INFO:Uploading results into container
2025-03-19 15:45:50,510:INFO:Uploading model into container now
2025-03-19 15:45:50,510:INFO:_master_model_container: 1
2025-03-19 15:45:50,510:INFO:_display_container: 2
2025-03-19 15:45:50,511:INFO:LinearRegression(n_jobs=-1)
2025-03-19 15:45:50,511:INFO:create_model() successfully completed......................................
2025-03-19 15:45:50,571:INFO:SubProcess create_model() end ==================================
2025-03-19 15:45:50,571:INFO:Creating metrics dataframe
2025-03-19 15:45:50,575:INFO:Initializing Lasso Regression
2025-03-19 15:45:50,575:INFO:Total runtime is 0.0429947296778361 minutes
2025-03-19 15:45:50,577:INFO:SubProcess create_model() called ==================================
2025-03-19 15:45:50,577:INFO:Initializing create_model()
2025-03-19 15:45:50,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:45:50,577:INFO:Checking exceptions
2025-03-19 15:45:50,577:INFO:Importing libraries
2025-03-19 15:45:50,577:INFO:Copying training dataset
2025-03-19 15:45:50,579:INFO:Defining folds
2025-03-19 15:45:50,579:INFO:Declaring metric variables
2025-03-19 15:45:50,581:INFO:Importing untrained model
2025-03-19 15:45:50,583:INFO:Lasso Regression Imported successfully
2025-03-19 15:45:50,586:INFO:Starting cross validation
2025-03-19 15:45:50,587:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:45:52,600:INFO:Calculating mean and std
2025-03-19 15:45:52,601:INFO:Creating metrics dataframe
2025-03-19 15:45:52,603:INFO:Uploading results into container
2025-03-19 15:45:52,603:INFO:Uploading model into container now
2025-03-19 15:45:52,604:INFO:_master_model_container: 2
2025-03-19 15:45:52,604:INFO:_display_container: 2
2025-03-19 15:45:52,604:INFO:Lasso(random_state=456)
2025-03-19 15:45:52,604:INFO:create_model() successfully completed......................................
2025-03-19 15:45:52,665:INFO:SubProcess create_model() end ==================================
2025-03-19 15:45:52,665:INFO:Creating metrics dataframe
2025-03-19 15:45:52,670:INFO:Initializing Ridge Regression
2025-03-19 15:45:52,670:INFO:Total runtime is 0.07790207862854004 minutes
2025-03-19 15:45:52,671:INFO:SubProcess create_model() called ==================================
2025-03-19 15:45:52,672:INFO:Initializing create_model()
2025-03-19 15:45:52,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:45:52,672:INFO:Checking exceptions
2025-03-19 15:45:52,672:INFO:Importing libraries
2025-03-19 15:45:52,672:INFO:Copying training dataset
2025-03-19 15:45:52,673:INFO:Defining folds
2025-03-19 15:45:52,673:INFO:Declaring metric variables
2025-03-19 15:45:52,675:INFO:Importing untrained model
2025-03-19 15:45:52,676:INFO:Ridge Regression Imported successfully
2025-03-19 15:45:52,679:INFO:Starting cross validation
2025-03-19 15:45:52,680:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:45:54,663:INFO:Calculating mean and std
2025-03-19 15:45:54,664:INFO:Creating metrics dataframe
2025-03-19 15:45:54,666:INFO:Uploading results into container
2025-03-19 15:45:54,667:INFO:Uploading model into container now
2025-03-19 15:45:54,667:INFO:_master_model_container: 3
2025-03-19 15:45:54,667:INFO:_display_container: 2
2025-03-19 15:45:54,667:INFO:Ridge(random_state=456)
2025-03-19 15:45:54,667:INFO:create_model() successfully completed......................................
2025-03-19 15:45:54,726:INFO:SubProcess create_model() end ==================================
2025-03-19 15:45:54,726:INFO:Creating metrics dataframe
2025-03-19 15:45:54,731:INFO:Initializing Elastic Net
2025-03-19 15:45:54,731:INFO:Total runtime is 0.11225481430689493 minutes
2025-03-19 15:45:54,732:INFO:SubProcess create_model() called ==================================
2025-03-19 15:45:54,733:INFO:Initializing create_model()
2025-03-19 15:45:54,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:45:54,733:INFO:Checking exceptions
2025-03-19 15:45:54,733:INFO:Importing libraries
2025-03-19 15:45:54,733:INFO:Copying training dataset
2025-03-19 15:45:54,734:INFO:Defining folds
2025-03-19 15:45:54,735:INFO:Declaring metric variables
2025-03-19 15:45:54,736:INFO:Importing untrained model
2025-03-19 15:45:54,738:INFO:Elastic Net Imported successfully
2025-03-19 15:45:54,741:INFO:Starting cross validation
2025-03-19 15:45:54,742:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:45:56,757:INFO:Calculating mean and std
2025-03-19 15:45:56,758:INFO:Creating metrics dataframe
2025-03-19 15:45:56,760:INFO:Uploading results into container
2025-03-19 15:45:56,760:INFO:Uploading model into container now
2025-03-19 15:45:56,760:INFO:_master_model_container: 4
2025-03-19 15:45:56,760:INFO:_display_container: 2
2025-03-19 15:45:56,761:INFO:ElasticNet(random_state=456)
2025-03-19 15:45:56,761:INFO:create_model() successfully completed......................................
2025-03-19 15:45:56,822:INFO:SubProcess create_model() end ==================================
2025-03-19 15:45:56,822:INFO:Creating metrics dataframe
2025-03-19 15:45:56,827:INFO:Initializing Least Angle Regression
2025-03-19 15:45:56,827:INFO:Total runtime is 0.14719527959823608 minutes
2025-03-19 15:45:56,829:INFO:SubProcess create_model() called ==================================
2025-03-19 15:45:56,829:INFO:Initializing create_model()
2025-03-19 15:45:56,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:45:56,829:INFO:Checking exceptions
2025-03-19 15:45:56,829:INFO:Importing libraries
2025-03-19 15:45:56,829:INFO:Copying training dataset
2025-03-19 15:45:56,831:INFO:Defining folds
2025-03-19 15:45:56,831:INFO:Declaring metric variables
2025-03-19 15:45:56,833:INFO:Importing untrained model
2025-03-19 15:45:56,834:INFO:Least Angle Regression Imported successfully
2025-03-19 15:45:56,838:INFO:Starting cross validation
2025-03-19 15:45:56,838:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:45:58,807:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.720e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-19 15:45:58,814:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.391e-02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-19 15:45:58,836:INFO:Calculating mean and std
2025-03-19 15:45:58,837:INFO:Creating metrics dataframe
2025-03-19 15:45:58,839:INFO:Uploading results into container
2025-03-19 15:45:58,840:INFO:Uploading model into container now
2025-03-19 15:45:58,840:INFO:_master_model_container: 5
2025-03-19 15:45:58,840:INFO:_display_container: 2
2025-03-19 15:45:58,840:INFO:Lars(random_state=456)
2025-03-19 15:45:58,840:INFO:create_model() successfully completed......................................
2025-03-19 15:45:58,899:INFO:SubProcess create_model() end ==================================
2025-03-19 15:45:58,900:INFO:Creating metrics dataframe
2025-03-19 15:45:58,905:INFO:Initializing Lasso Least Angle Regression
2025-03-19 15:45:58,905:INFO:Total runtime is 0.18182117541631063 minutes
2025-03-19 15:45:58,906:INFO:SubProcess create_model() called ==================================
2025-03-19 15:45:58,907:INFO:Initializing create_model()
2025-03-19 15:45:58,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:45:58,907:INFO:Checking exceptions
2025-03-19 15:45:58,907:INFO:Importing libraries
2025-03-19 15:45:58,907:INFO:Copying training dataset
2025-03-19 15:45:58,908:INFO:Defining folds
2025-03-19 15:45:58,908:INFO:Declaring metric variables
2025-03-19 15:45:58,910:INFO:Importing untrained model
2025-03-19 15:45:58,911:INFO:Lasso Least Angle Regression Imported successfully
2025-03-19 15:45:58,915:INFO:Starting cross validation
2025-03-19 15:45:58,915:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:00,961:INFO:Calculating mean and std
2025-03-19 15:46:00,961:INFO:Creating metrics dataframe
2025-03-19 15:46:00,963:INFO:Uploading results into container
2025-03-19 15:46:00,963:INFO:Uploading model into container now
2025-03-19 15:46:00,964:INFO:_master_model_container: 6
2025-03-19 15:46:00,964:INFO:_display_container: 2
2025-03-19 15:46:00,964:INFO:LassoLars(random_state=456)
2025-03-19 15:46:00,964:INFO:create_model() successfully completed......................................
2025-03-19 15:46:01,027:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:01,027:INFO:Creating metrics dataframe
2025-03-19 15:46:01,032:INFO:Initializing Orthogonal Matching Pursuit
2025-03-19 15:46:01,032:INFO:Total runtime is 0.21726657549540201 minutes
2025-03-19 15:46:01,034:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:01,034:INFO:Initializing create_model()
2025-03-19 15:46:01,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:01,034:INFO:Checking exceptions
2025-03-19 15:46:01,034:INFO:Importing libraries
2025-03-19 15:46:01,034:INFO:Copying training dataset
2025-03-19 15:46:01,035:INFO:Defining folds
2025-03-19 15:46:01,035:INFO:Declaring metric variables
2025-03-19 15:46:01,037:INFO:Importing untrained model
2025-03-19 15:46:01,038:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-19 15:46:01,041:INFO:Starting cross validation
2025-03-19 15:46:01,042:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:02,731:INFO:Calculating mean and std
2025-03-19 15:46:02,732:INFO:Creating metrics dataframe
2025-03-19 15:46:02,734:INFO:Uploading results into container
2025-03-19 15:46:02,734:INFO:Uploading model into container now
2025-03-19 15:46:02,734:INFO:_master_model_container: 7
2025-03-19 15:46:02,734:INFO:_display_container: 2
2025-03-19 15:46:02,735:INFO:OrthogonalMatchingPursuit()
2025-03-19 15:46:02,735:INFO:create_model() successfully completed......................................
2025-03-19 15:46:02,792:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:02,792:INFO:Creating metrics dataframe
2025-03-19 15:46:02,798:INFO:Initializing Bayesian Ridge
2025-03-19 15:46:02,798:INFO:Total runtime is 0.2467023213704427 minutes
2025-03-19 15:46:02,799:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:02,800:INFO:Initializing create_model()
2025-03-19 15:46:02,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:02,800:INFO:Checking exceptions
2025-03-19 15:46:02,800:INFO:Importing libraries
2025-03-19 15:46:02,800:INFO:Copying training dataset
2025-03-19 15:46:02,801:INFO:Defining folds
2025-03-19 15:46:02,801:INFO:Declaring metric variables
2025-03-19 15:46:02,803:INFO:Importing untrained model
2025-03-19 15:46:02,805:INFO:Bayesian Ridge Imported successfully
2025-03-19 15:46:02,808:INFO:Starting cross validation
2025-03-19 15:46:02,808:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:02,870:INFO:Calculating mean and std
2025-03-19 15:46:02,871:INFO:Creating metrics dataframe
2025-03-19 15:46:02,872:INFO:Uploading results into container
2025-03-19 15:46:02,873:INFO:Uploading model into container now
2025-03-19 15:46:02,873:INFO:_master_model_container: 8
2025-03-19 15:46:02,873:INFO:_display_container: 2
2025-03-19 15:46:02,873:INFO:BayesianRidge()
2025-03-19 15:46:02,873:INFO:create_model() successfully completed......................................
2025-03-19 15:46:02,929:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:02,930:INFO:Creating metrics dataframe
2025-03-19 15:46:02,935:INFO:Initializing Passive Aggressive Regressor
2025-03-19 15:46:02,935:INFO:Total runtime is 0.24899526834487914 minutes
2025-03-19 15:46:02,937:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:02,937:INFO:Initializing create_model()
2025-03-19 15:46:02,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:02,937:INFO:Checking exceptions
2025-03-19 15:46:02,937:INFO:Importing libraries
2025-03-19 15:46:02,937:INFO:Copying training dataset
2025-03-19 15:46:02,939:INFO:Defining folds
2025-03-19 15:46:02,939:INFO:Declaring metric variables
2025-03-19 15:46:02,940:INFO:Importing untrained model
2025-03-19 15:46:02,942:INFO:Passive Aggressive Regressor Imported successfully
2025-03-19 15:46:02,945:INFO:Starting cross validation
2025-03-19 15:46:02,946:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:03,008:INFO:Calculating mean and std
2025-03-19 15:46:03,009:INFO:Creating metrics dataframe
2025-03-19 15:46:03,011:INFO:Uploading results into container
2025-03-19 15:46:03,011:INFO:Uploading model into container now
2025-03-19 15:46:03,011:INFO:_master_model_container: 9
2025-03-19 15:46:03,011:INFO:_display_container: 2
2025-03-19 15:46:03,011:INFO:PassiveAggressiveRegressor(random_state=456)
2025-03-19 15:46:03,012:INFO:create_model() successfully completed......................................
2025-03-19 15:46:03,066:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:03,066:INFO:Creating metrics dataframe
2025-03-19 15:46:03,072:INFO:Initializing Huber Regressor
2025-03-19 15:46:03,072:INFO:Total runtime is 0.251271649201711 minutes
2025-03-19 15:46:03,073:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:03,073:INFO:Initializing create_model()
2025-03-19 15:46:03,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:03,074:INFO:Checking exceptions
2025-03-19 15:46:03,074:INFO:Importing libraries
2025-03-19 15:46:03,074:INFO:Copying training dataset
2025-03-19 15:46:03,075:INFO:Defining folds
2025-03-19 15:46:03,075:INFO:Declaring metric variables
2025-03-19 15:46:03,077:INFO:Importing untrained model
2025-03-19 15:46:03,078:INFO:Huber Regressor Imported successfully
2025-03-19 15:46:03,081:INFO:Starting cross validation
2025-03-19 15:46:03,082:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:03,120:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:46:03,128:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:46:03,130:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:46:03,131:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:46:03,134:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:46:03,162:INFO:Calculating mean and std
2025-03-19 15:46:03,163:INFO:Creating metrics dataframe
2025-03-19 15:46:03,165:INFO:Uploading results into container
2025-03-19 15:46:03,165:INFO:Uploading model into container now
2025-03-19 15:46:03,165:INFO:_master_model_container: 10
2025-03-19 15:46:03,166:INFO:_display_container: 2
2025-03-19 15:46:03,166:INFO:HuberRegressor()
2025-03-19 15:46:03,166:INFO:create_model() successfully completed......................................
2025-03-19 15:46:03,219:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:03,219:INFO:Creating metrics dataframe
2025-03-19 15:46:03,224:INFO:Initializing K Neighbors Regressor
2025-03-19 15:46:03,224:INFO:Total runtime is 0.25381291707356773 minutes
2025-03-19 15:46:03,226:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:03,226:INFO:Initializing create_model()
2025-03-19 15:46:03,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:03,227:INFO:Checking exceptions
2025-03-19 15:46:03,227:INFO:Importing libraries
2025-03-19 15:46:03,227:INFO:Copying training dataset
2025-03-19 15:46:03,229:INFO:Defining folds
2025-03-19 15:46:03,229:INFO:Declaring metric variables
2025-03-19 15:46:03,230:INFO:Importing untrained model
2025-03-19 15:46:03,232:INFO:K Neighbors Regressor Imported successfully
2025-03-19 15:46:03,235:INFO:Starting cross validation
2025-03-19 15:46:03,235:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:03,332:INFO:Calculating mean and std
2025-03-19 15:46:03,332:INFO:Creating metrics dataframe
2025-03-19 15:46:03,335:INFO:Uploading results into container
2025-03-19 15:46:03,335:INFO:Uploading model into container now
2025-03-19 15:46:03,335:INFO:_master_model_container: 11
2025-03-19 15:46:03,335:INFO:_display_container: 2
2025-03-19 15:46:03,335:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-19 15:46:03,335:INFO:create_model() successfully completed......................................
2025-03-19 15:46:03,394:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:03,394:INFO:Creating metrics dataframe
2025-03-19 15:46:03,400:INFO:Initializing Decision Tree Regressor
2025-03-19 15:46:03,400:INFO:Total runtime is 0.2567349751790365 minutes
2025-03-19 15:46:03,402:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:03,402:INFO:Initializing create_model()
2025-03-19 15:46:03,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:03,402:INFO:Checking exceptions
2025-03-19 15:46:03,402:INFO:Importing libraries
2025-03-19 15:46:03,402:INFO:Copying training dataset
2025-03-19 15:46:03,404:INFO:Defining folds
2025-03-19 15:46:03,404:INFO:Declaring metric variables
2025-03-19 15:46:03,406:INFO:Importing untrained model
2025-03-19 15:46:03,407:INFO:Decision Tree Regressor Imported successfully
2025-03-19 15:46:03,411:INFO:Starting cross validation
2025-03-19 15:46:03,412:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:03,486:INFO:Calculating mean and std
2025-03-19 15:46:03,487:INFO:Creating metrics dataframe
2025-03-19 15:46:03,488:INFO:Uploading results into container
2025-03-19 15:46:03,489:INFO:Uploading model into container now
2025-03-19 15:46:03,489:INFO:_master_model_container: 12
2025-03-19 15:46:03,489:INFO:_display_container: 2
2025-03-19 15:46:03,489:INFO:DecisionTreeRegressor(random_state=456)
2025-03-19 15:46:03,489:INFO:create_model() successfully completed......................................
2025-03-19 15:46:03,545:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:03,545:INFO:Creating metrics dataframe
2025-03-19 15:46:03,551:INFO:Initializing Random Forest Regressor
2025-03-19 15:46:03,551:INFO:Total runtime is 0.2592514157295227 minutes
2025-03-19 15:46:03,553:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:03,553:INFO:Initializing create_model()
2025-03-19 15:46:03,553:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:03,553:INFO:Checking exceptions
2025-03-19 15:46:03,553:INFO:Importing libraries
2025-03-19 15:46:03,553:INFO:Copying training dataset
2025-03-19 15:46:03,555:INFO:Defining folds
2025-03-19 15:46:03,555:INFO:Declaring metric variables
2025-03-19 15:46:03,556:INFO:Importing untrained model
2025-03-19 15:46:03,558:INFO:Random Forest Regressor Imported successfully
2025-03-19 15:46:03,561:INFO:Starting cross validation
2025-03-19 15:46:03,561:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:03,778:INFO:Calculating mean and std
2025-03-19 15:46:03,779:INFO:Creating metrics dataframe
2025-03-19 15:46:03,781:INFO:Uploading results into container
2025-03-19 15:46:03,781:INFO:Uploading model into container now
2025-03-19 15:46:03,781:INFO:_master_model_container: 13
2025-03-19 15:46:03,781:INFO:_display_container: 2
2025-03-19 15:46:03,781:INFO:RandomForestRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:46:03,781:INFO:create_model() successfully completed......................................
2025-03-19 15:46:03,836:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:03,836:INFO:Creating metrics dataframe
2025-03-19 15:46:03,842:INFO:Initializing Extra Trees Regressor
2025-03-19 15:46:03,842:INFO:Total runtime is 0.26411046584447223 minutes
2025-03-19 15:46:03,844:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:03,844:INFO:Initializing create_model()
2025-03-19 15:46:03,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:03,844:INFO:Checking exceptions
2025-03-19 15:46:03,844:INFO:Importing libraries
2025-03-19 15:46:03,844:INFO:Copying training dataset
2025-03-19 15:46:03,846:INFO:Defining folds
2025-03-19 15:46:03,846:INFO:Declaring metric variables
2025-03-19 15:46:03,848:INFO:Importing untrained model
2025-03-19 15:46:03,850:INFO:Extra Trees Regressor Imported successfully
2025-03-19 15:46:03,853:INFO:Starting cross validation
2025-03-19 15:46:03,854:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:04,024:INFO:Calculating mean and std
2025-03-19 15:46:04,025:INFO:Creating metrics dataframe
2025-03-19 15:46:04,027:INFO:Uploading results into container
2025-03-19 15:46:04,027:INFO:Uploading model into container now
2025-03-19 15:46:04,028:INFO:_master_model_container: 14
2025-03-19 15:46:04,028:INFO:_display_container: 2
2025-03-19 15:46:04,028:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:46:04,028:INFO:create_model() successfully completed......................................
2025-03-19 15:46:04,082:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:04,082:INFO:Creating metrics dataframe
2025-03-19 15:46:04,088:INFO:Initializing AdaBoost Regressor
2025-03-19 15:46:04,088:INFO:Total runtime is 0.26820795933405556 minutes
2025-03-19 15:46:04,090:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:04,090:INFO:Initializing create_model()
2025-03-19 15:46:04,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:04,090:INFO:Checking exceptions
2025-03-19 15:46:04,090:INFO:Importing libraries
2025-03-19 15:46:04,090:INFO:Copying training dataset
2025-03-19 15:46:04,092:INFO:Defining folds
2025-03-19 15:46:04,092:INFO:Declaring metric variables
2025-03-19 15:46:04,094:INFO:Importing untrained model
2025-03-19 15:46:04,095:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:46:04,099:INFO:Starting cross validation
2025-03-19 15:46:04,099:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:04,240:INFO:Calculating mean and std
2025-03-19 15:46:04,241:INFO:Creating metrics dataframe
2025-03-19 15:46:04,243:INFO:Uploading results into container
2025-03-19 15:46:04,243:INFO:Uploading model into container now
2025-03-19 15:46:04,243:INFO:_master_model_container: 15
2025-03-19 15:46:04,243:INFO:_display_container: 2
2025-03-19 15:46:04,243:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:46:04,243:INFO:create_model() successfully completed......................................
2025-03-19 15:46:04,301:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:04,301:INFO:Creating metrics dataframe
2025-03-19 15:46:04,307:INFO:Initializing Gradient Boosting Regressor
2025-03-19 15:46:04,307:INFO:Total runtime is 0.2718584577242533 minutes
2025-03-19 15:46:04,309:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:04,309:INFO:Initializing create_model()
2025-03-19 15:46:04,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:04,309:INFO:Checking exceptions
2025-03-19 15:46:04,309:INFO:Importing libraries
2025-03-19 15:46:04,309:INFO:Copying training dataset
2025-03-19 15:46:04,311:INFO:Defining folds
2025-03-19 15:46:04,311:INFO:Declaring metric variables
2025-03-19 15:46:04,312:INFO:Importing untrained model
2025-03-19 15:46:04,314:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:46:04,318:INFO:Starting cross validation
2025-03-19 15:46:04,318:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:04,548:INFO:Calculating mean and std
2025-03-19 15:46:04,549:INFO:Creating metrics dataframe
2025-03-19 15:46:04,550:INFO:Uploading results into container
2025-03-19 15:46:04,551:INFO:Uploading model into container now
2025-03-19 15:46:04,551:INFO:_master_model_container: 16
2025-03-19 15:46:04,551:INFO:_display_container: 2
2025-03-19 15:46:04,551:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:46:04,551:INFO:create_model() successfully completed......................................
2025-03-19 15:46:04,604:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:04,604:INFO:Creating metrics dataframe
2025-03-19 15:46:04,610:INFO:Initializing Extreme Gradient Boosting
2025-03-19 15:46:04,610:INFO:Total runtime is 0.27691616614659625 minutes
2025-03-19 15:46:04,612:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:04,612:INFO:Initializing create_model()
2025-03-19 15:46:04,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:04,612:INFO:Checking exceptions
2025-03-19 15:46:04,612:INFO:Importing libraries
2025-03-19 15:46:04,612:INFO:Copying training dataset
2025-03-19 15:46:04,614:INFO:Defining folds
2025-03-19 15:46:04,614:INFO:Declaring metric variables
2025-03-19 15:46:04,615:INFO:Importing untrained model
2025-03-19 15:46:04,617:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:46:04,620:INFO:Starting cross validation
2025-03-19 15:46:04,621:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:04,964:INFO:Calculating mean and std
2025-03-19 15:46:04,965:INFO:Creating metrics dataframe
2025-03-19 15:46:04,967:INFO:Uploading results into container
2025-03-19 15:46:04,967:INFO:Uploading model into container now
2025-03-19 15:46:04,967:INFO:_master_model_container: 17
2025-03-19 15:46:04,967:INFO:_display_container: 2
2025-03-19 15:46:04,968:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:46:04,968:INFO:create_model() successfully completed......................................
2025-03-19 15:46:05,024:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:05,024:INFO:Creating metrics dataframe
2025-03-19 15:46:05,031:INFO:Initializing Light Gradient Boosting Machine
2025-03-19 15:46:05,031:INFO:Total runtime is 0.2839191635449727 minutes
2025-03-19 15:46:05,033:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:05,033:INFO:Initializing create_model()
2025-03-19 15:46:05,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:05,033:INFO:Checking exceptions
2025-03-19 15:46:05,033:INFO:Importing libraries
2025-03-19 15:46:05,033:INFO:Copying training dataset
2025-03-19 15:46:05,036:INFO:Defining folds
2025-03-19 15:46:05,036:INFO:Declaring metric variables
2025-03-19 15:46:05,038:INFO:Importing untrained model
2025-03-19 15:46:05,040:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:46:05,043:INFO:Starting cross validation
2025-03-19 15:46:05,045:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:05,533:INFO:Calculating mean and std
2025-03-19 15:46:05,534:INFO:Creating metrics dataframe
2025-03-19 15:46:05,537:INFO:Uploading results into container
2025-03-19 15:46:05,537:INFO:Uploading model into container now
2025-03-19 15:46:05,537:INFO:_master_model_container: 18
2025-03-19 15:46:05,537:INFO:_display_container: 2
2025-03-19 15:46:05,538:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:46:05,538:INFO:create_model() successfully completed......................................
2025-03-19 15:46:05,601:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:05,601:INFO:Creating metrics dataframe
2025-03-19 15:46:05,610:INFO:Initializing CatBoost Regressor
2025-03-19 15:46:05,610:INFO:Total runtime is 0.2935793240865071 minutes
2025-03-19 15:46:05,612:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:05,613:INFO:Initializing create_model()
2025-03-19 15:46:05,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:05,613:INFO:Checking exceptions
2025-03-19 15:46:05,613:INFO:Importing libraries
2025-03-19 15:46:05,613:INFO:Copying training dataset
2025-03-19 15:46:05,615:INFO:Defining folds
2025-03-19 15:46:05,615:INFO:Declaring metric variables
2025-03-19 15:46:05,617:INFO:Importing untrained model
2025-03-19 15:46:05,619:INFO:CatBoost Regressor Imported successfully
2025-03-19 15:46:05,623:INFO:Starting cross validation
2025-03-19 15:46:05,624:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:07,258:INFO:Calculating mean and std
2025-03-19 15:46:07,259:INFO:Creating metrics dataframe
2025-03-19 15:46:07,260:INFO:Uploading results into container
2025-03-19 15:46:07,261:INFO:Uploading model into container now
2025-03-19 15:46:07,261:INFO:_master_model_container: 19
2025-03-19 15:46:07,261:INFO:_display_container: 2
2025-03-19 15:46:07,261:INFO:<catboost.core.CatBoostRegressor object at 0x000001B976248040>
2025-03-19 15:46:07,261:INFO:create_model() successfully completed......................................
2025-03-19 15:46:07,318:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:07,318:INFO:Creating metrics dataframe
2025-03-19 15:46:07,325:INFO:Initializing Dummy Regressor
2025-03-19 15:46:07,325:INFO:Total runtime is 0.3221605499585469 minutes
2025-03-19 15:46:07,328:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:07,328:INFO:Initializing create_model()
2025-03-19 15:46:07,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E53700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:07,328:INFO:Checking exceptions
2025-03-19 15:46:07,328:INFO:Importing libraries
2025-03-19 15:46:07,328:INFO:Copying training dataset
2025-03-19 15:46:07,330:INFO:Defining folds
2025-03-19 15:46:07,330:INFO:Declaring metric variables
2025-03-19 15:46:07,332:INFO:Importing untrained model
2025-03-19 15:46:07,333:INFO:Dummy Regressor Imported successfully
2025-03-19 15:46:07,337:INFO:Starting cross validation
2025-03-19 15:46:07,338:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:07,396:INFO:Calculating mean and std
2025-03-19 15:46:07,397:INFO:Creating metrics dataframe
2025-03-19 15:46:07,399:INFO:Uploading results into container
2025-03-19 15:46:07,399:INFO:Uploading model into container now
2025-03-19 15:46:07,400:INFO:_master_model_container: 20
2025-03-19 15:46:07,400:INFO:_display_container: 2
2025-03-19 15:46:07,400:INFO:DummyRegressor()
2025-03-19 15:46:07,400:INFO:create_model() successfully completed......................................
2025-03-19 15:46:07,454:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:07,454:INFO:Creating metrics dataframe
2025-03-19 15:46:07,465:INFO:Initializing create_model()
2025-03-19 15:46:07,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:07,465:INFO:Checking exceptions
2025-03-19 15:46:07,466:INFO:Importing libraries
2025-03-19 15:46:07,466:INFO:Copying training dataset
2025-03-19 15:46:07,468:INFO:Defining folds
2025-03-19 15:46:07,468:INFO:Declaring metric variables
2025-03-19 15:46:07,468:INFO:Importing untrained model
2025-03-19 15:46:07,468:INFO:Declaring custom model
2025-03-19 15:46:07,468:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:46:07,469:INFO:Cross validation set to False
2025-03-19 15:46:07,469:INFO:Fitting Model
2025-03-19 15:46:07,679:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:46:07,679:INFO:create_model() successfully completed......................................
2025-03-19 15:46:07,736:INFO:Creating Dashboard logs
2025-03-19 15:46:07,738:INFO:Model: Gradient Boosting Regressor
2025-03-19 15:46:07,754:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 456, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:46:07,791:INFO:Initializing predict_model()
2025-03-19 15:46:07,791:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=GradientBoostingRegressor(random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975B7A0D0>)
2025-03-19 15:46:07,791:INFO:Checking exceptions
2025-03-19 15:46:07,791:INFO:Preloading libraries
2025-03-19 15:46:07,909:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-19 15:46:07,934:ERROR:_log_model() for GradientBoostingRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:07,938:INFO:Initializing create_model()
2025-03-19 15:46:07,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:07,939:INFO:Checking exceptions
2025-03-19 15:46:07,940:INFO:Importing libraries
2025-03-19 15:46:07,940:INFO:Copying training dataset
2025-03-19 15:46:07,942:INFO:Defining folds
2025-03-19 15:46:07,942:INFO:Declaring metric variables
2025-03-19 15:46:07,942:INFO:Importing untrained model
2025-03-19 15:46:07,942:INFO:Declaring custom model
2025-03-19 15:46:07,942:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:46:07,943:INFO:Cross validation set to False
2025-03-19 15:46:07,943:INFO:Fitting Model
2025-03-19 15:46:07,975:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:46:07,975:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-03-19 15:46:07,975:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:46:07,975:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:46:07,975:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:46:07,976:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:46:08,070:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:46:08,070:INFO:create_model() successfully completed......................................
2025-03-19 15:46:08,143:INFO:Creating Dashboard logs
2025-03-19 15:46:08,146:INFO:Model: Light Gradient Boosting Machine
2025-03-19 15:46:08,168:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 456, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-19 15:46:08,214:INFO:Initializing predict_model()
2025-03-19 15:46:08,214:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975AC51F0>)
2025-03-19 15:46:08,214:INFO:Checking exceptions
2025-03-19 15:46:08,214:INFO:Preloading libraries
2025-03-19 15:46:08,352:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:08,356:INFO:Initializing create_model()
2025-03-19 15:46:08,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:08,356:INFO:Checking exceptions
2025-03-19 15:46:08,357:INFO:Importing libraries
2025-03-19 15:46:08,357:INFO:Copying training dataset
2025-03-19 15:46:08,360:INFO:Defining folds
2025-03-19 15:46:08,360:INFO:Declaring metric variables
2025-03-19 15:46:08,360:INFO:Importing untrained model
2025-03-19 15:46:08,360:INFO:Declaring custom model
2025-03-19 15:46:08,361:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:46:08,362:INFO:Cross validation set to False
2025-03-19 15:46:08,362:INFO:Fitting Model
2025-03-19 15:46:08,526:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:46:08,526:INFO:create_model() successfully completed......................................
2025-03-19 15:46:08,591:INFO:Creating Dashboard logs
2025-03-19 15:46:08,594:INFO:Model: Extreme Gradient Boosting
2025-03-19 15:46:08,616:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 456, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-19 15:46:08,681:INFO:Initializing predict_model()
2025-03-19 15:46:08,681:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B9746BC1F0>)
2025-03-19 15:46:08,681:INFO:Checking exceptions
2025-03-19 15:46:08,681:INFO:Preloading libraries
2025-03-19 15:46:08,821:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:08,824:INFO:Initializing create_model()
2025-03-19 15:46:08,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=AdaBoostRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:08,824:INFO:Checking exceptions
2025-03-19 15:46:08,825:INFO:Importing libraries
2025-03-19 15:46:08,825:INFO:Copying training dataset
2025-03-19 15:46:08,827:INFO:Defining folds
2025-03-19 15:46:08,828:INFO:Declaring metric variables
2025-03-19 15:46:08,828:INFO:Importing untrained model
2025-03-19 15:46:08,828:INFO:Declaring custom model
2025-03-19 15:46:08,828:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:46:08,829:INFO:Cross validation set to False
2025-03-19 15:46:08,829:INFO:Fitting Model
2025-03-19 15:46:08,945:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:46:08,946:INFO:create_model() successfully completed......................................
2025-03-19 15:46:09,004:INFO:Creating Dashboard logs
2025-03-19 15:46:09,005:INFO:Model: AdaBoost Regressor
2025-03-19 15:46:09,020:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 456}
2025-03-19 15:46:09,072:INFO:Initializing predict_model()
2025-03-19 15:46:09,072:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=AdaBoostRegressor(random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B9746BCCA0>)
2025-03-19 15:46:09,072:INFO:Checking exceptions
2025-03-19 15:46:09,072:INFO:Preloading libraries
2025-03-19 15:46:09,196:ERROR:_log_model() for AdaBoostRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,197:INFO:Creating Dashboard logs
2025-03-19 15:46:09,199:INFO:Model: CatBoost Regressor
2025-03-19 15:46:09,214:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-19 15:46:09,214:INFO:Logged params: {}
2025-03-19 15:46:09,278:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x000001B976248040> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,279:INFO:Creating Dashboard logs
2025-03-19 15:46:09,280:INFO:Model: Random Forest Regressor
2025-03-19 15:46:09,294:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 456, 'verbose': 0, 'warm_start': False}
2025-03-19 15:46:09,372:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,373:INFO:Creating Dashboard logs
2025-03-19 15:46:09,375:INFO:Model: Extra Trees Regressor
2025-03-19 15:46:09,390:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 456, 'verbose': 0, 'warm_start': False}
2025-03-19 15:46:09,474:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,475:INFO:Creating Dashboard logs
2025-03-19 15:46:09,477:INFO:Model: Decision Tree Regressor
2025-03-19 15:46:09,493:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 456, 'splitter': 'best'}
2025-03-19 15:46:09,580:ERROR:_log_model() for DecisionTreeRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,581:INFO:Creating Dashboard logs
2025-03-19 15:46:09,582:INFO:Model: Orthogonal Matching Pursuit
2025-03-19 15:46:09,596:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-19 15:46:09,691:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,692:INFO:Creating Dashboard logs
2025-03-19 15:46:09,694:INFO:Model: Bayesian Ridge
2025-03-19 15:46:09,708:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-19 15:46:09,804:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,804:INFO:Creating Dashboard logs
2025-03-19 15:46:09,806:INFO:Model: Ridge Regression
2025-03-19 15:46:09,819:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 456, 'solver': 'auto', 'tol': 0.0001}
2025-03-19 15:46:09,923:ERROR:_log_model() for Ridge(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:09,924:INFO:Creating Dashboard logs
2025-03-19 15:46:09,926:INFO:Model: Linear Regression
2025-03-19 15:46:09,940:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-19 15:46:10,041:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:10,042:INFO:Creating Dashboard logs
2025-03-19 15:46:10,044:INFO:Model: Huber Regressor
2025-03-19 15:46:10,058:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-19 15:46:10,165:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:10,166:INFO:Creating Dashboard logs
2025-03-19 15:46:10,168:INFO:Model: K Neighbors Regressor
2025-03-19 15:46:10,181:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-19 15:46:10,298:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:10,299:INFO:Creating Dashboard logs
2025-03-19 15:46:10,300:INFO:Model: Lasso Regression
2025-03-19 15:46:10,315:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 456, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-19 15:46:10,433:ERROR:_log_model() for Lasso(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:10,434:INFO:Creating Dashboard logs
2025-03-19 15:46:10,436:INFO:Model: Elastic Net
2025-03-19 15:46:10,449:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 456, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-19 15:46:10,578:ERROR:_log_model() for ElasticNet(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:10,579:INFO:Creating Dashboard logs
2025-03-19 15:46:10,581:INFO:Model: Lasso Least Angle Regression
2025-03-19 15:46:10,594:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 456, 'verbose': False}
2025-03-19 15:46:10,727:ERROR:_log_model() for LassoLars(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:10,727:INFO:Creating Dashboard logs
2025-03-19 15:46:10,729:INFO:Model: Dummy Regressor
2025-03-19 15:46:10,745:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-19 15:46:10,881:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:10,881:INFO:Creating Dashboard logs
2025-03-19 15:46:10,883:INFO:Model: Passive Aggressive Regressor
2025-03-19 15:46:10,898:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 456, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:46:11,050:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:11,050:INFO:Creating Dashboard logs
2025-03-19 15:46:11,052:INFO:Model: Least Angle Regression
2025-03-19 15:46:11,066:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 456, 'verbose': False}
2025-03-19 15:46:11,212:ERROR:_log_model() for Lars(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:46:11,220:INFO:_master_model_container: 20
2025-03-19 15:46:11,220:INFO:_display_container: 2
2025-03-19 15:46:11,221:INFO:[GradientBoostingRegressor(random_state=456), LGBMRegressor(n_jobs=-1, random_state=456), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), AdaBoostRegressor(random_state=456)]
2025-03-19 15:46:11,221:INFO:compare_models() successfully completed......................................
2025-03-19 15:46:11,245:INFO:Initializing tune_model()
2025-03-19 15:46:11,245:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>)
2025-03-19 15:46:11,245:INFO:Checking exceptions
2025-03-19 15:46:11,245:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:46:11,291:INFO:Copying training dataset
2025-03-19 15:46:11,294:INFO:Checking base model
2025-03-19 15:46:11,294:INFO:Base model : Gradient Boosting Regressor
2025-03-19 15:46:11,296:INFO:Declaring metric variables
2025-03-19 15:46:11,298:INFO:Defining Hyperparameters
2025-03-19 15:46:11,358:INFO:Tuning with n_jobs=-1
2025-03-19 15:46:11,358:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:46:11,359:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:46:11,359:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:46:11,363:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:46:11,363:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:46:11,364:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:46:59,282:INFO:best_params: {'actual_estimator__n_estimators': 65, 'actual_estimator__learning_rate': 0.12616882370758922, 'actual_estimator__subsample': 0.38505742926276704, 'actual_estimator__min_samples_split': 4, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_depth': 4, 'actual_estimator__max_features': 0.7725785954446928, 'actual_estimator__min_impurity_decrease': 0.03883923269439738}
2025-03-19 15:46:59,287:INFO:Hyperparameter search completed
2025-03-19 15:46:59,287:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:59,287:INFO:Initializing create_model()
2025-03-19 15:46:59,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E5E1C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 65, 'learning_rate': 0.12616882370758922, 'subsample': 0.38505742926276704, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 0.7725785954446928, 'min_impurity_decrease': 0.03883923269439738})
2025-03-19 15:46:59,287:INFO:Checking exceptions
2025-03-19 15:46:59,287:INFO:Importing libraries
2025-03-19 15:46:59,288:INFO:Copying training dataset
2025-03-19 15:46:59,290:INFO:Defining folds
2025-03-19 15:46:59,290:INFO:Declaring metric variables
2025-03-19 15:46:59,291:INFO:Importing untrained model
2025-03-19 15:46:59,291:INFO:Declaring custom model
2025-03-19 15:46:59,293:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:46:59,297:INFO:Starting cross validation
2025-03-19 15:46:59,298:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:59,421:INFO:Calculating mean and std
2025-03-19 15:46:59,422:INFO:Creating metrics dataframe
2025-03-19 15:46:59,426:INFO:Finalizing model
2025-03-19 15:46:59,515:INFO:Uploading results into container
2025-03-19 15:46:59,515:INFO:Uploading model into container now
2025-03-19 15:46:59,515:INFO:_master_model_container: 21
2025-03-19 15:46:59,516:INFO:_display_container: 3
2025-03-19 15:46:59,516:INFO:GradientBoostingRegressor(learning_rate=0.12616882370758922, max_depth=4,
                          max_features=0.7725785954446928,
                          min_impurity_decrease=0.03883923269439738,
                          min_samples_leaf=2, min_samples_split=4,
                          n_estimators=65, random_state=456,
                          subsample=0.38505742926276704)
2025-03-19 15:46:59,516:INFO:create_model() successfully completed......................................
2025-03-19 15:46:59,577:INFO:SubProcess create_model() end ==================================
2025-03-19 15:46:59,577:INFO:choose_better activated
2025-03-19 15:46:59,579:INFO:SubProcess create_model() called ==================================
2025-03-19 15:46:59,579:INFO:Initializing create_model()
2025-03-19 15:46:59,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:46:59,579:INFO:Checking exceptions
2025-03-19 15:46:59,580:INFO:Importing libraries
2025-03-19 15:46:59,580:INFO:Copying training dataset
2025-03-19 15:46:59,582:INFO:Defining folds
2025-03-19 15:46:59,582:INFO:Declaring metric variables
2025-03-19 15:46:59,582:INFO:Importing untrained model
2025-03-19 15:46:59,582:INFO:Declaring custom model
2025-03-19 15:46:59,583:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:46:59,583:INFO:Starting cross validation
2025-03-19 15:46:59,583:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:46:59,806:INFO:Calculating mean and std
2025-03-19 15:46:59,807:INFO:Creating metrics dataframe
2025-03-19 15:46:59,808:INFO:Finalizing model
2025-03-19 15:47:00,017:INFO:Uploading results into container
2025-03-19 15:47:00,018:INFO:Uploading model into container now
2025-03-19 15:47:00,018:INFO:_master_model_container: 22
2025-03-19 15:47:00,018:INFO:_display_container: 4
2025-03-19 15:47:00,018:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:47:00,018:INFO:create_model() successfully completed......................................
2025-03-19 15:47:00,078:INFO:SubProcess create_model() end ==================================
2025-03-19 15:47:00,078:INFO:GradientBoostingRegressor(random_state=456) result for R2 is 0.8404
2025-03-19 15:47:00,079:INFO:GradientBoostingRegressor(learning_rate=0.12616882370758922, max_depth=4,
                          max_features=0.7725785954446928,
                          min_impurity_decrease=0.03883923269439738,
                          min_samples_leaf=2, min_samples_split=4,
                          n_estimators=65, random_state=456,
                          subsample=0.38505742926276704) result for R2 is 0.8638
2025-03-19 15:47:00,079:INFO:GradientBoostingRegressor(learning_rate=0.12616882370758922, max_depth=4,
                          max_features=0.7725785954446928,
                          min_impurity_decrease=0.03883923269439738,
                          min_samples_leaf=2, min_samples_split=4,
                          n_estimators=65, random_state=456,
                          subsample=0.38505742926276704) is best model
2025-03-19 15:47:00,079:INFO:choose_better completed
2025-03-19 15:47:00,079:INFO:Creating Dashboard logs
2025-03-19 15:47:00,081:INFO:Model: Gradient Boosting Regressor
2025-03-19 15:47:00,097:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.12616882370758922, 'loss': 'squared_error', 'max_depth': 4, 'max_features': 0.7725785954446928, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.03883923269439738, 'min_samples_leaf': 2, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 65, 'n_iter_no_change': None, 'random_state': 456, 'subsample': 0.38505742926276704, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:47:00,267:INFO:Initializing predict_model()
2025-03-19 15:47:00,267:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=GradientBoostingRegressor(learning_rate=0.12616882370758922, max_depth=4,
                          max_features=0.7725785954446928,
                          min_impurity_decrease=0.03883923269439738,
                          min_samples_leaf=2, min_samples_split=4,
                          n_estimators=65, random_state=456,
                          subsample=0.38505742926276704), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975F43A60>)
2025-03-19 15:47:00,267:INFO:Checking exceptions
2025-03-19 15:47:00,267:INFO:Preloading libraries
2025-03-19 15:47:00,394:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.12616882370758922, max_depth=4,
                          max_features=0.7725785954446928,
                          min_impurity_decrease=0.03883923269439738,
                          min_samples_leaf=2, min_samples_split=4,
                          n_estimators=65, random_state=456,
                          subsample=0.38505742926276704) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:47:00,398:INFO:_master_model_container: 22
2025-03-19 15:47:00,398:INFO:_display_container: 3
2025-03-19 15:47:00,398:INFO:GradientBoostingRegressor(learning_rate=0.12616882370758922, max_depth=4,
                          max_features=0.7725785954446928,
                          min_impurity_decrease=0.03883923269439738,
                          min_samples_leaf=2, min_samples_split=4,
                          n_estimators=65, random_state=456,
                          subsample=0.38505742926276704)
2025-03-19 15:47:00,398:INFO:tune_model() successfully completed......................................
2025-03-19 15:47:00,461:INFO:Initializing predict_model()
2025-03-19 15:47:00,461:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=GradientBoostingRegressor(learning_rate=0.12616882370758922, max_depth=4,
                          max_features=0.7725785954446928,
                          min_impurity_decrease=0.03883923269439738,
                          min_samples_leaf=2, min_samples_split=4,
                          n_estimators=65, random_state=456,
                          subsample=0.38505742926276704), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B976149A60>)
2025-03-19 15:47:00,461:INFO:Checking exceptions
2025-03-19 15:47:00,461:INFO:Preloading libraries
2025-03-19 15:47:00,577:INFO:Initializing tune_model()
2025-03-19 15:47:00,577:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>)
2025-03-19 15:47:00,577:INFO:Checking exceptions
2025-03-19 15:47:00,577:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:47:00,586:INFO:Copying training dataset
2025-03-19 15:47:00,588:INFO:Checking base model
2025-03-19 15:47:00,588:INFO:Base model : Light Gradient Boosting Machine
2025-03-19 15:47:00,590:INFO:Declaring metric variables
2025-03-19 15:47:00,592:INFO:Defining Hyperparameters
2025-03-19 15:47:00,654:INFO:Tuning with n_jobs=-1
2025-03-19 15:47:00,655:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:47:00,655:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:47:00,655:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:47:00,655:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:47:00,655:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:47:00,655:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:47:35,152:INFO:best_params: {'actual_estimator__num_leaves': 16, 'actual_estimator__learning_rate': 0.2149389697617955, 'actual_estimator__n_estimators': 152, 'actual_estimator__min_split_gain': 0.8916137017799312, 'actual_estimator__reg_alpha': 0.0006433694362378049, 'actual_estimator__reg_lambda': 7.105995070181931e-05, 'actual_estimator__feature_fraction': 0.7703164034616452, 'actual_estimator__bagging_fraction': 0.7314965761356556, 'actual_estimator__bagging_freq': 0, 'actual_estimator__min_child_samples': 6}
2025-03-19 15:47:35,159:INFO:Hyperparameter search completed
2025-03-19 15:47:35,159:INFO:SubProcess create_model() called ==================================
2025-03-19 15:47:35,159:INFO:Initializing create_model()
2025-03-19 15:47:35,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975DF0520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 16, 'learning_rate': 0.2149389697617955, 'n_estimators': 152, 'min_split_gain': 0.8916137017799312, 'reg_alpha': 0.0006433694362378049, 'reg_lambda': 7.105995070181931e-05, 'feature_fraction': 0.7703164034616452, 'bagging_fraction': 0.7314965761356556, 'bagging_freq': 0, 'min_child_samples': 6})
2025-03-19 15:47:35,159:INFO:Checking exceptions
2025-03-19 15:47:35,159:INFO:Importing libraries
2025-03-19 15:47:35,160:INFO:Copying training dataset
2025-03-19 15:47:35,162:INFO:Defining folds
2025-03-19 15:47:35,162:INFO:Declaring metric variables
2025-03-19 15:47:35,165:INFO:Importing untrained model
2025-03-19 15:47:35,165:INFO:Declaring custom model
2025-03-19 15:47:35,167:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:47:35,171:INFO:Starting cross validation
2025-03-19 15:47:35,172:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:47:35,311:INFO:Calculating mean and std
2025-03-19 15:47:35,312:INFO:Creating metrics dataframe
2025-03-19 15:47:35,316:INFO:Finalizing model
2025-03-19 15:47:35,348:INFO:[LightGBM] [Warning] feature_fraction is set=0.7703164034616452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7703164034616452
2025-03-19 15:47:35,348:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7314965761356556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7314965761356556
2025-03-19 15:47:35,348:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-03-19 15:47:35,350:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:47:35,350:INFO:[LightGBM] [Warning] feature_fraction is set=0.7703164034616452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7703164034616452
2025-03-19 15:47:35,350:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7314965761356556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7314965761356556
2025-03-19 15:47:35,350:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-03-19 15:47:35,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003870 seconds.
2025-03-19 15:47:35,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:47:35,355:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:47:35,355:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:47:35,356:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:47:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:47:35,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:47:35,415:INFO:Uploading results into container
2025-03-19 15:47:35,416:INFO:Uploading model into container now
2025-03-19 15:47:35,416:INFO:_master_model_container: 23
2025-03-19 15:47:35,417:INFO:_display_container: 5
2025-03-19 15:47:35,417:INFO:LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05)
2025-03-19 15:47:35,417:INFO:create_model() successfully completed......................................
2025-03-19 15:47:35,487:INFO:SubProcess create_model() end ==================================
2025-03-19 15:47:35,487:INFO:choose_better activated
2025-03-19 15:47:35,489:INFO:SubProcess create_model() called ==================================
2025-03-19 15:47:35,490:INFO:Initializing create_model()
2025-03-19 15:47:35,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:47:35,490:INFO:Checking exceptions
2025-03-19 15:47:35,491:INFO:Importing libraries
2025-03-19 15:47:35,491:INFO:Copying training dataset
2025-03-19 15:47:35,493:INFO:Defining folds
2025-03-19 15:47:35,493:INFO:Declaring metric variables
2025-03-19 15:47:35,493:INFO:Importing untrained model
2025-03-19 15:47:35,493:INFO:Declaring custom model
2025-03-19 15:47:35,494:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:47:35,494:INFO:Starting cross validation
2025-03-19 15:47:35,494:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:47:35,973:INFO:Calculating mean and std
2025-03-19 15:47:35,974:INFO:Creating metrics dataframe
2025-03-19 15:47:35,975:INFO:Finalizing model
2025-03-19 15:47:36,009:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:47:36,009:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2025-03-19 15:47:36,009:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:47:36,009:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:47:36,010:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:47:36,010:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:47:36,120:INFO:Uploading results into container
2025-03-19 15:47:36,121:INFO:Uploading model into container now
2025-03-19 15:47:36,121:INFO:_master_model_container: 24
2025-03-19 15:47:36,121:INFO:_display_container: 6
2025-03-19 15:47:36,121:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:47:36,121:INFO:create_model() successfully completed......................................
2025-03-19 15:47:36,186:INFO:SubProcess create_model() end ==================================
2025-03-19 15:47:36,187:INFO:LGBMRegressor(n_jobs=-1, random_state=456) result for R2 is 0.8318
2025-03-19 15:47:36,187:INFO:LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05) result for R2 is 0.8728
2025-03-19 15:47:36,188:INFO:LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05) is best model
2025-03-19 15:47:36,188:INFO:choose_better completed
2025-03-19 15:47:36,188:INFO:Creating Dashboard logs
2025-03-19 15:47:36,191:INFO:Model: Light Gradient Boosting Machine
2025-03-19 15:47:36,214:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.2149389697617955, 'max_depth': -1, 'min_child_samples': 6, 'min_child_weight': 0.001, 'min_split_gain': 0.8916137017799312, 'n_estimators': 152, 'n_jobs': -1, 'num_leaves': 16, 'objective': None, 'random_state': 456, 'reg_alpha': 0.0006433694362378049, 'reg_lambda': 7.105995070181931e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7703164034616452, 'bagging_fraction': 0.7314965761356556, 'bagging_freq': 0}
2025-03-19 15:47:36,401:INFO:Initializing predict_model()
2025-03-19 15:47:36,401:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975F435E0>)
2025-03-19 15:47:36,401:INFO:Checking exceptions
2025-03-19 15:47:36,401:INFO:Preloading libraries
2025-03-19 15:47:36,585:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:47:36,591:INFO:_master_model_container: 24
2025-03-19 15:47:36,591:INFO:_display_container: 5
2025-03-19 15:47:36,592:INFO:LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05)
2025-03-19 15:47:36,592:INFO:tune_model() successfully completed......................................
2025-03-19 15:47:36,662:INFO:Initializing predict_model()
2025-03-19 15:47:36,663:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B976156E50>)
2025-03-19 15:47:36,663:INFO:Checking exceptions
2025-03-19 15:47:36,663:INFO:Preloading libraries
2025-03-19 15:47:36,792:INFO:Initializing tune_model()
2025-03-19 15:47:36,792:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>)
2025-03-19 15:47:36,792:INFO:Checking exceptions
2025-03-19 15:47:36,793:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:47:36,803:INFO:Copying training dataset
2025-03-19 15:47:36,806:INFO:Checking base model
2025-03-19 15:47:36,806:INFO:Base model : Extreme Gradient Boosting
2025-03-19 15:47:36,809:INFO:Declaring metric variables
2025-03-19 15:47:36,811:INFO:Defining Hyperparameters
2025-03-19 15:47:36,874:INFO:Tuning with n_jobs=-1
2025-03-19 15:47:36,875:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:47:36,875:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:47:36,875:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:47:36,875:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:47:36,875:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:47:36,875:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:48:30,759:INFO:best_params: {'actual_estimator__learning_rate': 0.2766388144302898, 'actual_estimator__n_estimators': 19, 'actual_estimator__subsample': 0.38281818786738314, 'actual_estimator__max_depth': 6, 'actual_estimator__colsample_bytree': 0.8126990176802827, 'actual_estimator__min_child_weight': 4, 'actual_estimator__reg_alpha': 1.95889962920255e-08, 'actual_estimator__reg_lambda': 1.7596504264603522e-09, 'actual_estimator__scale_pos_weight': 13.87611001592687}
2025-03-19 15:48:30,765:INFO:Hyperparameter search completed
2025-03-19 15:48:30,766:INFO:SubProcess create_model() called ==================================
2025-03-19 15:48:30,766:INFO:Initializing create_model()
2025-03-19 15:48:30,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975DFC490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.2766388144302898, 'n_estimators': 19, 'subsample': 0.38281818786738314, 'max_depth': 6, 'colsample_bytree': 0.8126990176802827, 'min_child_weight': 4, 'reg_alpha': 1.95889962920255e-08, 'reg_lambda': 1.7596504264603522e-09, 'scale_pos_weight': 13.87611001592687})
2025-03-19 15:48:30,767:INFO:Checking exceptions
2025-03-19 15:48:30,767:INFO:Importing libraries
2025-03-19 15:48:30,767:INFO:Copying training dataset
2025-03-19 15:48:30,770:INFO:Defining folds
2025-03-19 15:48:30,770:INFO:Declaring metric variables
2025-03-19 15:48:30,772:INFO:Importing untrained model
2025-03-19 15:48:30,773:INFO:Declaring custom model
2025-03-19 15:48:30,775:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:48:30,780:INFO:Starting cross validation
2025-03-19 15:48:30,781:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:48:31,109:INFO:Calculating mean and std
2025-03-19 15:48:31,110:INFO:Creating metrics dataframe
2025-03-19 15:48:31,115:INFO:Finalizing model
2025-03-19 15:48:31,183:INFO:Uploading results into container
2025-03-19 15:48:31,184:INFO:Uploading model into container now
2025-03-19 15:48:31,184:INFO:_master_model_container: 25
2025-03-19 15:48:31,184:INFO:_display_container: 7
2025-03-19 15:48:31,185:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.8126990176802827, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.2766388144302898, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=19, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:48:31,185:INFO:create_model() successfully completed......................................
2025-03-19 15:48:31,258:INFO:SubProcess create_model() end ==================================
2025-03-19 15:48:31,258:INFO:choose_better activated
2025-03-19 15:48:31,261:INFO:SubProcess create_model() called ==================================
2025-03-19 15:48:31,262:INFO:Initializing create_model()
2025-03-19 15:48:31,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:48:31,262:INFO:Checking exceptions
2025-03-19 15:48:31,262:INFO:Importing libraries
2025-03-19 15:48:31,262:INFO:Copying training dataset
2025-03-19 15:48:31,265:INFO:Defining folds
2025-03-19 15:48:31,265:INFO:Declaring metric variables
2025-03-19 15:48:31,265:INFO:Importing untrained model
2025-03-19 15:48:31,265:INFO:Declaring custom model
2025-03-19 15:48:31,266:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:48:31,266:INFO:Starting cross validation
2025-03-19 15:48:31,267:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:48:31,601:INFO:Calculating mean and std
2025-03-19 15:48:31,602:INFO:Creating metrics dataframe
2025-03-19 15:48:31,603:INFO:Finalizing model
2025-03-19 15:48:31,745:INFO:Uploading results into container
2025-03-19 15:48:31,745:INFO:Uploading model into container now
2025-03-19 15:48:31,745:INFO:_master_model_container: 26
2025-03-19 15:48:31,745:INFO:_display_container: 8
2025-03-19 15:48:31,746:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:48:31,746:INFO:create_model() successfully completed......................................
2025-03-19 15:48:31,810:INFO:SubProcess create_model() end ==================================
2025-03-19 15:48:31,811:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) result for R2 is 0.8356
2025-03-19 15:48:31,811:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.8126990176802827, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.2766388144302898, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=19, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) result for R2 is 0.877
2025-03-19 15:48:31,812:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.8126990176802827, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.2766388144302898, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=19, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) is best model
2025-03-19 15:48:31,812:INFO:choose_better completed
2025-03-19 15:48:31,812:INFO:Creating Dashboard logs
2025-03-19 15:48:31,815:INFO:Model: Extreme Gradient Boosting
2025-03-19 15:48:31,841:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8126990176802827, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.2766388144302898, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 6, 'max_leaves': None, 'min_child_weight': 4, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 19, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 456, 'reg_alpha': 1.95889962920255e-08, 'reg_lambda': 1.7596504264603522e-09, 'sampling_method': None, 'scale_pos_weight': 13.87611001592687, 'subsample': 0.38281818786738314, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-19 15:48:32,041:INFO:Initializing predict_model()
2025-03-19 15:48:32,041:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.8126990176802827, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.2766388144302898, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=19, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975BF00D0>)
2025-03-19 15:48:32,041:INFO:Checking exceptions
2025-03-19 15:48:32,041:INFO:Preloading libraries
2025-03-19 15:48:32,187:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.8126990176802827, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.2766388144302898, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=19, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:48:32,194:INFO:_master_model_container: 26
2025-03-19 15:48:32,194:INFO:_display_container: 7
2025-03-19 15:48:32,194:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.8126990176802827, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.2766388144302898, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=19, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:48:32,195:INFO:tune_model() successfully completed......................................
2025-03-19 15:48:32,264:INFO:Initializing predict_model()
2025-03-19 15:48:32,265:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.8126990176802827, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.2766388144302898, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=6, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=19, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B976156E50>)
2025-03-19 15:48:32,265:INFO:Checking exceptions
2025-03-19 15:48:32,265:INFO:Preloading libraries
2025-03-19 15:48:32,415:INFO:Initializing tune_model()
2025-03-19 15:48:32,415:INFO:tune_model(estimator=AdaBoostRegressor(random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>)
2025-03-19 15:48:32,416:INFO:Checking exceptions
2025-03-19 15:48:32,416:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:48:32,427:INFO:Copying training dataset
2025-03-19 15:48:32,430:INFO:Checking base model
2025-03-19 15:48:32,431:INFO:Base model : AdaBoost Regressor
2025-03-19 15:48:32,434:INFO:Declaring metric variables
2025-03-19 15:48:32,436:INFO:Defining Hyperparameters
2025-03-19 15:48:32,508:INFO:Tuning with n_jobs=-1
2025-03-19 15:48:32,509:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:48:32,509:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:48:32,510:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:48:32,510:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:48:32,510:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:48:32,510:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:49:56,752:INFO:best_params: {'actual_estimator__learning_rate': 1.8657583836280277e-05, 'actual_estimator__n_estimators': 136, 'actual_estimator__loss': 'square'}
2025-03-19 15:49:56,756:INFO:Hyperparameter search completed
2025-03-19 15:49:56,756:INFO:SubProcess create_model() called ==================================
2025-03-19 15:49:56,756:INFO:Initializing create_model()
2025-03-19 15:49:56,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=AdaBoostRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B975E0F130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 1.8657583836280277e-05, 'n_estimators': 136, 'loss': 'square'})
2025-03-19 15:49:56,756:INFO:Checking exceptions
2025-03-19 15:49:56,756:INFO:Importing libraries
2025-03-19 15:49:56,757:INFO:Copying training dataset
2025-03-19 15:49:56,758:INFO:Defining folds
2025-03-19 15:49:56,758:INFO:Declaring metric variables
2025-03-19 15:49:56,761:INFO:Importing untrained model
2025-03-19 15:49:56,761:INFO:Declaring custom model
2025-03-19 15:49:56,763:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:49:56,766:INFO:Starting cross validation
2025-03-19 15:49:56,767:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:49:57,037:INFO:Calculating mean and std
2025-03-19 15:49:57,038:INFO:Creating metrics dataframe
2025-03-19 15:49:57,041:INFO:Finalizing model
2025-03-19 15:49:57,335:INFO:Uploading results into container
2025-03-19 15:49:57,335:INFO:Uploading model into container now
2025-03-19 15:49:57,335:INFO:_master_model_container: 27
2025-03-19 15:49:57,335:INFO:_display_container: 9
2025-03-19 15:49:57,336:INFO:AdaBoostRegressor(learning_rate=1.8657583836280277e-05, loss='square',
                  n_estimators=136, random_state=456)
2025-03-19 15:49:57,336:INFO:create_model() successfully completed......................................
2025-03-19 15:49:57,392:INFO:SubProcess create_model() end ==================================
2025-03-19 15:49:57,392:INFO:choose_better activated
2025-03-19 15:49:57,394:INFO:SubProcess create_model() called ==================================
2025-03-19 15:49:57,394:INFO:Initializing create_model()
2025-03-19 15:49:57,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=AdaBoostRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:49:57,394:INFO:Checking exceptions
2025-03-19 15:49:57,395:INFO:Importing libraries
2025-03-19 15:49:57,395:INFO:Copying training dataset
2025-03-19 15:49:57,397:INFO:Defining folds
2025-03-19 15:49:57,397:INFO:Declaring metric variables
2025-03-19 15:49:57,397:INFO:Importing untrained model
2025-03-19 15:49:57,397:INFO:Declaring custom model
2025-03-19 15:49:57,397:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:49:57,397:INFO:Starting cross validation
2025-03-19 15:49:57,398:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:49:57,545:INFO:Calculating mean and std
2025-03-19 15:49:57,546:INFO:Creating metrics dataframe
2025-03-19 15:49:57,546:INFO:Finalizing model
2025-03-19 15:49:57,656:INFO:Uploading results into container
2025-03-19 15:49:57,657:INFO:Uploading model into container now
2025-03-19 15:49:57,657:INFO:_master_model_container: 28
2025-03-19 15:49:57,657:INFO:_display_container: 10
2025-03-19 15:49:57,657:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:49:57,657:INFO:create_model() successfully completed......................................
2025-03-19 15:49:57,715:INFO:SubProcess create_model() end ==================================
2025-03-19 15:49:57,715:INFO:AdaBoostRegressor(random_state=456) result for R2 is 0.7935
2025-03-19 15:49:57,716:INFO:AdaBoostRegressor(learning_rate=1.8657583836280277e-05, loss='square',
                  n_estimators=136, random_state=456) result for R2 is 0.8131
2025-03-19 15:49:57,716:INFO:AdaBoostRegressor(learning_rate=1.8657583836280277e-05, loss='square',
                  n_estimators=136, random_state=456) is best model
2025-03-19 15:49:57,716:INFO:choose_better completed
2025-03-19 15:49:57,716:INFO:Creating Dashboard logs
2025-03-19 15:49:57,718:INFO:Model: AdaBoost Regressor
2025-03-19 15:49:57,735:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.8657583836280277e-05, 'loss': 'square', 'n_estimators': 136, 'random_state': 456}
2025-03-19 15:49:57,931:INFO:Initializing predict_model()
2025-03-19 15:49:57,931:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=AdaBoostRegressor(learning_rate=1.8657583836280277e-05, loss='square',
                  n_estimators=136, random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975F43B80>)
2025-03-19 15:49:57,931:INFO:Checking exceptions
2025-03-19 15:49:57,931:INFO:Preloading libraries
2025-03-19 15:49:58,066:ERROR:_log_model() for AdaBoostRegressor(learning_rate=1.8657583836280277e-05, loss='square',
                  n_estimators=136, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:49:58,071:INFO:_master_model_container: 28
2025-03-19 15:49:58,072:INFO:_display_container: 9
2025-03-19 15:49:58,072:INFO:AdaBoostRegressor(learning_rate=1.8657583836280277e-05, loss='square',
                  n_estimators=136, random_state=456)
2025-03-19 15:49:58,072:INFO:tune_model() successfully completed......................................
2025-03-19 15:49:58,129:INFO:Initializing predict_model()
2025-03-19 15:49:58,129:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=AdaBoostRegressor(learning_rate=1.8657583836280277e-05, loss='square',
                  n_estimators=136, random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B976149F70>)
2025-03-19 15:49:58,129:INFO:Checking exceptions
2025-03-19 15:49:58,129:INFO:Preloading libraries
2025-03-19 15:49:58,282:INFO:Initializing finalize_model()
2025-03-19 15:49:58,282:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-19 15:49:58,283:INFO:Finalizing LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05)
2025-03-19 15:49:58,284:INFO:Initializing create_model()
2025-03-19 15:49:58,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=LGBMRegressor(bagging_fraction=0.7314965761356556, bagging_freq=0,
              feature_fraction=0.7703164034616452,
              learning_rate=0.2149389697617955, min_child_samples=6,
              min_split_gain=0.8916137017799312, n_estimators=152, n_jobs=-1,
              num_leaves=16, random_state=456, reg_alpha=0.0006433694362378049,
              reg_lambda=7.105995070181931e-05), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:49:58,285:INFO:Checking exceptions
2025-03-19 15:49:58,285:INFO:Importing libraries
2025-03-19 15:49:58,285:INFO:Copying training dataset
2025-03-19 15:49:58,285:INFO:Defining folds
2025-03-19 15:49:58,286:INFO:Declaring metric variables
2025-03-19 15:49:58,286:INFO:Importing untrained model
2025-03-19 15:49:58,286:INFO:Declaring custom model
2025-03-19 15:49:58,286:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:49:58,287:INFO:Cross validation set to False
2025-03-19 15:49:58,287:INFO:Fitting Model
2025-03-19 15:49:58,322:INFO:[LightGBM] [Warning] feature_fraction is set=0.7703164034616452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7703164034616452
2025-03-19 15:49:58,322:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7314965761356556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7314965761356556
2025-03-19 15:49:58,323:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-03-19 15:49:58,325:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:49:58,325:INFO:[LightGBM] [Warning] feature_fraction is set=0.7703164034616452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7703164034616452
2025-03-19 15:49:58,325:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7314965761356556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7314965761356556
2025-03-19 15:49:58,325:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-03-19 15:49:58,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.
2025-03-19 15:49:58,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:49:58,325:INFO:[LightGBM] [Info] Total Bins 1182
2025-03-19 15:49:58,326:INFO:[LightGBM] [Info] Number of data points in the train set: 1710, number of used features: 27
2025-03-19 15:49:58,326:INFO:[LightGBM] [Info] Start training from score 15.816689
2025-03-19 15:49:58,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:49:58,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:49:58,362:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7314965761356556,
                               bagging_freq=0,
                               feature_fraction=0.7703164034616452,
                               learning_rate=0.2149389697617955,
                               min_child_samples=6,
                               min_split_gain=0.8916137017799312,
                               n_estimators=152, n_jobs=-1, num_leaves=16,
                               random_state=456,
                               reg_alpha=0.0006433694362378049,
                               reg_lambda=7.105995070181931e-05))])
2025-03-19 15:49:58,362:INFO:create_model() successfully completed......................................
2025-03-19 15:49:58,427:INFO:Creating Dashboard logs
2025-03-19 15:49:58,427:INFO:Model: Light Gradient Boosting Machine
2025-03-19 15:49:58,447:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.2149389697617955, 'max_depth': -1, 'min_child_samples': 6, 'min_child_weight': 0.001, 'min_split_gain': 0.8916137017799312, 'n_estimators': 152, 'n_jobs': -1, 'num_leaves': 16, 'objective': None, 'random_state': 456, 'reg_alpha': 0.0006433694362378049, 'reg_lambda': 7.105995070181931e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.7703164034616452, 'bagging_fraction': 0.7314965761356556, 'bagging_freq': 0}
2025-03-19 15:49:58,655:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7314965761356556,
                               bagging_freq=0,
                               feature_fraction=0.7703164034616452,
                               learning_rate=0.2149389697617955,
                               min_child_samples=6,
                               min_split_gain=0.8916137017799312,
                               n_estimators=152, n_jobs=-1, num_leaves=16,
                               random_state=456,
                               reg_alpha=0.0006433694362378049,
                               reg_lambda=7.105995070181931e-05))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:49:58,655:INFO:_master_model_container: 28
2025-03-19 15:49:58,655:INFO:_display_container: 10
2025-03-19 15:49:58,660:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7314965761356556,
                               bagging_freq=0,
                               feature_fraction=0.7703164034616452,
                               learning_rate=0.2149389697617955,
                               min_child_samples=6,
                               min_split_gain=0.8916137017799312,
                               n_estimators=152, n_jobs=-1, num_leaves=16,
                               random_state=456,
                               reg_alpha=0.0006433694362378049,
                               reg_lambda=7.105995070181931e-05))])
2025-03-19 15:49:58,660:INFO:finalize_model() successfully completed......................................
2025-03-19 15:49:58,728:INFO:Initializing predict_model()
2025-03-19 15:49:58,728:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7314965761356556,
                               bagging_freq=0,
                               feature_fraction=0.7703164034616452,
                               learning_rate=0.2149389697617955,
                               min_child_samples=6,
                               min_split_gain=0.8916137017799312,
                               n_estimators=152, n_jobs=-1, num_leaves=16,
                               random_state=456,
                               reg_alpha=0.0006433694362378049,
                               reg_lambda=7.105995070181931e-05))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975F43310>)
2025-03-19 15:49:58,728:INFO:Checking exceptions
2025-03-19 15:49:58,728:INFO:Preloading libraries
2025-03-19 15:49:58,730:INFO:Set up data.
2025-03-19 15:49:58,735:INFO:Set up index.
2025-03-19 15:49:58,832:INFO:Initializing predict_model()
2025-03-19 15:49:58,832:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7314965761356556,
                               bagging_freq=0,
                               feature_fraction=0.7703164034616452,
                               learning_rate=0.2149389697617955,
                               min_child_samples=6,
                               min_split_gain=0.8916137017799312,
                               n_estimators=152, n_jobs=-1, num_leaves=16,
                               random_state=456,
                               reg_alpha=0.0006433694362378049,
                               reg_lambda=7.105995070181931e-05))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B976241B80>)
2025-03-19 15:49:58,833:INFO:Checking exceptions
2025-03-19 15:49:58,833:INFO:Preloading libraries
2025-03-19 15:49:58,834:INFO:Set up data.
2025-03-19 15:49:58,840:INFO:Set up index.
2025-03-19 15:49:58,945:INFO:Initializing save_model()
2025-03-19 15:49:58,945:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7314965761356556,
                               bagging_freq=0,
                               feature_fraction=0.7703164034616452,
                               learning_rate=0.2149389697617955,
                               min_child_samples=6,
                               min_split_gain=0.8916137017799312,
                               n_estimators=152, n_jobs=-1, num_leaves=16,
                               random_state=456,
                               reg_alpha=0.0006433694362378049,
                               reg_lambda=7.105995070181931e-05))]), model_name=msw_stacked_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-19 15:49:58,945:INFO:Adding model into prep_pipe
2025-03-19 15:49:58,945:WARNING:Only Model saved as it was a pipeline.
2025-03-19 15:49:58,951:INFO:msw_stacked_model.pkl saved in current working directory
2025-03-19 15:49:58,959:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7314965761356556,
                               bagging_freq=0,
                               feature_fraction=0.7703164034616452,
                               learning_rate=0.2149389697617955,
                               min_child_samples=6,
                               min_split_gain=0.8916137017799312,
                               n_estimators=152, n_jobs=-1, num_leaves=16,
                               random_state=456,
                               reg_alpha=0.0006433694362378049,
                               reg_lambda=7.105995070181931e-05))])
2025-03-19 15:49:58,959:INFO:save_model() successfully completed......................................
2025-03-19 15:49:59,151:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,151:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,160:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,160:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,160:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,160:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,160:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,161:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 21382 (\N{CJK UNIFIED IDEOGRAPH-5386}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,161:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 21490 (\N{CJK UNIFIED IDEOGRAPH-53F2}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,161:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,161:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 25454 (\N{CJK UNIFIED IDEOGRAPH-636E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,161:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,161:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,161:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,162:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,162:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\699593671.py:39: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,392:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,392:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,392:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,392:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,392:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,397:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,398:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21382 (\N{CJK UNIFIED IDEOGRAPH-5386}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21490 (\N{CJK UNIFIED IDEOGRAPH-53F2}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 25454 (\N{CJK UNIFIED IDEOGRAPH-636E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,404:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,405:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,588:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39057 (\N{CJK UNIFIED IDEOGRAPH-9891}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,588:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,589:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,590:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,590:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24067 (\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,654:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 19982 (\N{CJK UNIFIED IDEOGRAPH-4E0E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,654:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,654:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,654:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,654:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20851 (\N{CJK UNIFIED IDEOGRAPH-5173}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,654:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 31995 (\N{CJK UNIFIED IDEOGRAPH-7CFB}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:49:59,792:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,792:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,798:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 20154 (\N{CJK UNIFIED IDEOGRAPH-4EBA}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,801:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,801:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,801:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,801:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,801:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,802:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,802:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,802:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,802:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  plt.tight_layout()

2025-03-19 15:49:59,802:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:31: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,042:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20154 (\N{CJK UNIFIED IDEOGRAPH-4EBA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,043:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,043:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,043:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,043:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,044:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,044:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,050:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,057:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,057:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,057:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,057:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,057:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,229:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24179 (\N{CJK UNIFIED IDEOGRAPH-5E73}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,229:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22343 (\N{CJK UNIFIED IDEOGRAPH-5747}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22269 (\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23478 (\N{CJK UNIFIED IDEOGRAPH-5BB6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,230:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,231:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38543 (\N{CJK UNIFIED IDEOGRAPH-968F}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,231:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,231:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,231:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21464 (\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,231:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21270 (\N{CJK UNIFIED IDEOGRAPH-5316}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,238:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,238:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,306:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,307:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,307:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,307:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 19982 (\N{CJK UNIFIED IDEOGRAPH-4E0E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,307:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23545 (\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,390:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 22320 (\N{CJK UNIFIED IDEOGRAPH-5730}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,390:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 21306 (\N{CJK UNIFIED IDEOGRAPH-533A}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,396:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,396:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,396:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,396:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,396:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,397:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,397:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 22269 (\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 23478 (\N{CJK UNIFIED IDEOGRAPH-5BB6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 21508 (\N{CJK UNIFIED IDEOGRAPH-5404}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,399:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_84140\1388027748.py:74: UserWarning: Glyph 24067 (\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.
  plt.tight_layout()

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22269 (\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23478 (\N{CJK UNIFIED IDEOGRAPH-5BB6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,426:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,427:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,427:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,427:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21508 (\N{CJK UNIFIED IDEOGRAPH-5404}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,427:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22320 (\N{CJK UNIFIED IDEOGRAPH-5730}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,427:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21306 (\N{CJK UNIFIED IDEOGRAPH-533A}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:00,427:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24067 (\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:50:40,545:INFO:Initializing predict_model()
2025-03-19 15:50:40,545:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=VotingRegressor(estimators=[('model_0',
                             GradientBoostingRegressor(learning_rate=0.12616882370758922,
                                                       max_depth=4,
                                                       max_features=0.7725785954446928,
                                                       min_impurity_decrease=0.03883923269439738,
                                                       min_samples_leaf=2,
                                                       min_samples_split=4,
                                                       n_estimators=65,
                                                       random_state=456,
                                                       subsample=0.38505742926276704)),
                            ('model_1',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          call...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.2766388144302898,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=6,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=19,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=456, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B9A384E940>)
2025-03-19 15:50:40,545:INFO:Checking exceptions
2025-03-19 15:50:40,545:INFO:Preloading libraries
2025-03-19 15:51:30,508:INFO:Initializing finalize_model()
2025-03-19 15:51:30,508:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=VotingRegressor(estimators=[('model_0',
                             GradientBoostingRegressor(learning_rate=0.12616882370758922,
                                                       max_depth=4,
                                                       max_features=0.7725785954446928,
                                                       min_impurity_decrease=0.03883923269439738,
                                                       min_samples_leaf=2,
                                                       min_samples_split=4,
                                                       n_estimators=65,
                                                       random_state=456,
                                                       subsample=0.38505742926276704)),
                            ('model_1',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          call...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.2766388144302898,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=6,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=19,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=456, ...))]), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-19 15:51:30,511:INFO:Finalizing VotingRegressor(estimators=[('model_0',
                             GradientBoostingRegressor(learning_rate=0.12616882370758922,
                                                       max_depth=4,
                                                       max_features=0.7725785954446928,
                                                       min_impurity_decrease=0.03883923269439738,
                                                       min_samples_leaf=2,
                                                       min_samples_split=4,
                                                       n_estimators=65,
                                                       random_state=456,
                                                       subsample=0.38505742926276704)),
                            ('model_1',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          call...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.2766388144302898,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=6,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=19,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=456, ...))])
2025-03-19 15:51:30,515:INFO:Initializing create_model()
2025-03-19 15:51:30,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=VotingRegressor(estimators=[('model_0',
                             GradientBoostingRegressor(learning_rate=0.12616882370758922,
                                                       max_depth=4,
                                                       max_features=0.7725785954446928,
                                                       min_impurity_decrease=0.03883923269439738,
                                                       min_samples_leaf=2,
                                                       min_samples_split=4,
                                                       n_estimators=65,
                                                       random_state=456,
                                                       subsample=0.38505742926276704)),
                            ('model_1',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          call...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.2766388144302898,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=6,
                                          max_leaves=None, min_child_weight=4,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=19,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=456, ...))]), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:51:30,515:INFO:Checking exceptions
2025-03-19 15:51:30,516:INFO:Importing libraries
2025-03-19 15:51:30,516:INFO:Copying training dataset
2025-03-19 15:51:30,516:INFO:Defining folds
2025-03-19 15:51:30,516:INFO:Declaring metric variables
2025-03-19 15:51:30,516:INFO:Importing untrained model
2025-03-19 15:51:30,516:INFO:Declaring custom model
2025-03-19 15:51:30,517:INFO:Voting Regressor Imported successfully
2025-03-19 15:51:30,518:INFO:Cross validation set to False
2025-03-19 15:51:30,518:INFO:Fitting Model
2025-03-19 15:51:30,666:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.2766388144302898,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=6,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=19,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))])
2025-03-19 15:51:30,666:INFO:create_model() successfully completed......................................
2025-03-19 15:51:30,765:INFO:Creating Dashboard logs
2025-03-19 15:51:30,766:INFO:Model: Voting Regressor
2025-03-19 15:51:30,787:INFO:Logged params: {'n_jobs': None, 'verbose': False, 'weights': None, 'model_0__alpha': 0.9, 'model_0__ccp_alpha': 0.0, 'model_0__criterion': 'friedman_mse', 'model_0__init': None, 'model_0__learning_rate': 0.12616882370758922, 'model_0__loss': 'squared_error', 'model_0__max_depth': 4, 'model_0__max_features': 0.7725785954446928, 'model_0__max_leaf_nodes': None, 'model_0__min_impurity_decrease': 0.03883923269439738, 'model_0__min_samples_leaf': 2, 'model_0__min_samples_split': 4, 'model_0__min_weight_fraction_leaf': 0.0, 'model_0__n_estimators': 65, 'model_0__n_iter_no_change': None, 'model_0__random_state': 456, 'model_0__subsample': 0.38505742926276704, 'model_0__tol': 0.0001, 'model_0__validation_fraction': 0.1, 'model_0__verbose': 0, 'model_0__warm_start': False, 'model_1__objective': 'reg:squarederror', 'model_1__base_score': None, 'model_1__booster': 'gbtree', 'model_1__callbacks': None, 'model_1__colsample_bylevel': None, 'model_1__colsample_bynode': None, 'model_1__colsample_bytree': 0.8126990176802827, 'model_1__device': 'cpu', 'model_1__early_stopping_rounds': None, 'model_1__enable_categorical': False, 'model_1__eval_metric': None, 'model_1__feature_types': None, 'model_1__gamma': None, 'model_1__grow_policy': None, 'model_1__importance_type': None, 'model_1__interaction_constraints': None, 'model_1__learning_rate': 0.2766388144302898, 'model_1__max_bin': None, 'model_1__max_cat_threshold': None, 'model_1__max_cat_to_onehot': None, 'model_1__max_delta_step': None, 'model_1__max_depth': 6, 'model_1__max_leaves': None, 'model_1__min_child_weight': 4, 'model_1__missing': nan, 'model_1__monotone_constraints': None, 'model_1__multi_strategy': None, 'model_1__n_estimators': 19, 'model_1__n_jobs': -1, 'model_1__num_parallel_tree': None, 'model_1__random_state': 456, 'model_1__reg_alpha': 1.95889962920255e-08, 'model_1__reg_lambda': 1.7596504264603522e-09, 'model_1__sampling_method': None, 'model_1__scale_pos_weight': 13.87611001592687, 'model_1__subsample': 0.38281818786738314, 'model_1__tree_method': 'auto', 'model_1__validate_parameters': None, 'model_1__verbosity': 0}
2025-03-19 15:51:31,051:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.2766388144302898,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=6,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=19,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:51:31,052:INFO:_master_model_container: 28
2025-03-19 15:51:31,052:INFO:_display_container: 12
2025-03-19 15:51:31,067:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.2766388144302898,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=6,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=19,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))])
2025-03-19 15:51:31,067:INFO:finalize_model() successfully completed......................................
2025-03-19 15:51:31,159:INFO:Initializing predict_model()
2025-03-19 15:51:31,159:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.2766388144302898,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=6,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=19,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975BF0670>)
2025-03-19 15:51:31,159:INFO:Checking exceptions
2025-03-19 15:51:31,159:INFO:Preloading libraries
2025-03-19 15:51:31,160:INFO:Set up data.
2025-03-19 15:51:31,164:INFO:Set up index.
2025-03-19 15:51:31,283:INFO:Initializing predict_model()
2025-03-19 15:51:31,283:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B96EAD93A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.2766388144302898,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=6,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=19,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B975BF0670>)
2025-03-19 15:51:31,283:INFO:Checking exceptions
2025-03-19 15:51:31,283:INFO:Preloading libraries
2025-03-19 15:51:31,285:INFO:Set up data.
2025-03-19 15:51:31,291:INFO:Set up index.
2025-03-19 15:51:31,421:INFO:Initializing save_model()
2025-03-19 15:51:31,421:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.2766388144302898,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=6,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=19,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]), model_name=msw_stacked_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-19 15:51:31,421:INFO:Adding model into prep_pipe
2025-03-19 15:51:31,421:WARNING:Only Model saved as it was a pipeline.
2025-03-19 15:51:31,428:INFO:msw_stacked_model.pkl saved in current working directory
2025-03-19 15:51:31,445:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.2766388144302898,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=6,
                                                           max_leaves=None,
                                                           min_child_weight=4,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=19,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))])
2025-03-19 15:51:31,445:INFO:save_model() successfully completed......................................
2025-03-19 15:52:34,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:52:34,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:52:34,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:52:34,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 15:52:34,826:INFO:PyCaret RegressionExperiment
2025-03-19 15:52:34,826:INFO:Logging name: msw_prediction
2025-03-19 15:52:34,826:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-19 15:52:34,826:INFO:version 3.2.0
2025-03-19 15:52:34,826:INFO:Initializing setup()
2025-03-19 15:52:34,826:INFO:self.USI: 1354
2025-03-19 15:52:34,826:INFO:self._variable_keys: {'pipeline', 'gpu_param', 'X_train', 'log_plots_param', 'USI', 'exp_name_log', '_available_plots', 'y', 'fold_generator', 'X_test', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'target_param', 'transform_target_param', 'y_train', 'idx', 'memory', 'X', 'fold_groups_param', 'n_jobs_param', 'data'}
2025-03-19 15:52:34,826:INFO:Checking environment
2025-03-19 15:52:34,826:INFO:python_version: 3.8.20
2025-03-19 15:52:34,826:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-19 15:52:34,826:INFO:machine: AMD64
2025-03-19 15:52:34,826:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-19 15:52:34,832:INFO:Memory: svmem(total=68447973376, available=43054190592, percent=37.1, used=25393782784, free=43054190592)
2025-03-19 15:52:34,832:INFO:Physical Core: 24
2025-03-19 15:52:34,832:INFO:Logical Core: 32
2025-03-19 15:52:34,832:INFO:Checking libraries
2025-03-19 15:52:34,832:INFO:System:
2025-03-19 15:52:34,832:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-19 15:52:34,832:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-19 15:52:34,832:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-19 15:52:34,832:INFO:PyCaret required dependencies:
2025-03-19 15:52:35,373:INFO:                 pip: 24.2
2025-03-19 15:52:35,373:INFO:          setuptools: 75.1.0
2025-03-19 15:52:35,373:INFO:             pycaret: 3.2.0
2025-03-19 15:52:35,373:INFO:             IPython: 8.12.3
2025-03-19 15:52:35,373:INFO:          ipywidgets: 8.1.5
2025-03-19 15:52:35,373:INFO:                tqdm: 4.67.1
2025-03-19 15:52:35,373:INFO:               numpy: 1.24.4
2025-03-19 15:52:35,373:INFO:              pandas: 1.5.3
2025-03-19 15:52:35,373:INFO:              jinja2: 3.1.4
2025-03-19 15:52:35,373:INFO:               scipy: 1.10.1
2025-03-19 15:52:35,373:INFO:              joblib: 1.3.2
2025-03-19 15:52:35,373:INFO:             sklearn: 1.2.2
2025-03-19 15:52:35,373:INFO:                pyod: 2.0.2
2025-03-19 15:52:35,373:INFO:            imblearn: 0.12.4
2025-03-19 15:52:35,373:INFO:   category_encoders: 2.6.4
2025-03-19 15:52:35,373:INFO:            lightgbm: 4.5.0
2025-03-19 15:52:35,373:INFO:               numba: 0.58.1
2025-03-19 15:52:35,373:INFO:            requests: 2.32.3
2025-03-19 15:52:35,373:INFO:          matplotlib: 3.6.0
2025-03-19 15:52:35,373:INFO:          scikitplot: 0.3.7
2025-03-19 15:52:35,373:INFO:         yellowbrick: 1.5
2025-03-19 15:52:35,373:INFO:              plotly: 5.24.1
2025-03-19 15:52:35,373:INFO:    plotly-resampler: Not installed
2025-03-19 15:52:35,373:INFO:             kaleido: 0.2.1
2025-03-19 15:52:35,373:INFO:           schemdraw: 0.15
2025-03-19 15:52:35,373:INFO:         statsmodels: 0.14.1
2025-03-19 15:52:35,373:INFO:              sktime: 0.21.1
2025-03-19 15:52:35,373:INFO:               tbats: 1.1.3
2025-03-19 15:52:35,373:INFO:            pmdarima: 2.0.4
2025-03-19 15:52:35,373:INFO:              psutil: 6.1.0
2025-03-19 15:52:35,373:INFO:          markupsafe: 2.1.5
2025-03-19 15:52:35,373:INFO:             pickle5: Not installed
2025-03-19 15:52:35,373:INFO:         cloudpickle: 2.2.1
2025-03-19 15:52:35,373:INFO:         deprecation: 2.1.0
2025-03-19 15:52:35,373:INFO:              xxhash: 3.5.0
2025-03-19 15:52:35,373:INFO:           wurlitzer: Not installed
2025-03-19 15:52:35,373:INFO:PyCaret optional dependencies:
2025-03-19 15:52:36,714:INFO:                shap: 0.44.1
2025-03-19 15:52:36,714:INFO:           interpret: 0.6.6
2025-03-19 15:52:36,714:INFO:                umap: 0.5.7
2025-03-19 15:52:36,714:INFO:     ydata_profiling: 4.6.0
2025-03-19 15:52:36,714:INFO:  explainerdashboard: 0.4.7
2025-03-19 15:52:36,714:INFO:             autoviz: Not installed
2025-03-19 15:52:36,714:INFO:           fairlearn: 0.7.0
2025-03-19 15:52:36,714:INFO:          deepchecks: Not installed
2025-03-19 15:52:36,714:INFO:             xgboost: 2.1.3
2025-03-19 15:52:36,714:INFO:            catboost: 1.2.7
2025-03-19 15:52:36,714:INFO:              kmodes: 0.12.2
2025-03-19 15:52:36,714:INFO:             mlxtend: 0.23.1
2025-03-19 15:52:36,714:INFO:       statsforecast: 1.5.0
2025-03-19 15:52:36,714:INFO:        tune_sklearn: 0.5.0
2025-03-19 15:52:36,714:INFO:                 ray: 2.10.0
2025-03-19 15:52:36,714:INFO:            hyperopt: 0.2.7
2025-03-19 15:52:36,714:INFO:              optuna: 4.1.0
2025-03-19 15:52:36,714:INFO:               skopt: 0.10.2
2025-03-19 15:52:36,714:INFO:              mlflow: 1.30.1
2025-03-19 15:52:36,715:INFO:              gradio: 3.50.2
2025-03-19 15:52:36,715:INFO:             fastapi: 0.115.5
2025-03-19 15:52:36,715:INFO:             uvicorn: 0.32.1
2025-03-19 15:52:36,715:INFO:              m2cgen: 0.10.0
2025-03-19 15:52:36,715:INFO:           evidently: 0.2.8
2025-03-19 15:52:36,715:INFO:               fugue: 0.8.6
2025-03-19 15:52:36,715:INFO:           streamlit: Not installed
2025-03-19 15:52:36,715:INFO:             prophet: Not installed
2025-03-19 15:52:36,715:INFO:None
2025-03-19 15:52:36,715:INFO:Set up data.
2025-03-19 15:52:36,719:INFO:Set up folding strategy.
2025-03-19 15:52:36,719:INFO:Set up train/test split.
2025-03-19 15:52:36,720:INFO:Set up data.
2025-03-19 15:52:36,723:INFO:Set up index.
2025-03-19 15:52:36,723:INFO:Assigning column types.
2025-03-19 15:52:36,725:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-19 15:52:36,725:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,727:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,773:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:36,774:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:36,784:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,786:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,831:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:36,832:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:36,832:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-19 15:52:36,834:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,879:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:36,880:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:36,882:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,884:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,929:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:36,930:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:36,930:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-19 15:52:36,934:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:36,978:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:36,979:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:36,983:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,026:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,027:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,028:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-19 15:52:37,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,075:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,076:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,105:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,124:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,124:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,125:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,126:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-19 15:52:37,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,173:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,174:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 15:52:37,221:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,223:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,223:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-19 15:52:37,270:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,271:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,318:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,319:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,320:INFO:Preparing preprocessing pipeline...
2025-03-19 15:52:37,320:INFO:Set up simple imputation.
2025-03-19 15:52:37,321:INFO:Set up encoding of categorical features.
2025-03-19 15:52:37,322:INFO:Set up feature normalization.
2025-03-19 15:52:37,322:INFO:Set up column name cleaning.
2025-03-19 15:52:37,362:INFO:Finished creating preprocessing pipeline.
2025-03-19 15:52:37,366:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 15:52:37,366:INFO:Creating final display dataframe.
2025-03-19 15:52:37,474:INFO:Setup _display_container:                     Description            Value
0                    Session id              456
1                        Target          MSW_log
2                   Target type       Regression
3           Original data shape       (1755, 19)
4        Transformed data shape       (1755, 28)
5   Transformed train set shape       (1483, 28)
6    Transformed test set shape        (272, 28)
7              Numeric features               16
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15                    Normalize             True
16             Normalize method           minmax
17               Fold Generator  TimeSeriesSplit
18                  Fold Number                5
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name   msw_prediction
23                          USI             1354
2025-03-19 15:52:37,529:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,530:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,579:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:52:37,581:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 15:52:37,581:INFO:Logging experiment in loggers
2025-03-19 15:52:37,719:INFO:SubProcess save_model() called ==================================
2025-03-19 15:52:37,727:INFO:Initializing save_model()
2025-03-19 15:52:37,727:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmpuesab9y9\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-19 15:52:37,727:INFO:Adding model into prep_pipe
2025-03-19 15:52:37,727:WARNING:Only Model saved as it was a pipeline.
2025-03-19 15:52:37,731:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmpuesab9y9\Transformation Pipeline.pkl saved in current working directory
2025-03-19 15:52:37,735:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 15:52:37,735:INFO:save_model() successfully completed......................................
2025-03-19 15:52:37,794:INFO:SubProcess save_model() end ==================================
2025-03-19 15:52:37,799:INFO:setup() successfully completed in 2.76s...............
2025-03-19 15:52:37,799:INFO:Initializing compare_models()
2025-03-19 15:52:37,799:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, include=None, fold=None, round=4, cross_validation=True, sort=mape, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'mape', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-19 15:52:37,799:INFO:Checking exceptions
2025-03-19 15:52:37,800:INFO:Preparing display monitor
2025-03-19 15:52:37,813:INFO:Initializing Linear Regression
2025-03-19 15:52:37,813:INFO:Total runtime is 0.0 minutes
2025-03-19 15:52:37,815:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:37,815:INFO:Initializing create_model()
2025-03-19 15:52:37,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:37,815:INFO:Checking exceptions
2025-03-19 15:52:37,815:INFO:Importing libraries
2025-03-19 15:52:37,815:INFO:Copying training dataset
2025-03-19 15:52:37,816:INFO:Defining folds
2025-03-19 15:52:37,816:INFO:Declaring metric variables
2025-03-19 15:52:37,818:INFO:Importing untrained model
2025-03-19 15:52:37,821:INFO:Linear Regression Imported successfully
2025-03-19 15:52:37,824:INFO:Starting cross validation
2025-03-19 15:52:37,827:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:40,282:INFO:Calculating mean and std
2025-03-19 15:52:40,283:INFO:Creating metrics dataframe
2025-03-19 15:52:40,286:INFO:Uploading results into container
2025-03-19 15:52:40,286:INFO:Uploading model into container now
2025-03-19 15:52:40,286:INFO:_master_model_container: 1
2025-03-19 15:52:40,287:INFO:_display_container: 2
2025-03-19 15:52:40,287:INFO:LinearRegression(n_jobs=-1)
2025-03-19 15:52:40,287:INFO:create_model() successfully completed......................................
2025-03-19 15:52:40,343:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:40,343:INFO:Creating metrics dataframe
2025-03-19 15:52:40,348:INFO:Initializing Lasso Regression
2025-03-19 15:52:40,348:INFO:Total runtime is 0.04224973519643148 minutes
2025-03-19 15:52:40,349:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:40,349:INFO:Initializing create_model()
2025-03-19 15:52:40,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:40,349:INFO:Checking exceptions
2025-03-19 15:52:40,349:INFO:Importing libraries
2025-03-19 15:52:40,349:INFO:Copying training dataset
2025-03-19 15:52:40,351:INFO:Defining folds
2025-03-19 15:52:40,351:INFO:Declaring metric variables
2025-03-19 15:52:40,353:INFO:Importing untrained model
2025-03-19 15:52:40,354:INFO:Lasso Regression Imported successfully
2025-03-19 15:52:40,357:INFO:Starting cross validation
2025-03-19 15:52:40,358:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:42,361:INFO:Calculating mean and std
2025-03-19 15:52:42,362:INFO:Creating metrics dataframe
2025-03-19 15:52:42,364:INFO:Uploading results into container
2025-03-19 15:52:42,364:INFO:Uploading model into container now
2025-03-19 15:52:42,365:INFO:_master_model_container: 2
2025-03-19 15:52:42,365:INFO:_display_container: 2
2025-03-19 15:52:42,365:INFO:Lasso(random_state=456)
2025-03-19 15:52:42,365:INFO:create_model() successfully completed......................................
2025-03-19 15:52:42,426:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:42,426:INFO:Creating metrics dataframe
2025-03-19 15:52:42,430:INFO:Initializing Ridge Regression
2025-03-19 15:52:42,430:INFO:Total runtime is 0.07695846954981486 minutes
2025-03-19 15:52:42,432:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:42,432:INFO:Initializing create_model()
2025-03-19 15:52:42,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:42,432:INFO:Checking exceptions
2025-03-19 15:52:42,432:INFO:Importing libraries
2025-03-19 15:52:42,432:INFO:Copying training dataset
2025-03-19 15:52:42,434:INFO:Defining folds
2025-03-19 15:52:42,434:INFO:Declaring metric variables
2025-03-19 15:52:42,434:INFO:Importing untrained model
2025-03-19 15:52:42,436:INFO:Ridge Regression Imported successfully
2025-03-19 15:52:42,440:INFO:Starting cross validation
2025-03-19 15:52:42,440:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:44,486:INFO:Calculating mean and std
2025-03-19 15:52:44,486:INFO:Creating metrics dataframe
2025-03-19 15:52:44,488:INFO:Uploading results into container
2025-03-19 15:52:44,488:INFO:Uploading model into container now
2025-03-19 15:52:44,489:INFO:_master_model_container: 3
2025-03-19 15:52:44,489:INFO:_display_container: 2
2025-03-19 15:52:44,489:INFO:Ridge(random_state=456)
2025-03-19 15:52:44,489:INFO:create_model() successfully completed......................................
2025-03-19 15:52:44,549:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:44,549:INFO:Creating metrics dataframe
2025-03-19 15:52:44,554:INFO:Initializing Elastic Net
2025-03-19 15:52:44,554:INFO:Total runtime is 0.11235420306523641 minutes
2025-03-19 15:52:44,555:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:44,556:INFO:Initializing create_model()
2025-03-19 15:52:44,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:44,556:INFO:Checking exceptions
2025-03-19 15:52:44,556:INFO:Importing libraries
2025-03-19 15:52:44,556:INFO:Copying training dataset
2025-03-19 15:52:44,558:INFO:Defining folds
2025-03-19 15:52:44,558:INFO:Declaring metric variables
2025-03-19 15:52:44,559:INFO:Importing untrained model
2025-03-19 15:52:44,561:INFO:Elastic Net Imported successfully
2025-03-19 15:52:44,564:INFO:Starting cross validation
2025-03-19 15:52:44,565:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:46,641:INFO:Calculating mean and std
2025-03-19 15:52:46,642:INFO:Creating metrics dataframe
2025-03-19 15:52:46,644:INFO:Uploading results into container
2025-03-19 15:52:46,645:INFO:Uploading model into container now
2025-03-19 15:52:46,645:INFO:_master_model_container: 4
2025-03-19 15:52:46,645:INFO:_display_container: 2
2025-03-19 15:52:46,645:INFO:ElasticNet(random_state=456)
2025-03-19 15:52:46,645:INFO:create_model() successfully completed......................................
2025-03-19 15:52:46,715:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:46,715:INFO:Creating metrics dataframe
2025-03-19 15:52:46,720:INFO:Initializing Least Angle Regression
2025-03-19 15:52:46,720:INFO:Total runtime is 0.14845349391301474 minutes
2025-03-19 15:52:46,722:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:46,722:INFO:Initializing create_model()
2025-03-19 15:52:46,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:46,722:INFO:Checking exceptions
2025-03-19 15:52:46,722:INFO:Importing libraries
2025-03-19 15:52:46,722:INFO:Copying training dataset
2025-03-19 15:52:46,724:INFO:Defining folds
2025-03-19 15:52:46,724:INFO:Declaring metric variables
2025-03-19 15:52:46,725:INFO:Importing untrained model
2025-03-19 15:52:46,727:INFO:Least Angle Regression Imported successfully
2025-03-19 15:52:46,731:INFO:Starting cross validation
2025-03-19 15:52:46,731:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:48,741:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.720e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-19 15:52:48,744:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.391e-02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-19 15:52:48,765:INFO:Calculating mean and std
2025-03-19 15:52:48,766:INFO:Creating metrics dataframe
2025-03-19 15:52:48,768:INFO:Uploading results into container
2025-03-19 15:52:48,768:INFO:Uploading model into container now
2025-03-19 15:52:48,768:INFO:_master_model_container: 5
2025-03-19 15:52:48,769:INFO:_display_container: 2
2025-03-19 15:52:48,769:INFO:Lars(random_state=456)
2025-03-19 15:52:48,769:INFO:create_model() successfully completed......................................
2025-03-19 15:52:48,827:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:48,827:INFO:Creating metrics dataframe
2025-03-19 15:52:48,832:INFO:Initializing Lasso Least Angle Regression
2025-03-19 15:52:48,832:INFO:Total runtime is 0.18365884224573772 minutes
2025-03-19 15:52:48,834:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:48,834:INFO:Initializing create_model()
2025-03-19 15:52:48,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:48,834:INFO:Checking exceptions
2025-03-19 15:52:48,834:INFO:Importing libraries
2025-03-19 15:52:48,834:INFO:Copying training dataset
2025-03-19 15:52:48,836:INFO:Defining folds
2025-03-19 15:52:48,836:INFO:Declaring metric variables
2025-03-19 15:52:48,837:INFO:Importing untrained model
2025-03-19 15:52:48,839:INFO:Lasso Least Angle Regression Imported successfully
2025-03-19 15:52:48,841:INFO:Starting cross validation
2025-03-19 15:52:48,842:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:50,798:INFO:Calculating mean and std
2025-03-19 15:52:50,799:INFO:Creating metrics dataframe
2025-03-19 15:52:50,800:INFO:Uploading results into container
2025-03-19 15:52:50,801:INFO:Uploading model into container now
2025-03-19 15:52:50,801:INFO:_master_model_container: 6
2025-03-19 15:52:50,801:INFO:_display_container: 2
2025-03-19 15:52:50,801:INFO:LassoLars(random_state=456)
2025-03-19 15:52:50,801:INFO:create_model() successfully completed......................................
2025-03-19 15:52:50,862:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:50,862:INFO:Creating metrics dataframe
2025-03-19 15:52:50,867:INFO:Initializing Orthogonal Matching Pursuit
2025-03-19 15:52:50,867:INFO:Total runtime is 0.21758112907409669 minutes
2025-03-19 15:52:50,869:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:50,869:INFO:Initializing create_model()
2025-03-19 15:52:50,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:50,869:INFO:Checking exceptions
2025-03-19 15:52:50,869:INFO:Importing libraries
2025-03-19 15:52:50,869:INFO:Copying training dataset
2025-03-19 15:52:50,871:INFO:Defining folds
2025-03-19 15:52:50,871:INFO:Declaring metric variables
2025-03-19 15:52:50,873:INFO:Importing untrained model
2025-03-19 15:52:50,874:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-19 15:52:50,877:INFO:Starting cross validation
2025-03-19 15:52:50,878:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:52,491:INFO:Calculating mean and std
2025-03-19 15:52:52,492:INFO:Creating metrics dataframe
2025-03-19 15:52:52,494:INFO:Uploading results into container
2025-03-19 15:52:52,494:INFO:Uploading model into container now
2025-03-19 15:52:52,495:INFO:_master_model_container: 7
2025-03-19 15:52:52,495:INFO:_display_container: 2
2025-03-19 15:52:52,495:INFO:OrthogonalMatchingPursuit()
2025-03-19 15:52:52,495:INFO:create_model() successfully completed......................................
2025-03-19 15:52:52,550:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:52,550:INFO:Creating metrics dataframe
2025-03-19 15:52:52,555:INFO:Initializing Bayesian Ridge
2025-03-19 15:52:52,555:INFO:Total runtime is 0.24570077260335288 minutes
2025-03-19 15:52:52,556:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:52,556:INFO:Initializing create_model()
2025-03-19 15:52:52,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:52,557:INFO:Checking exceptions
2025-03-19 15:52:52,557:INFO:Importing libraries
2025-03-19 15:52:52,557:INFO:Copying training dataset
2025-03-19 15:52:52,559:INFO:Defining folds
2025-03-19 15:52:52,559:INFO:Declaring metric variables
2025-03-19 15:52:52,560:INFO:Importing untrained model
2025-03-19 15:52:52,562:INFO:Bayesian Ridge Imported successfully
2025-03-19 15:52:52,565:INFO:Starting cross validation
2025-03-19 15:52:52,565:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:52,630:INFO:Calculating mean and std
2025-03-19 15:52:52,631:INFO:Creating metrics dataframe
2025-03-19 15:52:52,633:INFO:Uploading results into container
2025-03-19 15:52:52,633:INFO:Uploading model into container now
2025-03-19 15:52:52,634:INFO:_master_model_container: 8
2025-03-19 15:52:52,634:INFO:_display_container: 2
2025-03-19 15:52:52,634:INFO:BayesianRidge()
2025-03-19 15:52:52,634:INFO:create_model() successfully completed......................................
2025-03-19 15:52:52,686:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:52,686:INFO:Creating metrics dataframe
2025-03-19 15:52:52,691:INFO:Initializing Passive Aggressive Regressor
2025-03-19 15:52:52,691:INFO:Total runtime is 0.24796887636184695 minutes
2025-03-19 15:52:52,693:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:52,693:INFO:Initializing create_model()
2025-03-19 15:52:52,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:52,693:INFO:Checking exceptions
2025-03-19 15:52:52,693:INFO:Importing libraries
2025-03-19 15:52:52,693:INFO:Copying training dataset
2025-03-19 15:52:52,695:INFO:Defining folds
2025-03-19 15:52:52,695:INFO:Declaring metric variables
2025-03-19 15:52:52,696:INFO:Importing untrained model
2025-03-19 15:52:52,698:INFO:Passive Aggressive Regressor Imported successfully
2025-03-19 15:52:52,701:INFO:Starting cross validation
2025-03-19 15:52:52,701:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:52,769:INFO:Calculating mean and std
2025-03-19 15:52:52,770:INFO:Creating metrics dataframe
2025-03-19 15:52:52,771:INFO:Uploading results into container
2025-03-19 15:52:52,772:INFO:Uploading model into container now
2025-03-19 15:52:52,772:INFO:_master_model_container: 9
2025-03-19 15:52:52,772:INFO:_display_container: 2
2025-03-19 15:52:52,772:INFO:PassiveAggressiveRegressor(random_state=456)
2025-03-19 15:52:52,772:INFO:create_model() successfully completed......................................
2025-03-19 15:52:52,823:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:52,823:INFO:Creating metrics dataframe
2025-03-19 15:52:52,828:INFO:Initializing Huber Regressor
2025-03-19 15:52:52,828:INFO:Total runtime is 0.25026175578435267 minutes
2025-03-19 15:52:52,830:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:52,830:INFO:Initializing create_model()
2025-03-19 15:52:52,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:52,830:INFO:Checking exceptions
2025-03-19 15:52:52,830:INFO:Importing libraries
2025-03-19 15:52:52,830:INFO:Copying training dataset
2025-03-19 15:52:52,832:INFO:Defining folds
2025-03-19 15:52:52,832:INFO:Declaring metric variables
2025-03-19 15:52:52,834:INFO:Importing untrained model
2025-03-19 15:52:52,835:INFO:Huber Regressor Imported successfully
2025-03-19 15:52:52,838:INFO:Starting cross validation
2025-03-19 15:52:52,839:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:52,873:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:52:52,876:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:52:52,879:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:52:52,882:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:52:52,886:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-19 15:52:52,907:INFO:Calculating mean and std
2025-03-19 15:52:52,908:INFO:Creating metrics dataframe
2025-03-19 15:52:52,910:INFO:Uploading results into container
2025-03-19 15:52:52,910:INFO:Uploading model into container now
2025-03-19 15:52:52,910:INFO:_master_model_container: 10
2025-03-19 15:52:52,910:INFO:_display_container: 2
2025-03-19 15:52:52,910:INFO:HuberRegressor()
2025-03-19 15:52:52,910:INFO:create_model() successfully completed......................................
2025-03-19 15:52:52,965:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:52,965:INFO:Creating metrics dataframe
2025-03-19 15:52:52,971:INFO:Initializing K Neighbors Regressor
2025-03-19 15:52:52,971:INFO:Total runtime is 0.25263748168945316 minutes
2025-03-19 15:52:52,972:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:52,973:INFO:Initializing create_model()
2025-03-19 15:52:52,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:52,973:INFO:Checking exceptions
2025-03-19 15:52:52,973:INFO:Importing libraries
2025-03-19 15:52:52,973:INFO:Copying training dataset
2025-03-19 15:52:52,974:INFO:Defining folds
2025-03-19 15:52:52,974:INFO:Declaring metric variables
2025-03-19 15:52:52,976:INFO:Importing untrained model
2025-03-19 15:52:52,977:INFO:K Neighbors Regressor Imported successfully
2025-03-19 15:52:52,980:INFO:Starting cross validation
2025-03-19 15:52:52,981:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:53,077:INFO:Calculating mean and std
2025-03-19 15:52:53,078:INFO:Creating metrics dataframe
2025-03-19 15:52:53,079:INFO:Uploading results into container
2025-03-19 15:52:53,080:INFO:Uploading model into container now
2025-03-19 15:52:53,080:INFO:_master_model_container: 11
2025-03-19 15:52:53,080:INFO:_display_container: 2
2025-03-19 15:52:53,080:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-19 15:52:53,080:INFO:create_model() successfully completed......................................
2025-03-19 15:52:53,135:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:53,135:INFO:Creating metrics dataframe
2025-03-19 15:52:53,140:INFO:Initializing Decision Tree Regressor
2025-03-19 15:52:53,140:INFO:Total runtime is 0.25546019474665327 minutes
2025-03-19 15:52:53,142:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:53,142:INFO:Initializing create_model()
2025-03-19 15:52:53,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:53,142:INFO:Checking exceptions
2025-03-19 15:52:53,142:INFO:Importing libraries
2025-03-19 15:52:53,142:INFO:Copying training dataset
2025-03-19 15:52:53,144:INFO:Defining folds
2025-03-19 15:52:53,144:INFO:Declaring metric variables
2025-03-19 15:52:53,146:INFO:Importing untrained model
2025-03-19 15:52:53,147:INFO:Decision Tree Regressor Imported successfully
2025-03-19 15:52:53,150:INFO:Starting cross validation
2025-03-19 15:52:53,151:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:53,231:INFO:Calculating mean and std
2025-03-19 15:52:53,232:INFO:Creating metrics dataframe
2025-03-19 15:52:53,233:INFO:Uploading results into container
2025-03-19 15:52:53,234:INFO:Uploading model into container now
2025-03-19 15:52:53,234:INFO:_master_model_container: 12
2025-03-19 15:52:53,234:INFO:_display_container: 2
2025-03-19 15:52:53,234:INFO:DecisionTreeRegressor(random_state=456)
2025-03-19 15:52:53,234:INFO:create_model() successfully completed......................................
2025-03-19 15:52:53,292:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:53,292:INFO:Creating metrics dataframe
2025-03-19 15:52:53,297:INFO:Initializing Random Forest Regressor
2025-03-19 15:52:53,297:INFO:Total runtime is 0.2580759684244792 minutes
2025-03-19 15:52:53,299:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:53,299:INFO:Initializing create_model()
2025-03-19 15:52:53,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:53,299:INFO:Checking exceptions
2025-03-19 15:52:53,299:INFO:Importing libraries
2025-03-19 15:52:53,299:INFO:Copying training dataset
2025-03-19 15:52:53,301:INFO:Defining folds
2025-03-19 15:52:53,301:INFO:Declaring metric variables
2025-03-19 15:52:53,303:INFO:Importing untrained model
2025-03-19 15:52:53,304:INFO:Random Forest Regressor Imported successfully
2025-03-19 15:52:53,307:INFO:Starting cross validation
2025-03-19 15:52:53,308:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:53,523:INFO:Calculating mean and std
2025-03-19 15:52:53,524:INFO:Creating metrics dataframe
2025-03-19 15:52:53,526:INFO:Uploading results into container
2025-03-19 15:52:53,526:INFO:Uploading model into container now
2025-03-19 15:52:53,526:INFO:_master_model_container: 13
2025-03-19 15:52:53,526:INFO:_display_container: 2
2025-03-19 15:52:53,527:INFO:RandomForestRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:52:53,527:INFO:create_model() successfully completed......................................
2025-03-19 15:52:53,583:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:53,583:INFO:Creating metrics dataframe
2025-03-19 15:52:53,589:INFO:Initializing Extra Trees Regressor
2025-03-19 15:52:53,589:INFO:Total runtime is 0.2629433035850525 minutes
2025-03-19 15:52:53,591:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:53,591:INFO:Initializing create_model()
2025-03-19 15:52:53,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:53,591:INFO:Checking exceptions
2025-03-19 15:52:53,592:INFO:Importing libraries
2025-03-19 15:52:53,592:INFO:Copying training dataset
2025-03-19 15:52:53,593:INFO:Defining folds
2025-03-19 15:52:53,593:INFO:Declaring metric variables
2025-03-19 15:52:53,595:INFO:Importing untrained model
2025-03-19 15:52:53,597:INFO:Extra Trees Regressor Imported successfully
2025-03-19 15:52:53,600:INFO:Starting cross validation
2025-03-19 15:52:53,601:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:53,769:INFO:Calculating mean and std
2025-03-19 15:52:53,770:INFO:Creating metrics dataframe
2025-03-19 15:52:53,772:INFO:Uploading results into container
2025-03-19 15:52:53,772:INFO:Uploading model into container now
2025-03-19 15:52:53,772:INFO:_master_model_container: 14
2025-03-19 15:52:53,772:INFO:_display_container: 2
2025-03-19 15:52:53,773:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:52:53,773:INFO:create_model() successfully completed......................................
2025-03-19 15:52:53,826:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:53,826:INFO:Creating metrics dataframe
2025-03-19 15:52:53,832:INFO:Initializing AdaBoost Regressor
2025-03-19 15:52:53,832:INFO:Total runtime is 0.266991130510966 minutes
2025-03-19 15:52:53,834:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:53,834:INFO:Initializing create_model()
2025-03-19 15:52:53,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:53,834:INFO:Checking exceptions
2025-03-19 15:52:53,834:INFO:Importing libraries
2025-03-19 15:52:53,834:INFO:Copying training dataset
2025-03-19 15:52:53,836:INFO:Defining folds
2025-03-19 15:52:53,837:INFO:Declaring metric variables
2025-03-19 15:52:53,838:INFO:Importing untrained model
2025-03-19 15:52:53,840:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:52:53,843:INFO:Starting cross validation
2025-03-19 15:52:53,844:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:53,985:INFO:Calculating mean and std
2025-03-19 15:52:53,986:INFO:Creating metrics dataframe
2025-03-19 15:52:53,987:INFO:Uploading results into container
2025-03-19 15:52:53,988:INFO:Uploading model into container now
2025-03-19 15:52:53,988:INFO:_master_model_container: 15
2025-03-19 15:52:53,988:INFO:_display_container: 2
2025-03-19 15:52:53,988:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:52:53,988:INFO:create_model() successfully completed......................................
2025-03-19 15:52:54,047:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:54,047:INFO:Creating metrics dataframe
2025-03-19 15:52:54,053:INFO:Initializing Gradient Boosting Regressor
2025-03-19 15:52:54,053:INFO:Total runtime is 0.27066646416982015 minutes
2025-03-19 15:52:54,054:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:54,054:INFO:Initializing create_model()
2025-03-19 15:52:54,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:54,054:INFO:Checking exceptions
2025-03-19 15:52:54,055:INFO:Importing libraries
2025-03-19 15:52:54,055:INFO:Copying training dataset
2025-03-19 15:52:54,057:INFO:Defining folds
2025-03-19 15:52:54,057:INFO:Declaring metric variables
2025-03-19 15:52:54,058:INFO:Importing untrained model
2025-03-19 15:52:54,060:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:52:54,064:INFO:Starting cross validation
2025-03-19 15:52:54,064:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:54,277:INFO:Calculating mean and std
2025-03-19 15:52:54,278:INFO:Creating metrics dataframe
2025-03-19 15:52:54,280:INFO:Uploading results into container
2025-03-19 15:52:54,280:INFO:Uploading model into container now
2025-03-19 15:52:54,280:INFO:_master_model_container: 16
2025-03-19 15:52:54,280:INFO:_display_container: 2
2025-03-19 15:52:54,280:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:52:54,280:INFO:create_model() successfully completed......................................
2025-03-19 15:52:54,335:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:54,335:INFO:Creating metrics dataframe
2025-03-19 15:52:54,341:INFO:Initializing Extreme Gradient Boosting
2025-03-19 15:52:54,341:INFO:Total runtime is 0.27547584374745687 minutes
2025-03-19 15:52:54,343:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:54,343:INFO:Initializing create_model()
2025-03-19 15:52:54,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:54,343:INFO:Checking exceptions
2025-03-19 15:52:54,343:INFO:Importing libraries
2025-03-19 15:52:54,343:INFO:Copying training dataset
2025-03-19 15:52:54,345:INFO:Defining folds
2025-03-19 15:52:54,345:INFO:Declaring metric variables
2025-03-19 15:52:54,346:INFO:Importing untrained model
2025-03-19 15:52:54,348:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:52:54,351:INFO:Starting cross validation
2025-03-19 15:52:54,351:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:54,662:INFO:Calculating mean and std
2025-03-19 15:52:54,663:INFO:Creating metrics dataframe
2025-03-19 15:52:54,664:INFO:Uploading results into container
2025-03-19 15:52:54,665:INFO:Uploading model into container now
2025-03-19 15:52:54,665:INFO:_master_model_container: 17
2025-03-19 15:52:54,665:INFO:_display_container: 2
2025-03-19 15:52:54,666:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:52:54,666:INFO:create_model() successfully completed......................................
2025-03-19 15:52:54,718:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:54,718:INFO:Creating metrics dataframe
2025-03-19 15:52:54,724:INFO:Initializing Light Gradient Boosting Machine
2025-03-19 15:52:54,724:INFO:Total runtime is 0.28186628421147664 minutes
2025-03-19 15:52:54,727:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:54,727:INFO:Initializing create_model()
2025-03-19 15:52:54,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:54,727:INFO:Checking exceptions
2025-03-19 15:52:54,727:INFO:Importing libraries
2025-03-19 15:52:54,727:INFO:Copying training dataset
2025-03-19 15:52:54,730:INFO:Defining folds
2025-03-19 15:52:54,730:INFO:Declaring metric variables
2025-03-19 15:52:54,731:INFO:Importing untrained model
2025-03-19 15:52:54,733:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:52:54,737:INFO:Starting cross validation
2025-03-19 15:52:54,738:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:55,217:INFO:Calculating mean and std
2025-03-19 15:52:55,218:INFO:Creating metrics dataframe
2025-03-19 15:52:55,220:INFO:Uploading results into container
2025-03-19 15:52:55,220:INFO:Uploading model into container now
2025-03-19 15:52:55,221:INFO:_master_model_container: 18
2025-03-19 15:52:55,221:INFO:_display_container: 2
2025-03-19 15:52:55,221:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:52:55,221:INFO:create_model() successfully completed......................................
2025-03-19 15:52:55,285:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:55,285:INFO:Creating metrics dataframe
2025-03-19 15:52:55,294:INFO:Initializing CatBoost Regressor
2025-03-19 15:52:55,295:INFO:Total runtime is 0.2913691441218058 minutes
2025-03-19 15:52:55,297:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:55,297:INFO:Initializing create_model()
2025-03-19 15:52:55,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=catboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:55,297:INFO:Checking exceptions
2025-03-19 15:52:55,297:INFO:Importing libraries
2025-03-19 15:52:55,298:INFO:Copying training dataset
2025-03-19 15:52:55,300:INFO:Defining folds
2025-03-19 15:52:55,300:INFO:Declaring metric variables
2025-03-19 15:52:55,303:INFO:Importing untrained model
2025-03-19 15:52:55,305:INFO:CatBoost Regressor Imported successfully
2025-03-19 15:52:55,309:INFO:Starting cross validation
2025-03-19 15:52:55,310:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:56,879:INFO:Calculating mean and std
2025-03-19 15:52:56,880:INFO:Creating metrics dataframe
2025-03-19 15:52:56,881:INFO:Uploading results into container
2025-03-19 15:52:56,882:INFO:Uploading model into container now
2025-03-19 15:52:56,882:INFO:_master_model_container: 19
2025-03-19 15:52:56,882:INFO:_display_container: 2
2025-03-19 15:52:56,882:INFO:<catboost.core.CatBoostRegressor object at 0x000001F89AA9D310>
2025-03-19 15:52:56,882:INFO:create_model() successfully completed......................................
2025-03-19 15:52:56,935:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:56,935:INFO:Creating metrics dataframe
2025-03-19 15:52:56,942:INFO:Initializing Dummy Regressor
2025-03-19 15:52:56,942:INFO:Total runtime is 0.3188173214594523 minutes
2025-03-19 15:52:56,944:INFO:SubProcess create_model() called ==================================
2025-03-19 15:52:56,944:INFO:Initializing create_model()
2025-03-19 15:52:56,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A6D3220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:56,944:INFO:Checking exceptions
2025-03-19 15:52:56,944:INFO:Importing libraries
2025-03-19 15:52:56,944:INFO:Copying training dataset
2025-03-19 15:52:56,946:INFO:Defining folds
2025-03-19 15:52:56,946:INFO:Declaring metric variables
2025-03-19 15:52:56,947:INFO:Importing untrained model
2025-03-19 15:52:56,949:INFO:Dummy Regressor Imported successfully
2025-03-19 15:52:56,951:INFO:Starting cross validation
2025-03-19 15:52:56,952:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:52:57,018:INFO:Calculating mean and std
2025-03-19 15:52:57,019:INFO:Creating metrics dataframe
2025-03-19 15:52:57,020:INFO:Uploading results into container
2025-03-19 15:52:57,021:INFO:Uploading model into container now
2025-03-19 15:52:57,021:INFO:_master_model_container: 20
2025-03-19 15:52:57,021:INFO:_display_container: 2
2025-03-19 15:52:57,021:INFO:DummyRegressor()
2025-03-19 15:52:57,021:INFO:create_model() successfully completed......................................
2025-03-19 15:52:57,071:INFO:SubProcess create_model() end ==================================
2025-03-19 15:52:57,071:INFO:Creating metrics dataframe
2025-03-19 15:52:57,082:INFO:Initializing create_model()
2025-03-19 15:52:57,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:57,082:INFO:Checking exceptions
2025-03-19 15:52:57,083:INFO:Importing libraries
2025-03-19 15:52:57,083:INFO:Copying training dataset
2025-03-19 15:52:57,085:INFO:Defining folds
2025-03-19 15:52:57,085:INFO:Declaring metric variables
2025-03-19 15:52:57,085:INFO:Importing untrained model
2025-03-19 15:52:57,085:INFO:Declaring custom model
2025-03-19 15:52:57,085:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:52:57,086:INFO:Cross validation set to False
2025-03-19 15:52:57,086:INFO:Fitting Model
2025-03-19 15:52:57,293:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:52:57,293:INFO:create_model() successfully completed......................................
2025-03-19 15:52:57,348:INFO:Creating Dashboard logs
2025-03-19 15:52:57,350:INFO:Model: Gradient Boosting Regressor
2025-03-19 15:52:57,367:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 456, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:52:57,403:INFO:Initializing predict_model()
2025-03-19 15:52:57,403:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=GradientBoostingRegressor(random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A8560D0>)
2025-03-19 15:52:57,404:INFO:Checking exceptions
2025-03-19 15:52:57,404:INFO:Preloading libraries
2025-03-19 15:52:57,520:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\_distutils_hack\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-03-19 15:52:57,534:ERROR:_log_model() for GradientBoostingRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:57,537:INFO:Initializing create_model()
2025-03-19 15:52:57,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:57,537:INFO:Checking exceptions
2025-03-19 15:52:57,538:INFO:Importing libraries
2025-03-19 15:52:57,538:INFO:Copying training dataset
2025-03-19 15:52:57,540:INFO:Defining folds
2025-03-19 15:52:57,540:INFO:Declaring metric variables
2025-03-19 15:52:57,540:INFO:Importing untrained model
2025-03-19 15:52:57,540:INFO:Declaring custom model
2025-03-19 15:52:57,540:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:52:57,541:INFO:Cross validation set to False
2025-03-19 15:52:57,541:INFO:Fitting Model
2025-03-19 15:52:57,568:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:52:57,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-03-19 15:52:57,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:52:57,569:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:52:57,569:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:52:57,570:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:52:57,654:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:52:57,654:INFO:create_model() successfully completed......................................
2025-03-19 15:52:57,714:INFO:Creating Dashboard logs
2025-03-19 15:52:57,716:INFO:Model: Light Gradient Boosting Machine
2025-03-19 15:52:57,736:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 456, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-19 15:52:57,782:INFO:Initializing predict_model()
2025-03-19 15:52:57,782:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A3B61F0>)
2025-03-19 15:52:57,782:INFO:Checking exceptions
2025-03-19 15:52:57,782:INFO:Preloading libraries
2025-03-19 15:52:57,927:ERROR:_log_model() for LGBMRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:57,932:INFO:Initializing create_model()
2025-03-19 15:52:57,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:57,932:INFO:Checking exceptions
2025-03-19 15:52:57,933:INFO:Importing libraries
2025-03-19 15:52:57,933:INFO:Copying training dataset
2025-03-19 15:52:57,935:INFO:Defining folds
2025-03-19 15:52:57,936:INFO:Declaring metric variables
2025-03-19 15:52:57,936:INFO:Importing untrained model
2025-03-19 15:52:57,936:INFO:Declaring custom model
2025-03-19 15:52:57,936:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:52:57,937:INFO:Cross validation set to False
2025-03-19 15:52:57,937:INFO:Fitting Model
2025-03-19 15:52:58,096:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:52:58,096:INFO:create_model() successfully completed......................................
2025-03-19 15:52:58,163:INFO:Creating Dashboard logs
2025-03-19 15:52:58,166:INFO:Model: Extreme Gradient Boosting
2025-03-19 15:52:58,187:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 456, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-19 15:52:58,248:INFO:Initializing predict_model()
2025-03-19 15:52:58,248:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F898ED31F0>)
2025-03-19 15:52:58,248:INFO:Checking exceptions
2025-03-19 15:52:58,248:INFO:Preloading libraries
2025-03-19 15:52:58,388:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:58,392:INFO:Initializing create_model()
2025-03-19 15:52:58,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=AdaBoostRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:52:58,392:INFO:Checking exceptions
2025-03-19 15:52:58,393:INFO:Importing libraries
2025-03-19 15:52:58,393:INFO:Copying training dataset
2025-03-19 15:52:58,395:INFO:Defining folds
2025-03-19 15:52:58,396:INFO:Declaring metric variables
2025-03-19 15:52:58,396:INFO:Importing untrained model
2025-03-19 15:52:58,396:INFO:Declaring custom model
2025-03-19 15:52:58,396:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:52:58,397:INFO:Cross validation set to False
2025-03-19 15:52:58,397:INFO:Fitting Model
2025-03-19 15:52:58,518:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:52:58,518:INFO:create_model() successfully completed......................................
2025-03-19 15:52:58,574:INFO:Creating Dashboard logs
2025-03-19 15:52:58,576:INFO:Model: AdaBoost Regressor
2025-03-19 15:52:58,590:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 456}
2025-03-19 15:52:58,643:INFO:Initializing predict_model()
2025-03-19 15:52:58,643:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=AdaBoostRegressor(random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A3B6280>)
2025-03-19 15:52:58,643:INFO:Checking exceptions
2025-03-19 15:52:58,643:INFO:Preloading libraries
2025-03-19 15:52:58,769:ERROR:_log_model() for AdaBoostRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:58,770:INFO:Creating Dashboard logs
2025-03-19 15:52:58,772:INFO:Model: CatBoost Regressor
2025-03-19 15:52:58,788:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\catboost\core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2025-03-19 15:52:58,788:INFO:Logged params: {}
2025-03-19 15:52:58,851:ERROR:_log_model() for <catboost.core.CatBoostRegressor object at 0x000001F89AA9D310> raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:58,851:INFO:Creating Dashboard logs
2025-03-19 15:52:58,853:INFO:Model: Random Forest Regressor
2025-03-19 15:52:58,868:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 456, 'verbose': 0, 'warm_start': False}
2025-03-19 15:52:58,945:ERROR:_log_model() for RandomForestRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:58,946:INFO:Creating Dashboard logs
2025-03-19 15:52:58,948:INFO:Model: Extra Trees Regressor
2025-03-19 15:52:58,961:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 456, 'verbose': 0, 'warm_start': False}
2025-03-19 15:52:59,045:ERROR:_log_model() for ExtraTreesRegressor(n_jobs=-1, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,046:INFO:Creating Dashboard logs
2025-03-19 15:52:59,047:INFO:Model: Decision Tree Regressor
2025-03-19 15:52:59,062:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 456, 'splitter': 'best'}
2025-03-19 15:52:59,146:ERROR:_log_model() for DecisionTreeRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,146:INFO:Creating Dashboard logs
2025-03-19 15:52:59,148:INFO:Model: Orthogonal Matching Pursuit
2025-03-19 15:52:59,163:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2025-03-19 15:52:59,263:ERROR:_log_model() for OrthogonalMatchingPursuit() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,264:INFO:Creating Dashboard logs
2025-03-19 15:52:59,265:INFO:Model: Bayesian Ridge
2025-03-19 15:52:59,281:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2025-03-19 15:52:59,385:ERROR:_log_model() for BayesianRidge() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,386:INFO:Creating Dashboard logs
2025-03-19 15:52:59,388:INFO:Model: Ridge Regression
2025-03-19 15:52:59,403:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 456, 'solver': 'auto', 'tol': 0.0001}
2025-03-19 15:52:59,506:ERROR:_log_model() for Ridge(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,507:INFO:Creating Dashboard logs
2025-03-19 15:52:59,508:INFO:Model: Linear Regression
2025-03-19 15:52:59,523:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-03-19 15:52:59,633:ERROR:_log_model() for LinearRegression(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,634:INFO:Creating Dashboard logs
2025-03-19 15:52:59,637:INFO:Model: Huber Regressor
2025-03-19 15:52:59,653:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-03-19 15:52:59,762:ERROR:_log_model() for HuberRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,763:INFO:Creating Dashboard logs
2025-03-19 15:52:59,764:INFO:Model: K Neighbors Regressor
2025-03-19 15:52:59,778:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-19 15:52:59,893:ERROR:_log_model() for KNeighborsRegressor(n_jobs=-1) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:52:59,894:INFO:Creating Dashboard logs
2025-03-19 15:52:59,896:INFO:Model: Lasso Regression
2025-03-19 15:52:59,910:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 456, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-19 15:53:00,034:ERROR:_log_model() for Lasso(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:53:00,034:INFO:Creating Dashboard logs
2025-03-19 15:53:00,036:INFO:Model: Elastic Net
2025-03-19 15:53:00,051:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 456, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-03-19 15:53:00,179:ERROR:_log_model() for ElasticNet(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:53:00,180:INFO:Creating Dashboard logs
2025-03-19 15:53:00,182:INFO:Model: Lasso Least Angle Regression
2025-03-19 15:53:00,196:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 456, 'verbose': False}
2025-03-19 15:53:00,331:ERROR:_log_model() for LassoLars(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:53:00,332:INFO:Creating Dashboard logs
2025-03-19 15:53:00,334:INFO:Model: Dummy Regressor
2025-03-19 15:53:00,351:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-03-19 15:53:00,488:ERROR:_log_model() for DummyRegressor() raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:53:00,489:INFO:Creating Dashboard logs
2025-03-19 15:53:00,490:INFO:Model: Passive Aggressive Regressor
2025-03-19 15:53:00,505:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 456, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:53:00,654:ERROR:_log_model() for PassiveAggressiveRegressor(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:53:00,654:INFO:Creating Dashboard logs
2025-03-19 15:53:00,656:INFO:Model: Least Angle Regression
2025-03-19 15:53:00,671:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 456, 'verbose': False}
2025-03-19 15:53:00,832:ERROR:_log_model() for Lars(random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:53:00,840:INFO:_master_model_container: 20
2025-03-19 15:53:00,840:INFO:_display_container: 2
2025-03-19 15:53:00,841:INFO:[GradientBoostingRegressor(random_state=456), LGBMRegressor(n_jobs=-1, random_state=456), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), AdaBoostRegressor(random_state=456)]
2025-03-19 15:53:00,841:INFO:compare_models() successfully completed......................................
2025-03-19 15:53:00,864:INFO:Initializing tune_model()
2025-03-19 15:53:00,864:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>)
2025-03-19 15:53:00,864:INFO:Checking exceptions
2025-03-19 15:53:00,864:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:53:00,904:INFO:Copying training dataset
2025-03-19 15:53:00,905:INFO:Checking base model
2025-03-19 15:53:00,905:INFO:Base model : Gradient Boosting Regressor
2025-03-19 15:53:00,907:INFO:Declaring metric variables
2025-03-19 15:53:00,909:INFO:Defining Hyperparameters
2025-03-19 15:53:00,977:INFO:Tuning with n_jobs=-1
2025-03-19 15:53:00,977:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:53:00,977:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:53:00,978:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:53:00,982:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:53:00,982:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:53:00,983:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:53:47,116:INFO:best_params: {'actual_estimator__n_estimators': 167, 'actual_estimator__learning_rate': 0.07267911071803841, 'actual_estimator__subsample': 0.8647484799647367, 'actual_estimator__min_samples_split': 4, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__max_depth': 1, 'actual_estimator__max_features': 0.8188582046293146, 'actual_estimator__min_impurity_decrease': 7.77203776919188e-06}
2025-03-19 15:53:47,120:INFO:Hyperparameter search completed
2025-03-19 15:53:47,120:INFO:SubProcess create_model() called ==================================
2025-03-19 15:53:47,121:INFO:Initializing create_model()
2025-03-19 15:53:47,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A2F8AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 167, 'learning_rate': 0.07267911071803841, 'subsample': 0.8647484799647367, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_depth': 1, 'max_features': 0.8188582046293146, 'min_impurity_decrease': 7.77203776919188e-06})
2025-03-19 15:53:47,121:INFO:Checking exceptions
2025-03-19 15:53:47,121:INFO:Importing libraries
2025-03-19 15:53:47,121:INFO:Copying training dataset
2025-03-19 15:53:47,124:INFO:Defining folds
2025-03-19 15:53:47,124:INFO:Declaring metric variables
2025-03-19 15:53:47,125:INFO:Importing untrained model
2025-03-19 15:53:47,125:INFO:Declaring custom model
2025-03-19 15:53:47,128:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:53:47,131:INFO:Starting cross validation
2025-03-19 15:53:47,132:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:53:47,288:INFO:Calculating mean and std
2025-03-19 15:53:47,289:INFO:Creating metrics dataframe
2025-03-19 15:53:47,291:INFO:Finalizing model
2025-03-19 15:53:47,424:INFO:Uploading results into container
2025-03-19 15:53:47,424:INFO:Uploading model into container now
2025-03-19 15:53:47,424:INFO:_master_model_container: 21
2025-03-19 15:53:47,425:INFO:_display_container: 3
2025-03-19 15:53:47,425:INFO:GradientBoostingRegressor(learning_rate=0.07267911071803841, max_depth=1,
                          max_features=0.8188582046293146,
                          min_impurity_decrease=7.77203776919188e-06,
                          min_samples_leaf=4, min_samples_split=4,
                          n_estimators=167, random_state=456,
                          subsample=0.8647484799647367)
2025-03-19 15:53:47,425:INFO:create_model() successfully completed......................................
2025-03-19 15:53:47,484:INFO:SubProcess create_model() end ==================================
2025-03-19 15:53:47,484:INFO:choose_better activated
2025-03-19 15:53:47,486:INFO:SubProcess create_model() called ==================================
2025-03-19 15:53:47,487:INFO:Initializing create_model()
2025-03-19 15:53:47,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=GradientBoostingRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:53:47,487:INFO:Checking exceptions
2025-03-19 15:53:47,487:INFO:Importing libraries
2025-03-19 15:53:47,488:INFO:Copying training dataset
2025-03-19 15:53:47,489:INFO:Defining folds
2025-03-19 15:53:47,489:INFO:Declaring metric variables
2025-03-19 15:53:47,489:INFO:Importing untrained model
2025-03-19 15:53:47,489:INFO:Declaring custom model
2025-03-19 15:53:47,490:INFO:Gradient Boosting Regressor Imported successfully
2025-03-19 15:53:47,490:INFO:Starting cross validation
2025-03-19 15:53:47,490:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:53:47,719:INFO:Calculating mean and std
2025-03-19 15:53:47,719:INFO:Creating metrics dataframe
2025-03-19 15:53:47,720:INFO:Finalizing model
2025-03-19 15:53:47,928:INFO:Uploading results into container
2025-03-19 15:53:47,928:INFO:Uploading model into container now
2025-03-19 15:53:47,928:INFO:_master_model_container: 22
2025-03-19 15:53:47,928:INFO:_display_container: 4
2025-03-19 15:53:47,928:INFO:GradientBoostingRegressor(random_state=456)
2025-03-19 15:53:47,928:INFO:create_model() successfully completed......................................
2025-03-19 15:53:47,987:INFO:SubProcess create_model() end ==================================
2025-03-19 15:53:47,987:INFO:GradientBoostingRegressor(random_state=456) result for R2 is 0.8404
2025-03-19 15:53:47,988:INFO:GradientBoostingRegressor(learning_rate=0.07267911071803841, max_depth=1,
                          max_features=0.8188582046293146,
                          min_impurity_decrease=7.77203776919188e-06,
                          min_samples_leaf=4, min_samples_split=4,
                          n_estimators=167, random_state=456,
                          subsample=0.8647484799647367) result for R2 is 0.8756
2025-03-19 15:53:47,988:INFO:GradientBoostingRegressor(learning_rate=0.07267911071803841, max_depth=1,
                          max_features=0.8188582046293146,
                          min_impurity_decrease=7.77203776919188e-06,
                          min_samples_leaf=4, min_samples_split=4,
                          n_estimators=167, random_state=456,
                          subsample=0.8647484799647367) is best model
2025-03-19 15:53:47,988:INFO:choose_better completed
2025-03-19 15:53:47,988:INFO:Creating Dashboard logs
2025-03-19 15:53:47,990:INFO:Model: Gradient Boosting Regressor
2025-03-19 15:53:48,006:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.07267911071803841, 'loss': 'squared_error', 'max_depth': 1, 'max_features': 0.8188582046293146, 'max_leaf_nodes': None, 'min_impurity_decrease': 7.77203776919188e-06, 'min_samples_leaf': 4, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 167, 'n_iter_no_change': None, 'random_state': 456, 'subsample': 0.8647484799647367, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-19 15:53:48,169:INFO:Initializing predict_model()
2025-03-19 15:53:48,169:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=GradientBoostingRegressor(learning_rate=0.07267911071803841, max_depth=1,
                          max_features=0.8188582046293146,
                          min_impurity_decrease=7.77203776919188e-06,
                          min_samples_leaf=4, min_samples_split=4,
                          n_estimators=167, random_state=456,
                          subsample=0.8647484799647367), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A436430>)
2025-03-19 15:53:48,169:INFO:Checking exceptions
2025-03-19 15:53:48,169:INFO:Preloading libraries
2025-03-19 15:53:48,306:ERROR:_log_model() for GradientBoostingRegressor(learning_rate=0.07267911071803841, max_depth=1,
                          max_features=0.8188582046293146,
                          min_impurity_decrease=7.77203776919188e-06,
                          min_samples_leaf=4, min_samples_split=4,
                          n_estimators=167, random_state=456,
                          subsample=0.8647484799647367) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:53:48,311:INFO:_master_model_container: 22
2025-03-19 15:53:48,311:INFO:_display_container: 3
2025-03-19 15:53:48,312:INFO:GradientBoostingRegressor(learning_rate=0.07267911071803841, max_depth=1,
                          max_features=0.8188582046293146,
                          min_impurity_decrease=7.77203776919188e-06,
                          min_samples_leaf=4, min_samples_split=4,
                          n_estimators=167, random_state=456,
                          subsample=0.8647484799647367)
2025-03-19 15:53:48,312:INFO:tune_model() successfully completed......................................
2025-03-19 15:53:48,377:INFO:Initializing predict_model()
2025-03-19 15:53:48,377:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=GradientBoostingRegressor(learning_rate=0.07267911071803841, max_depth=1,
                          max_features=0.8188582046293146,
                          min_impurity_decrease=7.77203776919188e-06,
                          min_samples_leaf=4, min_samples_split=4,
                          n_estimators=167, random_state=456,
                          subsample=0.8647484799647367), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A776C10>)
2025-03-19 15:53:48,377:INFO:Checking exceptions
2025-03-19 15:53:48,377:INFO:Preloading libraries
2025-03-19 15:53:48,500:INFO:Initializing tune_model()
2025-03-19 15:53:48,500:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>)
2025-03-19 15:53:48,500:INFO:Checking exceptions
2025-03-19 15:53:48,500:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:53:48,508:INFO:Copying training dataset
2025-03-19 15:53:48,510:INFO:Checking base model
2025-03-19 15:53:48,510:INFO:Base model : Light Gradient Boosting Machine
2025-03-19 15:53:48,512:INFO:Declaring metric variables
2025-03-19 15:53:48,514:INFO:Defining Hyperparameters
2025-03-19 15:53:48,581:INFO:Tuning with n_jobs=-1
2025-03-19 15:53:48,582:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:53:48,582:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:53:48,583:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:53:48,583:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:53:48,583:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:53:48,583:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:54:24,639:INFO:best_params: {'actual_estimator__num_leaves': 83, 'actual_estimator__learning_rate': 0.16764426167689794, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.5394487592844678, 'actual_estimator__reg_alpha': 0.00602751676630542, 'actual_estimator__reg_lambda': 5.217052409947684e-09, 'actual_estimator__feature_fraction': 0.9729146390755077, 'actual_estimator__bagging_fraction': 0.8301065670073495, 'actual_estimator__bagging_freq': 4, 'actual_estimator__min_child_samples': 8}
2025-03-19 15:54:24,645:INFO:Hyperparameter search completed
2025-03-19 15:54:24,646:INFO:SubProcess create_model() called ==================================
2025-03-19 15:54:24,646:INFO:Initializing create_model()
2025-03-19 15:54:24,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A2F6310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 83, 'learning_rate': 0.16764426167689794, 'n_estimators': 180, 'min_split_gain': 0.5394487592844678, 'reg_alpha': 0.00602751676630542, 'reg_lambda': 5.217052409947684e-09, 'feature_fraction': 0.9729146390755077, 'bagging_fraction': 0.8301065670073495, 'bagging_freq': 4, 'min_child_samples': 8})
2025-03-19 15:54:24,646:INFO:Checking exceptions
2025-03-19 15:54:24,647:INFO:Importing libraries
2025-03-19 15:54:24,647:INFO:Copying training dataset
2025-03-19 15:54:24,650:INFO:Defining folds
2025-03-19 15:54:24,650:INFO:Declaring metric variables
2025-03-19 15:54:24,652:INFO:Importing untrained model
2025-03-19 15:54:24,652:INFO:Declaring custom model
2025-03-19 15:54:24,656:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:54:24,661:INFO:Starting cross validation
2025-03-19 15:54:24,662:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:54:24,840:INFO:Calculating mean and std
2025-03-19 15:54:24,841:INFO:Creating metrics dataframe
2025-03-19 15:54:24,845:INFO:Finalizing model
2025-03-19 15:54:24,882:INFO:[LightGBM] [Warning] feature_fraction is set=0.9729146390755077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9729146390755077
2025-03-19 15:54:24,882:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8301065670073495, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8301065670073495
2025-03-19 15:54:24,882:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-19 15:54:24,883:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:54:24,883:INFO:[LightGBM] [Warning] feature_fraction is set=0.9729146390755077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9729146390755077
2025-03-19 15:54:24,883:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8301065670073495, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8301065670073495
2025-03-19 15:54:24,883:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2025-03-19 15:54:24,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-03-19 15:54:24,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:54:24,885:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:54:24,886:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:54:24,886:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:54:24,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-19 15:54:24,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-03-19 15:54:24,956:INFO:Uploading results into container
2025-03-19 15:54:24,957:INFO:Uploading model into container now
2025-03-19 15:54:24,957:INFO:_master_model_container: 23
2025-03-19 15:54:24,957:INFO:_display_container: 5
2025-03-19 15:54:24,958:INFO:LGBMRegressor(bagging_fraction=0.8301065670073495, bagging_freq=4,
              feature_fraction=0.9729146390755077,
              learning_rate=0.16764426167689794, min_child_samples=8,
              min_split_gain=0.5394487592844678, n_estimators=180, n_jobs=-1,
              num_leaves=83, random_state=456, reg_alpha=0.00602751676630542,
              reg_lambda=5.217052409947684e-09)
2025-03-19 15:54:24,958:INFO:create_model() successfully completed......................................
2025-03-19 15:54:25,030:INFO:SubProcess create_model() end ==================================
2025-03-19 15:54:25,030:INFO:choose_better activated
2025-03-19 15:54:25,034:INFO:SubProcess create_model() called ==================================
2025-03-19 15:54:25,034:INFO:Initializing create_model()
2025-03-19 15:54:25,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=LGBMRegressor(n_jobs=-1, random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:54:25,034:INFO:Checking exceptions
2025-03-19 15:54:25,035:INFO:Importing libraries
2025-03-19 15:54:25,035:INFO:Copying training dataset
2025-03-19 15:54:25,038:INFO:Defining folds
2025-03-19 15:54:25,038:INFO:Declaring metric variables
2025-03-19 15:54:25,038:INFO:Importing untrained model
2025-03-19 15:54:25,038:INFO:Declaring custom model
2025-03-19 15:54:25,038:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-19 15:54:25,039:INFO:Starting cross validation
2025-03-19 15:54:25,040:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:54:25,564:INFO:Calculating mean and std
2025-03-19 15:54:25,564:INFO:Creating metrics dataframe
2025-03-19 15:54:25,565:INFO:Finalizing model
2025-03-19 15:54:25,600:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-19 15:54:25,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2025-03-19 15:54:25,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-19 15:54:25,601:INFO:[LightGBM] [Info] Total Bins 1146
2025-03-19 15:54:25,601:INFO:[LightGBM] [Info] Number of data points in the train set: 1483, number of used features: 27
2025-03-19 15:54:25,601:INFO:[LightGBM] [Info] Start training from score 15.793222
2025-03-19 15:54:25,719:INFO:Uploading results into container
2025-03-19 15:54:25,719:INFO:Uploading model into container now
2025-03-19 15:54:25,720:INFO:_master_model_container: 24
2025-03-19 15:54:25,720:INFO:_display_container: 6
2025-03-19 15:54:25,720:INFO:LGBMRegressor(n_jobs=-1, random_state=456)
2025-03-19 15:54:25,720:INFO:create_model() successfully completed......................................
2025-03-19 15:54:25,785:INFO:SubProcess create_model() end ==================================
2025-03-19 15:54:25,785:INFO:LGBMRegressor(n_jobs=-1, random_state=456) result for R2 is 0.8318
2025-03-19 15:54:25,786:INFO:LGBMRegressor(bagging_fraction=0.8301065670073495, bagging_freq=4,
              feature_fraction=0.9729146390755077,
              learning_rate=0.16764426167689794, min_child_samples=8,
              min_split_gain=0.5394487592844678, n_estimators=180, n_jobs=-1,
              num_leaves=83, random_state=456, reg_alpha=0.00602751676630542,
              reg_lambda=5.217052409947684e-09) result for R2 is 0.8716
2025-03-19 15:54:25,786:INFO:LGBMRegressor(bagging_fraction=0.8301065670073495, bagging_freq=4,
              feature_fraction=0.9729146390755077,
              learning_rate=0.16764426167689794, min_child_samples=8,
              min_split_gain=0.5394487592844678, n_estimators=180, n_jobs=-1,
              num_leaves=83, random_state=456, reg_alpha=0.00602751676630542,
              reg_lambda=5.217052409947684e-09) is best model
2025-03-19 15:54:25,786:INFO:choose_better completed
2025-03-19 15:54:25,786:INFO:Creating Dashboard logs
2025-03-19 15:54:25,789:INFO:Model: Light Gradient Boosting Machine
2025-03-19 15:54:25,810:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.16764426167689794, 'max_depth': -1, 'min_child_samples': 8, 'min_child_weight': 0.001, 'min_split_gain': 0.5394487592844678, 'n_estimators': 180, 'n_jobs': -1, 'num_leaves': 83, 'objective': None, 'random_state': 456, 'reg_alpha': 0.00602751676630542, 'reg_lambda': 5.217052409947684e-09, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.9729146390755077, 'bagging_fraction': 0.8301065670073495, 'bagging_freq': 4}
2025-03-19 15:54:26,003:INFO:Initializing predict_model()
2025-03-19 15:54:26,003:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=LGBMRegressor(bagging_fraction=0.8301065670073495, bagging_freq=4,
              feature_fraction=0.9729146390755077,
              learning_rate=0.16764426167689794, min_child_samples=8,
              min_split_gain=0.5394487592844678, n_estimators=180, n_jobs=-1,
              num_leaves=83, random_state=456, reg_alpha=0.00602751676630542,
              reg_lambda=5.217052409947684e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A4363A0>)
2025-03-19 15:54:26,003:INFO:Checking exceptions
2025-03-19 15:54:26,003:INFO:Preloading libraries
2025-03-19 15:54:26,145:ERROR:_log_model() for LGBMRegressor(bagging_fraction=0.8301065670073495, bagging_freq=4,
              feature_fraction=0.9729146390755077,
              learning_rate=0.16764426167689794, min_child_samples=8,
              min_split_gain=0.5394487592844678, n_estimators=180, n_jobs=-1,
              num_leaves=83, random_state=456, reg_alpha=0.00602751676630542,
              reg_lambda=5.217052409947684e-09) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:54:26,151:INFO:_master_model_container: 24
2025-03-19 15:54:26,151:INFO:_display_container: 5
2025-03-19 15:54:26,151:INFO:LGBMRegressor(bagging_fraction=0.8301065670073495, bagging_freq=4,
              feature_fraction=0.9729146390755077,
              learning_rate=0.16764426167689794, min_child_samples=8,
              min_split_gain=0.5394487592844678, n_estimators=180, n_jobs=-1,
              num_leaves=83, random_state=456, reg_alpha=0.00602751676630542,
              reg_lambda=5.217052409947684e-09)
2025-03-19 15:54:26,151:INFO:tune_model() successfully completed......................................
2025-03-19 15:54:26,221:INFO:Initializing predict_model()
2025-03-19 15:54:26,221:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=LGBMRegressor(bagging_fraction=0.8301065670073495, bagging_freq=4,
              feature_fraction=0.9729146390755077,
              learning_rate=0.16764426167689794, min_child_samples=8,
              min_split_gain=0.5394487592844678, n_estimators=180, n_jobs=-1,
              num_leaves=83, random_state=456, reg_alpha=0.00602751676630542,
              reg_lambda=5.217052409947684e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A3B60D0>)
2025-03-19 15:54:26,221:INFO:Checking exceptions
2025-03-19 15:54:26,222:INFO:Preloading libraries
2025-03-19 15:54:26,365:INFO:Initializing tune_model()
2025-03-19 15:54:26,365:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>)
2025-03-19 15:54:26,365:INFO:Checking exceptions
2025-03-19 15:54:26,365:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:54:26,376:INFO:Copying training dataset
2025-03-19 15:54:26,380:INFO:Checking base model
2025-03-19 15:54:26,380:INFO:Base model : Extreme Gradient Boosting
2025-03-19 15:54:26,383:INFO:Declaring metric variables
2025-03-19 15:54:26,386:INFO:Defining Hyperparameters
2025-03-19 15:54:26,448:INFO:Tuning with n_jobs=-1
2025-03-19 15:54:26,448:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:54:26,448:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:54:26,449:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:54:26,449:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:54:26,449:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:54:26,449:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:55:21,123:INFO:best_params: {'actual_estimator__learning_rate': 0.07569174071684635, 'actual_estimator__n_estimators': 82, 'actual_estimator__subsample': 0.5886105303723904, 'actual_estimator__max_depth': 7, 'actual_estimator__colsample_bytree': 0.763441164637693, 'actual_estimator__min_child_weight': 2, 'actual_estimator__reg_alpha': 1.6256637567704968e-08, 'actual_estimator__reg_lambda': 0.018055514961540075, 'actual_estimator__scale_pos_weight': 9.758948164689391}
2025-03-19 15:55:21,130:INFO:Hyperparameter search completed
2025-03-19 15:55:21,130:INFO:SubProcess create_model() called ==================================
2025-03-19 15:55:21,131:INFO:Initializing create_model()
2025-03-19 15:55:21,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A304220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 0.07569174071684635, 'n_estimators': 82, 'subsample': 0.5886105303723904, 'max_depth': 7, 'colsample_bytree': 0.763441164637693, 'min_child_weight': 2, 'reg_alpha': 1.6256637567704968e-08, 'reg_lambda': 0.018055514961540075, 'scale_pos_weight': 9.758948164689391})
2025-03-19 15:55:21,131:INFO:Checking exceptions
2025-03-19 15:55:21,131:INFO:Importing libraries
2025-03-19 15:55:21,131:INFO:Copying training dataset
2025-03-19 15:55:21,134:INFO:Defining folds
2025-03-19 15:55:21,134:INFO:Declaring metric variables
2025-03-19 15:55:21,137:INFO:Importing untrained model
2025-03-19 15:55:21,137:INFO:Declaring custom model
2025-03-19 15:55:21,141:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:55:21,146:INFO:Starting cross validation
2025-03-19 15:55:21,147:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:55:21,546:INFO:Calculating mean and std
2025-03-19 15:55:21,547:INFO:Creating metrics dataframe
2025-03-19 15:55:21,552:INFO:Finalizing model
2025-03-19 15:55:21,725:INFO:Uploading results into container
2025-03-19 15:55:21,726:INFO:Uploading model into container now
2025-03-19 15:55:21,726:INFO:_master_model_container: 25
2025-03-19 15:55:21,726:INFO:_display_container: 7
2025-03-19 15:55:21,727:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.763441164637693, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.07569174071684635, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=82, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:55:21,727:INFO:create_model() successfully completed......................................
2025-03-19 15:55:21,798:INFO:SubProcess create_model() end ==================================
2025-03-19 15:55:21,798:INFO:choose_better activated
2025-03-19 15:55:21,801:INFO:SubProcess create_model() called ==================================
2025-03-19 15:55:21,802:INFO:Initializing create_model()
2025-03-19 15:55:21,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:55:21,802:INFO:Checking exceptions
2025-03-19 15:55:21,803:INFO:Importing libraries
2025-03-19 15:55:21,803:INFO:Copying training dataset
2025-03-19 15:55:21,806:INFO:Defining folds
2025-03-19 15:55:21,806:INFO:Declaring metric variables
2025-03-19 15:55:21,806:INFO:Importing untrained model
2025-03-19 15:55:21,806:INFO:Declaring custom model
2025-03-19 15:55:21,807:INFO:Extreme Gradient Boosting Imported successfully
2025-03-19 15:55:21,807:INFO:Starting cross validation
2025-03-19 15:55:21,808:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:55:22,116:INFO:Calculating mean and std
2025-03-19 15:55:22,116:INFO:Creating metrics dataframe
2025-03-19 15:55:22,117:INFO:Finalizing model
2025-03-19 15:55:22,282:INFO:Uploading results into container
2025-03-19 15:55:22,283:INFO:Uploading model into container now
2025-03-19 15:55:22,283:INFO:_master_model_container: 26
2025-03-19 15:55:22,283:INFO:_display_container: 8
2025-03-19 15:55:22,284:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:55:22,284:INFO:create_model() successfully completed......................................
2025-03-19 15:55:22,354:INFO:SubProcess create_model() end ==================================
2025-03-19 15:55:22,355:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) result for R2 is 0.8356
2025-03-19 15:55:22,355:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.763441164637693, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.07569174071684635, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=82, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) result for R2 is 0.8759
2025-03-19 15:55:22,356:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.763441164637693, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.07569174071684635, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=82, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) is best model
2025-03-19 15:55:22,356:INFO:choose_better completed
2025-03-19 15:55:22,356:INFO:Creating Dashboard logs
2025-03-19 15:55:22,358:INFO:Model: Extreme Gradient Boosting
2025-03-19 15:55:22,379:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.763441164637693, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.07569174071684635, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 7, 'max_leaves': None, 'min_child_weight': 2, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 82, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 456, 'reg_alpha': 1.6256637567704968e-08, 'reg_lambda': 0.018055514961540075, 'sampling_method': None, 'scale_pos_weight': 9.758948164689391, 'subsample': 0.5886105303723904, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2025-03-19 15:55:22,575:INFO:Initializing predict_model()
2025-03-19 15:55:22,575:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.763441164637693, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.07569174071684635, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=82, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A4365E0>)
2025-03-19 15:55:22,575:INFO:Checking exceptions
2025-03-19 15:55:22,575:INFO:Preloading libraries
2025-03-19 15:55:22,723:ERROR:_log_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.763441164637693, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.07569174071684635, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=82, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:55:22,729:INFO:_master_model_container: 26
2025-03-19 15:55:22,729:INFO:_display_container: 7
2025-03-19 15:55:22,730:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.763441164637693, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.07569174071684635, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=82, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...)
2025-03-19 15:55:22,730:INFO:tune_model() successfully completed......................................
2025-03-19 15:55:22,797:INFO:Initializing predict_model()
2025-03-19 15:55:22,798:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.763441164637693, device='cpu',
             early_stopping_rounds=None, enable_categorical=False,
             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.07569174071684635, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=82, n_jobs=-1,
             num_parallel_tree=None, random_state=456, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A776F70>)
2025-03-19 15:55:22,798:INFO:Checking exceptions
2025-03-19 15:55:22,798:INFO:Preloading libraries
2025-03-19 15:55:22,949:INFO:Initializing tune_model()
2025-03-19 15:55:22,949:INFO:tune_model(estimator=AdaBoostRegressor(random_state=456), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=20, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>)
2025-03-19 15:55:22,949:INFO:Checking exceptions
2025-03-19 15:55:22,949:INFO:Soft dependency imported: optuna: 4.1.0
2025-03-19 15:55:22,961:INFO:Copying training dataset
2025-03-19 15:55:22,965:INFO:Checking base model
2025-03-19 15:55:22,965:INFO:Base model : AdaBoost Regressor
2025-03-19 15:55:22,968:INFO:Declaring metric variables
2025-03-19 15:55:22,971:INFO:Defining Hyperparameters
2025-03-19 15:55:23,031:INFO:Tuning with n_jobs=-1
2025-03-19 15:55:23,031:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:55:23,032:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\optuna\_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-03-19 15:55:23,032:INFO:Initializing optuna.integration.OptunaSearchCV
2025-03-19 15:55:23,032:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 15:55:23,033:INFO:can_partial_fit: False, can_warm_start: False, is_xgboost: False
2025-03-19 15:55:23,033:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-03-19 15:56:48,846:INFO:best_params: {'actual_estimator__learning_rate': 1.2916185226090418e-05, 'actual_estimator__n_estimators': 132, 'actual_estimator__loss': 'square'}
2025-03-19 15:56:48,850:INFO:Hyperparameter search completed
2025-03-19 15:56:48,850:INFO:SubProcess create_model() called ==================================
2025-03-19 15:56:48,850:INFO:Initializing create_model()
2025-03-19 15:56:48,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=AdaBoostRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89A9960A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'learning_rate': 1.2916185226090418e-05, 'n_estimators': 132, 'loss': 'square'})
2025-03-19 15:56:48,850:INFO:Checking exceptions
2025-03-19 15:56:48,850:INFO:Importing libraries
2025-03-19 15:56:48,850:INFO:Copying training dataset
2025-03-19 15:56:48,853:INFO:Defining folds
2025-03-19 15:56:48,853:INFO:Declaring metric variables
2025-03-19 15:56:48,855:INFO:Importing untrained model
2025-03-19 15:56:48,855:INFO:Declaring custom model
2025-03-19 15:56:48,857:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:56:48,860:INFO:Starting cross validation
2025-03-19 15:56:48,861:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:56:49,122:INFO:Calculating mean and std
2025-03-19 15:56:49,123:INFO:Creating metrics dataframe
2025-03-19 15:56:49,127:INFO:Finalizing model
2025-03-19 15:56:49,412:INFO:Uploading results into container
2025-03-19 15:56:49,412:INFO:Uploading model into container now
2025-03-19 15:56:49,412:INFO:_master_model_container: 27
2025-03-19 15:56:49,412:INFO:_display_container: 9
2025-03-19 15:56:49,412:INFO:AdaBoostRegressor(learning_rate=1.2916185226090418e-05, loss='square',
                  n_estimators=132, random_state=456)
2025-03-19 15:56:49,413:INFO:create_model() successfully completed......................................
2025-03-19 15:56:49,473:INFO:SubProcess create_model() end ==================================
2025-03-19 15:56:49,473:INFO:choose_better activated
2025-03-19 15:56:49,476:INFO:SubProcess create_model() called ==================================
2025-03-19 15:56:49,476:INFO:Initializing create_model()
2025-03-19 15:56:49,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=AdaBoostRegressor(random_state=456), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:56:49,476:INFO:Checking exceptions
2025-03-19 15:56:49,477:INFO:Importing libraries
2025-03-19 15:56:49,477:INFO:Copying training dataset
2025-03-19 15:56:49,479:INFO:Defining folds
2025-03-19 15:56:49,479:INFO:Declaring metric variables
2025-03-19 15:56:49,479:INFO:Importing untrained model
2025-03-19 15:56:49,479:INFO:Declaring custom model
2025-03-19 15:56:49,479:INFO:AdaBoost Regressor Imported successfully
2025-03-19 15:56:49,479:INFO:Starting cross validation
2025-03-19 15:56:49,480:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2025-03-19 15:56:49,615:INFO:Calculating mean and std
2025-03-19 15:56:49,615:INFO:Creating metrics dataframe
2025-03-19 15:56:49,616:INFO:Finalizing model
2025-03-19 15:56:49,727:INFO:Uploading results into container
2025-03-19 15:56:49,728:INFO:Uploading model into container now
2025-03-19 15:56:49,728:INFO:_master_model_container: 28
2025-03-19 15:56:49,728:INFO:_display_container: 10
2025-03-19 15:56:49,728:INFO:AdaBoostRegressor(random_state=456)
2025-03-19 15:56:49,728:INFO:create_model() successfully completed......................................
2025-03-19 15:56:49,788:INFO:SubProcess create_model() end ==================================
2025-03-19 15:56:49,788:INFO:AdaBoostRegressor(random_state=456) result for R2 is 0.7935
2025-03-19 15:56:49,788:INFO:AdaBoostRegressor(learning_rate=1.2916185226090418e-05, loss='square',
                  n_estimators=132, random_state=456) result for R2 is 0.8125
2025-03-19 15:56:49,788:INFO:AdaBoostRegressor(learning_rate=1.2916185226090418e-05, loss='square',
                  n_estimators=132, random_state=456) is best model
2025-03-19 15:56:49,788:INFO:choose_better completed
2025-03-19 15:56:49,789:INFO:Creating Dashboard logs
2025-03-19 15:56:49,791:INFO:Model: AdaBoost Regressor
2025-03-19 15:56:49,808:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.2916185226090418e-05, 'loss': 'square', 'n_estimators': 132, 'random_state': 456}
2025-03-19 15:56:50,020:INFO:Initializing predict_model()
2025-03-19 15:56:50,020:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=AdaBoostRegressor(learning_rate=1.2916185226090418e-05, loss='square',
                  n_estimators=132, random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A7C6820>)
2025-03-19 15:56:50,020:INFO:Checking exceptions
2025-03-19 15:56:50,020:INFO:Preloading libraries
2025-03-19 15:56:50,174:ERROR:_log_model() for AdaBoostRegressor(learning_rate=1.2916185226090418e-05, loss='square',
                  n_estimators=132, random_state=456) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:56:50,180:INFO:_master_model_container: 28
2025-03-19 15:56:50,180:INFO:_display_container: 9
2025-03-19 15:56:50,181:INFO:AdaBoostRegressor(learning_rate=1.2916185226090418e-05, loss='square',
                  n_estimators=132, random_state=456)
2025-03-19 15:56:50,181:INFO:tune_model() successfully completed......................................
2025-03-19 15:56:50,241:INFO:Initializing predict_model()
2025-03-19 15:56:50,241:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=AdaBoostRegressor(learning_rate=1.2916185226090418e-05, loss='square',
                  n_estimators=132, random_state=456), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F898E640D0>)
2025-03-19 15:56:50,241:INFO:Checking exceptions
2025-03-19 15:56:50,241:INFO:Preloading libraries
2025-03-19 15:56:50,409:INFO:Initializing finalize_model()
2025-03-19 15:56:50,409:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=VotingRegressor(estimators=[('model_0',
                             GradientBoostingRegressor(learning_rate=0.07267911071803841,
                                                       max_depth=1,
                                                       max_features=0.8188582046293146,
                                                       min_impurity_decrease=7.77203776919188e-06,
                                                       min_samples_leaf=4,
                                                       min_samples_split=4,
                                                       n_estimators=167,
                                                       random_state=456,
                                                       subsample=0.8647484799647367)),
                            ('model_1',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          cal...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.07569174071684635,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=7,
                                          max_leaves=None, min_child_weight=2,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=82,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=456, ...))]), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-19 15:56:50,412:INFO:Finalizing VotingRegressor(estimators=[('model_0',
                             GradientBoostingRegressor(learning_rate=0.07267911071803841,
                                                       max_depth=1,
                                                       max_features=0.8188582046293146,
                                                       min_impurity_decrease=7.77203776919188e-06,
                                                       min_samples_leaf=4,
                                                       min_samples_split=4,
                                                       n_estimators=167,
                                                       random_state=456,
                                                       subsample=0.8647484799647367)),
                            ('model_1',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          cal...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.07569174071684635,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=7,
                                          max_leaves=None, min_child_weight=2,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=82,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=456, ...))])
2025-03-19 15:56:50,416:INFO:Initializing create_model()
2025-03-19 15:56:50,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=VotingRegressor(estimators=[('model_0',
                             GradientBoostingRegressor(learning_rate=0.07267911071803841,
                                                       max_depth=1,
                                                       max_features=0.8188582046293146,
                                                       min_impurity_decrease=7.77203776919188e-06,
                                                       min_samples_leaf=4,
                                                       min_samples_split=4,
                                                       n_estimators=167,
                                                       random_state=456,
                                                       subsample=0.8647484799647367)),
                            ('model_1',
                             XGBRegressor(base_score=None, booster='gbtree',
                                          cal...
                                          gamma=None, grow_policy=None,
                                          importance_type=None,
                                          interaction_constraints=None,
                                          learning_rate=0.07569174071684635,
                                          max_bin=None, max_cat_threshold=None,
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=7,
                                          max_leaves=None, min_child_weight=2,
                                          missing=nan,
                                          monotone_constraints=None,
                                          multi_strategy=None, n_estimators=82,
                                          n_jobs=-1, num_parallel_tree=None,
                                          random_state=456, ...))]), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 15:56:50,417:INFO:Checking exceptions
2025-03-19 15:56:50,417:INFO:Importing libraries
2025-03-19 15:56:50,417:INFO:Copying training dataset
2025-03-19 15:56:50,418:INFO:Defining folds
2025-03-19 15:56:50,418:INFO:Declaring metric variables
2025-03-19 15:56:50,418:INFO:Importing untrained model
2025-03-19 15:56:50,418:INFO:Declaring custom model
2025-03-19 15:56:50,419:INFO:Voting Regressor Imported successfully
2025-03-19 15:56:50,419:INFO:Cross validation set to False
2025-03-19 15:56:50,419:INFO:Fitting Model
2025-03-19 15:56:50,739:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07569174071684635,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=7,
                                                           max_leaves=None,
                                                           min_child_weight=2,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=82,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))])
2025-03-19 15:56:50,739:INFO:create_model() successfully completed......................................
2025-03-19 15:56:50,801:INFO:Creating Dashboard logs
2025-03-19 15:56:50,802:INFO:Model: Voting Regressor
2025-03-19 15:56:50,824:INFO:Logged params: {'n_jobs': None, 'verbose': False, 'weights': None, 'model_0__alpha': 0.9, 'model_0__ccp_alpha': 0.0, 'model_0__criterion': 'friedman_mse', 'model_0__init': None, 'model_0__learning_rate': 0.07267911071803841, 'model_0__loss': 'squared_error', 'model_0__max_depth': 1, 'model_0__max_features': 0.8188582046293146, 'model_0__max_leaf_nodes': None, 'model_0__min_impurity_decrease': 7.77203776919188e-06, 'model_0__min_samples_leaf': 4, 'model_0__min_samples_split': 4, 'model_0__min_weight_fraction_leaf': 0.0, 'model_0__n_estimators': 167, 'model_0__n_iter_no_change': None, 'model_0__random_state': 456, 'model_0__subsample': 0.8647484799647367, 'model_0__tol': 0.0001, 'model_0__validation_fraction': 0.1, 'model_0__verbose': 0, 'model_0__warm_start': False, 'model_1__objective': 'reg:squarederror', 'model_1__base_score': None, 'model_1__booster': 'gbtree', 'model_1__callbacks': None, 'model_1__colsample_bylevel': None, 'model_1__colsample_bynode': None, 'model_1__colsample_bytree': 0.763441164637693, 'model_1__device': 'cpu', 'model_1__early_stopping_rounds': None, 'model_1__enable_categorical': False, 'model_1__eval_metric': None, 'model_1__feature_types': None, 'model_1__gamma': None, 'model_1__grow_policy': None, 'model_1__importance_type': None, 'model_1__interaction_constraints': None, 'model_1__learning_rate': 0.07569174071684635, 'model_1__max_bin': None, 'model_1__max_cat_threshold': None, 'model_1__max_cat_to_onehot': None, 'model_1__max_delta_step': None, 'model_1__max_depth': 7, 'model_1__max_leaves': None, 'model_1__min_child_weight': 2, 'model_1__missing': nan, 'model_1__monotone_constraints': None, 'model_1__multi_strategy': None, 'model_1__n_estimators': 82, 'model_1__n_jobs': -1, 'model_1__num_parallel_tree': None, 'model_1__random_state': 456, 'model_1__reg_alpha': 1.6256637567704968e-08, 'model_1__reg_lambda': 0.018055514961540075, 'model_1__sampling_method': None, 'model_1__scale_pos_weight': 9.758948164689391, 'model_1__subsample': 0.5886105303723904, 'model_1__tree_method': 'auto', 'model_1__validate_parameters': None, 'model_1__verbosity': 0}
2025-03-19 15:56:51,070:ERROR:_log_model() for Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07569174071684635,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=7,
                                                           max_leaves=None,
                                                           min_child_weight=2,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=82,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]) raised an exception:
Traceback (most recent call last):
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 184, in log_model
    [
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 185, in <listcomp>
    logger.log_sklearn_pipeline(experiment, pipeline, model, path=tmpdir)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 166, in log_sklearn_pipeline
    mlflow.sklearn.log_model(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\sklearn\__init__.py", line 407, in log_model
    return Model.log(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\models\model.py", line 374, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\fluent.py", line 813, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\client.py", line 1182, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 469, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\mlflow\store\artifact\local_artifact_repo.py", line 58, in log_artifacts
    dir_util.copy_tree(src=local_dir, dst=artifact_dir, preserve_mode=0, preserve_times=0)
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 155, in copy_tree
    return list(itertools.chain.from_iterable(map(copy_one, names)))
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\dir_util.py", line 197, in _copy_one
    file_util.copy_file(
  File "d:\Anaconda\envs\pycaret3.0\lib\site-packages\setuptools\_distutils\file_util.py", line 104, in copy_file
    from distutils._modified import newer
ModuleNotFoundError: No module named 'distutils._modified'

2025-03-19 15:56:51,070:INFO:_master_model_container: 28
2025-03-19 15:56:51,070:INFO:_display_container: 10
2025-03-19 15:56:51,085:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07569174071684635,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=7,
                                                           max_leaves=None,
                                                           min_child_weight=2,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=82,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))])
2025-03-19 15:56:51,085:INFO:finalize_model() successfully completed......................................
2025-03-19 15:56:51,162:INFO:Initializing predict_model()
2025-03-19 15:56:51,162:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07569174071684635,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=7,
                                                           max_leaves=None,
                                                           min_child_weight=2,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=82,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A77C4C0>)
2025-03-19 15:56:51,162:INFO:Checking exceptions
2025-03-19 15:56:51,162:INFO:Preloading libraries
2025-03-19 15:56:51,163:INFO:Set up data.
2025-03-19 15:56:51,167:INFO:Set up index.
2025-03-19 15:56:51,286:INFO:Initializing predict_model()
2025-03-19 15:56:51,286:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8AD745940>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07569174071684635,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=7,
                                                           max_leaves=None,
                                                           min_child_weight=2,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=82,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F89A77C4C0>)
2025-03-19 15:56:51,286:INFO:Checking exceptions
2025-03-19 15:56:51,286:INFO:Preloading libraries
2025-03-19 15:56:51,288:INFO:Set up data.
2025-03-19 15:56:51,292:INFO:Set up index.
2025-03-19 15:56:51,415:INFO:Initializing save_model()
2025-03-19 15:56:51,415:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07569174071684635,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=7,
                                                           max_leaves=None,
                                                           min_child_weight=2,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=82,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))]), model_name=msw_stacked_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-19 15:56:51,415:INFO:Adding model into prep_pipe
2025-03-19 15:56:51,415:WARNING:Only Model saved as it was a pipeline.
2025-03-19 15:56:51,425:INFO:msw_stacked_model.pkl saved in current working directory
2025-03-19 15:56:51,445:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',
                                             'trend_region_Latin America & '
                                             'Caribbean',
                                             'tr...
                                                           grow_policy=None,
                                                           importance_type=None,
                                                           interaction_constraints=None,
                                                           learning_rate=0.07569174071684635,
                                                           max_bin=None,
                                                           max_cat_threshold=None,
                                                           max_cat_to_onehot=None,
                                                           max_delta_step=None,
                                                           max_depth=7,
                                                           max_leaves=None,
                                                           min_child_weight=2,
                                                           missing=nan,
                                                           monotone_constraints=None,
                                                           multi_strategy=None,
                                                           n_estimators=82,
                                                           n_jobs=-1,
                                                           num_parallel_tree=None,
                                                           random_state=456, ...))]))])
2025-03-19 15:56:51,445:INFO:save_model() successfully completed......................................
2025-03-19 15:56:51,616:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,617:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,625:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,625:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,625:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,625:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,625:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,626:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 21382 (\N{CJK UNIFIED IDEOGRAPH-5386}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 21490 (\N{CJK UNIFIED IDEOGRAPH-53F2}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 25454 (\N{CJK UNIFIED IDEOGRAPH-636E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,627:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\699593671.py:39: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:51,850:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,850:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,850:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,850:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,850:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,855:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,855:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21382 (\N{CJK UNIFIED IDEOGRAPH-5386}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21490 (\N{CJK UNIFIED IDEOGRAPH-53F2}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 25454 (\N{CJK UNIFIED IDEOGRAPH-636E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:51,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,037:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39057 (\N{CJK UNIFIED IDEOGRAPH-9891}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,037:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,038:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24067 (\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,109:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 19982 (\N{CJK UNIFIED IDEOGRAPH-4E0E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,109:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,109:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,109:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,110:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20851 (\N{CJK UNIFIED IDEOGRAPH-5173}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,110:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 31995 (\N{CJK UNIFIED IDEOGRAPH-7CFB}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,230:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,230:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,236:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 20154 (\N{CJK UNIFIED IDEOGRAPH-4EBA}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,239:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,239:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,239:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,239:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,239:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,240:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,240:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,240:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,240:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,240:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:31: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,481:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20154 (\N{CJK UNIFIED IDEOGRAPH-4EBA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,481:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,481:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30340 (\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,481:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,481:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,481:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24207 (\N{CJK UNIFIED IDEOGRAPH-5E8F}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,482:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21015 (\N{CJK UNIFIED IDEOGRAPH-5217}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,487:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,493:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,493:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,493:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,493:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,493:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,666:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24179 (\N{CJK UNIFIED IDEOGRAPH-5E73}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,666:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22343 (\N{CJK UNIFIED IDEOGRAPH-5747}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,666:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,666:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,666:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22269 (\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23478 (\N{CJK UNIFIED IDEOGRAPH-5BB6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,667:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38543 (\N{CJK UNIFIED IDEOGRAPH-968F}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,668:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26102 (\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,668:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38388 (\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,668:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21464 (\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,668:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21270 (\N{CJK UNIFIED IDEOGRAPH-5316}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,675:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24180 (\N{CJK UNIFIED IDEOGRAPH-5E74}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,675:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20221 (\N{CJK UNIFIED IDEOGRAPH-4EFD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,744:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20540 (\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,745:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23454 (\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,745:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38469 (\N{CJK UNIFIED IDEOGRAPH-9645}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,745:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 19982 (\N{CJK UNIFIED IDEOGRAPH-4E0E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,745:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23545 (\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,824:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 22320 (\N{CJK UNIFIED IDEOGRAPH-5730}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,824:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 21306 (\N{CJK UNIFIED IDEOGRAPH-533A}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,830:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,830:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,830:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,830:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,830:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,830:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,830:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,832:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 22269 (\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 23478 (\N{CJK UNIFIED IDEOGRAPH-5BB6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 21508 (\N{CJK UNIFIED IDEOGRAPH-5404}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,833:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_69864\1388027748.py:74: UserWarning: Glyph 24067 (\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.
  plt.tight_layout()

2025-03-19 15:56:52,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 39044 (\N{CJK UNIFIED IDEOGRAPH-9884}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27979 (\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35823 (\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24046 (\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 30334 (\N{CJK UNIFIED IDEOGRAPH-767E}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 20998 (\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,861:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22269 (\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 23478 (\N{CJK UNIFIED IDEOGRAPH-5BB6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22806 (\N{CJK UNIFIED IDEOGRAPH-5916}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26679 (\N{CJK UNIFIED IDEOGRAPH-6837}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 26412 (\N{CJK UNIFIED IDEOGRAPH-672C}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 35797 (\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 38598 (\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21508 (\N{CJK UNIFIED IDEOGRAPH-5404}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 22320 (\N{CJK UNIFIED IDEOGRAPH-5730}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 21306 (\N{CJK UNIFIED IDEOGRAPH-533A}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 15:56:52,862:WARNING:d:\Anaconda\envs\pycaret3.0\lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Glyph 24067 (\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-03-19 16:42:18,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 16:42:18,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 16:42:18,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 16:42:18,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-19 16:42:18,313:INFO:PyCaret RegressionExperiment
2025-03-19 16:42:18,314:INFO:Logging name: msw_prediction
2025-03-19 16:42:18,314:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-19 16:42:18,314:INFO:version 3.2.0
2025-03-19 16:42:18,314:INFO:Initializing setup()
2025-03-19 16:42:18,314:INFO:self.USI: 08c5
2025-03-19 16:42:18,314:INFO:self._variable_keys: {'gpu_param', 'USI', 'fold_groups_param', 'log_plots_param', 'fold_shuffle_param', 'target_param', '_ml_usecase', 'X', 'pipeline', 'idx', 'X_train', 'y_train', 'transform_target_param', 'html_param', 'gpu_n_jobs_param', 'fold_generator', 'seed', 'data', 'memory', 'y_test', 'y', 'n_jobs_param', 'X_test', 'exp_id', 'exp_name_log', '_available_plots', 'logging_param'}
2025-03-19 16:42:18,314:INFO:Checking environment
2025-03-19 16:42:18,314:INFO:python_version: 3.8.20
2025-03-19 16:42:18,314:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2025-03-19 16:42:18,314:INFO:machine: AMD64
2025-03-19 16:42:18,314:INFO:platform: Windows-10-10.0.19041-SP0
2025-03-19 16:42:18,319:INFO:Memory: svmem(total=68447973376, available=40903950336, percent=40.2, used=27544023040, free=40903950336)
2025-03-19 16:42:18,319:INFO:Physical Core: 24
2025-03-19 16:42:18,319:INFO:Logical Core: 32
2025-03-19 16:42:18,319:INFO:Checking libraries
2025-03-19 16:42:18,319:INFO:System:
2025-03-19 16:42:18,319:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2025-03-19 16:42:18,319:INFO:executable: d:\Anaconda\envs\pycaret3.0\python.exe
2025-03-19 16:42:18,319:INFO:   machine: Windows-10-10.0.19041-SP0
2025-03-19 16:42:18,319:INFO:PyCaret required dependencies:
2025-03-19 16:42:18,838:INFO:                 pip: 24.2
2025-03-19 16:42:18,838:INFO:          setuptools: 75.1.0
2025-03-19 16:42:18,838:INFO:             pycaret: 3.2.0
2025-03-19 16:42:18,838:INFO:             IPython: 8.12.3
2025-03-19 16:42:18,838:INFO:          ipywidgets: 8.1.5
2025-03-19 16:42:18,838:INFO:                tqdm: 4.67.1
2025-03-19 16:42:18,838:INFO:               numpy: 1.24.4
2025-03-19 16:42:18,838:INFO:              pandas: 1.5.3
2025-03-19 16:42:18,838:INFO:              jinja2: 3.1.4
2025-03-19 16:42:18,838:INFO:               scipy: 1.10.1
2025-03-19 16:42:18,838:INFO:              joblib: 1.3.2
2025-03-19 16:42:18,838:INFO:             sklearn: 1.2.2
2025-03-19 16:42:18,838:INFO:                pyod: 2.0.2
2025-03-19 16:42:18,838:INFO:            imblearn: 0.12.4
2025-03-19 16:42:18,838:INFO:   category_encoders: 2.6.4
2025-03-19 16:42:18,838:INFO:            lightgbm: 4.5.0
2025-03-19 16:42:18,838:INFO:               numba: 0.58.1
2025-03-19 16:42:18,838:INFO:            requests: 2.32.3
2025-03-19 16:42:18,838:INFO:          matplotlib: 3.6.0
2025-03-19 16:42:18,838:INFO:          scikitplot: 0.3.7
2025-03-19 16:42:18,838:INFO:         yellowbrick: 1.5
2025-03-19 16:42:18,838:INFO:              plotly: 5.24.1
2025-03-19 16:42:18,838:INFO:    plotly-resampler: Not installed
2025-03-19 16:42:18,838:INFO:             kaleido: 0.2.1
2025-03-19 16:42:18,838:INFO:           schemdraw: 0.15
2025-03-19 16:42:18,838:INFO:         statsmodels: 0.14.1
2025-03-19 16:42:18,838:INFO:              sktime: 0.21.1
2025-03-19 16:42:18,838:INFO:               tbats: 1.1.3
2025-03-19 16:42:18,838:INFO:            pmdarima: 2.0.4
2025-03-19 16:42:18,838:INFO:              psutil: 6.1.0
2025-03-19 16:42:18,838:INFO:          markupsafe: 2.1.5
2025-03-19 16:42:18,838:INFO:             pickle5: Not installed
2025-03-19 16:42:18,838:INFO:         cloudpickle: 2.2.1
2025-03-19 16:42:18,838:INFO:         deprecation: 2.1.0
2025-03-19 16:42:18,838:INFO:              xxhash: 3.5.0
2025-03-19 16:42:18,838:INFO:           wurlitzer: Not installed
2025-03-19 16:42:18,838:INFO:PyCaret optional dependencies:
2025-03-19 16:42:19,614:INFO:                shap: 0.44.1
2025-03-19 16:42:19,614:INFO:           interpret: 0.6.6
2025-03-19 16:42:19,614:INFO:                umap: 0.5.7
2025-03-19 16:42:19,614:INFO:     ydata_profiling: 4.6.0
2025-03-19 16:42:19,614:INFO:  explainerdashboard: 0.4.7
2025-03-19 16:42:19,614:INFO:             autoviz: Not installed
2025-03-19 16:42:19,614:INFO:           fairlearn: 0.7.0
2025-03-19 16:42:19,614:INFO:          deepchecks: Not installed
2025-03-19 16:42:19,614:INFO:             xgboost: 2.1.3
2025-03-19 16:42:19,614:INFO:            catboost: 1.2.7
2025-03-19 16:42:19,614:INFO:              kmodes: 0.12.2
2025-03-19 16:42:19,614:INFO:             mlxtend: 0.23.1
2025-03-19 16:42:19,614:INFO:       statsforecast: 1.5.0
2025-03-19 16:42:19,615:INFO:        tune_sklearn: 0.5.0
2025-03-19 16:42:19,615:INFO:                 ray: 2.10.0
2025-03-19 16:42:19,615:INFO:            hyperopt: 0.2.7
2025-03-19 16:42:19,615:INFO:              optuna: 4.1.0
2025-03-19 16:42:19,615:INFO:               skopt: 0.10.2
2025-03-19 16:42:19,615:INFO:              mlflow: 1.30.1
2025-03-19 16:42:19,615:INFO:              gradio: 3.50.2
2025-03-19 16:42:19,615:INFO:             fastapi: 0.115.5
2025-03-19 16:42:19,615:INFO:             uvicorn: 0.32.1
2025-03-19 16:42:19,615:INFO:              m2cgen: 0.10.0
2025-03-19 16:42:19,615:INFO:           evidently: 0.2.8
2025-03-19 16:42:19,615:INFO:               fugue: 0.8.6
2025-03-19 16:42:19,615:INFO:           streamlit: Not installed
2025-03-19 16:42:19,615:INFO:             prophet: Not installed
2025-03-19 16:42:19,615:INFO:None
2025-03-19 16:42:19,615:INFO:Set up data.
2025-03-19 16:42:19,620:INFO:Set up folding strategy.
2025-03-19 16:42:19,620:INFO:Set up train/test split.
2025-03-19 16:42:19,620:INFO:Set up data.
2025-03-19 16:42:19,624:INFO:Set up index.
2025-03-19 16:42:19,624:INFO:Assigning column types.
2025-03-19 16:42:19,625:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-19 16:42:19,625:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,627:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,629:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,674:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:19,675:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:19,685:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,687:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,689:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,714:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,733:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:19,735:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:19,735:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-19 16:42:19,737:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,784:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:19,785:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:19,787:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,789:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,833:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:19,834:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:19,834:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-19 16:42:19,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,863:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,883:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:19,884:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:19,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,932:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:19,934:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:19,934:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-19 16:42:19,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:19,982:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:19,983:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:20,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-19 16:42:20,031:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:20,032:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,032:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-19 16:42:20,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:20,080:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:20,081:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,109:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-19 16:42:20,128:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:20,130:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,130:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-19 16:42:20,177:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:20,178:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,226:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:20,227:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,229:INFO:Preparing preprocessing pipeline...
2025-03-19 16:42:20,229:INFO:Set up simple imputation.
2025-03-19 16:42:20,230:INFO:Set up encoding of categorical features.
2025-03-19 16:42:20,230:INFO:Set up feature normalization.
2025-03-19 16:42:20,230:INFO:Set up column name cleaning.
2025-03-19 16:42:20,273:INFO:Finished creating preprocessing pipeline.
2025-03-19 16:42:20,278:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 16:42:20,278:INFO:Creating final display dataframe.
2025-03-19 16:42:20,398:INFO:Setup _display_container:                     Description            Value
0                    Session id              456
1                        Target          MSW_log
2                   Target type       Regression
3           Original data shape       (1755, 19)
4        Transformed data shape       (1755, 28)
5   Transformed train set shape       (1483, 28)
6    Transformed test set shape        (272, 28)
7              Numeric features               16
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15                    Normalize             True
16             Normalize method           minmax
17               Fold Generator  TimeSeriesSplit
18                  Fold Number                5
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name   msw_prediction
23                          USI             08c5
2025-03-19 16:42:20,452:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:20,453:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,502:INFO:Soft dependency imported: xgboost: 2.1.3
2025-03-19 16:42:20,503:INFO:Soft dependency imported: catboost: 1.2.7
2025-03-19 16:42:20,503:INFO:Logging experiment in loggers
2025-03-19 16:42:20,637:INFO:SubProcess save_model() called ==================================
2025-03-19 16:42:20,645:INFO:Initializing save_model()
2025-03-19 16:42:20,645:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\ADMINI~1\AppData\Local\Temp\tmp73jwdsk4\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-19 16:42:20,645:INFO:Adding model into prep_pipe
2025-03-19 16:42:20,645:WARNING:Only Model saved as it was a pipeline.
2025-03-19 16:42:20,648:INFO:C:\Users\ADMINI~1\AppData\Local\Temp\tmp73jwdsk4\Transformation Pipeline.pkl saved in current working directory
2025-03-19 16:42:20,652:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Population', 'GDP PPP 2017',
                                             'GDP PPP/capita 2017',
                                             'year_trend', 'year_trend_squared',
                                             'trend_region_Middle East & North '
                                             'Africa',
                                             'trend_region_East Asia & Pacific',
                                             'trend_region_Europe & Central '
                                             'Asia',
                                             'trend_region_South Asia',...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Region', 'Income Group'],
                                    transformer=OneHotEncoder(cols=['Region',
                                                                    'Income '
                                                                    'Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-19 16:42:20,652:INFO:save_model() successfully completed......................................
2025-03-19 16:42:20,711:INFO:SubProcess save_model() end ==================================
2025-03-19 16:42:20,715:INFO:setup() successfully completed in 2.19s...............
2025-03-19 16:42:20,716:INFO:Initializing compare_models()
2025-03-19 16:42:20,716:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002570C2185B0>, include=None, fold=None, round=4, cross_validation=True, sort=mape, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002570C2185B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'mape', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-19 16:42:20,716:INFO:Checking exceptions
2025-03-19 16:42:20,717:INFO:Preparing display monitor
2025-03-19 16:42:20,732:INFO:Initializing Linear Regression
2025-03-19 16:42:20,732:INFO:Total runtime is 0.0 minutes
2025-03-19 16:42:20,734:INFO:SubProcess create_model() called ==================================
2025-03-19 16:42:20,735:INFO:Initializing create_model()
2025-03-19 16:42:20,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002570C2185B0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002570F0A1520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-19 16:42:20,735:INFO:Checking exceptions
2025-03-19 16:42:20,735:INFO:Importing libraries
2025-03-19 16:42:20,735:INFO:Copying training dataset
2025-03-19 16:42:20,737:INFO:Defining folds
2025-03-19 16:42:20,737:INFO:Declaring metric variables
2025-03-19 16:42:20,739:INFO:Importing untrained model
2025-03-19 16:42:20,741:INFO:Linear Regression Imported successfully
2025-03-19 16:42:20,746:INFO:Starting cross validation
2025-03-19 16:42:20,748:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
